<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Stay hungry, Stay foolish"><title>DeepSort：多目标跟踪算法 Sort 的进化版 | 四一的随写</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">DeepSort：多目标跟踪算法 Sort 的进化版</h1><a id="logo" href="/.">四一的随写</a><p class="description">Stay hungry, Stay foolish</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">DeepSort：多目标跟踪算法 Sort 的进化版</h1><div class="post-meta">2021-08-27<span> | </span><span class="category"><a href="/categories/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/">目标跟踪</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2.9k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 11</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>在<a target="_blank" rel="noopener" href="https://yunyang1994.gitee.io/2021/08/14/%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AASORT%E7%AE%97%E6%B3%95-Simple-Online-and-Realtime-Tracking/">之前的 Sort 算法</a>中讲到：<strong>尽管 Sort 具有速度快和计算量较小的优点，但它在关联匹配时没有用到物体的表观特征，导致物体被遮挡时容易出现 id-switch 的情况。</strong>针对这个算法的痛点，原 author 团队又发明了 Sort 的进化版 —— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.07402">DeepSort: Simple Online and Realtime Tracking with a Deep Associate Metric</a></p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827115042.png">
</p>
<span id="more"></span>

<h2 id="1-卡尔曼滤波追踪器"><a href="#1-卡尔曼滤波追踪器" class="headerlink" title="1. 卡尔曼滤波追踪器"></a>1. 卡尔曼滤波追踪器</h2><p><strong>DeepSort 的 KalmanFilter 假定跟踪场景是定义在 8 维状态空间（u, v, γ, h, ẋ, ẏ, γ̇, ḣ）中， 边框中心（u, v），宽高比 γ，高度 h 和和它们各自在图像坐标系中的速度。</strong>这里依旧使用的是匀速运动模型，并把（u，v，γ，h）作为对象状态的直接观测量（direct observations of the object state.）。在目标跟踪中，需要估计目标的以下两个状态：</p>
<ul>
<li><strong>均值(Mean)</strong>：包含目标的中心位置和速度信息，由 8 维向量（u, v, γ, h, ẋ, ẏ, γ̇, ḣ）表示，其中每个速度值初始化为 0。均值 Mean 可以通过观测矩阵 H 投影到测量空间输出（u，v，γ，h）。</li>
<li><strong>协方差(Covariance)</strong>：表示估计状态的不确定性，由 8x8 的对角矩阵表示，矩阵中数字越大则表明不确定性越大。</li>
</ul>
<p>关于以下公式的变量和符号说明，请参考<a target="_blank" rel="noopener" href="https://yunyang1994.gitee.io/2021/07/10/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%AE%97%E6%B3%95-%E6%B0%B8%E8%BF%9C%E6%BB%B4%E7%A5%9E/">卡尔曼滤波算法，永远滴神！</a></p>
<h3 id="1-1-predict-阶段"><a href="#1-1-predict-阶段" class="headerlink" title="1.1 predict 阶段"></a>1.1 predict 阶段</h3><ul>
<li>step1：首先利用上一时刻 k-1 的后验估计值通过状态转移矩阵 F 变换得到当前时刻 k 的先验估计状态</li>
</ul>
<p align="center">
    <img width="14%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827150310.png">
</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827153028.png">
</p>

<ul>
<li>step2：然后使用上一时刻 k-1 的后验估计协方差来计算当前时刻 k 的先验估计协方差</li>
</ul>
<p align="center">
    <img width="23%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827153635.png">
</p>

<p>整个过程如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, mean, covariance</span>):</span></span><br><span class="line">    <span class="comment"># mean, covariance 相当于上一时刻的后验估计均值和协方差</span></span><br><span class="line">    </span><br><span class="line">    std_pos = [</span><br><span class="line">        self._std_weight_position * mean[<span class="number">3</span>],</span><br><span class="line">        self._std_weight_position * mean[<span class="number">3</span>],</span><br><span class="line">        <span class="number">1e-2</span>,</span><br><span class="line">        self._std_weight_position * mean[<span class="number">3</span>]]</span><br><span class="line">    std_vel = [</span><br><span class="line">        self._std_weight_velocity * mean[<span class="number">3</span>],</span><br><span class="line">        self._std_weight_velocity * mean[<span class="number">3</span>],</span><br><span class="line">        <span class="number">1e-5</span>,</span><br><span class="line">        self._std_weight_velocity * mean[<span class="number">3</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化噪声矩阵 Q</span></span><br><span class="line">    motion_cov = np.diag(np.square(np.r_[std_pos, std_vel]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># x&#x27; = Fx</span></span><br><span class="line">    mean = np.dot(self._motion_mat, mean)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># P&#x27; = FPF^T + Q</span></span><br><span class="line">    covariance = np.linalg.multi_dot((</span><br><span class="line">        self._motion_mat, covariance, self._motion_mat.T)) + motion_cov</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 返回当前时刻的先验估计均值 x 和协方差 P</span></span><br><span class="line">    <span class="keyword">return</span> mean, covariance</span><br></pre></td></tr></table></figure>

<p>predict 函数的输入为卡尔曼滤波器在上一时刻的后验估计均值 <code>x_&#123;k-1&#125;</code> 和协方差 <code>P_&#123;k-1&#125;</code>，输出为当前时刻的先验估计均值<code>x_&#123;k&#125;</code> 和协方差 <code>P_&#123;k&#125;</code>。</p>
<h3 id="1-2-update-阶段"><a href="#1-2-update-阶段" class="headerlink" title="1.2 update 阶段"></a>1.2 update 阶段</h3><ul>
<li>step1：首先利用先验估计协方差矩阵 P 和观测矩阵 H 以及测量状态协方差矩阵 R 计算出卡尔曼增益矩阵 K</li>
</ul>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827170204.png">
</p>

<ul>
<li>step2：然后将卡尔曼滤波器的先验估计值 x 通过观测矩阵 H 投影到测量空间，并计算出与测量值 z 的残差 y</li>
</ul>
<p align="center">
    <img width="16%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827162140.png">
</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827173356.png">
</p>

<ul>
<li>step3：将卡尔曼滤波器的预测值和测量值按照卡尔曼增益的比例相融合，得到后验估计值 x</li>
</ul>
<p align="center">
    <img width="16%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827171038.png">
</p>

<ul>
<li>step4：计算出卡尔曼滤波器的后验估计协方差</li>
</ul>
<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827171350.png">
</p>

<p>整个过程如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self, mean, covariance, measurement</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将先验估计的均值和协方差映射到检测空间，得到 Hx&#x27; 和 HP&#x27;</span></span><br><span class="line">    projected_mean, projected_cov = self.project(mean, covariance)</span><br><span class="line"></span><br><span class="line">    chol_factor, lower = scipy.linalg.cho_factor(</span><br><span class="line">        projected_cov, lower=<span class="literal">True</span>, check_finite=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算卡尔曼增益 K</span></span><br><span class="line">    kalman_gain = scipy.linalg.cho_solve(</span><br><span class="line">        (chol_factor, lower), np.dot(covariance, self._update_mat.T).T,</span><br><span class="line">        check_finite=<span class="literal">False</span>).T</span><br><span class="line"></span><br><span class="line">    <span class="comment"># y = z - Hx&#x27;</span></span><br><span class="line">    innovation = measurement - projected_mean</span><br><span class="line"></span><br><span class="line">    <span class="comment"># x = x&#x27; + Ky</span></span><br><span class="line">    new_mean = mean + np.dot(innovation, kalman_gain.T)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># P = (I - KH)P&#x27;</span></span><br><span class="line">    new_covariance = covariance - np.linalg.multi_dot((</span><br><span class="line">        kalman_gain, projected_cov, kalman_gain.T))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回当前时刻的后验估计均值 x 和协方差 P</span></span><br><span class="line">    <span class="keyword">return</span> new_mean, new_covariance</span><br></pre></td></tr></table></figure>

<table><center><td bgcolor=Plum><font color=black>
最后总结一下：predict 阶段和 update 阶段都是为了计算出卡尔曼滤波的<strong><font color=blue>估计均值 x </font></strong>和<strong><font color= blue>协方差 P</font></strong>，不同的是前者是基于上一历史状态做出的<strong><font color=green>先验估计</font></strong>，而后者则是融合了测量值信息并作出校正的<font color=green><strong>后验估计</strong></font>。
</font></strong></td></center></table>

<h3 id="1-3-跟踪器的状态"><a href="#1-3-跟踪器的状态" class="headerlink" title="1.3 跟踪器的状态"></a>1.3 跟踪器的状态</h3><p>DeepSort 的跟踪器一共有 3 种状态：当 tracker 初始化时，分配为待定状态（tentative）；如果连续 n_init 帧匹配上，则转化为确定状态（confirmed），否则为删除状态（deleted）；如果 tracker 在确定状态下连续 max_age 帧没匹配上，那么就会变成删除状态被回收。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210828221215.png">
</p>

<h2 id="2-关联度量"><a href="#2-关联度量" class="headerlink" title="2. 关联度量"></a>2. 关联度量</h2><p>解决卡尔曼滤波器的预测状态和测量状态之间的关联可以通过构建匈牙利匹配来实现，在这个过程中需要结合两个合适的指标来整合物体的运动信息和外观特征。</p>
<h3 id="2-1-马氏距离"><a href="#2-1-马氏距离" class="headerlink" title="2.1 马氏距离"></a>2.1 马氏距离</h3><p>为了整合物体的运动信息，使用了预测状态和测量状态之间的（平方）<a target="_blank" rel="noopener" href="https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%93%88%E6%8B%89%E8%AF%BA%E6%AF%94%E6%96%AF%E8%B7%9D%E7%A6%BB">马氏距离</a>：</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210828135516.png">
</p>

<p>在上式中，d 和 y 分别代表测量分布和预测分布，S 为两个分布之间的协方差矩阵。由于测量分布的维度（4 维）和预测分布的维度（8 维）不一致，因此需要先将预测分布通过观测矩阵 H 投影到测量空间中（这一步其实就是从 8 个估计状态变量中取出前 4 个测量状态变量，详见 <a target="_blank" rel="noopener" href="https://github.com/nwojke/deep_sort/blob/280b8bdb255f223813ff4a8679f3e1321b08cdfc/deep_sort/kalman_filter.py#L125">project 函数</a>）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Project state distribution to measurement space.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">project</span>(<span class="params">self, mean, covariance</span>):</span></span><br><span class="line">    std = [</span><br><span class="line">        self._std_weight_position * mean[<span class="number">3</span>],</span><br><span class="line">        self._std_weight_position * mean[<span class="number">3</span>],</span><br><span class="line">        <span class="number">1e-1</span>,</span><br><span class="line">        self._std_weight_position * mean[<span class="number">3</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化测量状态的协方差矩阵 R</span></span><br><span class="line">    innovation_cov = np.diag(np.square(std)) <span class="comment"># 使用的是对角矩阵，不同维度之间没有关联</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将均值向量映射到检测空间 得到 Hx</span></span><br><span class="line">    mean = np.dot(self._update_mat, mean)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将协方差矩阵映射到检测空间，得到 HP&#x27;H^T</span></span><br><span class="line">    covariance = np.linalg.multi_dot((</span><br><span class="line">        self._update_mat, covariance, self._update_mat.T))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mean, covariance + innovation_cov <span class="comment"># 加上测量噪声</span></span><br></pre></td></tr></table></figure>

<p>协方差矩阵 S 是一个实对称正定矩阵，可以使用 Cholesky 分解来求解马氏距离，这部分内容就不展开讨论。在 DeepSort 代码中，计算马氏距离的整个过程如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Compute gating distance between state distribution and measurements.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gating_distance</span>(<span class="params">self, mean, covariance, measurements,</span></span></span><br><span class="line"><span class="params"><span class="function">                    only_position=<span class="literal">False</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 首先需要先将预测状态分布的均值和协方差投影到测量空间</span></span><br><span class="line">    mean, covariance = self.project(mean, covariance)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 假如仅考虑中心位置</span></span><br><span class="line">    <span class="keyword">if</span> only_position:</span><br><span class="line">        mean, covariance = mean[:<span class="number">2</span>], covariance[:<span class="number">2</span>, :<span class="number">2</span>]</span><br><span class="line">        measurements = measurements[:, :<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对协方差矩阵进行 cholesky 分解</span></span><br><span class="line">    cholesky_factor = np.linalg.cholesky(covariance)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算两个分布之间对差值</span></span><br><span class="line">    d = measurements - mean</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过三角求解计算出马氏距离</span></span><br><span class="line">    z = scipy.linalg.solve_triangular(</span><br><span class="line">        cholesky_factor, d.T, lower=<span class="literal">True</span>, check_finite=<span class="literal">False</span>,</span><br><span class="line">        overwrite_b=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回平方马氏距离</span></span><br><span class="line">    squared_maha = np.<span class="built_in">sum</span>(z * z, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> squared_maha</span><br></pre></td></tr></table></figure>

<p>马氏距离通过计算检测框距离预测框有多远的偏差来估计跟踪器状态的不确定性，<strong>此外还可以通过在 95% 的置信区间上从逆 χ2 分布中计算出的马氏距离来排除不可能的关联。</strong>在 DeepSort 的 4 维测量空间中，相应的马氏距离阈值为 9.4877，如果两个匹配框之间的马氏距离大于这个值，那么就认为两个框是不可能关联了。</p>
<h3 id="2-2-外观特征"><a href="#2-2-外观特征" class="headerlink" title="2.2 外观特征"></a>2.2 外观特征</h3><p>当物体运动状态的不确定性比较低时，使用马氏距离确实是一个不错的选择。由于卡尔曼滤波器使用的是匀速运动模型，它只能对物体的运动位置提供一个相对粗略的线性估计。<strong>当物体突然加速或减速时，跟踪器的预测框和检测框之间的距离就会变得比较远，这时仅使用马氏距离就会变得非常不准确</strong>。</p>
<p>因此 DeepSort 还对每个目标<strong>设计了一个深度外观特征描述符，它其实是一个在行人重识别数据集上离线训练的 ReID 网络提取到的 128 维单位特征向量（模长为 1 ）</strong>。对于每个追踪器 tracker，保留它最后 100 个与检测框关联成功的外观特征描述符集合 R 并计算出它们和检测框的最小余弦距离：</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210828151324.png">
</p>

<p>同样，可以设置一个合适的阈值来排除那些外观特征相差特别大的匹配。</p>
<h3 id="2-3-互相补充"><a href="#2-3-互相补充" class="headerlink" title="2.3 互相补充"></a>2.3 互相补充</h3><p>上述两个指标可以互相补充从而解决关联匹配的不同问题：<strong>一方面，马氏距离基于运动可以提供有关可能的物体位置的信息，这对于短期预测特别有用；另一方面，当运动的判别力较弱时，余弦距离会考虑外观信息，这对于长时间遮挡后恢复身份特别有用</strong>。</p>
<p>为了建立关联问题，我们使用加权总和将两个指标结合起来：</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210828155133.png">
</p>

<p>如果它同时在两个指标的门控范围之内，我们称其为可接受的关联。可以通过超参数 λ 来控制每个指标对合并成本的影响。在论文的实验过程中，发现当摄像机运动较大时，将 λ=0 是合理的选择（此时仅用到了外观信息）。</p>
<h2 id="3-1-匹配问题"><a href="#3-1-匹配问题" class="headerlink" title="3.1 匹配问题"></a>3.1 匹配问题</h2><h3 id="3-1-级联匹配"><a href="#3-1-级联匹配" class="headerlink" title="3.1 级联匹配"></a>3.1 级联匹配</h3><p>为了解决全局分配问题中检测框与跟踪器的关联，我们引入了一个级联来解决一系列的子问题。不妨先考虑这种场景：<strong>当物体被长时间遮挡时，后续的卡尔曼滤波预测结果会增大与物体位置关联的不确定性。因此概率分布会在状态空间中弥散，观察似然性就会变得比较平坦。</strong>关联度量应该增加检测框到预测框之间的距离来考虑这种概率分布的弥散，故而引入了一个级联匹配来优先考虑年龄较小的跟踪器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matching_cascade</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        distance_metric, max_distance, cascade_depth, tracks, detections,</span></span></span><br><span class="line"><span class="params"><span class="function">        track_indices=<span class="literal">None</span>, detection_indices=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> track_indices <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        track_indices = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(tracks)))</span><br><span class="line">    <span class="keyword">if</span> detection_indices <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        detection_indices = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(detections)))</span><br><span class="line"></span><br><span class="line">    unmatched_detections = detection_indices</span><br><span class="line">    matches = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历不同年龄</span></span><br><span class="line">    <span class="keyword">for</span> level <span class="keyword">in</span> <span class="built_in">range</span>(cascade_depth):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(unmatched_detections) == <span class="number">0</span>:  <span class="comment"># No detections left</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 挑选出对应年龄的跟踪器</span></span><br><span class="line">        track_indices_l = [</span><br><span class="line">            k <span class="keyword">for</span> k <span class="keyword">in</span> track_indices</span><br><span class="line">            <span class="keyword">if</span> tracks[k].time_since_update == <span class="number">1</span> + level</span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(track_indices_l) == <span class="number">0</span>:  <span class="comment"># Nothing to match at this level</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将跟踪器和尚未匹配的检测框进行匹配</span></span><br><span class="line">        matches_l, _, unmatched_detections = \</span><br><span class="line">            min_cost_matching(</span><br><span class="line">                distance_metric, max_distance, tracks, detections,</span><br><span class="line">                track_indices_l, unmatched_detections)</span><br><span class="line">        matches += matches_l</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 挑选出未匹配的跟踪器</span></span><br><span class="line">    unmatched_tracks = <span class="built_in">list</span>(<span class="built_in">set</span>(track_indices) - <span class="built_in">set</span>(k <span class="keyword">for</span> k, _ <span class="keyword">in</span> matches))</span><br><span class="line">    <span class="keyword">return</span> matches, unmatched_tracks, unmatched_detections</span><br></pre></td></tr></table></figure>

<p>在级联匹配的花费矩阵里，元素值为马氏距离和余弦距离的加权和。该匹配的精髓在于：<strong>挑选出所有 confirmed tracks，优先让那些年龄较小的 tracks 和未匹配的检测框相匹配，然后才轮得上那些年龄较大的 tracks 。</strong>这就使得在相同的外观特征和马氏距离的情况下，年龄较小的跟踪器更容易匹配上。<strong>至于年龄 age 的定义，跟踪器每次 predict 时则 age + 1。</strong> </p>
<h3 id="3-2-IOU-匹配"><a href="#3-2-IOU-匹配" class="headerlink" title="3.2 IOU 匹配"></a>3.2 IOU 匹配</h3><p>这个阶段是发生在级联匹配之后，匹配的跟踪器对象为那些 unconfirmed tracks 以及上一轮级联匹配失败中 age 为 1 的 tracks. 这有助于解决因上一帧部分遮挡而引起的突然出现的外观变化，从而减少被遗漏的概率。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从所有的跟踪器里挑选出 unconfirmed tracks</span></span><br><span class="line">unconfirmed_tracks = [</span><br><span class="line">    i <span class="keyword">for</span> i, t <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.tracks) <span class="keyword">if</span> <span class="keyword">not</span> t.is_confirmed()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从上一轮级联匹配失败的跟踪器中挑选出连续 1 帧没有匹配上（相当于age=1）</span></span><br><span class="line"><span class="comment"># 的跟踪器，并和 unconfirmed_tracks 相加</span></span><br><span class="line">iou_track_candidates = unconfirmed_tracks + [</span><br><span class="line">    k <span class="keyword">for</span> k <span class="keyword">in</span> unmatched_tracks_a <span class="keyword">if</span></span><br><span class="line">    self.tracks[k].time_since_update == <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将它们与剩下没匹配上的 detections 进行 IOU 匹配</span></span><br><span class="line">matches_b, unmatched_tracks_b, unmatched_detections = \</span><br><span class="line">    linear_assignment.min_cost_matching(</span><br><span class="line">        iou_matching.iou_cost, self.max_iou_distance, self.tracks,</span><br><span class="line">        detections, iou_track_candidates, unmatched_detections)</span><br></pre></td></tr></table></figure>

<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.07402">[1] Simple Online and Realtime Tracking with a Deep Association Metric</a></li>
<li><a target="_blank" rel="noopener" href="https://github.com/nwojke/deep_sort">[2] https://github.com/nwojke/deep_sort</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1602.00763">[3] Simple Online and Realtime Tracking</a></li>
</ul>
</div><script type="text/javascript" src="/js/share.js?v=1.0.0" async></script><a class="article-share-link" data-url="https://yunyang1994.github.io/2021/08/27/DeepSort-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E7%AE%97%E6%B3%95-SORT-%E7%9A%84%E8%BF%9B%E9%98%B6%E7%89%88/" data-id="ckw5vsraq00041vra5gzo0fq3" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAT4AAAE+CAAAAAAxUyPsAAAFPUlEQVR42u3aW47bSBAEwLn/pb0H8ErKzKLWCzj4NaDFR0cbYHVW//zEx68Xx6tftnd+f21y/ve3+vX2ePWbn28c+PDhw4cPX0CTvMqr++SUl+Hl90+moaXHhw8fPnz4LnxPPTi5Ni9Q8pIiL6feY9UlFD58+PDhw/ef8CUFx1Mr7vzaZFJfvSc+fPjw4cP3f+Zry4LL/bdFfh46/LG6Dx8+fPjw/cV8bSFyaVFvAX1eZGylzNd7Hfjw4cOHD19ZKPw9fz984MOHDx8+fFN5cSlK7sXENqn3MuXlKPDhw4cPH75lFPUG7vY7njfaL2H95SlbYx4fPnz48OG78BWf6qn9vLWxv7eFLi+APpRE+PDhw4cPX8zXLubbpvjWRN8W+Tl63vj/MDp8+PDhw4ev5PsGVhuX3ycjR2nLoCj+wIcPHz58+GK+PCK/B/Hvf9M2zvN3SJ44blzDhw8fPnz4Jr62BLkXE/dBtlO4TXMRFuDDhw8fPnwxXzKwJBzfIu+tiZ4UFm1JVLfk8eHDhw8fvn0310/+ad+2drUlyL2culQX7X8afPjw4cOHL+FrF/+XV28hLs2DpNk/lia/13348OHDhw9fmZDn5UiOkiy/20lqB5wTn0J/fPjw4cOHL+Zr44BtM9kWu/+ajqdihWQU+PDhw4cP3zf47jF9jrKF9XnocJ9yfPjw4cOH785Xf7CnhnpbEuVhfT6pG+LL5+LDhw8fPnwlX74xK4/CLxFAfudx/900nR9KJXz48OHDhy/ma8m2l8gD+rYxv01qPpYorMeHDx8+fPgmvvurP7V1bAvr3y/y7/RFWI8PHz58+PC9fZ/2035Z6m/R/GWpn2+PG5+CDx8+fPjwTXz5I5PS5CmIvNV9jw/ysuan3Q2HDx8+fPjwTZu68lJmG14b5SeRR7IVIBn7h10G+PDhw4cPX7lOTyKAS8HR8rWFS850ifLx4cOHDx++C98lOm9x72F9vuD/XrSBDx8+fPjwnbPxelGdb94qtnkF6O2ZNoLPt99Fc4sPHz58+PAFC+b8FdvFfDsBz24my++cNxjw4cOHDx++C1/7RW7P55RPTcnWDs9LOnz48OHDh6/lu4Tv20axrby4tMPb5v0WTODDhw8fPnz5uPJPex5/b3fOy5G8uGmDhrpwwYcPHz58+KY171NxwFOFSB46bPHBVhJ9KHfw4cOHDx++t1cl4fizwXc7nzlEXmRsGwLw4cOHDx++O1/bIG+3qeVhfVv6tBD53doz+PDhw4cPX34m/2nbbG6Dg7bJfdm4lk/eh6fgw4cPHz58E9+HWqZcim8t9vZM0bouY4uirY4PHz58+PAd+PJF+B0ib3g/1Q7fiIvCBR8+fPjw4Yv5igviwbfbzjaCdvq3u0VhPT58+PDhwxdXEZeleD7g94H7tpjf/jXhyws4fPjw4cOHr+XLl9PPFjTbmbw1vrX/8zILHz58+PDha/m2EDz/O6FvmwGXtkEeHET/FfDhw4cPH76Jb3vwPYK/F0OXUGAr1/6l14EPHz58+PAd+JKFdJtJ5K+YoyRXbaFAXu7gw4cPHz58LV9+5Av4y523NnYb/Sfhxb3cwYcPHz58+F498dliZQvZn4rp22bAA4ULPnz48OHDN/HlEcAWFhTt5xJrax5s5Rc+fPjw4cP3p/jyYTwVqV9KjbZhUIwRHz58+PDh+zLfFqBvZUEeSbQL/vu2AHz48OHDh+/Cl7/cFpRvA25Ln7Ypno/igTY5Pnz48OHDdwmpgy/4Fson3O0UtndrW/v48OHDhw9f8Fb/ALBM7v6KZRGwAAAAAElFTkSuQmCC">分享</a><div class="tags"><a href="/tags/DeepSort/"><i class="fa fa-tag"></i>DeepSort</a></div><div class="post-nav"><a class="pre" href="/2021/09/01/CornerNet-Detecting-Objects-as-Paired-Keypoints/">CornerNet：Detecting Objects as Paired Keypoints</a><a class="next" href="/2021/08/21/%E4%B8%89%E7%BB%B4%E4%BA%BA%E4%BD%93%E6%A8%A1%E5%9E%8B-SMPL-A-Skinned-Multi-Person-Linear-Model/">三维人体动捕模型 SMPL：A Skinned Multi Person Linear Model</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/">图像分割</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/">姿态估计</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/">杂七杂八</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/">目标跟踪</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/">立体视觉</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/anchor-free/" style="font-size: 15px;">anchor free</a> <a href="/tags/DeepSort/" style="font-size: 15px;">DeepSort</a> <a href="/tags/%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">角点检测</a> <a href="/tags/Faster-rcnn/" style="font-size: 15px;">Faster-rcnn</a> <a href="/tags/%E5%A4%9A%E5%8D%A1GPU%E8%AE%AD%E7%BB%83/" style="font-size: 15px;">多卡GPU训练</a> <a href="/tags/%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/" style="font-size: 15px;">移动端部署</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3/" style="font-size: 15px;">人脸矫正</a> <a href="/tags/%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2/" style="font-size: 15px;">仿射变换</a> <a href="/tags/%E7%9B%B8%E6%9C%BA%E4%BD%8D%E5%A7%BF/" style="font-size: 15px;">相机位姿</a> <a href="/tags/%E8%A7%86%E8%A7%89-Slam/" style="font-size: 15px;">视觉 Slam</a> <a href="/tags/mnist-%E5%88%86%E7%B1%BB/" style="font-size: 15px;">mnist 分类</a> <a href="/tags/rotated-object-detection/" style="font-size: 15px;">rotated object detection</a> <a href="/tags/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">全卷积网络</a> <a href="/tags/Skip-Connection/" style="font-size: 15px;">Skip Connection</a> <a href="/tags/Unet-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/" style="font-size: 15px;">Unet 网络结构</a> <a href="/tags/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/" style="font-size: 15px;">三维重建</a> <a href="/tags/%E5%8F%AF%E5%8F%98%E5%BD%A2%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">可变形卷积网络</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">深度估计</a> <a href="/tags/sort/" style="font-size: 15px;">sort</a> <a href="/tags/%E8%A7%86%E5%B7%AE%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">视差估计</a> <a href="/tags/%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D/" style="font-size: 15px;">立体匹配</a> <a href="/tags/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB/" style="font-size: 15px;">汉明距离</a> <a href="/tags/Batch-Normalization/" style="font-size: 15px;">Batch Normalization</a> <a href="/tags/TensorRT-%E9%83%A8%E7%BD%B2/" style="font-size: 15px;">TensorRT 部署</a> <a href="/tags/INT8-%E5%8A%A0%E9%80%9F%E5%8E%9F%E7%90%86/" style="font-size: 15px;">INT8 加速原理</a> <a href="/tags/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/" style="font-size: 15px;">立体视觉</a> <a href="/tags/%E7%9B%B8%E6%9C%BA%E5%8F%82%E6%95%B0/" style="font-size: 15px;">相机参数</a> <a href="/tags/%E7%B2%BE%E7%A1%AE%E7%8E%87%E3%80%81%E5%8F%AC%E5%9B%9E%E7%8E%87%E5%92%8CROC%E6%9B%B2%E7%BA%BF/" style="font-size: 15px;">精确率、召回率和ROC曲线</a> <a href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/" style="font-size: 15px;">梯度下降</a> <a href="/tags/hourglass-%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">hourglass 网络</a> <a href="/tags/C-%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">C++ 编程学习</a> <a href="/tags/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2/" style="font-size: 15px;">卡尔曼滤波</a> <a href="/tags/%E6%9C%AC%E8%B4%A8%E7%9F%A9%E9%98%B5/" style="font-size: 15px;">本质矩阵</a> <a href="/tags/YOLOv3/" style="font-size: 15px;">YOLOv3</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/09/18/%E8%AE%B2%E4%B8%80%E8%AE%B2%E7%9B%AE%E5%89%8D%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8B%E5%9F%BA%E4%BA%8E%E5%8D%95%E7%9B%AE%E7%9A%84%E4%B8%89%E7%BB%B4%E4%BA%BA%E4%BD%93%E9%87%8D%E5%BB%BA%E6%8A%80%E6%9C%AF/">讲一讲目前深度学习下基于单目的三维人体重建技术</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/09/FairMOT-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E9%87%8C%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%86%8D%E8%AF%86%E5%88%AB%E7%9A%84%E5%85%AC%E5%B9%B3%E6%80%A7/">FairMOT：讨论多目标跟踪里检测与再识别的公平性</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/08/%E6%BB%9A%E8%9B%8B%E5%90%A7-Anchor-%E5%90%9B-%E6%97%B7%E8%A7%86%E6%96%B0%E7%A7%91%E6%8A%80-YOLOX/">滚蛋吧，Anchor 君！旷视新科技，YOLOX</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/07/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F-Distilling-the-Knowledge-in-a-Neural-Network/">知识蒸馏：Distilling the Knowledge in a Neural Network</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/05/UnitBox%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84-iou-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-%E6%8A%8A%20box-%E5%BD%93%E4%BD%9C%E4%B8%80%E4%B8%AA%E6%95%B4%E4%BD%93%E5%8E%BB%E9%A2%84%E6%B5%8B/">UnitBox：一种新的 IoU 损失函数，把 box 当作一个整体去预测</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/03/%E8%A7%A3%E5%86%B3%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E4%B8%8D%E5%9D%87%E8%A1%A1%E9%97%AE%E9%A2%98%E2%80%94%E2%80%94Focal-Loss/">老生常谈 Focal Loss —— 解决正负样本不均衡问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/02/FCOS-Fully-Convolutional-One-Stage-Object-Detection/">FCOS：Fully Convolutional One-Stage Object Detection</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/01/CenterNet-Objects-as-Points/">CenterNet 和 CenterTrack：以点代物，同时进行目标检测和跟踪</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/01/CornerNet-Detecting-Objects-as-Paired-Keypoints/">CornerNet：Detecting Objects as Paired Keypoints</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/08/27/DeepSort-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E7%AE%97%E6%B3%95-SORT-%E7%9A%84%E8%BF%9B%E9%98%B6%E7%89%88/">DeepSort：多目标跟踪算法 Sort 的进化版</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://www.zhihu.com/people/yang-xiao-yun-tong-xue" title="我的知乎" target="_blank">我的知乎</a><ul></ul><a href="https://github.com/YunYang1994" title="我的 GitHub" target="_blank">我的 GitHub</a><ul></ul><a href="https://leetcode-cn.com/u/yunyang1994/" title="我的力扣" target="_blank">我的力扣</a><ul></ul><a href="https://blog.devtang.com" title="猿辅导创始人唐巧的博客" target="_blank">猿辅导创始人唐巧的博客</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">四一的随写.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=1.0.0"><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>