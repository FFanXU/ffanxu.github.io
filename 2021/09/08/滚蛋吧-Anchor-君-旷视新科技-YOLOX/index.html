<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Stay hungry, Stay foolish"><title>滚蛋吧，Anchor 君！旷视新科技，YOLOX | 四一的随写</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">滚蛋吧，Anchor 君！旷视新科技，YOLOX</h1><a id="logo" href="/.">四一的随写</a><p class="description">Stay hungry, Stay foolish</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">滚蛋吧，Anchor 君！旷视新科技，YOLOX</h1><div class="post-meta">2021-09-08<span> | </span><span class="category"><a href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 859</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 3</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>天下苦 anchor 久矣，这两年是 anchor-free 系列目标检测算法的爆发时间段。但是 YOLO 系列最新推出的 v4 和 v5 依然抱着 anchor 不放，在这种背景下旷视科技推出了基于 anchor-free 的 YOLOx 算法。今天就来盘点一下这里面一些有意思的东西。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/滚蛋吧-Anchor-君-旷视新科技-YOLOX-20210907145112.png">
</p>

<span id="more"></span>

<p>作者选用的是 YOLOv3-SPP 作为 baseline，在这个基础上使用了很多 trick 不断升级打怪将 AP 提升了<strong> 8.8个百分点</strong>。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/滚蛋吧-Anchor-君-旷视新科技-YOLOX-20210907152659.png">
</p>

<h3 id="decoupled-head"><a href="#decoupled-head" class="headerlink" title="decoupled head"></a>decoupled head</h3><p><strong>在目标检测里，回归任务和分类任务是有冲突的，</strong>所以最近几年出现的一些 anchor free 算法如 CornerNet、CenterNet 和 FCOS 等，都是将 regression 和 classification 分开进行预测。如下图所示：之前 regression 和 classification 任务都是长在一个头（head）上的，现在用了两个分支叉开了，因此称为 decoupled head。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/滚蛋吧-Anchor-君-旷视新科技-YOLOX-20210907154324.png">
</p>
<p align="center">
    <img width="65%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/滚蛋吧-Anchor-君-旷视新科技-YOLOX-20210907154908.png">
</p>
实验结果发现，解藕操作不仅提升了 YOLOX 的性能和收敛速度，还为检测下游任务的一体化带来可能：

<ul>
<li>和 yolact  相似，实现端侧的实例分割</li>
<li>YOLOX + 34 层输出，实现端侧人体的 17 个关键点检测。</li>
</ul>
<h3 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h3><p>数据增强在目标检测里一直有人在做，但是将 AP 提升了 2.4% 还是比较难得的。Mosaic 经过 yolov4 和 v5 的验证，表明对结果有显著的提升。作者在 YOLOX-L 模型上尝试了 <a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2021/papers/Ghiasi_Simple_Copy-Paste_Is_a_Strong_Data_Augmentation_Method_for_Instance_CVPR_2021_paper.pdf">copy-paste</a>，也带来了 0.8% 的提升。此外还将<strong>关闭 Aug 的时间节点设定为终止前的 10~15 个 epoch，目的是为了为了让检测器避开不准确标注框的影响，在自然图片的数据分布下完成最终的收敛。</strong></p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/滚蛋吧-Anchor-君-旷视新科技-YOLOX-20210907161944.png">
</p>
作者还提出一个观点：<strong>只有当模型容量足够大时，相对于先验知识（各种 tricks，hand-crafted rules ），更多的后验（data augmentation）知识才会产生本质影响。</strong>

<h3 id="anchor-free"><a href="#anchor-free" class="headerlink" title="anchor free"></a>anchor free</h3><p>将 YOLO 算法从 anchor-base 切换到 anchor-free 的做法非常简单，直接套用 FCOS 那套逻辑即可。但是想要提高预测精度达到 SOTA 却不简单，作者在知乎上对正负样本的匹配经验做了一些总结，大家可以移步<a target="_blank" rel="noopener" href="https://www.zhihu.com/question/473350307/answer/2021031747">知乎</a>。</p>
<h3 id="Multi-positives"><a href="#Multi-positives" class="headerlink" title="Multi positives"></a>Multi positives</h3><p>为了和 YOLOv3 正负样本匹配机制一致，作者刚开始是只选择了一个 positive sample（目标中心）。<strong>但是作者在实验过程中发现，中心附近的 positive samples 有助于缓解正负样本不均衡问题，不应该完全被忽略掉。</strong>因此在训练过程中，作者把中心 3x3 区域内的像素都当作正样本，这个其实也是 FCOS 里的 center sampling 操作。最终这个骚操作使精度提升了 2.1 个百分点，效果显著啊。</p>
<h3 id="SimOTA"><a href="#SimOTA" class="headerlink" title="SimOTA"></a>SimOTA</h3><p>OAT（Optimal Transport Assignment）是旷视发的一篇 CVPR 2021 论文，它把样本匹配建模成最优传输问题，找出前面 k 个最优的正样本。SimOTA 是在 OTA 的基础做了简化， 有兴趣可以去看看<a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2021/papers/Ge_OTA_Optimal_Transport_Assignment_for_Object_Detection_CVPR_2021_paper.pdf">原文</a>，这里就不做介绍了。</p>
<p>最后一些碎碎念：要说把这个算法取名 YOLOX，我是不服的。因为它其实和 YOLO 相关性并不大，反而和 FCOS 非常相似，所以感觉这样取名也是蹭了 YOLO 的热度吧 😂。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2107.08430">[1] YOLOX: Exceeding YOLO Series in 2021</a></li>
<li><a target="_blank" rel="noopener" href="https://www.zhihu.com/question/473350307/answer/2021031747">[2] 知乎：如何评价旷视开源的YOLOX，效果超过YOLOv5?</a></li>
</ul>
</div><script type="text/javascript" src="/js/share.js?v=1.0.0" async></script><a class="article-share-link" data-url="https://yunyang1994.github.io/2021/09/08/%E6%BB%9A%E8%9B%8B%E5%90%A7-Anchor-%E5%90%9B-%E6%97%B7%E8%A7%86%E6%96%B0%E7%A7%91%E6%8A%80-YOLOX/" data-id="ckw5vsrcb00281vrahswo5zc7" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASYAAAEmCAAAAADqr2IGAAAEk0lEQVR42u3aSW4cMRAEQP3/0zbgkw1L05lVLUhsxZwGs3CJPrAWvr3Fr19/Xn+/Tz75/9vk89ezf/Tfj8Z5vbabX5gwYcKE6VsyJVMm3yaL+2iJCfHr8XP6ZF/v/BcTJkyYMB3OtB8uP9rz7SVj5oHL60dyYYIJEyZMmH4AU7LtfHHtBtp0N0/aMWHChAkTpjY1zYOAvLI6Q2+TdkyYMGHC9FSm2XB54zApvM7Kx3el1rfVwjFhwoQJ0zdjmhVPn/H+0+83YcKECROmL2X6Vb5eJ4dt8vn6YE7GSbbdBgHvzIIJEyZMmI5latPOWbOwTV/v+uUsPioqBJgwYcKE6dsz5RCbwmhyYLetyiRQ2BSR/3mPCRMmTJiOZZodpe2y8v+214DyBuSsRYoJEyZMmJ7H1A7Rlm7bVLY9tmdBSVS2xoQJEyZMBzLNUDaNw7sO7FkBehisYMKECROmY5nyxt6sVbm5mpNvNS/droq8mDBhwoTpWKZkM/u2Zb6BWaM0+VfeOr2InjBhwoQJ01FM7aJzoLblOWupFvXsOI2/WAMmTJgwYTqEqc2PN0vf0+dpcF56ToIDTJgwYcJ0OlN7nG+u48xapJuw44YiLyZMmDBhOpypLXG2rcT2SlByeLeryq/7XKS+mDBhwoTpKKb2wk27jbzA2j6SPKFtG6sXo2HChAkTpsOZ8kst906fJ9j7B9Cm6JgwYcKE6XSmfak3+eTedHpP34ZBmDBhwoTpqUyzcuqmtJr/Jm+szoIATJgwYcL0DKY23Z0dq5uLNbMibx58tHkuJkyYMGE6l+k12ex9m9zem9bu14wJEyZMmJ7BtDnm22S4PaT3bdR2LkyYMGHC9AymPF3clF/btDMZbdYWbXeECRMmTJiewdSWd2eLm/2mTZvzBL5IrTFhwoQJ0+OY2sLrrFw7Q8kT3dn6i4AAEyZMmDAdwpSHBW0qO9tqe91nHzRcrBkTJkyYMB3L1F6UaZuXyZGfF4hniW4+zsV/MWHChAnTsUyzyzR5Gjz7pC1DJxybi0GYMGHChOlEptkFlxnH7DpOPnLOnYc471QIMGHChAnTI5iSpmObiLaHfYu1fyQXtQFMmDBhwnQgU7KBdkuzizKzVPauT4pkGBMmTJgwHc60aVjOWpJfRTNLsDFhwoQJ04lMbRqZHOFtOp2Ms0luV31dTJgwYcJ0LFPLMUtr90Xe/CG1JekoRMCECRMmTI9gyieYJZDJwb+51pMz5WEHJkyYMGF6ElM+fY41KxbPRtis/2JMTJgwYcJ0LFMywb5kvBk/L+/maXablmPChAkTpnOZZsdw0iZsifOUdd+qrNNjTJgwYcJ0LNPs7sq+CXpXazMpKG/mwoQJEyZMz2DKg4DZJZ48fc2bqbPjP1/VO99iwoQJE6bDmWZBQDLZMAaJ45dk9lnQgwkTJkyYfhpTEgrkIUWekdeHd0kZXQ/ChAkTJkw/hqkF2pR9k9/n12eTZPhtE3dgwoQJE6ZvzLQp8uZl082iZwFKS/yJ7UxMmDBhwvRFTJsya5K+tgd5nqa2heC7is6YMGHChOkQpt8ckItMXi8xOgAAAABJRU5ErkJggg==">分享</a><div class="tags"><a href="/tags/anchor-free/"><i class="fa fa-tag"></i>anchor free</a></div><div class="post-nav"><a class="pre" href="/2021/09/09/FairMOT-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E9%87%8C%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%86%8D%E8%AF%86%E5%88%AB%E7%9A%84%E5%85%AC%E5%B9%B3%E6%80%A7/">FairMOT：讨论多目标跟踪里检测与再识别的公平性</a><a class="next" href="/2021/09/07/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F-Distilling-the-Knowledge-in-a-Neural-Network/">知识蒸馏：Distilling the Knowledge in a Neural Network</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/">图像分割</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/">姿态估计</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/">杂七杂八</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/">目标跟踪</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/">立体视觉</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/anchor-free/" style="font-size: 15px;">anchor free</a> <a href="/tags/DeepSort/" style="font-size: 15px;">DeepSort</a> <a href="/tags/%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">角点检测</a> <a href="/tags/Faster-rcnn/" style="font-size: 15px;">Faster-rcnn</a> <a href="/tags/%E5%A4%9A%E5%8D%A1GPU%E8%AE%AD%E7%BB%83/" style="font-size: 15px;">多卡GPU训练</a> <a href="/tags/%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/" style="font-size: 15px;">移动端部署</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3/" style="font-size: 15px;">人脸矫正</a> <a href="/tags/%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2/" style="font-size: 15px;">仿射变换</a> <a href="/tags/%E7%9B%B8%E6%9C%BA%E4%BD%8D%E5%A7%BF/" style="font-size: 15px;">相机位姿</a> <a href="/tags/%E8%A7%86%E8%A7%89-Slam/" style="font-size: 15px;">视觉 Slam</a> <a href="/tags/mnist-%E5%88%86%E7%B1%BB/" style="font-size: 15px;">mnist 分类</a> <a href="/tags/rotated-object-detection/" style="font-size: 15px;">rotated object detection</a> <a href="/tags/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">全卷积网络</a> <a href="/tags/Skip-Connection/" style="font-size: 15px;">Skip Connection</a> <a href="/tags/Unet-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/" style="font-size: 15px;">Unet 网络结构</a> <a href="/tags/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/" style="font-size: 15px;">三维重建</a> <a href="/tags/%E5%8F%AF%E5%8F%98%E5%BD%A2%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">可变形卷积网络</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">深度估计</a> <a href="/tags/sort/" style="font-size: 15px;">sort</a> <a href="/tags/%E8%A7%86%E5%B7%AE%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">视差估计</a> <a href="/tags/%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D/" style="font-size: 15px;">立体匹配</a> <a href="/tags/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB/" style="font-size: 15px;">汉明距离</a> <a href="/tags/Batch-Normalization/" style="font-size: 15px;">Batch Normalization</a> <a href="/tags/TensorRT-%E9%83%A8%E7%BD%B2/" style="font-size: 15px;">TensorRT 部署</a> <a href="/tags/INT8-%E5%8A%A0%E9%80%9F%E5%8E%9F%E7%90%86/" style="font-size: 15px;">INT8 加速原理</a> <a href="/tags/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/" style="font-size: 15px;">立体视觉</a> <a href="/tags/%E7%9B%B8%E6%9C%BA%E5%8F%82%E6%95%B0/" style="font-size: 15px;">相机参数</a> <a href="/tags/%E7%B2%BE%E7%A1%AE%E7%8E%87%E3%80%81%E5%8F%AC%E5%9B%9E%E7%8E%87%E5%92%8CROC%E6%9B%B2%E7%BA%BF/" style="font-size: 15px;">精确率、召回率和ROC曲线</a> <a href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/" style="font-size: 15px;">梯度下降</a> <a href="/tags/hourglass-%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">hourglass 网络</a> <a href="/tags/C-%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">C++ 编程学习</a> <a href="/tags/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2/" style="font-size: 15px;">卡尔曼滤波</a> <a href="/tags/%E6%9C%AC%E8%B4%A8%E7%9F%A9%E9%98%B5/" style="font-size: 15px;">本质矩阵</a> <a href="/tags/YOLOv3/" style="font-size: 15px;">YOLOv3</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/09/18/%E8%AE%B2%E4%B8%80%E8%AE%B2%E7%9B%AE%E5%89%8D%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8B%E5%9F%BA%E4%BA%8E%E5%8D%95%E7%9B%AE%E7%9A%84%E4%B8%89%E7%BB%B4%E4%BA%BA%E4%BD%93%E9%87%8D%E5%BB%BA%E6%8A%80%E6%9C%AF/">讲一讲目前深度学习下基于单目的三维人体重建技术</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/09/FairMOT-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E9%87%8C%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%86%8D%E8%AF%86%E5%88%AB%E7%9A%84%E5%85%AC%E5%B9%B3%E6%80%A7/">FairMOT：讨论多目标跟踪里检测与再识别的公平性</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/08/%E6%BB%9A%E8%9B%8B%E5%90%A7-Anchor-%E5%90%9B-%E6%97%B7%E8%A7%86%E6%96%B0%E7%A7%91%E6%8A%80-YOLOX/">滚蛋吧，Anchor 君！旷视新科技，YOLOX</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/07/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F-Distilling-the-Knowledge-in-a-Neural-Network/">知识蒸馏：Distilling the Knowledge in a Neural Network</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/05/UnitBox%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84-iou-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-%E6%8A%8A%20box-%E5%BD%93%E4%BD%9C%E4%B8%80%E4%B8%AA%E6%95%B4%E4%BD%93%E5%8E%BB%E9%A2%84%E6%B5%8B/">UnitBox：一种新的 IoU 损失函数，把 box 当作一个整体去预测</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/03/%E8%A7%A3%E5%86%B3%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E4%B8%8D%E5%9D%87%E8%A1%A1%E9%97%AE%E9%A2%98%E2%80%94%E2%80%94Focal-Loss/">老生常谈 Focal Loss —— 解决正负样本不均衡问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/02/FCOS-Fully-Convolutional-One-Stage-Object-Detection/">FCOS：Fully Convolutional One-Stage Object Detection</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/01/CenterNet-Objects-as-Points/">CenterNet 和 CenterTrack：以点代物，同时进行目标检测和跟踪</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/01/CornerNet-Detecting-Objects-as-Paired-Keypoints/">CornerNet：Detecting Objects as Paired Keypoints</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/08/27/DeepSort-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E7%AE%97%E6%B3%95-SORT-%E7%9A%84%E8%BF%9B%E9%98%B6%E7%89%88/">DeepSort：多目标跟踪算法 Sort 的进化版</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://www.zhihu.com/people/yang-xiao-yun-tong-xue" title="我的知乎" target="_blank">我的知乎</a><ul></ul><a href="https://github.com/YunYang1994" title="我的 GitHub" target="_blank">我的 GitHub</a><ul></ul><a href="https://leetcode-cn.com/u/yunyang1994/" title="我的力扣" target="_blank">我的力扣</a><ul></ul><a href="https://blog.devtang.com" title="猿辅导创始人唐巧的博客" target="_blank">猿辅导创始人唐巧的博客</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">四一的随写.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=1.0.0"><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>