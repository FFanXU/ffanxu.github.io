<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Think different</title>
    <url>/2019/10/01/Think-different/</url>
    <content><![CDATA[<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210715125847.jpg">
</p>

<table><center><td bgcolor= LightSalmon><font color=blue>
Here’s to the crazy ones. The misfits. The rebels. The troublemakers. The round pegs in the square holes. The ones who see things differently. They’re not fond of rules. And they have no respect for the status quo. You can quote them, disagree with them, glorify or vilify them. About the only thing you can’t do is ignore them. Because they change things. They push the human race forward. And while some may see them as the crazy ones, we see genius. Because people who are crazy enough to think they can change the world are the ones who do.<br>
</font></strong></td></center></table>
<span id="more"></span>

<h4 id="给努力奋斗的自己："><a href="#给努力奋斗的自己：" class="headerlink" title="给努力奋斗的自己："></a>给努力奋斗的自己：</h4><p align="center">
<iframe src="//player.bilibili.com/player.html?aid=18778202&bvid=BV1qW411e7hV&cid=30626795&page=1&high_quality=1"  width="400" height="300"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</p>

]]></content>
  </entry>
  <entry>
    <title>讲一讲目前深度学习下基于单目的三维人体重建技术</title>
    <url>/2021/09/18/%E8%AE%B2%E4%B8%80%E8%AE%B2%E7%9B%AE%E5%89%8D%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8B%E5%9F%BA%E4%BA%8E%E5%8D%95%E7%9B%AE%E7%9A%84%E4%B8%89%E7%BB%B4%E4%BA%BA%E4%BD%93%E9%87%8D%E5%BB%BA%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<p>近年来，基于深度学习的单目三维人体重建技术已经取得了巨大的进展。特别是基于马普所的 SMPL 参数化人体模型这块，今天就来简单聊聊这一系列的相关工作。</p>
<p align="center">
    <img width="65%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/讲一讲目前深度学习下基于单目的三维人体重建技术-20210914160852.png">
</p>

<span id="more"></span>

<p>如上图所示，给定一张 RGB 图片，我们希望恢复出图中人体的姿态和形状等信息。从前面讲的 <a href="https://yunyang1994.gitee.io/2021/08/21/%E4%B8%89%E7%BB%B4%E4%BA%BA%E4%BD%93%E6%A8%A1%E5%9E%8B-SMPL-A-Skinned-Multi-Person-Linear-Model/">SMPL 参数化人体模型</a>可知，我们只需要估计出数字人体模型的相关参数即可。例如在 HMR 算法中，则需要预测出 23x3 + 10 + 2 + 1 + 3 = 85 个参数：</p>
<ul>
<li>23 个关节点的 pose 参数，每个参数由轴角表示（axis-angle representation）</li>
<li>10 个人体形状 shape 参数</li>
<li>相机外参数 t (图像平面上的 2D 平移）和缩放尺度 s 以及根结点的旋转轴角 R</li>
</ul>
<p>对这些参数直接回归是比较困难的，所以网络预测的是相对于初始 SMPL 参数的偏移量。一般是通过两层全连接网络作为回归器 Regressor 输出偏移量，然后再与预测的 SMPL 参数拼接相加然后继续迭代 3 次得到。</p>
<p align="center">
    <img width="22%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/讲一讲目前深度学习下基于单目的三维人体重建技术-20210914172101.png">
</p>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">pred_pose = init_pose</span><br><span class="line">pred_shape = init_shape</span><br><span class="line">pred_cam = init_cam</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_iter):</span><br><span class="line">    xc = torch.cat([x, pred_pose, pred_shape, pred_cam], <span class="number">1</span>)</span><br><span class="line">    xc = self.fc1(xc)</span><br><span class="line">    xc = self.drop1(xc)</span><br><span class="line">    xc = self.fc2(xc)</span><br><span class="line">    xc = self.drop2(xc)</span><br><span class="line">    pred_pose = self.decpose(xc) + pred_pose</span><br><span class="line">    pred_shape = self.decshape(xc) + pred_shape</span><br><span class="line">    pred_cam = self.deccam(xc) + pred_cam</span><br></pre></td></tr></table></figure>

<p>考虑到目前业界里 3D 动捕数据的稀缺性，而目前市面上能获得很多人工标注的 2D 关键点数据集（比如 <a href="https://cocodataset.org/#keypoints-2020">COCO</a> 和 <a href="https://posetrack.net/">PoseTrack</a> 等）。因此会引入 3D -&gt; 2D 的<a href="https://github.com/mkocabas/VIBE/blob/master/lib/core/loss.py#L149"><strong>重投影损失（reprojection loss）</strong></a>，即将 SMPL 人体的 3D 关键点投影到 2D 图像上与人工标注的 2D 关节点计算损失。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/讲一讲目前深度学习下基于单目的三维人体重建技术-20210914173824.png">
</p>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 定义 2D 关键点的损失函数</span></span><br><span class="line">self.criterion_keypoints = nn.MSELoss(reduction=<span class="string">&#x27;none&#x27;</span>).to(self.device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 SMPL 人体 3D 关键点重投影到 2D 关键点</span></span><br><span class="line">pred_keypoints_2d = projection(pred_joints, pred_cam)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">keypoint2d_loss</span>(<span class="params">self, pred_keypoints_2d, gt_keypoints_2d, openpose_weight, gt_weight</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute 2D reprojection loss on the keypoints.</span></span><br><span class="line"><span class="string">    The loss is weighted by the confidence.</span></span><br><span class="line"><span class="string">    The available keypoints are different for each dataset.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    conf = gt_keypoints_2d[:, :, -<span class="number">1</span>].unsqueeze(-<span class="number">1</span>).clone()</span><br><span class="line">    conf[:, :<span class="number">25</span>] *= openpose_weight</span><br><span class="line">    conf[:, <span class="number">25</span>:] *= gt_weight              <span class="comment"># 如果没有标注，gt_weight = 0，否则为 1</span></span><br><span class="line">    loss = (conf * self.criterion_keypoints(pred_keypoints_2d, gt_keypoints_2d[:, :, :-<span class="number">1</span>])).mean()</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="25%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/讲一讲目前深度学习下基于单目的三维人体重建技术-20210919142654.png">
</p>

<p>尽管 3D 数据集比较难获得，但是 3D 关键点损失也要考虑在内。它的损失函数与 2D 关键点损失一样，都是 nn.MSELoss 函数，输入则为 24 （23+1）个关键点的 3D 标注坐标和预测坐标。详见 <a href="https://github.com/mkocabas/VIBE/blob/master/lib/core/loss.py#L161">keypoint_3d_loss 损失函数</a>。</p>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/讲一讲目前深度学习下基于单目的三维人体重建技术-20210914175801.png">
</p>

<p>一些数据集如 <a href="http://vision.imar.ro/human3.6m/description.php">Human3.6M</a> 不仅能获得人体的 3D 关键点坐标和 pose 信息，还用到了 3D scan 扫描获得人体的 mesh 信息。我们可以通过使用 Mosh 工具将这些标注数据转化成 SMPL 的（β，θ）参数，然后对它们直接进行监督，详见 <a href="https://github.com/mkocabas/VIBE/blob/master/lib/core/loss.py#L185">smpl_losses 损失函数</a>。</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/讲一讲目前深度学习下基于单目的三维人体重建技术-20210914180527.png">
</p>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 使用 MSELoss 损失函数</span></span><br><span class="line">self.criterion_regr = nn.MSELoss().to(self.device)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">smpl_losses</span>(<span class="params">self, pred_rotmat, pred_betas, gt_pose, gt_betas</span>):</span></span><br><span class="line">    pred_rotmat_valid = batch_rodrigues(pred_rotmat.reshape(-<span class="number">1</span>,<span class="number">3</span>)).reshape(-<span class="number">1</span>, <span class="number">24</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    gt_rotmat_valid = batch_rodrigues(gt_pose.reshape(-<span class="number">1</span>,<span class="number">3</span>)).reshape(-<span class="number">1</span>, <span class="number">24</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">    pred_betas_valid = pred_betas</span><br><span class="line">    gt_betas_valid = gt_betas</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(pred_rotmat_valid) &gt; <span class="number">0</span>:</span><br><span class="line">        loss_regr_pose = self.criterion_regr(pred_rotmat_valid, gt_rotmat_valid)</span><br><span class="line">        loss_regr_betas = self.criterion_regr(pred_betas_valid, gt_betas_valid)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        loss_regr_pose = torch.FloatTensor(<span class="number">1</span>).fill_(<span class="number">0.</span>).to(self.device)</span><br><span class="line">        loss_regr_betas = torch.FloatTensor(<span class="number">1</span>).fill_(<span class="number">0.</span>).to(self.device)</span><br><span class="line">    <span class="keyword">return</span> loss_regr_pose, loss_regr_betas</span><br></pre></td></tr></table></figure>

<p>如果你觉得光靠上面几种监督方式就能实现很好地对人体三维重建，那就大错特错了。尽管人体的 2D 关键点可能预测得很准，但是<strong>由于深度的模糊性和人体关节点的自由度比较大</strong>，所以模型预测的人体姿态很容易发生扭曲，而这种扭曲形态显然是正常人类无法做到的。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/讲一讲目前深度学习下基于单目的三维人体重建技术-20210919143136.png">
</p>

<p>常用的方法是使用判别器（discriminator）对模型输出的（β，θ）参数进行监督，用来判断是否属于真实人体。在 HMR 算法中，一共使用了 K+2 个判别器，K 指的是人体的关节数目，2 则指的是 SMPL 的 β 和 θ 参数。每个判别器输出的值在 [0, 1] 范围内，代表了参数来源于真实数据的概率。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/讲一讲目前深度学习下基于单目的三维人体重建技术-20210919145126.png">
</p>

<p>当我们做到这里的时候已经能达到 SOTA 的效果了，但是在实际的野外场景中应用会发现：我们依然无法捕获到人类实际运动的复杂性和可变性以及准确而又自然的运动序列。在 HMR 预训练模型的基础上，VIBE 算法使用了<strong>时序编码器 GRU 来考虑上下帧人体动作的连贯性</strong>，并且增加了一个动作判别器（Motion discriminator）来判断生成器输出的人体动作序列是否接近真实人类。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/讲一讲目前深度学习下基于单目的三维人体重建技术-20210919151301.png">
</p>

<p>结束语：尽管基于 SMPL 参数的人体三维重建技术取得了一定的成就，但是由于这块领域的开拓的时间其实不是很长，我觉得未来的想象空间依然很大。SMPL 算法其实早在 2015 年就提出来了，但是这块的人体重建算法也就这两年才开始爆发和逐渐成熟。目前基于纯视觉的人体重建技术的阻力依然很大，例如基于室外场景的 3D 标注数据很稀缺、多人场景下的遮挡问题和模型的 real-time 性等，这其中的任何一个子问题都亟待我们去探索和解决。</p>
]]></content>
      <categories>
        <category>姿态估计</category>
      </categories>
  </entry>
  <entry>
    <title>FairMOT：讨论多目标跟踪里检测与再识别的公平性</title>
    <url>/2021/09/09/FairMOT-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E9%87%8C%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%86%8D%E8%AF%86%E5%88%AB%E7%9A%84%E5%85%AC%E5%B9%B3%E6%80%A7/</url>
    <content><![CDATA[<p>基于 anchor-free 的目标跟踪 family 又迎来了一位新成员，FairMOT. 它是在 CenterNet 基础上进行创新的，并真正意义上实现了端到端地将 Detection 和 ReId 任务进行联合训练。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/FairMOT-多目标跟踪里检测与再识别的公平性-20210909145011.gif">
</p>
<span id="more"></span>

<p>以往大多数的目标跟踪都是采用 Detection + ReId 的方式，没有实现 jointly 端到端地联合训练，使得算法的跟踪精度也有限。FairMOT 分析了这种结果不佳的原因，总结下来主要有三点：</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/FairMOT-多目标跟踪里检测与再识别的公平性-20210909153247.png">
</p>

<ul>
<li><p>作者认为 anchor-base 不适合 ReId 任务，应该使用 anchor-free 的方法。原因是可能会出现<strong>一个 anchor 响应多个目标或者多个 anchor 响应一个目标</strong>的情况（如上图所示），导致歧义性。如果我们只用一个中心点去看待，那么就不会出现这种情况。</p>
</li>
<li><p>现有的目标跟踪算法过度地依赖 Detection 精度，导致 ReId 任务受到不公平的忽视。ReId 任务需要高低层不同分辨率的特征融合，这在目前大多数的 Detection + ReId 框架里不太好做到。</p>
</li>
<li><p>在 MOT 中 ReID 特征的维数不宜过高，因为 MOT 的数据集一般来说都比较小。维度过高容易造成过拟合，而且显存和计算量都会增大。</p>
</li>
</ul>
<p>FairMOT 网络有两个分支：Detection 分支和 ReID 分支。Detection 分支与 CenterNet 里的基本一样，这里不做介绍，让我们重点来看看 ReID 分支。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/FairMOT-多目标跟踪里检测与再识别的公平性-20210909154840.png">
</p>

<p>ReID 分支的作用是在于输出每个目标的 embedding 向量。在 backbone 顶部设有一个 128 核的卷积层来提取<strong>每个位置</strong>的 embedding，如上图所示输出的是一个维度为 [128, H, W] 的 Re-ID Embeddings，然后喂入分类器：<a href="https://github.com/ifzhang/FairMOT/blob/ca63d27f19e8d2170b84edb80cc2dc348c3dcd5a/src/lib/trains/mot.py#L32">nn.Linear(self.emb_dim, self.nID)</a> 计算 loss（需要注意的是，作者通过 reg_mask 对正样本进行了<strong>挑选</strong>，也就是说<strong>只有正样本才会计算 regression loss 和 ReID loss</strong>)。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># https://github.com/ifzhang/FairMOT/blob/ca63d27f19e8d2170b84edb80cc2dc348c3dcd5a/src/detection_demo.py#L33</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------- 每个分支和它所对应的输出维度 ---------------#</span></span><br><span class="line">reid_dim = <span class="number">128</span></span><br><span class="line">heads = &#123;<span class="string">&#x27;hm&#x27;</span>: num_classes, <span class="string">&#x27;wh&#x27;</span>: <span class="number">2</span> <span class="keyword">if</span> <span class="keyword">not</span> ltrb <span class="keyword">else</span> <span class="number">4</span>, <span class="string">&#x27;id&#x27;</span>: reid_dim, <span class="string">&#x27;reg&#x27;</span>: <span class="number">2</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">#------------ 根据 heads 字典和它的维度创建每个分支-----------#</span></span><br><span class="line"><span class="comment"># https://github.com/ifzhang/FairMOT/blob/ca63d27f19e8d2170b84edb80cc2dc348c3dcd5a/src/lib/models/networks/resnet_dcn.py#L155</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> head <span class="keyword">in</span> self.heads:          <span class="comment"># 创建每个分支</span></span><br><span class="line">    classes = self.heads[head]   <span class="comment"># classes 为每个分支的输出维度，如 hm(高斯热图): num_classes</span></span><br><span class="line">    <span class="keyword">if</span> head_conv &gt; <span class="number">0</span>:            <span class="comment">#                                  wh(宽和高): 2</span></span><br><span class="line">        fc = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">64</span>, head_conv,</span><br><span class="line">            kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>, bias=<span class="literal">True</span>),</span><br><span class="line">            nn.ReLU(inplace=<span class="literal">True</span>),</span><br><span class="line">            nn.Conv2d(head_conv, classes,           <span class="comment"># 分支的最后一层卷积核为 1x1，输出对应维度</span></span><br><span class="line">            kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>,</span><br><span class="line">            padding=<span class="number">0</span>, bias=<span class="literal">True</span>))</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&#x27;hm&#x27;</span> <span class="keyword">in</span> head:</span><br><span class="line">            fc[-<span class="number">1</span>].bias.data.fill_(-<span class="number">2.19</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            fill_fc_weights(fc)</span><br><span class="line"></span><br><span class="line"><span class="comment">#---------------------- 计算 re-ID 的 loss ------------------#</span></span><br><span class="line"><span class="comment"># https://github.com/ifzhang/FairMOT/blob/ca63d27f19e8d2170b84edb80cc2dc348c3dcd5a/src/lib/trains/mot.py#L56</span></span><br><span class="line"></span><br><span class="line">self.classifier = nn.Linear(self.emb_dim, self.nID)</span><br><span class="line">self.IDLoss = nn.CrossEntropyLoss(ignore_index=-<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> opt.id_weight &gt; <span class="number">0</span>:</span><br><span class="line">    id_head = _tranpose_and_gather_feat(output[<span class="string">&#x27;id&#x27;</span>], batch[<span class="string">&#x27;ind&#x27;</span>])</span><br><span class="line">    id_head = id_head[batch[<span class="string">&#x27;reg_mask&#x27;</span>] &gt; <span class="number">0</span>].contiguous()   <span class="comment"># 选出正样本</span></span><br><span class="line">    id_head = self.emb_scale * F.normalize(id_head)</span><br><span class="line">    id_target = batch[<span class="string">&#x27;ids&#x27;</span>][batch[<span class="string">&#x27;reg_mask&#x27;</span>] &gt; <span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    id_output = self.classifier(id_head).contiguous()</span><br><span class="line">    id_loss += self.IDLoss(id_output, id_target)</span><br></pre></td></tr></table></figure>

<table><center><td bgcolor=Plum><font color=black>
作者很巧妙地将整个过程中每个目标 ID 设置成一个类别，这样 ReID  Loss 就变成了一个多分类交叉熵损失函数。在训练阶段，ReID task 成了多分类任务；在测试阶段，砍掉 Linear 层直接取出 embedding 向量计算余弦距离，这其实和人脸识别过程一模一样。
</font></strong></td></center></table>

<p>至于何时创建和销毁 tracker 以及它和 detection 之间怎么关联，这和 DeepSort 里的流程基本一致，具体请移步于<a href="https://yunyang1994.gitee.io/2021/08/27/DeepSort-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E7%AE%97%E6%B3%95-SORT-%E7%9A%84%E8%BF%9B%E9%98%B6%E7%89%88/">DeepSort：多目标跟踪算法 Sort 的进化版</a>。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="http://arxiv.org/abs/2004.01888">[1] FairMOT: On the Fairness of Detection and Re-Identification in Multiple Object Tracking,</a></li>
<li><a href="https://github.com/ifzhang/FairMOT">[2] https://github.com/ifzhang/FairMOT</a></li>
</ul>
]]></content>
      <categories>
        <category>目标跟踪</category>
      </categories>
  </entry>
  <entry>
    <title>滚蛋吧，Anchor 君！旷视新科技，YOLOX</title>
    <url>/2021/09/08/%E6%BB%9A%E8%9B%8B%E5%90%A7-Anchor-%E5%90%9B-%E6%97%B7%E8%A7%86%E6%96%B0%E7%A7%91%E6%8A%80-YOLOX/</url>
    <content><![CDATA[<p>天下苦 anchor 久矣，这两年是 anchor-free 系列目标检测算法的爆发时间段。但是 YOLO 系列最新推出的 v4 和 v5 依然抱着 anchor 不放，在这种背景下旷视科技推出了基于 anchor-free 的 YOLOx 算法。今天就来盘点一下这里面一些有意思的东西。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/滚蛋吧-Anchor-君-旷视新科技-YOLOX-20210907145112.png">
</p>

<span id="more"></span>

<p>作者选用的是 YOLOv3-SPP 作为 baseline，在这个基础上使用了很多 trick 不断升级打怪将 AP 提升了<strong> 8.8个百分点</strong>。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/滚蛋吧-Anchor-君-旷视新科技-YOLOX-20210907152659.png">
</p>

<h3 id="decoupled-head"><a href="#decoupled-head" class="headerlink" title="decoupled head"></a>decoupled head</h3><p><strong>在目标检测里，回归任务和分类任务是有冲突的，</strong>所以最近几年出现的一些 anchor free 算法如 CornerNet、CenterNet 和 FCOS 等，都是将 regression 和 classification 分开进行预测。如下图所示：之前 regression 和 classification 任务都是长在一个头（head）上的，现在用了两个分支叉开了，因此称为 decoupled head。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/滚蛋吧-Anchor-君-旷视新科技-YOLOX-20210907154324.png">
</p>
<p align="center">
    <img width="65%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/滚蛋吧-Anchor-君-旷视新科技-YOLOX-20210907154908.png">
</p>
实验结果发现，解藕操作不仅提升了 YOLOX 的性能和收敛速度，还为检测下游任务的一体化带来可能：

<ul>
<li>和 yolact  相似，实现端侧的实例分割</li>
<li>YOLOX + 34 层输出，实现端侧人体的 17 个关键点检测。</li>
</ul>
<h3 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h3><p>数据增强在目标检测里一直有人在做，但是将 AP 提升了 2.4% 还是比较难得的。Mosaic 经过 yolov4 和 v5 的验证，表明对结果有显著的提升。作者在 YOLOX-L 模型上尝试了 <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Ghiasi_Simple_Copy-Paste_Is_a_Strong_Data_Augmentation_Method_for_Instance_CVPR_2021_paper.pdf">copy-paste</a>，也带来了 0.8% 的提升。此外还将<strong>关闭 Aug 的时间节点设定为终止前的 10~15 个 epoch，目的是为了为了让检测器避开不准确标注框的影响，在自然图片的数据分布下完成最终的收敛。</strong></p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/滚蛋吧-Anchor-君-旷视新科技-YOLOX-20210907161944.png">
</p>
作者还提出一个观点：<strong>只有当模型容量足够大时，相对于先验知识（各种 tricks，hand-crafted rules ），更多的后验（data augmentation）知识才会产生本质影响。</strong>

<h3 id="anchor-free"><a href="#anchor-free" class="headerlink" title="anchor free"></a>anchor free</h3><p>将 YOLO 算法从 anchor-base 切换到 anchor-free 的做法非常简单，直接套用 FCOS 那套逻辑即可。但是想要提高预测精度达到 SOTA 却不简单，作者在知乎上对正负样本的匹配经验做了一些总结，大家可以移步<a href="https://www.zhihu.com/question/473350307/answer/2021031747">知乎</a>。</p>
<h3 id="Multi-positives"><a href="#Multi-positives" class="headerlink" title="Multi positives"></a>Multi positives</h3><p>为了和 YOLOv3 正负样本匹配机制一致，作者刚开始是只选择了一个 positive sample（目标中心）。<strong>但是作者在实验过程中发现，中心附近的 positive samples 有助于缓解正负样本不均衡问题，不应该完全被忽略掉。</strong>因此在训练过程中，作者把中心 3x3 区域内的像素都当作正样本，这个其实也是 FCOS 里的 center sampling 操作。最终这个骚操作使精度提升了 2.1 个百分点，效果显著啊。</p>
<h3 id="SimOTA"><a href="#SimOTA" class="headerlink" title="SimOTA"></a>SimOTA</h3><p>OAT（Optimal Transport Assignment）是旷视发的一篇 CVPR 2021 论文，它把样本匹配建模成最优传输问题，找出前面 k 个最优的正样本。SimOTA 是在 OTA 的基础做了简化， 有兴趣可以去看看<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Ge_OTA_Optimal_Transport_Assignment_for_Object_Detection_CVPR_2021_paper.pdf">原文</a>，这里就不做介绍了。</p>
<p>最后一些碎碎念：要说把这个算法取名 YOLOX，我是不服的。因为它其实和 YOLO 相关性并不大，反而和 FCOS 非常相似，所以感觉这样取名也是蹭了 YOLO 的热度吧 😂。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="https://arxiv.org/abs/2107.08430">[1] YOLOX: Exceeding YOLO Series in 2021</a></li>
<li><a href="https://www.zhihu.com/question/473350307/answer/2021031747">[2] 知乎：如何评价旷视开源的YOLOX，效果超过YOLOv5?</a></li>
</ul>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>anchor free</tag>
      </tags>
  </entry>
  <entry>
    <title>知识蒸馏：Distilling the Knowledge in a Neural Network</title>
    <url>/2021/09/07/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F-Distilling-the-Knowledge-in-a-Neural-Network/</url>
    <content><![CDATA[<p><strong>知识蒸馏（Knowledge Distillation，KD）</strong>，就是将一个大网络学习到的知识通过蒸馏提炼到另一个小网络中去。通常是存在一个已经训练好的、具备知识的成熟 Teacher Model，用它来指导 Student Model 学习。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/知识蒸馏-Distilling-the-Knowledge-in-a-Neural-Network-20210906202808.png"></p>

<span id="more"></span>

<p>知识蒸馏这个名字第一次是出现在 Hinton 祖师爷的<a href="https://arxiv.org/abs/1503.02531">《Distilling the Knowledge in a Neural Network（2015）》</a> 论文里的，它提出可以同时利用真实的 hard target 和教师网络输出的 soft target 对学生网络进行监督训练。hard target 是由原始数据集标注的 one-shot 标签，除了正标签为 1，其他负标签都是 0，分布比较尖锐。soft target 是经过温度 T 软化后的概率分布，每个类别都分配了概率，但是正标签的概率最高，分布比较平缓。</p>
<p align="center">
    <img width="65%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/知识蒸馏-Distilling-the-Knowledge-in-a-Neural-Network-20210907101318.jpg"></p>
    
<p>在训练阶段，教师网络输出的 Logits 除以温度参数 T 后再做 softmax 变换得到软化的概率分布。<strong>温度 T 越大，概率分布就越缓和，就越容易放大错误分类的概率而引入不必要的噪声，</strong>因此要合理控制 T 参数。在高温 T 蒸馏下，将教师网络的知识传递给学生网络，这个过程通过 soft loss 监督学习；与此同时，还要让学生网络看看 ground truth 标签（老师也不一定全对）计算 hard loss。在测试阶段，学生网络输出的 Logits 不再需要除以温度 T 而是直接送入 soft max 层。</p>
<p align="center">
    <img width="85%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/知识蒸馏-Distilling-the-Knowledge-in-a-Neural-Network-20210907102646.png"></p>

<p>引入一个权重 λ 来权衡两种损失的重要程度，λ 越大，表示对老师的信赖程度越高。通常训练初期会给一个比较大的 λ 值，然后在后期逐渐降低。这就叫，<strong>师傅领进门，修行在个人。</strong></p>
<p align="center">
    <img width="35%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/知识蒸馏-Distilling-the-Knowledge-in-a-Neural-Network-20210907111935.png"></p>  

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss_fn_kd</span>(<span class="params">outputs, labels, teacher_outputs, params</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Compute the knowledge-distillation (KD) loss given outputs, labels.</span></span><br><span class="line"><span class="string">    &quot;Hyperparameters&quot;: temperature and alpha</span></span><br><span class="line"><span class="string">    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher</span></span><br><span class="line"><span class="string">    and student expects the input tensor to be log probabilities! See Issue #2</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    alpha = params.alpha</span><br><span class="line">    T = params.temperature</span><br><span class="line">    KD_loss = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=<span class="number">1</span>),</span><br><span class="line">                             F.softmax(teacher_outputs/T, dim=<span class="number">1</span>)) * (alpha * T * T) + \</span><br><span class="line">              F.cross_entropy(outputs, labels) * (<span class="number">1.</span> - alpha)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> KD_loss</span><br></pre></td></tr></table></figure>

<p>至于说知识蒸馏为什么能 work，至今还没有一个定论。目前比较流行的一种说法是，<strong>soft target 的信息熵比较高，隐含了不同 label 特征之间的相似性。</strong>比如同时分类驴和马的时候，尽管某张图片是马，但是 soft target 就不会像 hard target 那样只有在马的 index 处为 1，其余为 0，而是在驴这里也会给予一定概率。其实也可以这样理解：<strong>如果只有正样本的概率为 1 而其他所有负样本的概率为 0 的话，那么就抹平了其他负样本之间的 distance，其实这种 distance 信息是可以通过教师网络事先学习到然后再传递给学生网络。</strong></p>
<p>总结一下：在整个知识蒸馏过程中，我们先让温度 T 升高，然后在测试阶段恢复常温（ T=1 ），从而将教师模型中的知识提取出来，是为蒸馏。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="https://arxiv.org/abs/1503.02531">[1] Distilling the Knowledge in a Neural Network</a></li>
<li><a href="https://github.com/peterliht/knowledge-distillation-pytorch/blob/ef06124d67a98abcb3a5bc9c81f7d0f1f016a7ef/model/net.py#L100">[2] https://github.com/peterliht/knowledge-distillation-pytorch</a></li>
<li><a href="https://www.yuque.com/yahei/hey-yahei/knowledge_distillation">[3] 知识蒸馏，语雀文档</a></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>UnitBox：一种新的 IoU 损失函数，把 box 当作一个整体去预测</title>
    <url>/2021/09/05/UnitBox%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84-iou-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-%E6%8A%8A%20box-%E5%BD%93%E4%BD%9C%E4%B8%80%E4%B8%AA%E6%95%B4%E4%BD%93%E5%8E%BB%E9%A2%84%E6%B5%8B/</url>
    <content><![CDATA[<p>这篇论文注意到了一个大多数人没有注意到的问题：现在很多目标检测都是将物体的边框看作四个独立的变量，使用 L1 或 L2 loss 对其分别进行回归，但是这样获得的检测精度其实有限，因为它忽略了物体的尺度和形状等因素。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/UnitBox一种新的-iou-损失函数-把 box-当作一个整体去预测-20210905170323.png">
</p>

<span id="more"></span>

<p><strong>比如大目标的尺度较大，所以它的 L2 损失可能会比小目标相对更大一些，但是这并不意味着它就预测得比小目标更差。</strong>像下面这幅图里，小目标的 loss 低，但是它反而预测得没有大目标好。</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/UnitBox一种新的-iou-损失函数-把 box-当作一个整体去预测-20210905170950.png">
</p>

<p>作者就想到把 box 看作一个整体，考虑到 IoU ∈ [0, 1] 范围内，那么 L = - In(IoU) 其实就相当于 ground-truth 框和预测框之间的交叉熵损失。不妨将 IoU 看成是采样于伯努利分布（Bernoulli distribution）的一种随机变量，p(IoU=1)=1，它描述了预测框成为真实框的概率分布，因此得到交叉熵损失如下：</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/UnitBox一种新的-iou-损失函数-把 box-当作一个整体去预测-20210905172938.png">
</p>

<p>与 L2 Loss相比，IoU Loss 将边框视为一个整体，并且不论方框的尺度大小，因此预测结果会比 L2 Loss的更加精确。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="https://arxiv.org/abs/1608.01471">[1] UnitBox: An Advanced Object Detection Network</a></li>
</ul>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>anchor free</tag>
      </tags>
  </entry>
  <entry>
    <title>老生常谈 Focal Loss —— 解决正负样本不均衡问题</title>
    <url>/2021/09/03/%E8%A7%A3%E5%86%B3%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E4%B8%8D%E5%9D%87%E8%A1%A1%E9%97%AE%E9%A2%98%E2%80%94%E2%80%94Focal-Loss/</url>
    <content><![CDATA[<p>最近看的一些 anchor-free 目标检测算法都普遍用到了 Focal Loss，今天就来老生常谈重新聊聊它吧！</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/解决正负样本不均衡问题——Focal-Loss-20210903163748.png">
</p>

<span id="more"></span>

<p>在讲 Focal Loss 之前，咱们先简单回顾一下交叉熵损失（cross entropy loss）函数。</p>
<h2 id="1-交叉熵损失"><a href="#1-交叉熵损失" class="headerlink" title="1. 交叉熵损失"></a>1. 交叉熵损失</h2><p>在物理学中，“熵”被用来表示热力学系统所呈现的无序程度。香农将这一概念引入信息论领域，提出了“信息熵”概念，通过对数函数来测量信息的不确定性。</p>
<p>交叉熵（cross entropy）是信息论中的重要概念，主要用来度量两个概率分布间的差异。假定 𝑝 和 𝑞 是数据 𝑥 的两个概率分布，通过 𝑞 来表示 𝑝 的交叉熵可如下计算：</p>
<p align="center">
    <img width="32%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/解决正负样本不均衡问题——Focal-Loss-20210903170506.png">
</p>

<p><strong>交叉熵刻画了两个概率分布 𝑝  和 𝑞 之间的距离。</strong>根据公式不难理解，如果交叉熵越小，那么两个概率分布 𝑝  和 𝑞 越接近。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/解决正负样本不均衡问题——Focal-Loss-20210903171510.png">
</p>

<p>如上图所示，在神经网络中，<strong>我们通常是利用 softmax 层输出一个多分类的预测概率分布，然后与真实概率分布计算交叉熵损失。</strong>在上面公式中，通常我们是假设 𝑝 为真实概率分布， 𝑞 为预测概率分布。以一个二分类为例， 𝑝 = [1, 0]，𝑞 = [ p, 1-p]，那么计算出交叉熵损失为 <code>L = - log(p)</code></p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/解决正负样本不均衡问题——Focal-Loss-20210903172756.png">
</p>

<h2 id="2-Focal-Loss-损失"><a href="#2-Focal-Loss-损失" class="headerlink" title="2. Focal Loss 损失"></a>2. Focal Loss 损失</h2><p>Focal Loss 是在交叉熵损失函数上进行改进的，其背景是来源于解决 one-stage detector 里 anchor 正负样本不均衡问题。作者认为 one-stage detector 检测还不够准的原因完全在于：</p>
<ul>
<li>正负样本非常不均衡，而且绝大多数负样本都是 easy example；</li>
<li>虽然这些 easy example 的损失可能比较低，但是它们数量众多，依旧对 loss 有很大贡献，从而使得梯度被 easy example 主导。</li>
</ul>
<p>因此我们就<strong>自然想到提高困难样本的权重和降低简单样本的权重，因此在交叉熵损失函数的基础上增加一个调节因子</strong>，得到 Focal Loss 如下：</p>
<p align="center">
    <img width="35%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/解决正负样本不均衡问题——Focal-Loss-20210903222245.png">
</p>

<p>其中 γ ∈ [0, 5] 范围内。文章认为 detector 对某目标的预测概率越接近 1，那么说明这个目标就越容易被分类，属于简单样本类型。从最上面的图中可以看出：当一个样本被错误分类时它的概率 Pt 就会很低，属于困难样本，这个时候权重值就接近于 1；而当它的概率接近于 1 时，属于简单样本，其权重就会趋于 0.</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献:"></a>参考文献:</h2><ul>
<li><a href="https://paddlepedia.readthedocs.io/en/latest/tutorials/deep_learning/loss_functions/CE_Loss.html">[1] 深度学习基础篇——交叉熵损失函数</a></li>
<li><a href="https://arxiv.org/abs/1708.02002">[2] Focal Loss for Dense Object Detection</a></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>FCOS：Fully Convolutional One-Stage Object Detection</title>
    <url>/2021/09/02/FCOS-Fully-Convolutional-One-Stage-Object-Detection/</url>
    <content><![CDATA[<p>最近看了不少关于 anchor-free 目标检测的文章，弄得有些审美疲劳了。今天带来一篇我觉得非常有创意的文章，<a href="https://arxiv.org/pdf/1904.01355.pdf">FCOS：Fully Convolutional One-Stage Object Detection</a>. <strong>这篇文章用图像分割的思想去解决 detection 问题，并提出可以用 FPN 的思路来解决重叠目标的 bad case。</strong>从实验结果来看，FCOS 能够与主流的 anchor-base 检测算法相媲美，达到 SOTA 的效果。</p>
<p align="center">
    <img width="35%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/FCOS-Fully-Convolutional-One-Stage-Object-Detection-20210902144334.png">
</p>

<span id="more"></span>

<p>毫无疑问，anchor-free 系列的文章一上来就是<strong>先痛骂一顿 anchor-based 的缺点</strong>。在作者看来，anchor-based 虽然能带来很大的准确率提升，但是也有不可避免的以下几个问题：</p>
<ul>
<li>模型的性能对 anchor 的尺寸、宽高比和数量会比较敏感，例如 RetinaNet 在不同的超参下在 COCO 数据集上的 AP 会有 4% 的波动；</li>
<li>anchor 的尺寸和宽高都是固定的，如果目标的尺寸范围波动比较大，这会比较比较难预测；</li>
<li>为了提高召回率，anchor 的数量通常很大，并且容易出现样本不均衡的情况；</li>
<li>在训练阶段还得涉及复杂的 iou 计算，这使得显存的占用也比较大。</li>
</ul>
<h2 id="1-相关工作"><a href="#1-相关工作" class="headerlink" title="1. 相关工作"></a>1. 相关工作</h2><h3 id="1-1-anchor-based-detector"><a href="#1-1-anchor-based-detector" class="headerlink" title="1.1 anchor-based detector"></a>1.1 anchor-based detector</h3><p>大多数 anchor-based 的检测算法都是基于传统的滑动窗口思想，或者用的是 Fast-RCNN 那套候选框机制：<strong>预先定义好滑动窗口或者候选框，然后对它们分类成正样本和负样本，对于正样本还需要额外回归出精确的位置和尺寸。</strong>即使后来的一些有名的单阶段检测算法如 SSD 和 YOLO 系列，也是在 Faster-RCNN 的 RPN 基础上发展的。</p>
<p>但是这种 anchor 会带来大量的超参数，影响到算法的性能，比如 iou 阈值会影响到正负样本标注。因此在训练一个 anchor-based detector 时，我们需要对 anchor 的超参数进行精细的调试。</p>
<h3 id="1-2-anchor-free-detector"><a href="#1-2-anchor-free-detector" class="headerlink" title="1.2 anchor-free detector"></a>1.2 anchor-free detector</h3><p>在 anchor-based 机制的痛点刺激下，最近也涌现出了一些不错的 anchor-free 检测算法。比较早的可能要属 <strong>YOLOv1 了，它是直接回归出目标的中心和尺寸。但是因为它只用了中心点来预测框，这使得它的召回率很低。</strong>在那个 RPN 召唤的时代，Joseph Redmon 在 YOLOv2 中立马采用了 RPN 的 anchor 机制，并提出 anchor 的先验尺寸可以通过聚类得到。</p>
<p><strong>CornerNet</strong> 是最近提出的一个不错的 anchor-free 算法，它是通过检测一对角点来实现目标检测。但是它<strong>在后处理阶段引入了一套额外的 corners grouping 过程</strong>，看起来也不是最好的。</p>
<h2 id="2-FCOS-算法介绍"><a href="#2-FCOS-算法介绍" class="headerlink" title="2. FCOS 算法介绍"></a>2. FCOS 算法介绍</h2><h3 id="2-1-基本思路"><a href="#2-1-基本思路" class="headerlink" title="2.1 基本思路"></a>2.1 基本思路</h3><p>近年来全卷积神经网络（ Fully Convolutional Network，FCN）已经在语义分割、深度估计和关键点检测等领域取得了巨大的突破，这不禁令人想到：<strong>我们能不能像 FCN 语义分割那样在 pixel 级别上解决目标检测问题？</strong> 这样一来这些基本的视觉任务几乎就可以在同一套框架内完成了，FCOS 证实了这一猜想。</p>
<p>当像素（x, y）落入任何一个 ground-truth 框时被认为是正样本，并将 ground-truth 框的类别 c 设置为该像素的类别，否则就是 0. 此外还有一个 4D 向量作为位置回归目标，里面每个元素值分别为该像素到 bbox 四条边的距离（如上图所示）。</p>
<p align="center">
    <img width="33%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/FCOS-Fully-Convolutional-One-Stage-Object-Detection-20210902195049.png">
</p>

<p>当像素落在多个 ground-truth 框中时，直接选择面积最小的那个作为回归目标。<strong>相对于 anchor-based 的IOU判断，FCOS 能生成更多的正样本来训练 detector 并且也没引入额外的超参。</strong></p>
<h3 id="2-2-FCOS-网络"><a href="#2-2-FCOS-网络" class="headerlink" title="2.2 FCOS 网络"></a>2.2 FCOS 网络</h3><p>目标检测里一个比较棘手的问题就是对于重叠目标的识别效果不太好：一个原因是 anchor 对于这类目标的响应具有一定的模糊性，还有另一个重要的原因就是较小的重叠目标的特征在深度下采样时会消失。<strong>FCOS 提出了利用 FPN 模块对不同 size 的目标使用不同分辨率的 feature map 进行预测，并且对 pixel 所属的 feature map level 进行了指定。</strong>比如某个 pixel 满足 max(l∗, t∗, r∗, b∗) &gt; mi 或 max(l∗, t∗, r∗, b∗) &lt; m(i−1) 则认为该 pixel 不属于第 i 层 feature map了，其中 m 是 feature map 的最大回归长度。（这一点其实和 anchor-based 里不同分辨率的 feature map 设置不同大小的 anchor 一样）</p>
<p align="center">
    <img width="35%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/FCOS-Fully-Convolutional-One-Stage-Object-Detection-20210902211107.png">
</p>

<p>FCOS 结构如下图所示，它最终输出 80D 分类标签向量 p 和 4D box 坐标向量 t = (l, t, r, b)，训练 C 个二分类器而不是多分类器，并在最后特征后面分别接 4 个卷积层用于分类和定位分支。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/FCOS-Fully-Convolutional-One-Stage-Object-Detection-20210902202015.png">
</p>

<p>对于每个最终输出 feature map （相对于原图的缩放倍数为 s）上的某个点（x, y），我们可以将它映射回原图得到位置：</p>
<p align="center">
    <img width="25%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/FCOS-Fully-Convolutional-One-Stage-Object-Detection-20210902202910.png">
</p>

<p>此外，为了保证预测的长度为正数，论文使用了 exp(x) 函数从而保证任何实数的映射范围在（0，∞).最终的整个训练损失函数如下所示：</p>
<p align="center">
    <img width="55%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/FCOS-Fully-Convolutional-One-Stage-Object-Detection-20210902203920.png">
</p>

<p>L_cls 为 focal loss 分类损失，L_reg 为 UnitBox 里的 iou 损失，N_pos 为正样本数量，λ 为平衡权重. </p>
<h3 id="2-3-Center-ness"><a href="#2-3-Center-ness" class="headerlink" title="2.3 Center-ness"></a>2.3 Center-ness</h3><p>在使用多尺度预测后，FCOS 依然和主流的 anchor-based 算法存在一定的差距，这主要是来源于低质量的预测框，这些框大多是由距离目标中心点比较远的像素所产生。因此，论文提出新的独立分支来预测像素的 <strong>center-ness，用来评估像素与目标中心点的距离</strong>：</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/FCOS-Fully-Convolutional-One-Stage-Object-Detection-20210903111701.png">
</p>

<p>center-ness 值的范围为（0， 1）：当像素位于 ground-truth 框边上时，它距离中心位置最远，此时值为 0；当像素位于中心时，此时值为 1.</p>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/FCOS-Fully-Convolutional-One-Stage-Object-Detection-20210903112233.png">
</p>

<p>在测试阶段，最终的分数是将分类的 score 分数与 center-ness 进行加权相乘，从而降低那些低质量预测框的分数。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="https://arxiv.org/pdf/1904.01355.pdf">[1] FCOS: Fully Convolutional One-Stage Object Detection</a></li>
<li><a href="https://github.com/tianzhi0549/FCOS">[2] https://github.com/tianzhi0549/FCOS</a></li>
</ul>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>anchor free</tag>
      </tags>
  </entry>
  <entry>
    <title>CenterNet 和 CenterTrack：以点代物，同时进行目标检测和跟踪</title>
    <url>/2021/09/01/CenterNet-Objects-as-Points/</url>
    <content><![CDATA[<p>在 CornerNet 使用角点框出目标后，就自然会想到直接用中心点检测目标。CenterNet 提出一种新的检测思路：<strong>把目标看成一个点，它的一些性质如尺寸、3D 坐标、朝向和关键点能直接回归得到，并且还不需要 nms 过程。</strong></p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CenterNet-Objects-as-Points-20210901104400.png">
</p>

<p><strong>既然目标已经用一个点来代替了，那么能不能按时间顺序去跟踪这个中心点？</strong>依旧是同样的配方、熟悉的团队，提出了一个基于中心点的联合检测与跟踪框架 —— CenterTrack</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CenterNet-Objects-as-Points-20210902111640.png">
</p>
<span id="more"></span>

<h2 id="1-CenterNet"><a href="#1-CenterNet" class="headerlink" title="1. CenterNet"></a>1. CenterNet</h2><p>和 CornerNet 一样，作者也是通过二维高斯热图的方式去预测关键点，输出的热图 shape 为 [C, H, W]。如果物体属于该类别，其中心点位置对应的概率为 1，其他类别为 0，而对于远离中心点的像素概率随着<strong>二维高斯分布</strong>衰减。如果出现两个高斯分布发生重叠，那么直接取元素间最大值的就行。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CenterNet-Objects-as-Points-20210901130719.jpg">
</p>

<p>对于 heatmap 的损失函数，作者也采用了 focal loss 来处理难易样本不均衡的问题。<strong>由于 CenterNet 只会对每个物体预测出一个正样本（只选择概率最高的），因此就不需要非极大值抑制过程了，</strong>大大简化了目标检测的后处理流程。对于物体中心位置，这里也是和 CornerNet 一样使用的是 offset prediction 方式。</p>
<p><strong>对每个目标的尺寸 s = (xmax - xmin, ymax - ymin），它这里是直接进行回归的（因为没有 anchor，所以无法回归偏移量）同样是采用 L1 损失函数。需要说明的是，预测框的 offset 损失和 size 损失都是只考虑正样本的。</strong>CenterNet 最终输出的 feature map 的维度为 [C+4，H，W]，C 指的是类别概率，4 分别指的是中心位置的 offset 和 bbox 尺寸。</p>
<p align="center">
    <img width="65%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CenterNet-Objects-as-Points-20210901130610.png">
</p>

<p>其他就没什么讲的了，可能是为了凑工作量吧，作者对目标的属性预测延伸到了深度、3D 位置和肢体关键点检测，但是这方面的工作都没有让人眼前特别一亮的感觉 😂。</p>
<table><center><td bgcolor=Plum><font color=black>
其实像 CenterNet 这种直接回归目标中心位置的偏移量和尺寸的思路，YOLOv1 早在 2015 年就已经这样做过了。但是由于当时 YOLOv1 没有采用高斯热图这种方式，导致正样本只有物体中心这一个点，使得它的召回率特别低。在时代的局限性下，Joseph Redmon 只好在 YOLOv2 中采用了 anchor-base 机制。
</font></strong></td></center></table>

<h2 id="2-CenterTrack"><a href="#2-CenterTrack" class="headerlink" title="2. CenterTrack"></a>2. CenterTrack</h2><p>CenterTrack 的思想比较简洁：<strong>直接预测相邻两帧同一物体在图像上的 2D 位移，然后通过它们之间的距离去判断两个 detection 是否是属于同一个物体。</strong> CenterTrack 的网络结构和 CenterNet 基本一致，只不过输入和输出有些差别。如下图所示：CenterTrack 输入<strong>当前帧与前一帧 ➕ 一张heatmap图</strong>，然后输出<strong>当前帧的高斯热图、目标 size 和相对前一帧的位移</strong>。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CenterNet-Objects-as-Points-20210902115504.png">
</p>

<p>对于预测位移 offset 的损失函数，和 CenterNet 一样使用的也是 L1 损失函数。中心点的位移量 d 预测好了以后，可以通过简单的贪婪匹配算法实现跨时间关联目标。 <strong>对于当前位置 p 的检测结果，可以与上一帧位于 p-d 附近的检测结果相关联</strong>，并且以置信度进行降序排列。<strong>如果在半径 κ 范围内没有匹配上，则生成一个新的跟踪片（tracklet）</strong>，其中 κ 定义为每个跟踪片所对应预测框的宽度和高度的几何平均值。</p>
<p>CenterTrack 实现了 end-to-end 的训练方式，并且在性能和速度方面也达到了 SOTA 的效果。但是它的缺点也很明显：<strong>因为它只能关联连续两帧之间的检测框，所以无法重新激活那些消失较长时间的目标</strong>，期待后面的工作能对此进行改进吧。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="https://arxiv.org/abs/1904.07850">[1] Objects as Points</a></li>
<li><a href="https://arxiv.org/abs/2004.01177">[2] Tracking Objects as Points</a></li>
<li><a href="https://arxiv.org/abs/1506.02640">[3] You Only Look Once: Unified, Real-Time Object Detection</a></li>
</ul>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
  </entry>
  <entry>
    <title>CornerNet：Detecting Objects as Paired Keypoints</title>
    <url>/2021/09/01/CornerNet-Detecting-Objects-as-Paired-Keypoints/</url>
    <content><![CDATA[<p>CornerNet 是一种用于目标检测的新方法，<strong>它使用单个卷积神经网络将物体的边界框检测为一对关键点，即左上角和右下角</strong>。 通过这种新思路，它摆脱了以往目标检测中使用的 anchor-base 机制，设计了一种新的池化方式 —— <strong>角点池化（corner pooling），可以帮助网络更好地定位角点。</strong>实验表明，CornerNet 在 MS COCO 数据集上到了 <strong>42.2%</strong> 的 AP 值，碾压了当时所有的 one-stage 检测算法。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CornerNet-Detecting-Objects-as-Paired-Keypoints--20210830145823.jpg">
</p>

<span id="more"></span>

<h2 id="1-CornerNet-介绍"><a href="#1-CornerNet-介绍" class="headerlink" title="1. CornerNet 介绍"></a>1. CornerNet 介绍</h2><p>现在基于 anchor-base 机制的目标检测算法的思路为：<strong>将一张图片下采样为低分辨率的特征图，在特征图的每个像素点上放置一些不同大小和宽高比的 anchor，然后让这些 anchor 框与 ground-truth 框进行响应并预测出对应的偏移量。</strong>anchor 的本质其实是候选框，由于目标的形状和位置具有多样性，因而 anchor 的数量往往会被设置得非常庞大从而保证足够多的 anchor 能与 ground-truth 框重叠。但是这也带来了以下两个缺点：</p>
<ul>
<li>需要大量的 anchor（例如 DSSD 需要 40K 个，RetinaNet 需要 100K 个），大量的 anchor 中其实只有少部分 anchor 和 ground-truth 相重合，其他则是负样本，这就造成了正负样本不均衡的局面。</li>
<li>anchor 框引入了许多超参，并且需要进行细致设计。包括 anchor 框的数量、尺寸、宽高比例。特别是在单一网络在多尺度进行预测的情况下会变得非常复杂，并且每个尺度都需要独立设计。</li>
</ul>
<p>基于上述两点原因，<strong>受 keypoint 问题的启发，就想到用关键点检测的思路来处理 detection 问题：只要找到左上角（top-left）和右下角（bottom-right）两个角点，就可以准确框出一个目标了。</strong>作者认为预测物体的角点比预测中心更容易，因为预测一个角点只需要物体的 2 个边，而预测中心却需要 4 个边。其次，角点检测的搜索复杂度仅为 O(wh)，而 proposal bboxes 的搜索复杂度却为 O(w^2h^2）（这是因为在  proposal bboxes 范围里又检索了一次特征，这导致大量  proposal bboxes 之间的特征存在冗余）。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CornerNet-Detecting-Objects-as-Paired-Keypoints--20210830203636.png">
</p>

<p>如下图所示：CornerNet 使用一个单一网络来预测所有目标的角点热图（heat map）和 embedding 向量，找出那些最有可能的角点并根据它们之间的 embedding 向量距离来进行分组。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CornerNet-Detecting-Objects-as-Paired-Keypoints--20210830161133.png">
</p>

<h2 id="2-检测角点"><a href="#2-检测角点" class="headerlink" title="2. 检测角点"></a>2. 检测角点</h2><h3 id="2-1-heatmap"><a href="#2-1-heatmap" class="headerlink" title="2.1 heatmap"></a>2.1 heatmap</h3><p>CornerNet 会输出两个热图（heat map）分别预测出所有目标的左上角和右下角的位置，每个热图的 shape 为 [C, H, W]，其中 C 是目标的类别（没有background channel），H 和 W 分别是高和宽。每个角点都有一个对应的 ground-truth 正位置，其他地方则是负位置，这里并没有对所有对负位置进行相同惩罚。<strong>这是因为在一些在离 ground-truth 一定半径范围内的角点，它们仍然能产生与 ground-truth 充分重叠的 bbox</strong>。</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CornerNet-Detecting-Objects-as-Paired-Keypoints--20210830164142.png">
</p>

<p>那么这个半径范围选多大呢，作者是这样说的：<strong>通过判断这些角点构成的预测框与 ground-truth 框之间的 iou 大于 t 时计算出半径</strong>，在论文里 t 设置为 0.3 。这个半径范围内，惩罚权重的衰减则由一个二维的高斯分布给出。为了减少正负样本不均衡性带来的影响，作者还用了 focal loss 来计算预测热图和真实热图之间的损失。</p>
<h3 id="2-2-location-offset"><a href="#2-2-location-offset" class="headerlink" title="2.2 location offset"></a>2.2 location offset</h3><p><strong>物体的位置精度在下采样时通常会丢失，比如图片上某个像素点 [x，y] 在经过 n 倍下采样后得到新位置为 [floor(x/n)，floor(y/n)]，floor 表示向下取整。</strong>当我们将这个新位置 remap 回原图时会偏离原来的位置，这会严重影响到一些小目标的预测。为了解决这个问题，CornerNet 采用<strong>预测位置偏移量（location offset）</strong>的方法来对角点位置进行微调。对于位置偏移量的定义，作者是这么定义的：</p>
<p align="center">
    <img width="35%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CornerNet-Detecting-Objects-as-Paired-Keypoints--20210830181448.png">
</p>

<p>从公式中可以看出，<strong>物体角点的精确位置减去其向下取整的位置（其实就是角点左上角最近的网格）就是偏移量。这种方法没什么新奇的，和 YOLOv3 对物体中心点位置预测的思路基本一致。</strong>对于偏移量的损失，作者采用了 smooth L1 Loss 函数。</p>
<h2 id="3-角点成对"><a href="#3-角点成对" class="headerlink" title="3. 角点成对"></a>3. 角点成对</h2><p>前面介绍的角点预测工作都是孤立的，不涉及一对角点构成一个检测框的概念。受 <a href="https://arxiv.org/abs/1611.05424">Newell 等人</a>姿态估计工作的启发，可以基于不同角点的 embedding 向量之间的距离来对它们进行关联。<strong>embedding 特征图的维度为 [N, H, W]，即每个角点都会产生一个 N 维的向量。考虑到 MOT 的数据集一般来说都比较小，ReID 特征的维度不宜过高，文章将 N 设置成了 1，</strong>这样 embedding 向量就成了一个标量。</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CornerNet-Detecting-Objects-as-Paired-Keypoints--20210830204425.png">
</p>

<p>这个向量编码了这个角点对应目标的特征，<strong>如果一个左上角和右下角属于同一个目标，那对应的这两个 embedding 向量应该很相似，因而它们之间的距离应该最小。网络在训练时，使用了 push 损失让同一个目标之间的角点距离最小，push 损失让不同目标之间的角点距离最大。</strong></p>
<h2 id="4-Corner-Pooling"><a href="#4-Corner-Pooling" class="headerlink" title="4. Corner Pooling"></a>4. Corner Pooling</h2><h3 id="4-1-角池化介绍"><a href="#4-1-角池化介绍" class="headerlink" title="4.1 角池化介绍"></a>4.1 角池化介绍</h3><p>预测框的角点通常在物体范围外，这使得角点附近没有可用的物体特征。例如为了确定像素是否在左上角，我们需要在水平方向上沿着物体的最上边界朝右看，而在垂直方向上沿着物体的最左边界朝下看。因此我们提出了一种角池化（corner pooling）操作，确保在池化过程中能够编码到整个物体的特征。</p>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CornerNet-Detecting-Objects-as-Paired-Keypoints--20210831123656.png">
</p>

<p>下面有 2 个输入特征图，宽高分别用 W 和 H 表示。<strong>假设接下来要对红点（i，j）做 corner pooling：在纵向上就要计算 (i, j) 到 (i, H) 的最大值，在横向上就要计算 (i, j) 到 (W, j) 的最大值，然后将这两个值相加即可。</strong></p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CornerNet-Detecting-Objects-as-Paired-Keypoints--20210831124339.png">
</p>

<p>动态规划其实可以减少这个计算的复杂度，我们可以在横向上从右往左、在纵向上从下往上去扫描计算最大值，这样大大减少了复杂度。如下图所示：以 2, 1, 3, 0, 2 这一行为例，最后的 2 保持不变，倒数第二个是 max(0,2) = 2，然后倒数第三个为 max(3,2)=3 …… 依次类推。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CornerNet-Detecting-Objects-as-Paired-Keypoints--20210831124856.png">
</p>

<h3 id="4-2-角池化位置"><a href="#4-2-角池化位置" class="headerlink" title="4.2 角池化位置"></a>4.2 角池化位置</h3><p>corner pooling 层放在预测模块（prediction module）里，用于预测热图和 embedding 向量。预测模块对何凯明的残差模块做了修改：将第一个 3×3 卷积模块替换为一个 corner pooling 模块，它通过两个具有 128 个通道的 3×3 卷积模块处理来自主干网的特征，然后再应用于 corner pooling 层，接着将特征合并送入 256 个通道的 3×3 Conv-BN 层中并与 short-cut 特征融合，以生成热图、embedding 向量和位置偏移量。</p>
<p align="center">
    <img width="80%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/CornerNet-Detecting-Objects-as-Paired-Keypoints--20210831130846.png">
</p>

<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwicmO2w29jyAhURwosBHSAECHUQFnoECAQQAQ&url=https://heilaw.github.io/slides/CornerNet.pptx&usg=AOvVaw3MegcZlGlGI-F7tM6Pp8qP">[1] CornerNet: Detecting Objects as Paired Keypoints - PPT</a></li>
<li><a href="https://arxiv.org/abs/1808.01244">[2] CornerNet: Detecting Objects as Paired Keypoints - paper</a></li>
</ul>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>anchor free</tag>
      </tags>
  </entry>
  <entry>
    <title>DeepSort：多目标跟踪算法 Sort 的进化版</title>
    <url>/2021/08/27/DeepSort-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E7%AE%97%E6%B3%95-SORT-%E7%9A%84%E8%BF%9B%E9%98%B6%E7%89%88/</url>
    <content><![CDATA[<p>在<a href="https://yunyang1994.gitee.io/2021/08/14/%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AASORT%E7%AE%97%E6%B3%95-Simple-Online-and-Realtime-Tracking/">之前的 Sort 算法</a>中讲到：<strong>尽管 Sort 具有速度快和计算量较小的优点，但它在关联匹配时没有用到物体的表观特征，导致物体被遮挡时容易出现 id-switch 的情况。</strong>针对这个算法的痛点，原 author 团队又发明了 Sort 的进化版 —— <a href="https://arxiv.org/abs/1703.07402">DeepSort: Simple Online and Realtime Tracking with a Deep Associate Metric</a></p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827115042.png">
</p>
<span id="more"></span>

<h2 id="1-卡尔曼滤波追踪器"><a href="#1-卡尔曼滤波追踪器" class="headerlink" title="1. 卡尔曼滤波追踪器"></a>1. 卡尔曼滤波追踪器</h2><p><strong>DeepSort 的 KalmanFilter 假定跟踪场景是定义在 8 维状态空间（u, v, γ, h, ẋ, ẏ, γ̇, ḣ）中， 边框中心（u, v），宽高比 γ，高度 h 和和它们各自在图像坐标系中的速度。</strong>这里依旧使用的是匀速运动模型，并把（u，v，γ，h）作为对象状态的直接观测量（direct observations of the object state.）。在目标跟踪中，需要估计目标的以下两个状态：</p>
<ul>
<li><strong>均值(Mean)</strong>：包含目标的中心位置和速度信息，由 8 维向量（u, v, γ, h, ẋ, ẏ, γ̇, ḣ）表示，其中每个速度值初始化为 0。均值 Mean 可以通过观测矩阵 H 投影到测量空间输出（u，v，γ，h）。</li>
<li><strong>协方差(Covariance)</strong>：表示估计状态的不确定性，由 8x8 的对角矩阵表示，矩阵中数字越大则表明不确定性越大。</li>
</ul>
<p>关于以下公式的变量和符号说明，请参考<a href="https://yunyang1994.gitee.io/2021/07/10/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%AE%97%E6%B3%95-%E6%B0%B8%E8%BF%9C%E6%BB%B4%E7%A5%9E/">卡尔曼滤波算法，永远滴神！</a></p>
<h3 id="1-1-predict-阶段"><a href="#1-1-predict-阶段" class="headerlink" title="1.1 predict 阶段"></a>1.1 predict 阶段</h3><ul>
<li>step1：首先利用上一时刻 k-1 的后验估计值通过状态转移矩阵 F 变换得到当前时刻 k 的先验估计状态</li>
</ul>
<p align="center">
    <img width="14%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827150310.png">
</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827153028.png">
</p>

<ul>
<li>step2：然后使用上一时刻 k-1 的后验估计协方差来计算当前时刻 k 的先验估计协方差</li>
</ul>
<p align="center">
    <img width="23%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827153635.png">
</p>

<p>整个过程如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self, mean, covariance</span>):</span></span><br><span class="line">    <span class="comment"># mean, covariance 相当于上一时刻的后验估计均值和协方差</span></span><br><span class="line">    </span><br><span class="line">    std_pos = [</span><br><span class="line">        self._std_weight_position * mean[<span class="number">3</span>],</span><br><span class="line">        self._std_weight_position * mean[<span class="number">3</span>],</span><br><span class="line">        <span class="number">1e-2</span>,</span><br><span class="line">        self._std_weight_position * mean[<span class="number">3</span>]]</span><br><span class="line">    std_vel = [</span><br><span class="line">        self._std_weight_velocity * mean[<span class="number">3</span>],</span><br><span class="line">        self._std_weight_velocity * mean[<span class="number">3</span>],</span><br><span class="line">        <span class="number">1e-5</span>,</span><br><span class="line">        self._std_weight_velocity * mean[<span class="number">3</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化噪声矩阵 Q</span></span><br><span class="line">    motion_cov = np.diag(np.square(np.r_[std_pos, std_vel]))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># x&#x27; = Fx</span></span><br><span class="line">    mean = np.dot(self._motion_mat, mean)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># P&#x27; = FPF^T + Q</span></span><br><span class="line">    covariance = np.linalg.multi_dot((</span><br><span class="line">        self._motion_mat, covariance, self._motion_mat.T)) + motion_cov</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 返回当前时刻的先验估计均值 x 和协方差 P</span></span><br><span class="line">    <span class="keyword">return</span> mean, covariance</span><br></pre></td></tr></table></figure>

<p>predict 函数的输入为卡尔曼滤波器在上一时刻的后验估计均值 <code>x_&#123;k-1&#125;</code> 和协方差 <code>P_&#123;k-1&#125;</code>，输出为当前时刻的先验估计均值<code>x_&#123;k&#125;</code> 和协方差 <code>P_&#123;k&#125;</code>。</p>
<h3 id="1-2-update-阶段"><a href="#1-2-update-阶段" class="headerlink" title="1.2 update 阶段"></a>1.2 update 阶段</h3><ul>
<li>step1：首先利用先验估计协方差矩阵 P 和观测矩阵 H 以及测量状态协方差矩阵 R 计算出卡尔曼增益矩阵 K</li>
</ul>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827170204.png">
</p>

<ul>
<li>step2：然后将卡尔曼滤波器的先验估计值 x 通过观测矩阵 H 投影到测量空间，并计算出与测量值 z 的残差 y</li>
</ul>
<p align="center">
    <img width="16%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827162140.png">
</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827173356.png">
</p>

<ul>
<li>step3：将卡尔曼滤波器的预测值和测量值按照卡尔曼增益的比例相融合，得到后验估计值 x</li>
</ul>
<p align="center">
    <img width="16%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827171038.png">
</p>

<ul>
<li>step4：计算出卡尔曼滤波器的后验估计协方差</li>
</ul>
<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827171350.png">
</p>

<p>整个过程如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self, mean, covariance, measurement</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将先验估计的均值和协方差映射到检测空间，得到 Hx&#x27; 和 HP&#x27;</span></span><br><span class="line">    projected_mean, projected_cov = self.project(mean, covariance)</span><br><span class="line"></span><br><span class="line">    chol_factor, lower = scipy.linalg.cho_factor(</span><br><span class="line">        projected_cov, lower=<span class="literal">True</span>, check_finite=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算卡尔曼增益 K</span></span><br><span class="line">    kalman_gain = scipy.linalg.cho_solve(</span><br><span class="line">        (chol_factor, lower), np.dot(covariance, self._update_mat.T).T,</span><br><span class="line">        check_finite=<span class="literal">False</span>).T</span><br><span class="line"></span><br><span class="line">    <span class="comment"># y = z - Hx&#x27;</span></span><br><span class="line">    innovation = measurement - projected_mean</span><br><span class="line"></span><br><span class="line">    <span class="comment"># x = x&#x27; + Ky</span></span><br><span class="line">    new_mean = mean + np.dot(innovation, kalman_gain.T)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># P = (I - KH)P&#x27;</span></span><br><span class="line">    new_covariance = covariance - np.linalg.multi_dot((</span><br><span class="line">        kalman_gain, projected_cov, kalman_gain.T))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回当前时刻的后验估计均值 x 和协方差 P</span></span><br><span class="line">    <span class="keyword">return</span> new_mean, new_covariance</span><br></pre></td></tr></table></figure>

<table><center><td bgcolor=Plum><font color=black>
最后总结一下：predict 阶段和 update 阶段都是为了计算出卡尔曼滤波的<strong><font color=blue>估计均值 x </font></strong>和<strong><font color= blue>协方差 P</font></strong>，不同的是前者是基于上一历史状态做出的<strong><font color=green>先验估计</font></strong>，而后者则是融合了测量值信息并作出校正的<font color=green><strong>后验估计</strong></font>。
</font></strong></td></center></table>

<h3 id="1-3-跟踪器的状态"><a href="#1-3-跟踪器的状态" class="headerlink" title="1.3 跟踪器的状态"></a>1.3 跟踪器的状态</h3><p>DeepSort 的跟踪器一共有 3 种状态：当 tracker 初始化时，分配为待定状态（tentative）；如果连续 n_init 帧匹配上，则转化为确定状态（confirmed），否则为删除状态（deleted）；如果 tracker 在确定状态下连续 max_age 帧没匹配上，那么就会变成删除状态被回收。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210828221215.png">
</p>

<h2 id="2-关联度量"><a href="#2-关联度量" class="headerlink" title="2. 关联度量"></a>2. 关联度量</h2><p>解决卡尔曼滤波器的预测状态和测量状态之间的关联可以通过构建匈牙利匹配来实现，在这个过程中需要结合两个合适的指标来整合物体的运动信息和外观特征。</p>
<h3 id="2-1-马氏距离"><a href="#2-1-马氏距离" class="headerlink" title="2.1 马氏距离"></a>2.1 马氏距离</h3><p>为了整合物体的运动信息，使用了预测状态和测量状态之间的（平方）<a href="https://zh.wikipedia.org/wiki/%E9%A9%AC%E5%93%88%E6%8B%89%E8%AF%BA%E6%AF%94%E6%96%AF%E8%B7%9D%E7%A6%BB">马氏距离</a>：</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210828135516.png">
</p>

<p>在上式中，d 和 y 分别代表测量分布和预测分布，S 为两个分布之间的协方差矩阵。由于测量分布的维度（4 维）和预测分布的维度（8 维）不一致，因此需要先将预测分布通过观测矩阵 H 投影到测量空间中（这一步其实就是从 8 个估计状态变量中取出前 4 个测量状态变量，详见 <a href="https://github.com/nwojke/deep_sort/blob/280b8bdb255f223813ff4a8679f3e1321b08cdfc/deep_sort/kalman_filter.py#L125">project 函数</a>）。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Project state distribution to measurement space.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">project</span>(<span class="params">self, mean, covariance</span>):</span></span><br><span class="line">    std = [</span><br><span class="line">        self._std_weight_position * mean[<span class="number">3</span>],</span><br><span class="line">        self._std_weight_position * mean[<span class="number">3</span>],</span><br><span class="line">        <span class="number">1e-1</span>,</span><br><span class="line">        self._std_weight_position * mean[<span class="number">3</span>]]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化测量状态的协方差矩阵 R</span></span><br><span class="line">    innovation_cov = np.diag(np.square(std)) <span class="comment"># 使用的是对角矩阵，不同维度之间没有关联</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将均值向量映射到检测空间 得到 Hx</span></span><br><span class="line">    mean = np.dot(self._update_mat, mean)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将协方差矩阵映射到检测空间，得到 HP&#x27;H^T</span></span><br><span class="line">    covariance = np.linalg.multi_dot((</span><br><span class="line">        self._update_mat, covariance, self._update_mat.T))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mean, covariance + innovation_cov <span class="comment"># 加上测量噪声</span></span><br></pre></td></tr></table></figure>

<p>协方差矩阵 S 是一个实对称正定矩阵，可以使用 Cholesky 分解来求解马氏距离，这部分内容就不展开讨论。在 DeepSort 代码中，计算马氏距离的整个过程如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Compute gating distance between state distribution and measurements.</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gating_distance</span>(<span class="params">self, mean, covariance, measurements,</span></span></span><br><span class="line"><span class="params"><span class="function">                    only_position=<span class="literal">False</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 首先需要先将预测状态分布的均值和协方差投影到测量空间</span></span><br><span class="line">    mean, covariance = self.project(mean, covariance)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 假如仅考虑中心位置</span></span><br><span class="line">    <span class="keyword">if</span> only_position:</span><br><span class="line">        mean, covariance = mean[:<span class="number">2</span>], covariance[:<span class="number">2</span>, :<span class="number">2</span>]</span><br><span class="line">        measurements = measurements[:, :<span class="number">2</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对协方差矩阵进行 cholesky 分解</span></span><br><span class="line">    cholesky_factor = np.linalg.cholesky(covariance)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算两个分布之间对差值</span></span><br><span class="line">    d = measurements - mean</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通过三角求解计算出马氏距离</span></span><br><span class="line">    z = scipy.linalg.solve_triangular(</span><br><span class="line">        cholesky_factor, d.T, lower=<span class="literal">True</span>, check_finite=<span class="literal">False</span>,</span><br><span class="line">        overwrite_b=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 返回平方马氏距离</span></span><br><span class="line">    squared_maha = np.<span class="built_in">sum</span>(z * z, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> squared_maha</span><br></pre></td></tr></table></figure>

<p>马氏距离通过计算检测框距离预测框有多远的偏差来估计跟踪器状态的不确定性，<strong>此外还可以通过在 95% 的置信区间上从逆 χ2 分布中计算出的马氏距离来排除不可能的关联。</strong>在 DeepSort 的 4 维测量空间中，相应的马氏距离阈值为 9.4877，如果两个匹配框之间的马氏距离大于这个值，那么就认为两个框是不可能关联了。</p>
<h3 id="2-2-外观特征"><a href="#2-2-外观特征" class="headerlink" title="2.2 外观特征"></a>2.2 外观特征</h3><p>当物体运动状态的不确定性比较低时，使用马氏距离确实是一个不错的选择。由于卡尔曼滤波器使用的是匀速运动模型，它只能对物体的运动位置提供一个相对粗略的线性估计。<strong>当物体突然加速或减速时，跟踪器的预测框和检测框之间的距离就会变得比较远，这时仅使用马氏距离就会变得非常不准确</strong>。</p>
<p>因此 DeepSort 还对每个目标<strong>设计了一个深度外观特征描述符，它其实是一个在行人重识别数据集上离线训练的 ReID 网络提取到的 128 维单位特征向量（模长为 1 ）</strong>。对于每个追踪器 tracker，保留它最后 100 个与检测框关联成功的外观特征描述符集合 R 并计算出它们和检测框的最小余弦距离：</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210828151324.png">
</p>

<p>同样，可以设置一个合适的阈值来排除那些外观特征相差特别大的匹配。</p>
<h3 id="2-3-互相补充"><a href="#2-3-互相补充" class="headerlink" title="2.3 互相补充"></a>2.3 互相补充</h3><p>上述两个指标可以互相补充从而解决关联匹配的不同问题：<strong>一方面，马氏距离基于运动可以提供有关可能的物体位置的信息，这对于短期预测特别有用；另一方面，当运动的判别力较弱时，余弦距离会考虑外观信息，这对于长时间遮挡后恢复身份特别有用</strong>。</p>
<p>为了建立关联问题，我们使用加权总和将两个指标结合起来：</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210828155133.png">
</p>

<p>如果它同时在两个指标的门控范围之内，我们称其为可接受的关联。可以通过超参数 λ 来控制每个指标对合并成本的影响。在论文的实验过程中，发现当摄像机运动较大时，将 λ=0 是合理的选择（此时仅用到了外观信息）。</p>
<h2 id="3-1-匹配问题"><a href="#3-1-匹配问题" class="headerlink" title="3.1 匹配问题"></a>3.1 匹配问题</h2><h3 id="3-1-级联匹配"><a href="#3-1-级联匹配" class="headerlink" title="3.1 级联匹配"></a>3.1 级联匹配</h3><p>为了解决全局分配问题中检测框与跟踪器的关联，我们引入了一个级联来解决一系列的子问题。不妨先考虑这种场景：<strong>当物体被长时间遮挡时，后续的卡尔曼滤波预测结果会增大与物体位置关联的不确定性。因此概率分布会在状态空间中弥散，观察似然性就会变得比较平坦。</strong>关联度量应该增加检测框到预测框之间的距离来考虑这种概率分布的弥散，故而引入了一个级联匹配来优先考虑年龄较小的跟踪器：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">matching_cascade</span>(<span class="params"></span></span></span><br><span class="line"><span class="params"><span class="function">        distance_metric, max_distance, cascade_depth, tracks, detections,</span></span></span><br><span class="line"><span class="params"><span class="function">        track_indices=<span class="literal">None</span>, detection_indices=<span class="literal">None</span></span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> track_indices <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        track_indices = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(tracks)))</span><br><span class="line">    <span class="keyword">if</span> detection_indices <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        detection_indices = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">len</span>(detections)))</span><br><span class="line"></span><br><span class="line">    unmatched_detections = detection_indices</span><br><span class="line">    matches = []</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 遍历不同年龄</span></span><br><span class="line">    <span class="keyword">for</span> level <span class="keyword">in</span> <span class="built_in">range</span>(cascade_depth):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(unmatched_detections) == <span class="number">0</span>:  <span class="comment"># No detections left</span></span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 挑选出对应年龄的跟踪器</span></span><br><span class="line">        track_indices_l = [</span><br><span class="line">            k <span class="keyword">for</span> k <span class="keyword">in</span> track_indices</span><br><span class="line">            <span class="keyword">if</span> tracks[k].time_since_update == <span class="number">1</span> + level</span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(track_indices_l) == <span class="number">0</span>:  <span class="comment"># Nothing to match at this level</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 将跟踪器和尚未匹配的检测框进行匹配</span></span><br><span class="line">        matches_l, _, unmatched_detections = \</span><br><span class="line">            min_cost_matching(</span><br><span class="line">                distance_metric, max_distance, tracks, detections,</span><br><span class="line">                track_indices_l, unmatched_detections)</span><br><span class="line">        matches += matches_l</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 挑选出未匹配的跟踪器</span></span><br><span class="line">    unmatched_tracks = <span class="built_in">list</span>(<span class="built_in">set</span>(track_indices) - <span class="built_in">set</span>(k <span class="keyword">for</span> k, _ <span class="keyword">in</span> matches))</span><br><span class="line">    <span class="keyword">return</span> matches, unmatched_tracks, unmatched_detections</span><br></pre></td></tr></table></figure>

<p>在级联匹配的花费矩阵里，元素值为马氏距离和余弦距离的加权和。该匹配的精髓在于：<strong>挑选出所有 confirmed tracks，优先让那些年龄较小的 tracks 和未匹配的检测框相匹配，然后才轮得上那些年龄较大的 tracks 。</strong>这就使得在相同的外观特征和马氏距离的情况下，年龄较小的跟踪器更容易匹配上。<strong>至于年龄 age 的定义，跟踪器每次 predict 时则 age + 1。</strong> </p>
<h3 id="3-2-IOU-匹配"><a href="#3-2-IOU-匹配" class="headerlink" title="3.2 IOU 匹配"></a>3.2 IOU 匹配</h3><p>这个阶段是发生在级联匹配之后，匹配的跟踪器对象为那些 unconfirmed tracks 以及上一轮级联匹配失败中 age 为 1 的 tracks. 这有助于解决因上一帧部分遮挡而引起的突然出现的外观变化，从而减少被遗漏的概率。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 从所有的跟踪器里挑选出 unconfirmed tracks</span></span><br><span class="line">unconfirmed_tracks = [</span><br><span class="line">    i <span class="keyword">for</span> i, t <span class="keyword">in</span> <span class="built_in">enumerate</span>(self.tracks) <span class="keyword">if</span> <span class="keyword">not</span> t.is_confirmed()]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从上一轮级联匹配失败的跟踪器中挑选出连续 1 帧没有匹配上（相当于age=1）</span></span><br><span class="line"><span class="comment"># 的跟踪器，并和 unconfirmed_tracks 相加</span></span><br><span class="line">iou_track_candidates = unconfirmed_tracks + [</span><br><span class="line">    k <span class="keyword">for</span> k <span class="keyword">in</span> unmatched_tracks_a <span class="keyword">if</span></span><br><span class="line">    self.tracks[k].time_since_update == <span class="number">1</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将它们与剩下没匹配上的 detections 进行 IOU 匹配</span></span><br><span class="line">matches_b, unmatched_tracks_b, unmatched_detections = \</span><br><span class="line">    linear_assignment.min_cost_matching(</span><br><span class="line">        iou_matching.iou_cost, self.max_iou_distance, self.tracks,</span><br><span class="line">        detections, iou_track_candidates, unmatched_detections)</span><br></pre></td></tr></table></figure>

<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="https://arxiv.org/abs/1703.07402">[1] Simple Online and Realtime Tracking with a Deep Association Metric</a></li>
<li><a href="https://github.com/nwojke/deep_sort">[2] https://github.com/nwojke/deep_sort</a></li>
<li><a href="https://arxiv.org/abs/1602.00763">[3] Simple Online and Realtime Tracking</a></li>
</ul>
]]></content>
      <categories>
        <category>目标跟踪</category>
      </categories>
      <tags>
        <tag>DeepSort</tag>
      </tags>
  </entry>
  <entry>
    <title>三维人体动捕模型 SMPL：A Skinned Multi Person Linear Model</title>
    <url>/2021/08/21/%E4%B8%89%E7%BB%B4%E4%BA%BA%E4%BD%93%E6%A8%A1%E5%9E%8B-SMPL-A-Skinned-Multi-Person-Linear-Model/</url>
    <content><![CDATA[<p>在<strong>人体动作捕捉</strong>（motion capture）领域，SMPL 算法最为常见，它是由德国马普所提出的一种参数化的三维人体动捕模型，具有通用性、易于渲染和兼容现有商业软件（比如 UE4 和 Unity）的优点。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/三维人体模型-SMPL-A-Skinned-Multi-Person-Linear-Model-20210816165705.png">
</p>

<p>「这是一篇鸽了很久的文章，今天补上。」</p>
<span id="more"></span>

<h2 id="1-人体动捕介绍"><a href="#1-人体动捕介绍" class="headerlink" title="1. 人体动捕介绍"></a>1. 人体动捕介绍</h2><h3 id="1-1-动作捕捉技术"><a href="#1-1-动作捕捉技术" class="headerlink" title="1.1 动作捕捉技术"></a>1.1 动作捕捉技术</h3><p>目前人体动作捕捉技术在影视制作和游戏领域已经应用得很成熟了，最常见的就是基于可穿戴设备（比如 IMU）的人体动捕技术。当动作人做出运动时，穿戴的传感器会捕捉人体的姿态数据并回传给虚拟角色，进而驱动虚拟角色做出与动作人相同的角色。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/三维人体模型-SMPL-A-Skinned-Multi-Person-Linear-Model-20210819170007.png">
</p>
美术师在制作一个虚拟形象模型时，会让其呈现 T-pose 摆放，并定义一套<strong>人体关节树（skeleton tree）</strong>。该关节树的特点在于每个<strong>关节点（joint）</strong>都有一个<strong>父节点（parent joint）</strong>，并且是<strong>一个父节点和一个子节点连接成一个关节</strong>。整个骨架的旋转和平移则通过<strong>根结点（root）</strong>实现，例如下图中 PELVIS 则是根节点。
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/三维人体模型-SMPL-A-Skinned-Multi-Person-Linear-Model-20210819173522.png">
</p>

<table>
<thead>
<tr>
<th align="center">Index</th>
<th align="center">Joint name</th>
<th align="center">Parent joint</th>
</tr>
</thead>
<tbody><tr>
<td align="center">0</td>
<td align="center">PELVIS</td>
<td align="center">-</td>
</tr>
<tr>
<td align="center">1</td>
<td align="center">SPINE_NAVAL</td>
<td align="center">PELVIS</td>
</tr>
<tr>
<td align="center">2</td>
<td align="center">SPINE_CHEST</td>
<td align="center">SPINE_NAVAL</td>
</tr>
<tr>
<td align="center">…</td>
<td align="center">…</td>
<td align="center">…</td>
</tr>
</tbody></table>
<p>如下图所示：<strong>每个关节点都有一套自己的坐标系，当人体在运动时，每个关节点就会相对其父节点发生旋转，这个旋转过程可以用一个四元数表达。</strong>如果两套虚拟形象的关节点坐标系朝向不一致，那么还需要进行一些适配工作（相当枯燥乏味）。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/三维人体模型-SMPL-A-Skinned-Multi-Person-Linear-Model-20210819180003.png">
</p>

<h3 id="1-2-线性混合蒙皮"><a href="#1-2-线性混合蒙皮" class="headerlink" title="1.2 线性混合蒙皮"></a>1.2 线性混合蒙皮</h3><p>SMPL 涉及到游戏制作和渲染技术里面的一些东西，特别是计算机图形学领域。考虑到 SMPL 是在 LBS（Linear Blending Skinning，线性混合蒙皮）的基础上开发的，因此先对 LBS 做个简单的介绍。</p>
<p>对于一个虚拟形象，其实可以大致分为两大块：<strong>骨架（bones）</strong>和<strong>表皮（skin）</strong>。骨架一般由一套<strong>关节树（skeleton tree）</strong>构成，表皮则由一系列的<strong>网格顶点（vertices）</strong>组成，每个 vertices 都有坐标位置 xyz，然后这些 vertices 就组成了面（也就是表皮）。 在虚拟形象的美术制作过程中，通常是先制作出一套骨架，然后将这些网格顶点（皮）在 rest-pose 状态下按照一定的权重绑定在每个关节上，这个过程我们称之为<strong>蒙皮（skinning）</strong>。</p>
<p align="center">
    <img width="80%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/三维人体模型-SMPL-A-Skinned-Multi-Person-Linear-Model-20210818173252.png">
</p>

<p>当虚拟形象发生运动时，骨骼的每个关节也会发生相应的旋转和位移，这个时候所绑定的网格顶点就需要根据每个绑定的关节点的影响加权求和算出运动后的位置。由于整个过程都是可以通过矩阵的线性运算得到，并且考虑到了所有关节点的混合影响，因此称为<strong>线性混合蒙皮</strong>。</p>
<p>LBS 主要是用来计算蒙皮后的网格顶点位置，假设虚拟人物一共有 <code>&#123;1，2，3，...，m&#125;</code> 个关节点，<code>n</code> 个网格顶点，其数学表达式如下：</p>
<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/三维人体模型-SMPL-A-Skinned-Multi-Person-Linear-Model-20210818175355.png">
</p>

<p><code>p&#39;</code> 为蒙皮后的网格顶点新位置，维度为 <code>[n, 3]</code>；<code>w</code> 为<strong>权重矩阵</strong>，维度为 <code>[n, m]</code>；<code>T</code> 则是每个关节点的<strong>仿射变换矩阵</strong>，维度为 <code>[m, 4, 4]</code>，该矩阵代表了关节点的旋转和平移；<code>p</code> 为蒙皮前的网格顶点位置。</p>
<h2 id="2-SMPL-模型"><a href="#2-SMPL-模型" class="headerlink" title="2. SMPL 模型"></a>2. SMPL 模型</h2><h3 id="2-1-SMPL-的背景"><a href="#2-1-SMPL-的背景" class="headerlink" title="2.1 SMPL 的背景"></a>2.1 SMPL 的背景</h3><p>LBS 面临的一个难点是：<strong>线性混合蒙皮算法会出现皮肤塌陷和皱褶的问题</strong>，作者称之为<strong> “taffy”（太妃糖） </strong>和<strong> “bowtie”（领结）</strong>。比如下图中当手臂弯曲的时候，LBS 的效果（青绿色）就折叠得比较夸张，而且在关节连接处不能提供平滑自然的过渡。<strong>目前商业上普遍的做法是通过人工绑定（rigging）和手工雕刻 blend shape 来改善这个问题，这个过程会比较耗费人力。</strong></p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/三维人体模型-SMPL-A-Skinned-Multi-Person-Linear-Model-20210819151954.png">
</p>

<p>SMPL 较好地解决了上述的痛点，并且一开始的出发点就是为了提出业界兼容、简单易用和渲染速度快的三维人体重建模型，作者认为像这种以往需要人工绑定（rigging）和手工雕刻 blend shape 的过程其实是可以通过大量数据学习得到。</p>
<h3 id="2-2-SMPL-参数定义"><a href="#2-2-SMPL-参数定义" class="headerlink" title="2.2 SMPL 参数定义"></a>2.2 SMPL 参数定义</h3><p>SMPL 模型一共定义了 <code>N=6890</code> 个 vertices 和 <code>K=23</code> 个 joints，并且通过以下两类统计参数对人体进行描述。</p>
<ul>
<li><p><strong>体型参数 β：</strong>拥有 10 个维度去描述一个人的身材形状，每一个维度的值都可以解释为人体形状的某个指标，比如高矮，胖瘦等。</p>
</li>
<li><p><strong>姿态参数 θ：</strong>拥有 24×3 个维度去描述人体的动作姿态，其中 24 指的是 23 个关节点 + 1 个根结点，3 则指的是轴角（axis-angle）里的数值。</p>
</li>
</ul>
<p>在 python 代码中，我们可以这样随机设置 SMPL 参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 设置身材参数 betas 和姿态参数 poses</span></span><br><span class="line">betas = np.random.rand(<span class="number">10</span>) * <span class="number">0.03</span></span><br><span class="line">poses = np.random.rand(<span class="number">72</span>) * <span class="number">0.20</span></span><br></pre></td></tr></table></figure>

<h3 id="2-3-SMPL-的过程"><a href="#2-3-SMPL-的过程" class="headerlink" title="2.3 SMPL 的过程"></a>2.3 SMPL 的过程</h3><p>SMPL 过程主要可以分为以下三大阶段：</p>
<h4 id="1-基于形状的-blend-shape-（混合变形）"><a href="#1-基于形状的-blend-shape-（混合变形）" class="headerlink" title="1. 基于形状的 blend shape （混合变形）"></a>1. 基于形状的 blend shape （混合变形）</h4><p>人体的网格顶点（vertices）会随着 shape 参数 β 变化而变化，这个变化过程是在一个<strong>基模版（或者称之为统计上的均值模版，mean template）</strong>上线性叠加的。关于这个<strong>线性叠加偏量</strong>，作者使用了 <code>Bs(β)</code> 函数来计算：</p>
<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/三维人体模型-SMPL-A-Skinned-Multi-Person-Linear-Model-20210819202619.png">
</p>

<p>它表示每个 shape 参数对 vertices 的影响。其中 S （对应 <code>smpl[&#39;shapedirs&#39;]</code>）是通过数据学习出来的，它的维度为 (6890, 3, 10)。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 根据 betas 调整 T-pose, 计算 vertices</span></span><br><span class="line">v_shaped = smpl[<span class="string">&#x27;shapedirs&#x27;</span>].dot(betas) + smpl[<span class="string">&#x27;v_template&#x27;</span>]  <span class="comment"># 还要与基模版相加</span></span><br></pre></td></tr></table></figure>
<h4 id="2-基于姿态的-blend-shape"><a href="#2-基于姿态的-blend-shape" class="headerlink" title="2. 基于姿态的 blend shape"></a>2. 基于姿态的 blend shape</h4><p>前面计算的是人体在静默姿态（T-pose）下的 blend shape，这里将计算人体在不同 pose 参数 θ 下的影响。同样的定义了一个函数 <code>Bp(θ)</code> 计算该线性叠加偏量：</p>
<p align="center">
    <img width="35%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/三维人体模型-SMPL-A-Skinned-Multi-Person-Linear-Model-20210819204307.png">
</p>

<p>在上面公式中，<strong>因为我们是计算相对 T-pose 状态下的线性叠加偏量，所以人体的位姿应该也是要相对 T-pose 状态下进行变化，因此括号里减去了 T-pose 位姿的影响。</strong>每个 pose 参数都用旋转矩阵 R 表示，所以是 9K。同样 P （即权重矩阵，对应 <code>smpl[&#39;posedirs&#39;]</code>）也是通过数据学习出来的，它的维度为 (6890, 3, 207），其中 207 是因为 23x9 得到。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">posemap</span>(<span class="params">p</span>):</span></span><br><span class="line">    p = p.ravel()[<span class="number">3</span>:]   <span class="comment"># 跳过根结点</span></span><br><span class="line">    <span class="keyword">return</span> np.concatenate([(cv2.Rodrigues(</span><br><span class="line">        np.array(pp))[<span class="number">0</span>]-np.eye(<span class="number">3</span>)).ravel() <span class="keyword">for</span> pp <span class="keyword">in</span> p.reshape((-<span class="number">1</span>,<span class="number">3</span>))]).ravel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算受 pose 影响下调整臀部之后的 vertices</span></span><br><span class="line">v_posed = v_shaped + smpl[<span class="string">&#x27;posedirs&#x27;</span>].dot(utils.posemap(poses))</span><br></pre></td></tr></table></figure>
<h4 id="3-蒙皮过程（blend-skinning）"><a href="#3-蒙皮过程（blend-skinning）" class="headerlink" title="3. 蒙皮过程（blend skinning）"></a>3. 蒙皮过程（blend skinning）</h4><p>当人体关节（joint）运动时，由网格顶点（vertex）组成的“皮肤”将会随着关节的运动而变化，这个过程称之为蒙皮。<strong>蒙皮过程可以认为是皮肤节点随着关节的变化而产生的加权线性组合。</strong>简单来说，就是距离某个具体的关节越近的端点，其跟随着该关节旋转/平移等变化的影响越强。</p>
<p>由于输入的 pose 参数是每个子关节点相对父关节点进行旋转的（ relative rota- tion of part k with respect to its parent in the kinematic tree），因此需要计算每个关节坐标系变换到相机坐标系的 transform 矩阵 T：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rodrigues = <span class="keyword">lambda</span> x: cv2.Rodrigues(x)[<span class="number">0</span>]</span><br><span class="line">Ts = np.zeros([<span class="number">24</span>,<span class="number">4</span>,<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 首先计算根结点 (0) 的相机坐标变换, 或者说是根结点相对相机坐标系的位姿</span></span><br><span class="line">T = np.zeros([<span class="number">4</span>,<span class="number">4</span>])</span><br><span class="line">T[:<span class="number">3</span>, :<span class="number">3</span>] = rodrigues(poses[<span class="number">0</span>])     <span class="comment"># 轴角转换到旋转矩阵，相对相机坐标而言</span></span><br><span class="line">T[:<span class="number">3</span>, <span class="number">3</span>] = J[<span class="number">0</span>]                     <span class="comment"># 根结点在相机坐标系下的位置</span></span><br><span class="line">T[<span class="number">3</span>, <span class="number">3</span>] = <span class="number">1</span>                         <span class="comment"># 齐次矩阵，1</span></span><br><span class="line">Ts[<span class="number">0</span>] = T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算子节点 (1~24) 的相机坐标变换</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">24</span>):</span><br><span class="line">    <span class="comment"># 首先计算子节点相对父节点坐标系的位姿 [R|t]</span></span><br><span class="line">    T = np.zeros([<span class="number">4</span>,<span class="number">4</span>])</span><br><span class="line">    T[<span class="number">3</span>, <span class="number">3</span>] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算子节点相对父节点的旋转矩阵 R</span></span><br><span class="line">    T[:<span class="number">3</span>, :<span class="number">3</span>] = rodrigues(poses[i])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算子节点相对父节点的偏移量 t</span></span><br><span class="line">    T[:<span class="number">3</span>, <span class="number">3</span>]  = J[i] - J[parent[i]]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 然后计算子节点相对相机坐标系的位姿</span></span><br><span class="line">    Ts[i] = np.matmul(Ts[parent[i]], T) <span class="comment"># 乘上其父节点的变换矩阵</span></span><br><span class="line">    <span class="built_in">print</span>(Ts[i])</span><br><span class="line"></span><br><span class="line">global_joints = Ts[:, :<span class="number">3</span>, <span class="number">3</span>].copy() <span class="comment"># 所有关节点在相机坐标系下的位置</span></span><br></pre></td></tr></table></figure>

<p><strong>在人体动作捕捉领域中，描述人体关节点的刚性运动指的是每个关节点在运动时相对于静默姿态（T-pose）时的旋转平移。</strong>例如对于左腿抬起这样一个动作，1 号节点 <code>L_HIP</code> 可以通过 T1 矩阵从静默姿态变换到该姿态，并且底下的子节点都会发生相应的变换（这在上一步骤子节点乘上父节点的变换矩阵已体现）。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/三维人体模型-SMPL-A-Skinned-Multi-Person-Linear-Model-20210821150131.png">
</p>

<p><strong>由于 SMPL 模型的子节点在 T-pose 状态下坐标系的朝向和相机坐标系相同</strong>，因此旋转矩阵不用发生变化, 只需要减去 T-pose 时的关节点位置得到相对偏移量就行：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 计算每个子节点相对 T-pose 时的位姿矩阵</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">24</span>):</span><br><span class="line">    R = Ts[i][:<span class="number">3</span>, :<span class="number">3</span>]</span><br><span class="line">    t = Ts[i][:<span class="number">3</span>, <span class="number">3</span>] - R.dot(J[i]) <span class="comment"># 子节点相对T-pose的偏移 t</span></span><br><span class="line">    Ts[i][:<span class="number">3</span>, <span class="number">3</span>] = t</span><br></pre></td></tr></table></figure>

<p>以上 <code>Ts</code> 就是各个子节点相对各自在 T-pose 情况下的变换矩阵（transform matrix)，该矩阵可以使得每个 vertices 在 T-pose 状态下的位置映射到发生运动时的新位置。蒙皮时还要考虑所有关节对每个 vertice 的加权影响，因此乘上一个维度为 (6890, 24) 的加权矩阵 <code>smpl[&#39;weights&#39;]</code>：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 开始蒙皮操作，LBS 过程</span></span><br><span class="line">vertices_homo = np.matmul(smpl[<span class="string">&#x27;weights&#x27;</span>].dot(Ts.reshape([<span class="number">24</span>,<span class="number">16</span>])).reshape([-<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>]),</span><br><span class="line">        v_posed_homo.T.reshape([-<span class="number">1</span>, <span class="number">4</span>, <span class="number">1</span>]))</span><br><span class="line">vertices = vertices_homo.reshape([-<span class="number">1</span>, <span class="number">4</span>])[:,:<span class="number">3</span>]    <span class="comment"># 由于是齐次矩阵，取前3列</span></span><br></pre></td></tr></table></figure>

<p>在得到网格顶点 vertices 后，还可以通过乘上一个 J_regressor 矩阵（通过大量数据学习得到）得到每个关节点的位置 joints （与 global_joints 的值基本相同）：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">joints = smpl[<span class="string">&#x27;J_regressor&#x27;</span>].dot(vertices)     <span class="comment"># 计算 pose 下 joints 位置，其值基本与 global_joints 一致</span></span><br></pre></td></tr></table></figure>

<h3 id="2-4-3D-到-2D-投影"><a href="#2-4-3D-到-2D-投影" class="headerlink" title="2.4 3D 到 2D 投影"></a>2.4 3D 到 2D 投影</h3><p><strong>上述过程中计算得到的网格顶点 vertices 和 joints 位置，都是在相机坐标系内。</strong>在一些相关的 SMPL 算法（如 vibe 和 expose）中，SMPL 的相机内参都是假定为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fx = <span class="number">5000</span></span><br><span class="line">fy = <span class="number">5000</span></span><br><span class="line">cx = width / <span class="number">2.</span> </span><br><span class="line">cy = height / <span class="number">2.</span></span><br><span class="line"></span><br><span class="line">K = np.zeros([<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">K[<span class="number">0</span>,<span class="number">0</span>] = fx</span><br><span class="line">K[<span class="number">1</span>,<span class="number">1</span>] = fy</span><br><span class="line">K[<span class="number">2</span>,<span class="number">2</span>] = <span class="number">1.</span></span><br><span class="line">K[:-<span class="number">1</span>,-<span class="number">1</span>] = np.array([cx, cy])</span><br></pre></td></tr></table></figure>

<p>这里一般不怎么涉及到相机的外参（假定为单位矩阵），因为相机的外参描述的是相机坐标系和世界坐标系之间的转换关系，这通常在虚拟角色和UE4里渲染场景相融合时才会用到。</p>
<p>有了相机的内参后，我们就可以将关节点的位置从相机坐标系变换到图像坐标系中。不妨先将三维 SMPL 人体基模版关节点投影到一张分辨率为 256x256 的图片中：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">root_transl = [<span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">50</span>]    <span class="comment"># 根结点位移(不是位置)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 基模版的关节点</span></span><br><span class="line">global_joints = smpl[<span class="string">&#x27;J_regressor&#x27;</span>].dot(smpl[<span class="string">&#x27;v_template&#x27;</span>])</span><br><span class="line">points = global_joints + root_transl</span><br><span class="line">points = points / points[:,<span class="number">2</span>:]  <span class="comment"># 归一化坐标</span></span><br><span class="line"></span><br><span class="line">projected_joints = points.dot(K.T)</span><br><span class="line">projected_joints = projected_joints[:, :<span class="number">2</span>].astype(np.<span class="built_in">int</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> projected_joint <span class="keyword">in</span> projected_joints:</span><br><span class="line">    image = cv2.circle(image, <span class="built_in">tuple</span>(projected_joint), <span class="number">3</span>, [<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>], <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(projected_joints)</span><br><span class="line">cv2.imwrite(<span class="string">&quot;skeleton.png&quot;</span>, image)</span><br></pre></td></tr></table></figure>

<p>需要说明的是：<strong>SMPL 模型一开始就假定人体是位于相机前方正中央的。但是在很多实际的场景中，人体位置复杂多变，因此就需要一个三维变量 <code>translation</code> 来描述与原始假定位置的偏移。</strong> 在上面代码中，我们依然设置人体位于相机的正前方，只不过远离了相机 50 个单元的距离，然后将三维人体关节点投影到图像中得到：</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/三维人体模型-SMPL-A-Skinned-Multi-Person-Linear-Model-20210823180106.png">
</p>

<p>为什么人体是倒立的呢？<strong>你要知道在相机坐标系中：向前是 z 轴，向下是 y 轴，向右是 x 轴，所以基模版的关节点这么看它就是倒立了。</strong>假如你要把它变换到我们常见的世界坐标系（向前 x 轴，向右 y 轴，向上 z 轴）中，那么将它们再乘以一个相应的 transform 矩阵就行了。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="https://files.is.tue.mpg.de/black/papers/SMPL2015.pdf">[1] SMPL: A Skinned Multi-Person Linear Model</a></li>
<li><a href="http://xb.sut.edu.cn/CN/abstract/abstract1733.shtml">[2] 基于李代数的人体手臂惯性动作捕捉算法</a></li>
<li><a href="https://github.com/YunYang1994/openwork/tree/master/smpl">[3] https://github.com/YunYang1994/openwork/tree/master/smpl</a></li>
</ul>
]]></content>
      <categories>
        <category>姿态估计</category>
      </categories>
  </entry>
  <entry>
    <title>多目标追踪 SORT 算法：Simple Online and Realtime Tracking</title>
    <url>/2021/08/14/%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AASORT%E7%AE%97%E6%B3%95-Simple-Online-and-Realtime-Tracking/</url>
    <content><![CDATA[<p>在<strong>多目标跟踪</strong>（multiple object tracking）领域，<a href="https://arxiv.org/abs/1602.00763">SORT（Simple Online and Realtime Tracking）</a>算是最经典的入门算法了。<a href="https://github.com/YunYang1994/openwork/tree/master/sort">这份代码</a>对该算法进行了 python 和 C++ 实现，感兴趣的可以点开看看。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/多目标追踪SORT算法-Simple-Online-and-Realtime-Tracking-20210812202019.png">
</p>

<span id="more"></span>

<h2 id="1-SORT-简介"><a href="#1-SORT-简介" class="headerlink" title="1. SORT 简介"></a>1. SORT 简介</h2><p>整个流程如下图所示：在第 1 帧时，<strong>人体检测器 detector 输出 3 个 bbox（黑色）</strong>，模型会分别为这 3 个 bbox 创建卡尔曼滤波追踪器 kf1，kf2 和 kf3，对应人的编号为 1，2，3 。在第 2 帧的过程 a 中，<strong>这 3 个跟踪器会利用上一帧的状态分别输出棕红色 bbox、黄色 bbox 和 青绿色 bbox</strong>。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/多目标追踪SORT算法-Simple-Online-and-Realtime-Tracking-20210812201919.png">
</p>

<table><center><td bgcolor=Plum><font color=black>
由于 detector 输出的黑色 bbox 是没有 id 的，因此需要将它们和上一帧的跟踪器相对应起来。换句话说就是把 detector 输出的目标检测框和 KalmanFilter 输出的预测框相<font color=black><strong>关联</strong></font>，这样使得每个目标检测框的 id 就是它所关联的跟踪器 id。这里关联的核心是：<font color=green><strong>用 iou 计算 bbox 之间的距离 ➕ 匈牙利算法匹配。</strong></font>
</font></strong></td></center></table>

<p>首先计算出 <strong><font color=red>detector 输出的目标检测框</font></strong>（黑色框）和 <strong><font color=red>KalmanFilter 输出的预测框</font></strong> （棕红色 bbox、黄色 bbox 和 青绿色 bbox）之间的 <strong><font color=red>iou 表格</font></strong>如下：</p>
<table>
<thead>
<tr>
<th align="center">iou</th>
<th align="center">黑色 bbox1</th>
<th align="center">黑色 bbox2</th>
<th align="center">黑色 bbox3</th>
</tr>
</thead>
<tbody><tr>
<td align="center">棕红色 bbox</td>
<td align="center">0.91</td>
<td align="center">0.00</td>
<td align="center">0.00</td>
</tr>
<tr>
<td align="center">黄色 bbox</td>
<td align="center">0.00</td>
<td align="center">0.98</td>
<td align="center">0.00</td>
</tr>
<tr>
<td align="center">青绿色 bbox</td>
<td align="center">0.00</td>
<td align="center">0.00</td>
<td align="center">0.99</td>
</tr>
</tbody></table>
<p>上表可以抽象成一个矩阵，如果是如上表所示的求和最小问题，那么这个矩阵就叫做<strong>花费矩阵（Cost Matrix）</strong>；如果要求的问题是使之和最大化，那么这个矩阵就叫做<strong>利益矩阵（Profit Matrix）</strong>。sort 算法使用的是花费矩阵，矩阵里的每一个元素值都是预测框和检测框之间的<strong> iou 距离（定义为 1-iou)</strong>，并使用了 <a href="https://www.pythonf.cn/read/34325">匈牙利算法</a> 进行最小化求解，它的最坏时间复杂度为 <code>O(n^3)</code>，python 求解如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> scipy.optimize <span class="keyword">import</span> linear_sum_assignment</span><br><span class="line"></span><br><span class="line">cost_matrix = np.array([[<span class="number">0.09</span>, <span class="number">1.00</span>, <span class="number">1.00</span>],</span><br><span class="line">                          [<span class="number">1.00</span>, <span class="number">0.02</span>, <span class="number">1.00</span>],</span><br><span class="line">                          [<span class="number">1.00</span>, <span class="number">1.00</span>, <span class="number">0.01</span>]])</span><br><span class="line"></span><br><span class="line">rows, cols = linear_sum_assignment(cost_matrix)</span><br><span class="line">matches = <span class="built_in">list</span>(<span class="built_in">zip</span>(rows, cols))        <span class="comment"># [(0, 0), (1, 1), (2, 2)] 得到匹配队列</span></span><br></pre></td></tr></table></figure>

<p>在完成目标检测框和跟踪器预测框的关联匹配后，我们还需要更新校正卡尔曼滤波跟踪器，并输出优化后的 bbox（如 frame2-b 所示）。需要补充以下两点：</p>
<ul>
<li><p>这里会对目标检测框进行修正和优化，是因为 detector 的检测框都有一定的抖动，而卡尔曼滤波刚好可以用于防抖。</p>
</li>
<li><p>跟踪器在 frame2-a 过程中输出的是基于上一历史状态的预测框，是一种先验估计；而在 frame2-b 过程中输出的则是将测量框（目标检测 bbox）与预测框（先验估计）加权后的结果，是一种后验估计。</p>
</li>
</ul>
<h2 id="2-KalmanBoxTracker"><a href="#2-KalmanBoxTracker" class="headerlink" title="2. KalmanBoxTracker"></a>2. KalmanBoxTracker</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KalmanBoxTracker</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    This class represents the internal state of individual tracked objects observed as bbox.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    count = <span class="number">0</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self,bbox</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Initialises a tracker using initial bounding box.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment">#define constant velocity model</span></span><br><span class="line">        self.kf = KalmanFilter(dim_x=<span class="number">7</span>, dim_z=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<h3 id="2-1-卡尔曼滤波参数"><a href="#2-1-卡尔曼滤波参数" class="headerlink" title="2.1 卡尔曼滤波参数"></a>2.1 卡尔曼滤波参数</h3><h4 id="状态变量-x"><a href="#状态变量-x" class="headerlink" title="状态变量 x"></a>状态变量 x</h4><p>状态变量 x 的设定是一个 7维向量：<code>x=[u, v, s, r, u^, v^, s^]T</code>。u、v 分别表示目标框的中心点位置的 x、y 坐标，s 表示目标框的面积，r 表示目标框的宽高比。u^、v^、s^ 分别表示横向 u(x方向)、纵向 v(y方向)、面积 s 的运动变化速率。</p>
<ul>
<li>u、v、s、r 初始化：根据第一帧的观测结果进行初始化。</li>
<li>u^、v^、s^ 初始化：当第一帧开始的时候初始化为0，到后面帧时会根据预测的结果来进行变化。</li>
</ul>
<h4 id="状态转移矩阵-F"><a href="#状态转移矩阵-F" class="headerlink" title="状态转移矩阵 F"></a>状态转移矩阵 F</h4><p>定义的是一个 <code>7x7</code> 的单位方阵，运动形式和转换矩阵的确定都是基于匀速运动模型，状态转移矩阵F根据运动学公式确定，跟踪的目标假设为一个匀速运动的目标。通过 <code>7x7</code> 的状态转移矩阵F 乘以 <code>7*1</code> 的状态变量 x 即可得到一个更新后的 <code>7x1</code> 的状态更新向量x。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.kf.F = np.array([[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],      <span class="comment"># 7x7 维度</span></span><br><span class="line">                      [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>]])</span><br></pre></td></tr></table></figure>

<h4 id="观测矩阵-H"><a href="#观测矩阵-H" class="headerlink" title="观测矩阵 H"></a>观测矩阵 H</h4><p>定义的是一个 <code>4x7</code> 的矩阵，乘以 <code>7x1</code> 的状态更新向量 x 即可得到一个 <code>4x1</code> 的 <code>[u,v,s,r]</code> 的估计值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.kf.H = np.array([[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],      <span class="comment"># 4x7 维度</span></span><br><span class="line">                      [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>],</span><br><span class="line">                      [<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]])</span><br></pre></td></tr></table></figure>

<h4 id="协方差矩阵-RPQ"><a href="#协方差矩阵-RPQ" class="headerlink" title="协方差矩阵 RPQ"></a>协方差矩阵 RPQ</h4><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">self.kf.R[<span class="number">2</span>:,<span class="number">2</span>:] *= <span class="number">10.</span></span><br><span class="line">self.kf.P[<span class="number">4</span>:,<span class="number">4</span>:] *= <span class="number">1000.</span> <span class="comment">#give high uncertainty to the unobservable initial velocities</span></span><br><span class="line">self.kf.P *= <span class="number">10.</span></span><br><span class="line">self.kf.Q[-<span class="number">1</span>,-<span class="number">1</span>] *= <span class="number">0.01</span></span><br><span class="line">self.kf.Q[<span class="number">4</span>:,<span class="number">4</span>:] *= <span class="number">0.01</span></span><br></pre></td></tr></table></figure>

<ul>
<li>测量噪声的协方差矩阵 R：<code>diag([1,1,10,10]T)</code></li>
<li>先验估计的协方差矩阵 P：<code>diag([10,10,10,10,1e4,1e4,1e4]T)</code>。1e4：1x10 的 4 次方。</li>
<li>过程激励噪声的协方差矩阵 Q：<code>diag([1,1,1,1,0.01,0.01,1e-4]T)</code>。</li>
</ul>
<h3 id="2-2-predict-预测阶段"><a href="#2-2-predict-预测阶段" class="headerlink" title="2.2 predict 预测阶段"></a>2.2 predict 预测阶段</h3><p>在预测阶段，追踪器不仅需要预测 bbox，还要记录它自己的活跃度。如果这个追踪器连续多次预测而没有进行一次更新操作，那么表明该跟踪器可能已经“失活”了。因为它没有和检测框匹配上，说明它之前记录的目标有可能已经消失或者误匹配了。但是也不一定会发生这种情况，还一种结果是目标在连续几帧消失后又出现在画面里。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">predict</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Advances the state vector and returns the predicted bounding box estimate.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span>((self.kf.x[<span class="number">6</span>]+self.kf.x[<span class="number">2</span>])&lt;=<span class="number">0</span>):</span><br><span class="line">        self.kf.x[<span class="number">6</span>] *= <span class="number">0.0</span></span><br><span class="line">    </span><br><span class="line">    self.kf.predict()</span><br><span class="line">    self.age += <span class="number">1</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span>(self.time_since_update&gt;<span class="number">0</span>):   <span class="comment"># 一旦出现不匹配的情况，连续匹配次数被归 0</span></span><br><span class="line">        self.hit_streak = <span class="number">0</span></span><br><span class="line">    self.time_since_update += <span class="number">1</span>     <span class="comment"># 连续不匹配的次数 + 1</span></span><br><span class="line">    </span><br><span class="line">    self.history.append(convert_x_to_bbox(self.kf.x))  <span class="comment"># [u,v,s,r] --&gt; [x1,y1,x2,y2]</span></span><br><span class="line">    <span class="keyword">return</span> self.history[-<span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<p>考虑到这种情况，使用 <strong>time_since_update 记录了追踪器连续没有匹配上的次数</strong>，该变量在每次 predict 时都会加 1，每次 update 时都会归 0. 并且使用了 max_age 设置了追踪器的最大存活期限，如果跟踪器出现超过连续 <code>max_age</code> 帧都没有匹配关联上，即当 tracker.time_since_update &gt; max_age 时，该跟踪器则会被判定失活而被移除列表。</p>
<h3 id="2-3-update-更新阶段"><a href="#2-3-update-更新阶段" class="headerlink" title="2.3 update 更新阶段"></a>2.3 update 更新阶段</h3><table><center><td bgcolor=LightPink><font color=black>
大家都知道，卡尔曼滤波器的更新阶段是使用了观测值 z 来校正误差矩阵和更新卡尔曼增益，并计算出先验估计值和测量值之间的加权结果，该加权结果即为后验估计值。
</font></strong></td></center></table>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">update</span>(<span class="params">self,bbox</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Updates the state vector with observed bbox.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    self.history = []</span><br><span class="line">    </span><br><span class="line">    self.time_since_update = <span class="number">0</span>   <span class="comment"># 连续不匹配的次数归 0</span></span><br><span class="line">    self.hits += <span class="number">1</span>               <span class="comment"># 总的匹配次数 + 1</span></span><br><span class="line">    self.hit_streak += <span class="number">1</span>         <span class="comment"># 连续匹配次数 + 1</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 卡尔曼滤波器更新校正</span></span><br><span class="line">    self.kf.update(convert_bbox_to_z(bbox))  <span class="comment"># bbox 是观测值 [x1,y1,x2,y2] --&gt; [u,v,s,r]</span></span><br></pre></td></tr></table></figure>

<p>每次更新时，总的匹配次数 hit 会加 1，连续匹配次数 hit_streak 也加 1. <strong>而如果一旦出现不匹配的情况时，hit_streak 变量会在 predict 阶段被归 0 而重新计时。</strong></p>
<h2 id="3-bbox-关联匹配"><a href="#3-bbox-关联匹配" class="headerlink" title="3. bbox 关联匹配"></a>3. bbox 关联匹配</h2><p>bbox 的关联匹配过程在前面已经讲得很详细了，它是将 tracker 输出的预测框（注意是先验估计值）和 detector 输出的检测框相关联匹配起来。输入是 dets： [[x1,y1,x2,y2,score],…] 和 trks： [[x1,y1,x2,y2,tracking_id],…] 以及一个设定的 iou 阈值，该门槛是为了过滤掉那些低重合度的目标。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">associate_detections_to_trackers</span>(<span class="params">dets, trks, iou_threshold = <span class="number">0.3</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Assigns detections to tracked object (both represented as bounding boxes)</span></span><br><span class="line"><span class="string">        dets:</span></span><br><span class="line"><span class="string">            [[x1,y1,x2,y2,score],...]</span></span><br><span class="line"><span class="string">        trks:</span></span><br><span class="line"><span class="string">            [[x1,y1,x2,y2,tracking_id],...]</span></span><br><span class="line"><span class="string">    Returns 3 lists of matches, unmatched_detections and unmatched_trackers</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>

<p>该过程返回：matches（已经匹配成功的追踪器）, unmatched_detections（没有匹配成功的检测目标） and unmatched_trackers（没有匹配成功的跟踪器）。</p>
<table><center><td bgcolor=DarkTurquoise><font color=black>
对于已经匹配成功的追踪器，则需要用观测值（目标检测框）去更新校正 tracker 并输出修正后的 bbox；对于没有匹配成功的检测目标，则需要新增 tracker 与之对应；对于没有匹配成功的跟踪器，如果长时间处于失活状态，则可以考虑删除了。
</font></strong></td></center></table>

<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/多目标追踪SORT算法-Simple-Online-and-Realtime-Tracking-20210813161621.png">
</p>

<h2 id="4-SORT-的优缺点"><a href="#4-SORT-的优缺点" class="headerlink" title="4. SORT 的优缺点"></a>4. SORT 的优缺点</h2><p>讲了这么多，那么 sort 有哪些优缺点呢？</p>
<ul>
<li>作者在卡尔曼滤波器追踪中使用了匀速运动模型，这一点可能在某些场景下是不合理的。</li>
<li>关联匹配过程中没有使用 feature，这就造成两个物体在重合度较高的时候会发生 id-switch。</li>
<li>优点也很明显，那就是非常快，而且计算量小。</li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献:"></a>参考文献:</h2><ul>
<li><a href="https://arxiv.org/abs/1602.00763">[1] Simple Online and Realtime Tracking</a></li>
<li><a href="https://www.geek-share.com/detail/2765731307.html">[2] SORT跟踪算法的详细解释，不容错过</a></li>
<li><a href="https://www.codenong.com/cs106088758/">[2] 车流量检测实现：多目标追踪、卡尔曼滤波器、匈牙利算法、SORT/DeepSORT、yoloV3、虚拟线圈法、交并比IOU计算</a></li>
</ul>
]]></content>
      <categories>
        <category>目标跟踪</category>
      </categories>
      <tags>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title>C++11 新特性解析与应用</title>
    <url>/2021/07/18/C++11_%E6%96%B0%E7%89%B9%E6%80%A7%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<p>这是我这阵子学习 C++11 做的一些记录，材料大多来自《深入理解 C++11 新特性解析与应用》这本书。</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/C++11新特性解析与应用-20210720143126.jpg">
</p>

<span id="more"></span>


<h1 id="第一节-右值引用"><a href="#第一节-右值引用" class="headerlink" title="第一节 右值引用"></a>第一节 右值引用</h1><h2 id="指针成员和拷贝构造"><a href="#指针成员和拷贝构造" class="headerlink" title="指针成员和拷贝构造"></a>指针成员和拷贝构造</h2><p>对 C++ 程序员来说，编写 C++ 程序有一条必须注意的规则，就是类中包含了一个指针成员的话，那么就要特别小心拷贝构造函数的编写。因为一不小心，就会出现内存泄漏。我们来看看下面代码清单中的例子。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HasPtrMem</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">HasPtrMem</span>(): <span class="built_in">ptr</span>(<span class="keyword">new</span> <span class="built_in"><span class="keyword">int</span></span>(<span class="number">0</span>)) &#123;&#125;</span><br><span class="line">        ~<span class="built_in">HasPtrMem</span>() &#123; <span class="keyword">delete</span> ptr; &#125;</span><br><span class="line">        <span class="keyword">int</span> *ptr;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    HasPtrMem a;</span><br><span class="line">    <span class="function">HasPtrMem <span class="title">b</span><span class="params">(a)</span></span>;</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; a.ptr &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; b.ptr &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在上述代码中，我们定义了一个 HasPtrMem 的类，它包含一个指针成员，该成员在构造时会接受一个 new 操作分配堆内存返回的指针，而在析构的时候则会被 delete 操作用于释放之前分配的堆内存。在 main 函数中，我们声明了 HasPtrMem 类型的变量 a，又使用 a 初始化了变量 b。按照 C++ 的语法，这会调用 HasPtrMem 的默认拷贝构造函数，它由编译器隐式生成，其作用是类似于 memcpy 的按位拷贝，它其实是一种浅拷贝。</p>
<p>但是这样的构造方式有一个问题，就是 a.ptr 和 b.ptr 都指向了同一块堆内存。因此在 main 作用域结束的时候，a 和 b 的析构函数纷纷被调用，当其中之一完成析构（比如 b), 那么 a.ptr 就成了一个悬挂指针，因为其指向的内存不再有效了，这时候就会报错（如下所示)：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">╭─yang@yangdeMacBook-Pro.local ~  </span><br><span class="line">╰─➤  g++ test.cpp &amp;&amp; ./a.out </span><br><span class="line">0x7fb22f405790</span><br><span class="line">0x7fb22f405790</span><br><span class="line">a.out(76052,0x115450dc0) malloc: *** error for object 0x7fb22f405790: pointer being freed was not allocated</span><br><span class="line">a.out(76052,0x115450dc0) malloc: *** set a breakpoint in malloc_error_break to debug</span><br><span class="line">[1]    76052 abort      ./a.out</span><br></pre></td></tr></table></figure>

<p>这个问题在 C++ 编程中非常经典。这样的拷贝构造方式，在 C++ 中也常称为“浅拷贝”。而在未声明构造函数的情况下，C++ 也会为类生成一个浅拷贝的构造函数。通常最佳的解决方案是用户自定义拷贝构造函数来实现“深拷贝”，我们来看看下面代码清单中的修正方法。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HasPtrMem</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">HasPtrMem</span>(): <span class="built_in">ptr</span>(<span class="keyword">new</span> <span class="built_in"><span class="keyword">int</span></span>(<span class="number">0</span>)) &#123;&#125;</span><br><span class="line">        <span class="built_in">HasPtrMem</span>(<span class="keyword">const</span> HasPtrMem &amp;h):</span><br><span class="line">            <span class="built_in">ptr</span>(<span class="keyword">new</span> <span class="built_in"><span class="keyword">int</span></span>(*h.ptr)) &#123;&#125;    <span class="comment">// 拷贝构造函数，从堆中分配内存，并用 *h.ptr 初始化</span></span><br><span class="line">        ~<span class="built_in">HasPtrMem</span>() &#123; <span class="keyword">delete</span> ptr; &#125;</span><br><span class="line">        <span class="keyword">int</span> *ptr;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    HasPtrMem a;</span><br><span class="line">    <span class="function">HasPtrMem <span class="title">b</span><span class="params">(a)</span></span>;                    <span class="comment">// 或者 HasPtrMem b = a，这都是调用拷贝构造函数的方式</span></span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; a.ptr &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; b.ptr &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在上述代码清单中，我们为 HasPtrMem 添加了一个拷贝构造函数 <code>HasPtrMem(const HasPtrMem &amp;h)</code>。拷贝构造函数从堆中分配新内存，将该分配来的内存指针还给 <code>ptr</code>，又使用 <code>*(h.ptr)</code> 对 <code>*ptr</code> 进行了初始化。通过这样的方法，避免了悬挂指针的困扰。</p>
<h2 id="移动语义"><a href="#移动语义" class="headerlink" title="移动语义"></a>移动语义</h2><p>拷贝构造函数中为指针成员分配新的内存再进行内容拷贝的做法在 C++ 编程中几乎被视为不可违背的。不过在一些时候，我们确实不需要这样的拷贝构造语义。我们可以看看下面代码清单中的例子。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span> </span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HasPtrMem</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">HasPtrMem</span>(): <span class="built_in">ptr</span>(<span class="keyword">new</span> <span class="built_in"><span class="keyword">int</span></span>(<span class="number">0</span>)) &#123;</span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;Construct: &quot;</span> &lt;&lt; ++n_cstr &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">HasPtrMem</span>(<span class="keyword">const</span> HasPtrMem &amp;h): <span class="built_in">ptr</span>(<span class="keyword">new</span> <span class="built_in"><span class="keyword">int</span></span>(*h.ptr)) &#123;</span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;Copy Construct: &quot;</span> &lt;&lt; ++n_cptr &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">        ~<span class="built_in">HasPtrMem</span>() &#123;</span><br><span class="line">            <span class="keyword">delete</span> ptr;</span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;Destruct: &quot;</span> &lt;&lt; ++n_dstr &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> *ptr;</span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">int</span> n_cstr;</span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">int</span> n_cptr;</span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">int</span> n_dstr;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> HasPtrMem::n_cstr = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> HasPtrMem::n_dstr = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> HasPtrMem::n_cptr = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function">HasPtrMem <span class="title">getTemp</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> <span class="built_in">HasPtrMem</span>(); &#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    HasPtrMem a = <span class="built_in">getTemp</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在代码清单中，我们声明了一个返回一个 HasPtrMem 变量的函数。为了记录构造函数、拷贝构造函数，以及析构函数调用的次数，我们使用了一些静态变量。在 main 函数中，我们简单地声明了一个 HasPtrMem 的变量 a，要求它使用 getTemp 函数的返回值进行初始化。编译运行该程序，我们可以看到下面输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">╭─yang@yangdeMacBook-Pro.local ~  </span><br><span class="line">╰─➤  g++ test.cpp -fno-elide-constructors &amp;&amp; ./a.out </span><br><span class="line">Construct: 1</span><br><span class="line">Copy Construct: 1</span><br><span class="line">Destruct: 1</span><br><span class="line">Copy Construct: 2</span><br><span class="line">Destruct: 2</span><br><span class="line">Destruct: 3</span><br></pre></td></tr></table></figure>

<table><center><td bgcolor= LightSalmon><font color=blue>
注意：指定这个参数（-fno-elide-constructors）是为了关闭编译器的优化，强制 g++ 在所有情况下都会调用拷贝构造函数。
</font></strong></td></center></table>

<p>这里构造函数被调用了 1 次，这是在 getTemp 函数中 HasPtrMem() 表达式显式地调用了构造函数而打印出来的。而拷贝构造函数则被调用了 2 次：一次是从 getTemp 函数中 HasPtrMem() 生成的变量上拷贝构造出一个临时值，以用作 getTemp 的返回值，而另外一次则是由临时值构造出 main 中变量 a 调用的。对应的，析构函数也就被调用了 3 次。</p>
<table><center><td bgcolor= LightSalmon><font color=blue>
拷贝构造函数的调用场景为：（1）当用类的一个对象初始化该类的另一个对象时，例如 B(A) 或者 B=A；（2）函数的形参为类的对象时,当调用函数时,拷贝构造函数被调用；（3）如果函数的返回值是类的对象，函数执行完成返回调用者时。
</font></strong></td></center></table>

<p>在我们的例子里，类 HasPtrMem 只有一个 int 类型的指针。而如果 HasPtrMem 的指针指向非常大的堆内存数据的话，那么拷贝构造的过程就会非常昂贵。可以想象，这种情况一旦发生，a 的初始化表达式的执行速度将相当堪忧。( 事实上，编译器常常对函数的返回值有专门的优化，我们在本节结束时将会提到。）</p>
<p>在上面的例子中可以看出从临时变量中拷贝构造变量 a 的做法：即在拷贝时分配新的堆内存，并从临时对象的堆内存中拷贝内容至 a.ptr。而构造结束后，临时对象将析构，因此其拥有的堆内存资源会被析构函数所释放. <strong>C++11 提出了一种新方法，该方法在构造时使得 a.ptr 指向临时对象的堆内存资源, 同时我们保证临时对象不释放所指向的堆内存。那么构造完成后，临时对象虽然被析构，但是那块内存还在，只不过是被对象 a 偷走了。</strong></p>
<p>在 C++11 中，这样 “偷走” 临时变量资源的构造函数，被称为移动构造函数。说白了就是将临时变量的资源管理权移交给另一个变量，我们可以看看下面代码清单是如何实现这种移动语义的：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HasPtrMem</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">HasPtrMem</span>(): <span class="built_in">ptr</span>(<span class="keyword">new</span> <span class="built_in"><span class="keyword">int</span></span>(<span class="number">0</span>)) &#123;</span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;Construct: &quot;</span> &lt;&lt; ++n_cstr &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">HasPtrMem</span>(<span class="keyword">const</span> HasPtrMem &amp;h): <span class="built_in">ptr</span>(<span class="keyword">new</span> <span class="built_in"><span class="keyword">int</span></span>(*h.ptr)) &#123;</span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;Copy Construct: &quot;</span> &lt;&lt; ++n_cptr &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">HasPtrMem</span>(HasPtrMem &amp;&amp;h): <span class="built_in">ptr</span>(h.ptr) &#123;                 <span class="comment">// 移动构造函数</span></span><br><span class="line">            h.ptr = <span class="literal">nullptr</span>;                         <span class="comment">// 将临时变量的指针成员置空</span></span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;Move Construct: &quot;</span> &lt;&lt; ++n_mvtr &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">        ~<span class="built_in">HasPtrMem</span>() &#123;</span><br><span class="line">            <span class="keyword">delete</span> ptr;</span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;Destruct: &quot;</span> &lt;&lt; ++n_dstr &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> *ptr;</span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">int</span> n_cstr;</span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">int</span> n_cptr;</span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">int</span> n_dstr;</span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">int</span> n_mvtr;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> HasPtrMem::n_cstr = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> HasPtrMem::n_dstr = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> HasPtrMem::n_cptr = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span> HasPtrMem::n_mvtr = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line"><span class="function">HasPtrMem <span class="title">getTemp</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    HasPtrMem h;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Resource from &quot;</span> &lt;&lt; __func__ &lt;&lt; <span class="string">&quot;: &quot;</span> &lt;&lt; h.ptr &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> h;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    HasPtrMem a = <span class="built_in">getTemp</span>();</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Resource from &quot;</span> &lt;&lt; __func__ &lt;&lt; <span class="string">&quot;: &quot;</span> &lt;&lt; a.ptr &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到：而不像拷贝构造函数一样需要重新分配内存，然后将内容依次拷贝到新分配的内存中。移动构造函数是将对象 h 的指针地址 h.ptr 赋值给了本对象的指针 ptr，随后将 h.ptr 置为空指针 nullptr，这就相当于完成了内存资源管理权的交接过程。下面看看程序运行的输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">╭─yang@yangdeMacBook-Pro.local ~  </span><br><span class="line">╰─➤  g++ test.cpp -fno-elide-constructors -std=c++11 &amp;&amp; ./a.out</span><br><span class="line">Construct: 1</span><br><span class="line">Resource from getTemp: 0x7fe248c05790</span><br><span class="line">Move Construct: 1</span><br><span class="line">Destruct: 1</span><br><span class="line">Move Construct: 2</span><br><span class="line">Destruct: 2</span><br><span class="line">Resource from main: 0x7fe248c05790</span><br><span class="line">Destruct: 3</span><br></pre></td></tr></table></figure>

<p>可以看到，这里没有调用拷贝构造函数，而是调用了两次移动构造函数。移动构造的结果是，getTemp 中的 h.ptr 和 main 函数中的 a.ptr 的值是相同的 (即 h.ptr 和 a.ptr 都指向了相同的堆地址内存). 该堆内存在函数返回的过程中， 成功地逃避了被析构的厄运，取而代之地成为了赋值表达式中的变量 a 的资源。如果这块内存不是一个 int 长度的数据，而是以 MByte 为单位的空间，那么它带来的性能提升将非常惊人。</p>
<h2 id="左值、右值和引用"><a href="#左值、右值和引用" class="headerlink" title="左值、右值和引用"></a>左值、右值和引用</h2><p>在 C 语言中，我们常常会提起左值 (lvalue)、右值 (rvalue) 这样的称呼。而在编译程序时，编译器有时也会在报出的错误信息中会包含左值、右值的说法。关于左值和右值，一个最为典型的判别方法就是： 在赋值表达式中， 出现在等号左边的就是 “左值” ，而在等号右边的，则称为“右值”。比如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">a = b + c;</span><br></pre></td></tr></table></figure>

<p>在这个赋值表达式中，a 就是一个左值，而 b+c 则是一个右值。这种识别左值、右值的方法在 C++ 中依然有效。不过 C++ 中还有一个被广泛认同的说法，那就是<strong>可以取地址的、有名字的就是左值，反之，不能取地址的、没有名字的就是右值。</strong>那么这个加法赋值表达式中，&amp;a 是允许的操作，但 &amp;(b+c) 这样的操作则不会通过编译。因此 a 是一个左值，(b+c) 是一个右值。</p>
<p>这些判别方法通常都非常有效。更为细致地讲， 右值是由两个概念构成：一个是将亡值，另一个是纯右值。其中纯右值就是 C++98 标准中右值的概念，讲的是用于辨识临时变量和一些不跟对象关联的值。 比如 1+3 所产生的临时变量值，是纯右值。 而不跟对象相关联的一些字面值如：2、’c’、true，也是纯右值。而将亡值则是 C++11 新增的跟右值引用相关的表达式，这样表达式通常是将要移动的对象（移为他用），比如返回右值引用 T&amp;&amp;  函数的返回值、std::move 的返回值等等。</p>
<p>在 C++11 中，右值引用就是对一个右值进行引用的类型。事实上，由于右值通常不具有名字，我们也只能通过引用的方式找到它的存在。通常情况下，我们只能是从右值表达式获得其引用。比如：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">T &amp;&amp;a = <span class="built_in">returnRvalue</span>();</span><br><span class="line">T   b = <span class="built_in">returnRvalue</span>();</span><br></pre></td></tr></table></figure>

<p>上面第一个表达式中，假设 returnRvalue 返回了一个右值，我们就声明了一个名为 a 的右值引用，其值等于 returnRvalue 函数返回的临时变量的值，该函数在执行结束后会将右值的内存所有权移交给变量 a。而在第二个表达式中，b 只是临时变量构造而成的，因此在表达式结束后就会多了一次析构和拷贝的开销。</p>
<h2 id="std-move-强制转化为右值"><a href="#std-move-强制转化为右值" class="headerlink" title="std::move 强制转化为右值"></a>std::move 强制转化为右值</h2><p>std::move 函数的功能是将一个左值强制转化成右值引用，继而我们可以通过右值引用使用该值。从实现上来讲，std::move 基本等同于一个类型转换。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static_cast</span>&lt;T &amp;&amp;&gt; (lvalue);</span><br></pre></td></tr></table></figure>

<p>让我们来看看下面代码清单中的例子：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Moveable</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">Moveable</span>(): <span class="built_in">ptr</span>(<span class="keyword">new</span> <span class="built_in"><span class="keyword">int</span></span>(<span class="number">3</span>)) &#123;&#125;</span><br><span class="line">        ~<span class="built_in">Moveable</span>() &#123;<span class="keyword">delete</span>  ptr;&#125;</span><br><span class="line">        <span class="built_in">Moveable</span>(<span class="keyword">const</span> Moveable &amp;m): <span class="built_in">ptr</span>(<span class="keyword">new</span> <span class="built_in"><span class="keyword">int</span></span>(*m.ptr)) &#123;&#125;</span><br><span class="line">        <span class="built_in">Moveable</span>(Moveable &amp;&amp;m): <span class="built_in">ptr</span>(m.ptr)&#123;</span><br><span class="line">            m.ptr = <span class="literal">nullptr</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> *ptr;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    Moveable a;</span><br><span class="line">    std::cout &lt;&lt; *a.ptr &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="function">Moveable <span class="title">c</span><span class="params">(std::move(a))</span></span>;             <span class="comment">// 会调用移动构造函数</span></span><br><span class="line">    std::cout &lt;&lt; *a.ptr &lt;&lt; std::endl;     <span class="comment">// 运行时错误</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们为类型 Moveable 定义来移动构造函数。这个函数本身其实没有什么问题，但调用的时候使用了 Moveable c(std::move(a)); 这样的语句。这里 a 本来是一个左值变量，通过 std::move 将其转换成右值。这样一来，a.ptr 就被 c 的移动构造函数设置为指针空值，那么随后对表达式 *a.ptr 执行时就会发生严重的运行时错误。下面是执行结果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">╭─yang@yangdeMacBook-Pro.local ~  </span><br><span class="line">╰─➤  g++ test.cpp -fno-elide-constructors -std=c++11 &amp;&amp; ./a.out</span><br><span class="line">3</span><br><span class="line">[1]    1340 segmentation fault  ./a.out</span><br></pre></td></tr></table></figure>

<p>有了移动语义，还有一个比较典型的应用是可以实现高性能的置换（swap）函数，看看下面这段 swap 模版函数代码：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="class"><span class="keyword">class</span> <span class="title">T</span>&gt;</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(T &amp;a, T &amp;b)</span></span>&#123;</span><br><span class="line">    <span class="function">T <span class="title">c</span><span class="params">(std::move(a))</span></span>;</span><br><span class="line">    a = std::<span class="built_in">move</span>(b);</span><br><span class="line">    b = std::<span class="built_in">move</span>(c);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>代码中，a 先将自己的资源交给 c，随后 b 再将资源交给 a，c 随后又将 a 中得到的资源交给 b，从而完成了一个置换动作。<strong>整个过程，代码都只会按照移动语义进行指针交换，不会有资源的释放与申请。</strong></p>
<h1 id="第二节-智能指针和垃圾回收"><a href="#第二节-智能指针和垃圾回收" class="headerlink" title="第二节 智能指针和垃圾回收"></a>第二节 智能指针和垃圾回收</h1><h2 id="C-11-的智能指针"><a href="#C-11-的智能指针" class="headerlink" title="C++11 的智能指针"></a>C++11 的智能指针</h2><p>在 C++98 中，智能指针通过一个模版类型 auto_ptr 来实现。auto_ptr 以对象的方式管理堆分配的内存，并在适当的时间（比如析构）释放所获得的堆内存。这种堆内存管理的方式只需要程序员将 new 操作返回的指针作为 auto_ptr 的初始值即可，程序员不用再显式地调用 delete。比如：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">auto_ptr&lt;<span class="keyword">int</span>&gt; <span class="title">pt</span><span class="params">(<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">123</span>))</span></span>;     <span class="comment">//  包含一个int*的指针，并初始化为 123 的地址</span></span><br></pre></td></tr></table></figure>

<p>这在一定程度上避免了堆内存忘记释放造成的问题。不过 auto_ptr 有一些缺点，先来看看下面一个例子：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="function">std::auto_ptr&lt;<span class="keyword">int</span>&gt; <span class="title">p1</span><span class="params">(<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">100</span>))</span></span>;</span><br><span class="line">    std::cout &lt;&lt; *p1 &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> p2 = p1;</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; *p1 &lt;&lt; std::endl;           <span class="comment">// 运行时错误</span></span><br><span class="line">    std::cout &lt;&lt; *p2 &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>为什么在把 p1 复制给 p2 之后 p1 再使用就异常了呢？这也正是它被抛弃的主要原因。<strong>因为 auto_ptr 拷贝构造函数中会把指向的地址进行转移，也就是从 p1 转移给了 p2。此时 p2 拥有了 p1 所指向的内存地址，但 p1 却为空，再使用它就会异常了。</strong></p>
<p>如果我们使用 unique_ptr 指针，那么：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="function">std::unique_ptr&lt;<span class="keyword">int</span>&gt; <span class="title">p1</span><span class="params">(<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">100</span>))</span></span>;        <span class="comment">// unique_ptr 无法复制，只能转移</span></span><br><span class="line">    std::cout &lt;&lt; *p1 &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> p2 = p1;                    <span class="comment">// 错误使用，不能通过编译</span></span><br><span class="line">    <span class="keyword">auto</span> p2 = std::<span class="built_in">move</span>(p1);         <span class="comment">// 正确使用，可以通过编译</span></span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; *p2 &lt;&lt; std::endl;</span><br><span class="line">    p2.<span class="built_in">reset</span>();                              <span class="comment">// 显式释放内存</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看到，如果我们直接使用 <code>auto p2 = p1</code>，编译器将会告诉我们这是错误行为。这是因为每个 unique_ptr 都是唯一地拥有所指向的对象内存，并且这种所有权只能通过 std::move 函数移交出去。</p>
<p>对此，C++11 推出了另一智能指针 shared_ptr，它能实现对象内存所有权的共享。示例代码如下所示：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="function">std::shared_ptr&lt;<span class="keyword">int</span>&gt; <span class="title">p1</span><span class="params">(<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">100</span>))</span></span>;</span><br><span class="line">    std::cout &lt;&lt; *p1 &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> p2 = p1;                    <span class="comment">// 正确使用;</span></span><br><span class="line"></span><br><span class="line">    p1.<span class="built_in">reset</span>();                         <span class="comment">// 虽然 p1 调用 reset 进行销毁</span></span><br><span class="line">    std::cout &lt;&lt; *p2 &lt;&lt; std::endl;     <span class="comment">// 但是 p2 仍能正常访问</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<table><center><td bgcolor= LightSalmon><font color=blue>
从上面来看：shared_ptr 允许 p1 将地址复制给 p2（内容并没有复制），实现 p1 和 p2 共享地拥有同一堆分配对象内存的所有权。但与 unique_ptr 不同的是，shared_ptr 在实现上采用了引用计数，一旦其中一个 shared_ptr 指针放弃了“所有权”，其他的 shared_ptr 对象内存的引用并不会受到影响：<strong> 虽然 p1 调用了 reset() 函数进行销毁，但只会导致引用计数降低，而不会引起堆内存的释放，所以 p2 仍能正常访问。</strong>
</font></strong></td></center></table>

<p>除了 unique_ptr 和 shared_ptr， 智能指针还包括了 <strong>weak_ptr</strong> 这个类模版。<strong>weak_ptr 的使用更复杂一点，它可以指向 shared_ptr 指针指向的对象内存，却不拥有该内存。</strong>而使用 weak_ptr 成员 lock，则可返回其指向内存的一个 shared_ptr 对象，且在所指对象内存已经无效时，返回空指针（nullptr）。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;memory&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">check</span><span class="params">(std::weak_ptr&lt;<span class="keyword">int</span>&gt; &amp;wp)</span></span>&#123;</span><br><span class="line">    std::shared_ptr&lt;<span class="keyword">int</span>&gt; sp = wp.<span class="built_in">lock</span>();</span><br><span class="line">    <span class="keyword">if</span>(sp != <span class="literal">nullptr</span>)</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;still &quot;</span> &lt;&lt; *sp &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Point is invalid&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="function">std::shared_ptr&lt;<span class="keyword">int</span>&gt; <span class="title">sp1</span><span class="params">(<span class="keyword">new</span> <span class="keyword">int</span>(<span class="number">22</span>))</span></span>;</span><br><span class="line">    std::shared_ptr&lt;<span class="keyword">int</span>&gt; sp2 = sp1;</span><br><span class="line">    std::weak_ptr&lt;<span class="keyword">int</span>&gt; wp = sp1;         <span class="comment">// 让 wp 指向 sp1 所指的对象</span></span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; *sp1 &lt;&lt; std::endl;      <span class="comment">// 22</span></span><br><span class="line">    std::cout &lt;&lt; *sp2 &lt;&lt; std::endl;      <span class="comment">// 22</span></span><br><span class="line">    <span class="built_in">check</span>(wp);                           <span class="comment">// still 22</span></span><br><span class="line"></span><br><span class="line">    sp1.<span class="built_in">reset</span>();</span><br><span class="line">    std::cout &lt;&lt; *sp2 &lt;&lt; std::endl;      <span class="comment">// 22</span></span><br><span class="line">    <span class="built_in">check</span>(wp);                           <span class="comment">// still 22</span></span><br><span class="line"></span><br><span class="line">    sp2.<span class="built_in">reset</span>();</span><br><span class="line">    <span class="built_in">check</span>(wp);                           <span class="comment">// Point is invalid</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>在上面代码清单中， 我们<strong>定义了一个共享对象内存的两个 shared_ptr 指针，sp1 和 sp2。而 weak_ptr wp 同样指向该对象内存。可以看到 sp1 及 sp2 都有效的时候，我们调用 wp 的 lock 函数，将返回一个有效的 shared_ptr 对象供使用，</strong>于是 check 函数会输出以下内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">still 22</span><br></pre></td></tr></table></figure>

<p>此后我们<strong>分别调用了 sp1 及 sp2 的 reset 函数，这会导致唯一的堆内存对象的引用计数降至 0 。而一旦引用计数归 0，shared_ptr 就会释放堆内存空间，使之失效。此时我们再调用 weak_ptr 的 lock 函数时，则返回一个指针空值 nullptr。</strong>这时 check 函数则会打印出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pointer is invalid</span><br></pre></td></tr></table></figure>

<p>在整个过程中，<strong>只有 shared_ptr 参与了引用计数，而 weak_ptr 指针没有影响其指向内存的引用计数，</strong>因此可以用于验证 shared_ptr 指针的有效性。</p>
<h2 id="垃圾回收机制"><a href="#垃圾回收机制" class="headerlink" title="垃圾回收机制"></a>垃圾回收机制</h2><p>在程序中，不再使用或者没有任何指针指向的内存空间就称为垃圾，而将这些垃圾收集起来以便再次利用的机智，就称为垃圾回收。垃圾回收的方式虽然有很多，但主要可以分两大类：</p>
<ul>
<li>基于引用计数机制：</li>
</ul>
<p>简单地来说， 引用计数主要是使用系统记录对象被引用的次数， 当对象被引用计数的次数变为 0 时， 该对象即可被视作垃圾而回收。但这种方法有一个著名的缺点就是：难以处理 “ 环形引用 ” 问题，即两个垃圾对象彼此之间互相引用，它们各自的计数器不为 0，这种情况对引用计数算法来说是无能为力的。</p>
<ul>
<li>基于跟踪处理机制：</li>
</ul>
<p>相比于引用计数，跟踪处理的垃圾回收机制被更为广泛地应用。其基本方法是产生跟踪对象的关系图，然后进行垃圾回收。使用跟踪方式的垃圾回收算法主要有以下几种：</p>
<p><strong>(1) 标记-清除：</strong>顾名思义，这个算法可以分为两个过程。首先将该算法将程序中正在使用的对象视为“根对象”，从根对象开始查找它所引用的堆空间，并在这些堆空间上做标记。当标记结束后，所有被标记的对象就是可达对象，而没有标记的对象就被认为是垃圾，在第二步清扫阶段就会被回收掉。</p>
<p><strong>(2) 标记-整理：</strong>这个算法标记的方法和之前标记-清除的方法一样，但是在标记完之后， 不再遍历所有对象清扫垃圾了，而是将可达对象向左靠齐，这就解决了内存碎片的问题。该方法有个特点是，需要移动所有活对象，因此相对应的，程序中所有堆内存的引用都必须更新。</p>
<p><strong>(3) 标记-拷贝：</strong>这种算法将堆空间分为两个部分：From 和 To 。刚开始系统只从 From 的堆空间里分配内存，当 From 分配满的时候系统就开始垃圾回收： 从 From 堆空间找出所有活对象，拷贝至 To 的堆空间里。这样一来，From 的堆空间里面就全剩下垃圾了。 而对象被拷贝到 To 里之后， 在 To 里是紧凑排列的。</p>
<h1 id="第三节-auto-类型推导"><a href="#第三节-auto-类型推导" class="headerlink" title="第三节 auto 类型推导"></a>第三节 auto 类型推导</h1><h2 id="静态类型、动态类型和类型推导"><a href="#静态类型、动态类型和类型推导" class="headerlink" title="静态类型、动态类型和类型推导"></a>静态类型、动态类型和类型推导</h2><p>在编程语言的分类中，C/C++ 常被冠以静态类型的称号，而有的编程语言则号称是动态类型的，比如 Python。通常情况下，静和动的区别非常直观，我们可以看看下面这段 Python 代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">name = <span class="string">&#x27;world\n&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;hello, &#x27;</span> %name)</span><br></pre></td></tr></table></figure>

<p>我们发现，变量 name 在使用前从未进行过任何的类型声明，而当程序员想使用时，就可以拿来用。这种变量的使用方式显得非常随性，而在 C++ 程序员的眼中，每个变量使用前必须定义类型几乎是天经地义的事情，这样通常被视为编程语言中的静态类型的体现。而对于 Python 这种拿来就用的变量使用方式，则被视为<strong>动态类型</strong>的体现。</p>
<p>不过从技术上严格来讲，<strong>静态类型和动态类型的主要区别在于对变量进行类型检查的时间点。对于所谓的静态类型，类型检查主要发生在编译阶段；对于动态类型，类型检查主要发生在运行阶段。</strong>形如 Python 等语言中变量拿来就用的特性，则需要归功于一个技术，即<strong>类型推导</strong>。</p>
<p>我们可以使用 C++11 中 auto 的方式书写一下刚才的 Python 代码：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">auto</span> name = <span class="string">&quot;world\n&quot;</span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;hello, &quot;</span> &lt;&lt; name &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>指的注意的是，auto 声明的变量必须立即被初始化，以使编译器能够从初始化表达式中推导出其类型。从这个意义上来讲，auto 并非一种类型的声明，而是一个类型声明时的占位符，编译器在编译时期会将 auto 替代为变量实际的类型。</p>
<h2 id="auto-的优势"><a href="#auto-的优势" class="headerlink" title="auto 的优势"></a>auto 的优势</h2><p><strong>直观地，auto 推导的一个最大优势就是拥有初始化表达式的复杂类型声明时简化代码。</strong>由于 C++ 的发展，声明变量类型也变得越来越复杂，很多时候，名字空间、模版成为了类型的一部分，导致程序员在使用库的时候如履薄冰。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    std::vector&lt;<span class="keyword">int</span>&gt; c = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">auto</span> i=c.<span class="built_in">begin</span>(); i!=c.<span class="built_in">end</span>(); i++)&#123;      <span class="comment">// std::vector&lt;int&gt;::iterator i = c.begin();</span></span><br><span class="line">        std::cout &lt;&lt; *i &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如我们所见，使用了 auto 后，写出的代码变得更加清晰可读了。</p>
]]></content>
      <categories>
        <category>杂七杂八</category>
      </categories>
      <tags>
        <tag>C++ 编程学习</tag>
      </tags>
  </entry>
  <entry>
    <title>卡尔曼滤波算法，永远滴神！</title>
    <url>/2021/07/10/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%AE%97%E6%B3%95-%E6%B0%B8%E8%BF%9C%E6%BB%B4%E7%A5%9E/</url>
    <content><![CDATA[<p>鲁道夫 • 卡尔曼在一次访问 NASA 埃姆斯研究中心时，发现他的卡尔曼滤波算法能帮助解决阿波罗计划的轨道预测问题，最终，飞船正确驶向月球，完成了人类历史上的第一次登月。卡尔曼因而一举成名，后来还被美国总统奥巴马授予了国家科学勋章。</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210712113922.jpeg">
</p>


<span id="more"></span>

<h2 id="1-阿波罗登月"><a href="#1-阿波罗登月" class="headerlink" title="1. 阿波罗登月"></a>1. 阿波罗登月</h2><p>让我们来想象一下阿波罗登月这个不可思议的神话：当飞行器飞向太空时，会不停地用各种传感器来测量自己的位置，希望自己在预定轨道上。但由于传感器的噪声影响，虽然它一直在测量和调整，但仍有可能慢慢偏离预定轨道。我们需要做的是，过滤掉那些噪声，估算出飞行器正确的位置。</p>
<p>我们先尝试下使用 S-G 滤波器（<a href="https://en.wikipedia.org/wiki/Savitzky%E2%80%93Golay_filter">Savitzky–Golay filter</a>)，它的核心思想是对一定长度窗口内的数据点进行 k 阶多项式拟合，其加权系数是通过在滑动窗口内对给定高阶多项式的最小二乘拟合得出。下面写了一段程序模拟 S-G 滤波器是如何实时处理一段噪声数据的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.signal <span class="keyword">import</span> savgol_filter</span><br><span class="line"></span><br><span class="line">N = <span class="number">100</span></span><br><span class="line">X = np.arange(N)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 模拟 100 帧带有噪声的原始数据</span></span><br><span class="line">Y1 = np.sin(np.linspace(<span class="number">0</span>, np.pi*<span class="number">2</span>, num=N)) + np.random.normal(<span class="number">0</span>, <span class="number">0.1</span>, size=N)</span><br><span class="line"></span><br><span class="line">window_length = <span class="number">5</span>      <span class="comment"># 滑动窗口长度，该值需为正奇整数。</span></span><br><span class="line">poly_order = <span class="number">1</span>         <span class="comment"># 窗口内的数据点进行k阶多项式拟合，其值需要小于 window_length。</span></span><br><span class="line"></span><br><span class="line">Y2 = []             <span class="comment"># 用于存储平滑后的数据</span></span><br><span class="line">cache_data = []     <span class="comment"># 缓存队列</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(N):                      <span class="comment"># 实时地遍历每帧噪声数据</span></span><br><span class="line">    origin_data = Y1[i]</span><br><span class="line">    cache_data.append(origin_data)      <span class="comment"># 将数据塞入缓存队列</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> i &lt; window_length:               <span class="comment"># 忽略前面几帧在滑动窗口以内的数据</span></span><br><span class="line">        smooth_data = origin_data</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        window_data = np.array(cache_data)  <span class="comment"># 对滑动窗口数据进行平滑</span></span><br><span class="line">        window_data = savgol_filter(window_data, window_length, poly_order)</span><br><span class="line">        </span><br><span class="line">        smooth_data = window_data[window_length//<span class="number">2</span>] <span class="comment"># 滑动窗口中间位置的数据</span></span><br><span class="line">        cache_data.pop(<span class="number">0</span>)                           <span class="comment"># 队列尾部数据弹出</span></span><br><span class="line">    </span><br><span class="line">    Y2.append(smooth_data)</span><br></pre></td></tr></table></figure>

<p>上述程序中提供了 100 帧带有正态分布噪声的数据，我们需要 S-G 滤波器对它们进行实时处理。由于窗口 size 设置成了 5，我们首先缓存了前 5 帧数据并对它们不进行任何平滑处理。等遍历到第 6 帧数据时，我们使用 savgol_filter 计算出缓存队列里经过平滑后的数据，并取出缓存队列中间的数据。为了保证滑动窗口（即缓存队列）的长度不变，在整个过程中我们需要不停地 push 数据和 pop 数据。整个滑动过程类似于下图所示：</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210712175055.gif">
</p>

<p>观察这个过程，发现有个非常严重的 bug：被平滑的数据需要依赖前几帧，也就是说 S-G 滤波具有一定的滞后性，比如说如果 window_size = 5，那么就会滞后 2 帧。这里截取一帧并放大显示（红色曲线表示的是滑动窗口）：</p>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210712180925.png">
</p>

<p>而卡尔曼滤波可以较好地解决这个问题的痛点，<font color=red><strong>它只要获知上一时刻状态的估计值以及当前状态的观测值就可以计算出当前状态的估计值，因此不需要记录观测或者估计的历史信息。</strong></font>在讲卡尔曼滤波之前，我们先来了解两个例子：</p>
<h2 id="2-两个例子"><a href="#2-两个例子" class="headerlink" title="2. 两个例子"></a>2. 两个例子</h2><h3 id="2-1-例子1-–-金条重量"><a href="#2-1-例子1-–-金条重量" class="headerlink" title="2.1 例子1 – 金条重量"></a>2.1 例子1 – 金条重量</h3><p>在本例中，我们将估计金条的重量。我们将使用一个无偏秤，也就是说，它没有系统误差，但每次称重会伴随着随机噪声。</p>
<p align="center">
    <img width="25%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210712205621.png">
</p>

<p>在本例中，系统是金条，系统的状态就是金条的重量。假设金条的重量在短时间内不发生变化，即系统的动态模型是恒定的。为了估计系统的状态(金条的重量)，可以进行多次测量并求平均值。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210712205737.png">
</p>

<p>经过 N 次测量，其估计值是所有测量值的平均值：</p>
<p align="center">
    <img width="80%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210713142228.png">
</p>

<p>在上面方程式中，我们需要记住所有历史测量数据。假设我们没有笔和纸来记录，也不能凭的记忆记下所有的历史测量数据。但我们可以仅用上一次的估计值和一点小小的调整(在现实生活的应用中，我们想节省计算机内存)，以及一个数学小技巧来做到这一点：</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210713142529.png">
</p>

<p>上述方程是卡尔曼滤波五个方程之一，名为状态更新 State Update Equation。其含义为：</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210713143804.png">
</p>

<p>因此，状态更新方程为:</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210713151127.png">
</p>

<p>让我们继续看这个例子，在进行第一次测量前需要预设一个初始猜测值，这个值不用很精准。下面为比较详细的计算过程：</p>
<ul>
<li>第 0 次预测：</li>
</ul>
<p>我们对金条重量的初步估计是1000克。滤波器初始化操作仅需一次，不会用在下一次迭代中。</p>
<p align="center">
    <img width="15%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210713151504.png">
</p>

<p>状态的下一个估计值(预测值)等于初始值：</p>
<p align="center">
    <img width="21%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210713152600.png">
</p>

<ul>
<li>第 1 次预测：</li>
</ul>
<p>第一次秤重：</p>
<p align="center">
    <img width="13.5%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210713152048.png">
</p>

<p>计算卡尔曼增益：</p>
<p align="center">
    <img width="13%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210713152205.png">
</p>

<p>用状态更新方程计算当前估计值：</p>
<p align="center">
    <img width="65%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210713152332.png">
</p>

<blockquote>
<p><font color=red>在这个特定的例子中，最初的猜测可以是任何值，因为 α1=1，初始猜测值在第一次迭代就被消去了。</font></p>
</blockquote>
<p>状态的下一个估计值(预测值)等于当前的估计值:</p>
<p align="center">
    <img width="22%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210713152817.png">
</p>

<p>上述过程一直进行到第 10 次预测，下图比较了测量值、估计值和真实值。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210713153123.png">
</p>

<h3 id="2-2-例子2-–-飞行器位置"><a href="#2-2-例子2-–-飞行器位置" class="headerlink" title="2.2 例子2 – 飞行器位置"></a>2.2 例子2 – 飞行器位置</h3><p>假设在一个一维空间，有一架飞行器正在向远离雷达的方向飞行。在一维空间中，雷达的角度不变，飞行器的高度不变，如下图所示。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210713155516.png">
</p>

<p>已知前面 N 个时刻飞机的位置，并且雷达已经测量到了此刻飞机的位置，那么我们如何估算出此刻飞机真正的位置呢？</p>
<ul>
<li>方法 1：使用雷达的测量值，但是雷达一般都有一定的系统误差怎么办。</li>
<li>方法 2：利用这个时间点之前的所有数据，预测这个时间点的数据。当然，这个预测值也是不准的。</li>
</ul>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210714111700.png">
</p>


<p>这两种方法告诉了我们不同的答案，两种方法都有一定的可信度。那能否将两种答案相融合呢，卡尔曼滤波就是做了这样的事情。<strong><font color=red>如下图所示，假设两种方法的误差都满足正态分布，如下图所示。如果正态分布越尖锐陡峭，则说明这种方法的预测结果越可信；如果越缓和平坦，则说明越不可信。</font></strong>为了融合这两种方法的预测结果，我们给这两种分布分别赋予一个权重，该权重代表了这个分布对融合结果的重要性。经过融合后的分布变得比之前两种分布更加尖锐，这表明结果更加可信了。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210713175050.jpeg">
</p>

<p><strong><font color=red>那么如何给出一个合理的权重分布呢，这就是卡尔曼滤波要做的事情。</font></strong></p>
<h2 id="3-卡尔曼滤波模型"><a href="#3-卡尔曼滤波模型" class="headerlink" title="3. 卡尔曼滤波模型"></a>3. 卡尔曼滤波模型</h2><h3 id="3-1-Kalman-filter-的数学表示"><a href="#3-1-Kalman-filter-的数学表示" class="headerlink" title="3.1 Kalman filter 的数学表示"></a>3.1 Kalman filter 的数学表示</h3><p>Kalman 滤波分为 2 个步骤，预测(predict)和校正(correct)。<font color=red>预测是基于上一时刻状态估计当前时刻状态，而校正则是综合当前时刻的估计状态与观测状态，估计出最优的状态。</font>预测与校正的过程如下：</p>
<ul>
<li><strong>预测：根据上一时刻（k-1 时刻）的后验估计值来估计当前时刻（k时刻）的状态，得到 k 时刻的先验估计值;</strong></li>
</ul>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210714161211.png">
</p>

<ul>
<li><strong>校正：使用当前时刻的测量值来校正预测阶段的估计值，得到当前时刻的后验估计值。</strong></li>
</ul>
<p align="center">
    <img width="33%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210714161316.png">
</p>

<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210715104151.png">
</p>

<p><strong><font color=red>预测阶段负责根据前一时刻的状态估计值来推算当前时刻的状态变量先验估计值和误差协方差先验估计值；校正阶段负责将先验估计和新的测量变量相融合改进的后验估计。</font></strong>卡尔曼滤波算法是一个递归的预测—校正方法，即只要获知上一时刻状态的估计值以及当前状态的观测值就可以计算出当前状态的估计值，因此不需要记录观测或者估计的历史信息。</p>
<table><center><td bgcolor= LightSalmon><font color=blue>从上面的五个公式中，我们发现：其实卡尔曼滤波的每次迭代更新就是为了求出卡尔曼增益 K，因为它代表了融合估计值和测量值之间的权重。下面这个视频很好地讲解如何通过最小化误差协方差矩阵求出 K：</font></strong></td></center></table>

<p align="center">
<iframe src="//player.bilibili.com/player.html?aid=796490974&bvid=BV1hC4y1b7K7&cid=213756096&page=1&high_quality=1"  width="550" height="400"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</p>

<p><strong>视频中的相关推导过程可见 <a href="https://www.guyuehome.com/15356">「卡尔曼滤波的理解、推导和应用」</a></strong></p>
<h3 id="3-2-Python-代码实现"><a href="#3-2-Python-代码实现" class="headerlink" title="3.2 Python 代码实现"></a>3.2 Python 代码实现</h3><p>在上面过程中，只有 <code>PQRK</code> 四个矩阵还尚未确定。显然增益矩阵 K 是不需要初始化的，P 是误差矩阵，初始化可以是一个随机的矩阵或者 0，只要经过几次的处理基本上就能调整到正常的水平，因此也就只会影响前面几次的滤波结果。</p>
<ul>
<li>Q：预测状态协方差，越小系统越容易收敛，我们对模型预测的值信任度越高；但是太小则容易发散，如果 Q 为零，那么我们只相信预测值；Q 值越大我们对于预测的信任度就越低，而对测量值的信任度就变高；如果 Q 值无穷大，那么我们只信任测量值；</li>
<li>R：观测状态协方差，如果 R 太大，则表现它对新测量值的信任度降低而更愿意相信预测值，从而使得 kalman 的滤波结果会表现得比较规整和平滑，但是其响应速度会变慢而出现滞后；</li>
<li>P：误差协方差初始值，表示我们对当前预测状态的信任度。它越小说明我们越相信当前预测状态；它的值决定了初始收敛速度，一般开始设一个较小的值以便于获取较快的收敛速度。随着卡尔曼滤波的迭代，P的值会不断的改变，当系统进入稳态之后P值会收敛成一个最小的估计方差矩阵，这个时候的卡尔曼增益也是最优的，所以这个值只是影响初始收敛速度。</li>
</ul>
<p>假设系统的真实状态是一条正弦曲线，我们在测量过程中伴随一定正态分布的随机噪声，使用 python 模拟该过程如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line">plt.rcParams[<span class="string">&#x27;figure.figsize&#x27;</span>] = (<span class="number">10</span>, <span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># intial parameters</span></span><br><span class="line">n_iter = <span class="number">500</span></span><br><span class="line">sz = (n_iter,) <span class="comment"># size of array</span></span><br><span class="line"></span><br><span class="line">x = np.sin(np.linspace(<span class="number">0</span>, np.pi*<span class="number">2</span>, num=n_iter)) <span class="comment">#测量值</span></span><br><span class="line">z = np.sin(np.linspace(<span class="number">0</span>, np.pi*<span class="number">2</span>, num=n_iter)) + np.random.normal(<span class="number">0</span>, <span class="number">0.1</span>, size=n_iter) <span class="comment">#真实值</span></span><br><span class="line"></span><br><span class="line">plt.figure()</span><br><span class="line">plt.plot(z,<span class="string">&#x27;k+&#x27;</span>,label=<span class="string">&#x27;noisy measurements&#x27;</span>)         </span><br><span class="line">plt.plot(x,color=<span class="string">&#x27;g&#x27;</span>,label=<span class="string">&#x27;truth value&#x27;</span>)           </span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>


<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波算法，永远滴神！-20210730160747.png">
</p>

<p>接下来我们使用卡尔曼滤波对这段噪声进行实时去燥和平滑处理：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># allocate space for arrays</span></span><br><span class="line">xhat=np.zeros(sz)      <span class="comment"># a posteri estimate of x</span></span><br><span class="line">P=np.zeros(sz)         <span class="comment"># a posteri error estimate</span></span><br><span class="line">xhatminus=np.zeros(sz) <span class="comment"># a priori estimate of x</span></span><br><span class="line">Pminus=np.zeros(sz)    <span class="comment"># a priori error estimate</span></span><br><span class="line">K=np.zeros(sz)         <span class="comment"># gain or blending factor</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 超参数设定，实测调整</span></span><br><span class="line">R = <span class="number">0.1</span>**<span class="number">2</span>              <span class="comment"># 观测状态协方差</span></span><br><span class="line">Q = <span class="number">1e-4</span>                <span class="comment"># 预测状态协方差</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># intial guesses</span></span><br><span class="line">xhat[<span class="number">0</span>] = <span class="number">0.0</span></span><br><span class="line">P[<span class="number">0</span>] = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,n_iter):</span><br><span class="line">    <span class="comment"># 预测</span></span><br><span class="line">    xhatminus[k] = xhat[k-<span class="number">1</span>] <span class="comment"># X(k|k-1) = AX(k-1|k-1) + BU(k) + W(k), A=1,BU(k) = 0</span></span><br><span class="line">    Pminus[k] = P[k-<span class="number">1</span>]+Q     <span class="comment"># P(k|k-1) = AP(k-1|k-1)A&#x27; + Q(k), A=1</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新</span></span><br><span class="line">    K[k] = Pminus[k]/( Pminus[k]+R )    <span class="comment"># Kg(k)=P(k|k-1)H&#x27;/[HP(k|k-1)H&#x27; + R], H=1</span></span><br><span class="line">    xhat[k] = xhatminus[k]+K[k]*(z[k]-xhatminus[k]) <span class="comment"># X(k|k) = X(k|k-1) + Kg(k)[Z(k) - HX(k|k-1)], H=1</span></span><br><span class="line">    P[k] = (<span class="number">1</span>-K[k])*Pminus[k]                       <span class="comment"># P(k|k) = (1 - Kg(k)H)P(k|k-1), H=1</span></span><br><span class="line"></span><br><span class="line">plt.plot(z,<span class="string">&#x27;k+&#x27;</span>,label=<span class="string">&#x27;noisy measurements&#x27;</span>)         <span class="comment"># 测量值</span></span><br><span class="line">plt.plot(x,color=<span class="string">&#x27;g&#x27;</span>,label=<span class="string">&#x27;truth value&#x27;</span>)           <span class="comment"># 真实值</span></span><br><span class="line">plt.plot(xhat,<span class="string">&#x27;b-&#x27;</span>,label=<span class="string">&#x27;a posteri estimate&#x27;</span>)      <span class="comment"># 估计值</span></span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p>卡尔曼滤波增益 K 值和 Q, R 的比值有关系，而与 Q ,R 的绝对值没有关系。因此我们固定 R 的值为 <code>0.1**2</code>，比较了 Q 分别在 <code>1e-2</code> 和 <code>1e-6</code> 的情况，如下图所示：</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/C++11新特性解析与应用-20210730160526.png">
</p>

<table><center><td bgcolor= LightSalmon><font color=blue>
从上面的结果可以看出：当 Q 较大时，表明预测状态的方差较大，使得我们比较相信测量值；而当 Q 较小时，我们则比较相信预测值，提高了滤波结果的平滑性，但也增大了滤波结果的滞后性。因此在实际应用中，应当特别注意 Q 和 R 值的选择。</font></strong></td></center></table>

<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献:"></a>参考文献:</h2><ul>
<li><a href="https://www.sohu.com/a/114471342_354973">[1] 纪念一位深远地改变了现代世界的非著名发明家：鲁道夫•卡尔曼 </a></li>
<li><a href="https://courses.cs.washington.edu/courses/cse571/03wi/notes/welch-bishop-tutorial.pdf">[2] An Introduction to the Kalman Filter </a></li>
<li><a href="https://www.kalmanfilter.net/CN/default_cn.aspx">[3] https://www.kalmanfilter.net </a></li>
<li><a href="https://www.zhihu.com/question/23971601">[4] 知乎上 Matlab 中国对卡尔曼滤波的动画讲解 </a></li>
<li><a href="https://www.zhihu.com/question/30481204">[5] KF，EKF怎样设置Q和R阵? </a></li>
</ul>
]]></content>
      <categories>
        <category>杂七杂八</category>
      </categories>
      <tags>
        <tag>卡尔曼滤波</tag>
      </tags>
  </entry>
  <entry>
    <title>理解英伟达 TensorRT 的 INT8 加速原理</title>
    <url>/2021/06/06/%E7%90%86%E8%A7%A3%E8%8B%B1%E4%BC%9F%E8%BE%BE-TensorRT-%E7%9A%84-INT8-%E5%8A%A0%E9%80%9F%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<p>目前的神经网络推理大部分是利用 32bit float 类型的数据进行计算的，bit 位数的多少直接限制了数据类型能够表达的数据范围，比如 float 32 的数据是由 1bit 表示符号，8bit 表示整数部，23 位表示分数部组成。但是这种运算比较耗时和消耗计算资源，因此诞生了 int8 量化算法。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/理解英伟达-TensorRT-的-INT8-加速原理-20210609152045.png">
</p>


<p>int8 量化是将数据保存为 int8 格式，这样一样计算时间和占用内存大大减小。目前量化有两种方式：一种是通过训练量化 finetune 原来的模型，另一种是直接对模型和计算进行量化。后者的代表便是英伟达的方案了，目前 PPT 已经公开，但是代码并没有开源。</p>
<span id="more"></span>

<h2 id="1-量化卷积核权重"><a href="#1-量化卷积核权重" class="headerlink" title="1. 量化卷积核权重"></a>1. 量化卷积核权重</h2><p>量化的目的是为了把原来的 float32 位的卷积操作，转换为 int8 的卷积操作，这样<strong>计算就变为原来的 <code>1/4</code>，但是访存并没有变少哈，因为我们是在 kernel 里面才把 float32 变为 int8 进行计算的</strong>。</p>
<p>比如说 <code>float32</code> 位的变量 <code>a=6.238561919405008</code>，可以通过 <code>scale=23.242536 </code> 映射到 <code>int8</code> 空间上到整数 <code>a*scale=145</code>。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/理解英伟达-TensorRT-的-INT8-加速原理-20210609152310.png" style="max-width:70%;"></p>
 
<p> 如上所示，这个 scale 是根据最大的权重绝对值 <code>thresh</code> 决定的，然后计算 <code>127</code> 与它的比值，便得到了 <code>scale</code> 值。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quantize_weight</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    对该层的卷积核权重进行量化, 计算出 scale</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    weights = self.layer.weight.cpu().detach().numpy()      <span class="comment"># 剥离每一层的卷积权重</span></span><br><span class="line">    group_weights = np.array_split(weights, self.channels)  <span class="comment"># 将卷积权重按通道划分</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, group_weight <span class="keyword">in</span> <span class="built_in">enumerate</span>(group_weights):        <span class="comment"># 对每个通道的卷积权重进行遍历</span></span><br><span class="line">        max_val = np.<span class="built_in">max</span>(group_weight)</span><br><span class="line">        min_val = np.<span class="built_in">min</span>(group_weight)</span><br><span class="line"></span><br><span class="line">        thresh  = <span class="built_in">max</span>(<span class="built_in">abs</span>(max_val), <span class="built_in">abs</span>(min_val))           <span class="comment"># 求出阈值 thresh 从而求出 scale</span></span><br><span class="line">        <span class="keyword">if</span> thresh &lt; <span class="number">0.0001</span>:</span><br><span class="line">            self.weight_scales[i] = <span class="number">0.</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.weight_scales[i] = <span class="number">127</span> / thresh            <span class="comment"># int8: -127 ~ 127</span></span><br></pre></td></tr></table></figure>

<p><strong>由于卷积运算是卷积核(<code>weights</code>)和数据流(<code>blob</code>)之间乘加操作，因此光对卷积核量化是不够的，还需要对数据流进行量化！</strong></p>
<h2 id="2-量化输入数据流"><a href="#2-量化输入数据流" class="headerlink" title="2. 量化输入数据流"></a>2. 量化输入数据流</h2><p>我们发现，量化的过程与数据的分布有关。如下图所示：当数据的直方图分布比较均匀时，高精度向低精度进行映射就会将刻度利用比较充分；如果分布不均匀，就会浪费很大空间。通俗地来讲，就会出现很多数字挤在一个刻度里：比如 <code>scale=23.456</code> 时，<code>6.1817</code> 和 <code>6.1823</code> 都表示成了 <code>145</code>。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/理解英伟达-TensorRT-的-INT8-加速原理-20210609152346.png" style="max-width:100%;"></p>

<p>关于上面这种直接将量化阈值设置为 <code>|max|</code> 的方法，它的显著特点是低精度的 <code>int8</code> 空间没有充分利用，因此称为<strong><font color=red>不饱和量化(no saturation quantization)</font></strong>。针对这种情况，我们可以选择一个合适的<strong>量化阈值(threshold)</strong>，舍弃那些超出范围的数进行量化，这种量化方式充分利用了低精度空间，因此称为<strong><font color=red>饱和量化(saturation quantization)</font></strong>。</p>
<p align="center">
    <img width="75%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/理解英伟达-TensorRT-的-INT8-加速原理-20210609152419.png" style="max-width:80%;"></p>

<blockquote>
<p>图中黄色部分被舍弃掉了，它们将直接被量化为 -127</p>
</blockquote>
<p>通过对比两种量化方式我们可以发现，它们各有优缺点：不饱和量化方式的量化范围大，但是可能会浪费一些低精度空间从而导致量化精度低；饱和量化方式虽然充分利用了低精度空间，但是会舍弃一些量化范围。<strong>因此这两种方式其实是一个量化精度和量化范围之间的平衡</strong>。那么如何选择合适的量化方式呢，英伟达说了：卷积核权重量化应该使用不饱和量化，数据流量化应该使用饱和量化方式。那么问题来了，对于数据流的饱和量化，<strong>怎么在数据流中找到这个最佳阈值(threshold) ？</strong></p>
<p>我们首先应该将经过网络每一层的数据流(<code>Blob</code>)给提取出来，得到它们的直方图分布。为了提取每一层的输入流，我们可以使用 <a href="https://discuss.pytorch.org/t/understanding-register-forward-pre-hook-and-register-backward-hook/61457"><code>torch.nn.Module.register_forward_pre_hook</code></a> 函数来操作。它就像一个钩子，可以把我们想要的东西给钩出来，并且不会对数据进行修改。不妨先在 <code>QuantizeLayer</code> 设置一个 hook 函：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hook</span>(<span class="params">self, modules, <span class="built_in">input</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    VGG16 模型每次 forward 时，都会调用 QuantizeLayer.hook 函数，更新数据流的直方图分布</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    self.blob = <span class="built_in">input</span>[<span class="number">0</span>].cpu().detach().numpy().flatten()</span><br><span class="line">    max_val = np.<span class="built_in">max</span>(self.blob)</span><br><span class="line">    min_val = np.<span class="built_in">min</span>(self.blob)</span><br><span class="line">    self.blob_max = <span class="built_in">max</span>(self.blob_max, <span class="built_in">max</span>(<span class="built_in">abs</span>(max_val), <span class="built_in">abs</span>(min_val)))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将数据的绝对值范围 (0, blob_max) 划分为 2048 个区间，然后计算每个区间内的数据的总数, 即一个直方图分布</span></span><br><span class="line">    count, _ = np.histogram(self.blob, bins=self.grids, <span class="built_in">range</span>=(<span class="number">0</span>, self.blob_max))</span><br><span class="line">    self.blob_count = self.blob_count + count</span><br><span class="line"></span><br><span class="line">    threshold_bin = self.quantize_blob()</span><br><span class="line">    threshold_val = (threshold_bin + <span class="number">0.5</span>) * (self.blob_max / <span class="number">2048</span>)</span><br><span class="line">    self.blob_scale = <span class="number">127</span> / threshold_val</span><br></pre></td></tr></table></figure>
<p>然后模型每次执行 <code>forward</code> 函数时，都会去执行 <code>hook</code> 函数里的内容：把该层的输入流复制给 <code>blob</code> 变量。</p>
<p><strong>跟权重量化的原理类似，数据流量化也需要找到最大绝对值 blob_max</strong>。理论上这个值应该是全局的，但是模型的测试图片数量和分布都具有不可穷举性，因此我们往往会选择一些图片进行<font color=red><strong>校准 (calibration)</strong></font>，使得<code>blob_max</code>尽量接近理论值。因此我们在上面这个钩子函数里设置了一个动态规划，数据流每次经过该层时都会对该值进行更新。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> name, layer <span class="keyword">in</span> model.named_modules():</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(layer, nn.Conv2d):</span><br><span class="line">        Qlayer = QuantizeLayer(name, layer)</span><br><span class="line">        Qlayer.quantize_weight()</span><br><span class="line">        <span class="comment"># Qlayer.quantize_blob()</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 对每一层 layer 注册 hook，目的是每次 forward 时更新 blob_max 值</span></span><br><span class="line">        layer.register_forward_pre_hook(Qlayer.hook)</span><br></pre></td></tr></table></figure>

<p>在获得这个 <code>blob_max</code> 值之后，我们会在 (0, blob_max) 划分 <code>2048</code> 个刻度（你也可以划分成4096个刻度，只要你喜欢），然后统计每个刻度范围内的数字出现的个数。例如，VGG16 最后一层输入流的直方图分布为：</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/理解英伟达-TensorRT-的-INT8-加速原理-20210609152447.png" style="max-width:60%;"></p>

<blockquote>
<p>可以看到第 <code>0</code> 个刻度的概率特别大，这表明大部分的数字都集中在(<code>-blob_max/2048, blob_max/2048</code>）区间内。</p>
</blockquote>
<p>假如我们设定阈值刻度 <code>Threshold=512</code>，因此需要将 <code>512</code> 个刻度合并成 <code>128</code> 个刻度（因为 int8 的正数范围为 0～127，一共 128 个刻度）。假设合并前 <code>(0,512)</code> 的分布为 P， 合并成 <code>(0, 127)</code> 后的分布为 Q。那么我们肯定要计算这两个分布的差异性，并希望它们之间的差异越小越好。</p>
<p align="center">
    <img width="43%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/理解英伟达-TensorRT-的-INT8-加速原理-20210609152516.png" style="max-width:80%;"></p>
    
<p>怎么计算两个分布的差异性呢？使用<a href="https://baike.baidu.com/item/%E7%9B%B8%E5%AF%B9%E7%86%B5/4233536?fromtitle=KL%E6%95%A3%E5%BA%A6&fromid=23238109&fr=aladdin"><strong><code>KL 散度</code></strong></a>就可以！它又称为交叉熵，等于概率分布的信息熵(<strong>Shannon entropy</strong>)的差值。我们可以使用<a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html">scipy.stats.entropy(p, q)</a>进行计算，但是它要求两个输入的长度必须相等：<code>len(p) == len(q)</code>。而<code>P</code>和<code>Q</code>的长度分别为512和128，因此我们需要将 <code>Q</code> 拓展回去，其长度也变成512。例如：</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/理解英伟达-TensorRT-的-INT8-加速原理-20210609152539.png" style="max-width:100%;"></p>

<table><center><td bgcolor= LightSalmon><font color=blue>
这里是将阈值刻度 Threshold 假设为 512，但在实际过程中我们需要遍历得到。由于量化刻度为 128，因此我们从 128 起遍历至最后一个刻度，计算出每个对应的 KL 散度值，最后那个最小 KL 散度所对应的刻度即为最佳阈值。</font></strong></td></center></table>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">quantize_blob</span>(<span class="params">self</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    对该层的输入数据流进行量化, 计算出最佳阈值</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    target_bin=<span class="number">128</span></span><br><span class="line">    distribution = self.blob_count[<span class="number">1</span>:] <span class="comment"># 第一刻度的量化不在考虑范围内，因为它映射到 int8 为0</span></span><br><span class="line">    length = distribution.size</span><br><span class="line">    threshold_sum = <span class="built_in">sum</span>(distribution[target_bin:])</span><br><span class="line">    kl_divergence = np.zeros(length - target_bin)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> threshold <span class="keyword">in</span> <span class="built_in">range</span>(target_bin, length):                 <span class="comment"># 遍历每个刻度值，并求出相应的 kl 散度</span></span><br><span class="line">        sliced_nd_hist = copy.deepcopy(distribution[:threshold])</span><br><span class="line"></span><br><span class="line">        p = sliced_nd_hist.copy()</span><br><span class="line">        p[threshold - <span class="number">1</span>] += threshold_sum <span class="comment"># boundary sum</span></span><br><span class="line">        threshold_sum = threshold_sum - distribution[threshold]</span><br><span class="line"></span><br><span class="line">        is_nonzeros = (p != <span class="number">0</span>).astype(np.int64)</span><br><span class="line">        quantized_bins = np.zeros(target_bin, dtype=np.int64)</span><br><span class="line">        num_merged_bins = sliced_nd_hist.size // target_bin</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(target_bin):</span><br><span class="line">            start = j * num_merged_bins</span><br><span class="line">            stop = start + num_merged_bins</span><br><span class="line">            quantized_bins[j] = sliced_nd_hist[start:stop].<span class="built_in">sum</span>()</span><br><span class="line">        quantized_bins[-<span class="number">1</span>] += sliced_nd_hist[target_bin * num_merged_bins:].<span class="built_in">sum</span>()</span><br><span class="line"></span><br><span class="line">        q = np.zeros(sliced_nd_hist.size, dtype=np.float64)</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(target_bin):</span><br><span class="line">            start = j * num_merged_bins</span><br><span class="line">            <span class="keyword">if</span> j == target_bin - <span class="number">1</span>:</span><br><span class="line">                stop = -<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                stop = start + num_merged_bins</span><br><span class="line">            norm = is_nonzeros[start:stop].<span class="built_in">sum</span>()</span><br><span class="line">            <span class="keyword">if</span> norm != <span class="number">0</span>:</span><br><span class="line">                q[start:stop] = <span class="built_in">float</span>(quantized_bins[j]) / <span class="built_in">float</span>(norm)</span><br><span class="line">        q[p == <span class="number">0</span>] = <span class="number">0</span></span><br><span class="line">        p[p == <span class="number">0</span>] = <span class="number">0.0001</span></span><br><span class="line">        q[q == <span class="number">0</span>] = <span class="number">0.0001</span></span><br><span class="line">        kl_divergence[threshold - target_bin] = stats.entropy(p, q)</span><br><span class="line"></span><br><span class="line">    min_kl_divergence = np.argmin(kl_divergence)        <span class="comment"># 求出最小的 kl 散度</span></span><br><span class="line">    threshold_bin = min_kl_divergence + target_bin      <span class="comment"># 求出最小 kl 散度对应的刻度</span></span><br><span class="line">    <span class="keyword">return</span> threshold_bin</span><br></pre></td></tr></table></figure>

<p>一旦获得了最佳阈值刻度后，我们就可以求出每层数据流的 blob_scale 值了，这一步发生在上面的 <code>hook</code> 函数中：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">hook</span>(<span class="params">self, modules, <span class="built_in">input</span></span>):</span></span><br><span class="line">    ... </span><br><span class="line">    threshold_bin = self.quantize_blob()</span><br><span class="line">    threshold_val = (threshold_bin + <span class="number">0.5</span>) * (self.blob_max / <span class="number">2048</span>)</span><br><span class="line">    self.blob_scale = <span class="number">127</span> / threshold_val</span><br></pre></td></tr></table></figure>

<h2 id="3-INT8-推理过程"><a href="#3-INT8-推理过程" class="headerlink" title="3. INT8 推理过程"></a>3. INT8 推理过程</h2><p>在上面的过程，其实无非就是求<strong><font color=red>卷积核权重和每层 feature map（即数据流）</font></strong>的 scale 值。有了这个 scale 值后，就可以实现 float32 和 int8 数据类型之间的映射。</p>
<table><center><td bgcolor= LightSalmon><font color=blue>
整个 INT8 推理过程可以简述为：输入流 x 在喂入每层卷积之前，需要先乘以 blob_scale 映射为 int8 类型数据，然后得到 int8 类型的卷积结果 x。由于卷积层的偏置 bias 没有被量化，它仍然是 float32 类型，因此我们需要将卷积结果 x 再映射回 float32，然后再与偏置 bias 相加。</font></strong></td></center></table>

<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/理解英伟达-TensorRT-的-INT8-加速原理-20210803170924.gif">
</p>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">    <span class="comment"># x= round(x * blobscale) →  input to int8</span></span><br><span class="line">    x = x * <span class="number">51.91119082631764</span>                     <span class="comment"># 乘以 feature map 的 scale，即 blob_scale</span></span><br><span class="line">    x = torch.<span class="built_in">round</span>(x)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># int8 conv due to dp4a-gpu  cudnn cublas support  we got int32 and transform to float32</span></span><br><span class="line">    x = self.conv1(x)</span><br><span class="line">    x = x - self.conv1.bias.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">2</span>).unsqueeze(<span class="number">3</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># output float32 /div weight scale(every channel)</span></span><br><span class="line">    <span class="keyword">for</span> i,scale <span class="keyword">in</span> <span class="built_in">enumerate</span>(conv1_param_0):</span><br><span class="line">        x[:,i,:,:]/=<span class="built_in">float</span>(scale)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># output float32 /div blobscale(input scale)</span></span><br><span class="line">    x = x / <span class="number">51.91119082631764</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># output = x +  conv&#x27;s fp32 bias</span></span><br><span class="line">    x = x + self.conv1.bias.unsqueeze(<span class="number">0</span>).unsqueeze(<span class="number">2</span>).unsqueeze(<span class="number">3</span>)</span><br><span class="line">    x = F.relu(x)</span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<p>需要说明的是：在上面的 python 代码中，我们首先将卷积结果 x 减去 bias，然后又分别按照 channel 通道除以 scale 和除以 blob_scale，最后再重新加上 bias 的值。这是因为卷积过程 <code>self.conv1(x)</code> 已经实现了 bias 相加的过程，因此我们要将结果先减去 bias 才能得到真正的卷积结果 x，由于卷积结果 x 的数据类型为 int8，所以要映射回 float32 再与 bias 相加。而实际应用的部署代码中是会将卷积计算和偏置相加的两个过程剥离开来的，这样就不用多此一举地将 bias 相减和相加了。</p>
<blockquote>
<p>思考一下，为什么英伟达的 TensorRT 没有对偏置 bias 进行 INT8 量化？我觉得可能是基于以下几点原因：</p>
</blockquote>
<ul>
<li>偏置 bias 是加法运算，其性能和开销本身就比卷积核的乘法运算要小很多。</li>
<li>NVIDIA 的研究人员已经用实验说明了偏置项量化并不太重要，并不能带来很大的性能提升。既然如此，本着奥卡姆剃刀原则，那就不必要牺牲精度来做量化。</li>
</ul>
<table><center><td bgcolor= LightSalmon><font color=blue>
最后想说说量化适合的应用场景：由于量化是牺牲了部分精度（虽然比较小）来压缩和加速网络，因此不适合精度非常敏感的任务。由于图片的信息冗余是非常大的，比如相邻一块的像素几乎都一模一样，因此用量化处理一些图像任务，比如目标检测、分类等对于精度不是非常敏感的 CV 任务而言是很适合的，但是对于一些回归任务比如深度估计就不太适合了。</font></strong></td></center></table>

<h2 id="4-如何处理-batchnorm-层"><a href="#4-如何处理-batchnorm-层" class="headerlink" title="4. 如何处理 batchnorm 层"></a>4. 如何处理 batchnorm 层</h2><p>对于卷积层之后带batchnorm的网络，因为一般在实际使用阶段，为了优化速度，batchnorm 的参数都会提前融合进卷积层的参数中，所以训练模拟量化的过程也要按照这个流程。首先把 batchnorm 的参数与卷积层的参数融合，然后再对这个参数做量化。</p>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/理解英伟达-TensorRT-的-INT8-加速原理-20210803163328.png">
</p>

<p>从而可以得到新的卷积权重和偏置：</p>
<p align="center">
    <img width="42%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/理解英伟达-TensorRT-的-INT8-加速原理-20210803163525.png">
</p>



<ul>
<li><a href="https://on-demand.gputechconf.com/gtc/2017/presentation/s7310-8-bit-inference-with-tensorrt.pdf">[1] nvdia官方的 tensorrt-int8 文档 </a></li>
<li><a href="https://paddleslim.readthedocs.io/zh_CN/v1.2.0/algo/algo.html#">[2] paddleslim 的 int8 量化文档，写得很赞👍 </a></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>TensorRT 部署</tag>
        <tag>INT8 加速原理</tag>
      </tags>
  </entry>
  <entry>
    <title> 去年阅读 《C++ Primer 中文版(第5版)》 的印象笔记</title>
    <url>/2021/05/23/C++_Primer-%E7%AC%AC5%E7%89%88-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<p>去年5月份我一个人从上海跳槽来广州，在这半年多的独居生活里我利用零碎的时间读了这本久负盛名 《C++ Primer 中文版(第5版)》。当时每周双休的时候坚持读大概二十页，竟不知不觉也读了一半多。但我觉得还是第六版写得更好，否则我也不会读了七八遍。而这本书还尚未读完，惭愧！</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/C++_Primer-第5版-阅读笔记-20210524180315.jpg">
</p>

<p>今天整理文档的时候发现了这份宝藏笔记，于是乎拿出来晒一晒。</p>
<span id="more"></span>




<h1 id="第一章-开始"><a href="#第一章-开始" class="headerlink" title="第一章 开始"></a>第一章 开始</h1><h2 id="编写一个简单的-C-程序"><a href="#编写一个简单的-C-程序" class="headerlink" title="编写一个简单的 C++ 程序"></a>编写一个简单的 C++ 程序</h2><p>每一个 C++ 程序都包含一个或多个函数(function)，但是其中一个必须命名为 <code>main</code>，操作系统将调用 <code>main</code> 来运行 C++ 程序。下面是一个非常简单的 <code>main</code> 函数，它什么也不干，只是返回操作系统一个值：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>大多数系统中，<code>main</code> 的返回值被用来指示状态。返回值 0 表明成功，非 0 的返回值的含义由系统来定义，通常用来指出错误类型。然后我们可以用 <code>gcc</code> 对它进行编译和运行:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ g++ prog1.cc</span><br><span class="line">$ ./a.out</span><br></pre></td></tr></table></figure>

<p>我们可以通过 <code>echo</code> 来获取其返回值，在 <code>UNIX</code> 系统中，通过如下命令获取状态:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">% echo $?</span><br><span class="line">0</span><br></pre></td></tr></table></figure>

<h2 id="初识输入输出"><a href="#初识输入输出" class="headerlink" title="初识输入输出"></a>初识输入输出</h2><p><code>iostream</code> 库包括两个基础类型 <code>istream</code> 和 <code>ostream</code>，分别表示输入流和输出流。</p>
<h3 id="向流写入数据"><a href="#向流写入数据" class="headerlink" title="向流写入数据"></a>向流写入数据</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::cout &lt;&lt; <span class="string">&quot;Enter two numbers:&quot;</span>;</span><br><span class="line">std::cout &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure>

<p>第一个输出运输符给用户打印一条信息，在双引号之间的文本将被打印到标准输出。第二个运算符打印 <code>endl</code> ，它表示的效果是结束当前行，并将设备关联的缓冲区（buff) 中的内容刷新到设备中，从而可以保证目前为止程序所产生的所有输出都真正写入到输入流中，而不是仅停留在内存中等待写入流。</p>
<h3 id="从流读取数据"><a href="#从流读取数据" class="headerlink" title="从流读取数据"></a>从流读取数据</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i, j;</span><br><span class="line">    std::cin &gt;&gt; i &gt;&gt; j;</span><br><span class="line">    std::cout &lt;&lt; i + j &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>编译运行后：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ./a.out</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td></tr></table></figure>

<h1 id="第二章-变量和基本类型"><a href="#第二章-变量和基本类型" class="headerlink" title="第二章 变量和基本类型"></a>第二章 变量和基本类型</h1><h2 id="基本内置类型"><a href="#基本内置类型" class="headerlink" title="基本内置类型"></a>基本内置类型</h2><p>通过添加下表所列的前缀和后缀，可以改变整型，浮点型和字符型字面值的默认类型：</p>
<ul>
<li>  对于字符和字符串字面值</li>
</ul>
<table>
<thead>
<tr>
<th>前缀</th>
<th>含义</th>
<th>类型</th>
</tr>
</thead>
<tbody><tr>
<td>u</td>
<td>Unicode 16 字符</td>
<td>char16_t</td>
</tr>
<tr>
<td>U</td>
<td>Unicode 32 字符</td>
<td>char32_t</td>
</tr>
<tr>
<td>L</td>
<td>宽字符</td>
<td>wchar_t</td>
</tr>
<tr>
<td>u8</td>
<td>UTF-8</td>
<td>char</td>
</tr>
</tbody></table>
<ul>
<li>  对于整型字面值</li>
</ul>
<table>
<thead>
<tr>
<th>后缀</th>
<th>最小匹配类型</th>
</tr>
</thead>
<tbody><tr>
<td>u or U</td>
<td>unsigned</td>
</tr>
<tr>
<td>l or L</td>
<td>long</td>
</tr>
<tr>
<td>ll or LL</td>
<td>long long</td>
</tr>
</tbody></table>
<ul>
<li>  对于浮点型字面型</li>
</ul>
<table>
<thead>
<tr>
<th>后缀</th>
<th>类型</th>
</tr>
</thead>
<tbody><tr>
<td>f or F</td>
<td>float</td>
</tr>
<tr>
<td>l or L</td>
<td>long double</td>
</tr>
</tbody></table>
<p>例如：</p>
<pre><code>L&#39;a&#39;          // 宽字符型字面值，类型是 wchar_t
u8&quot;hi!&quot;       // utf-8 字符串字面值
42ULL         // 无符号整型字面值， 类型是 unsigned long long
1E3-F         // 单精度浮点型字面值，类型是 float
3.14159L      // 扩展精度浮点字面型，类型是 long double
</code></pre>
<h2 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h2><p>变量定义的基本形式是：首先是类型说明符，随后紧跟由一个或多个变量名组成的列表，其中变量名以逗号分割，最后以分号结束。例如</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> sum = <span class="number">0</span>, val = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">double</span> price = <span class="number">109.9</span>, discount = price * <span class="number">0.16</span>;</span><br></pre></td></tr></table></figure>

<p>变量都是具有作用域的，一般用花括号 <code>&#123; &#125;</code> 去声明，有时候会配合关键词 <code>namespace</code>，例如:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">namespace</span> cv&#123;</span><br><span class="line">    <span class="keyword">int</span> val = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>上述这种带名字的作用域既可以出现在 <code>.h</code> 文件中，也可以出现在 <code>.cpp</code><br>文件中。</p>
<h2 id="复合类型"><a href="#复合类型" class="headerlink" title="复合类型"></a>复合类型</h2><p>复合类型是基于其他类型定义的类型。C++ 语言有几种复合类型，本章将介绍其中的两种：引用和指针。</p>
<h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p>引用（reference）为对象起了另外一个名字，引用类型引用另外一种类型。通过将声明符写成<br><code>&amp;d</code> 的形式来定义引用类型，其中 <code>d</code> 是声明<strong>变量的别名</strong>：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> ival = <span class="number">1024</span>;</span><br><span class="line"><span class="keyword">int</span> &amp;refVal = ival;             <span class="comment">// refVal 是 ival 的另外一个名字</span></span><br><span class="line"><span class="keyword">int</span> &amp;refVal2;                 <span class="comment">// 报错，引用必须初始化</span></span><br></pre></td></tr></table></figure>

<p>允许在一条语句中定义多个引用，其中每个引用标识符都必须以符号<code>&amp;</code>开头：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i=<span class="number">1024</span>, j=<span class="number">2048</span>;</span><br><span class="line"><span class="keyword">int</span> &amp;ri=i, &amp;rj=j;</span><br></pre></td></tr></table></figure>

<h3 id="指针"><a href="#指针" class="headerlink" title="指针"></a>指针</h3><h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>与引用类似，指针也实现了对其他对象的间接访问，然而指针与引用又有很多不同点。其一，指针本身就是一个对象，允许对指针赋值和拷贝，而且在指针的生命周期内他可以先后指向几个不同的对象。其二，指针无须在定义时赋初值。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> *ip1, *ip2;    <span class="comment">// ip1 和 ip2 都是指向 int 型对象的指针</span></span><br></pre></td></tr></table></figure>

<p>指针存放某个对象的地址，要想获取该地址，需要使用取地址符号 <code>&amp;</code>：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> ival = <span class="number">42</span>;</span><br><span class="line"><span class="keyword">int</span> *p = &amp;ival;     <span class="comment">// p 存放的是 ival 的地址</span></span><br></pre></td></tr></table></figure>

<p>如果指针指向了一个对象，则允许使用解引用符 <code>*</code> 来访问该对象：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> ival = <span class="number">42</span>;</span><br><span class="line"><span class="keyword">int</span> *p = &amp;ival;</span><br><span class="line">cout &lt;&lt; *p;         <span class="comment">// 由 * 得到指针 p 所指向的对象，输出 42</span></span><br></pre></td></tr></table></figure>

<h4 id="nullptr-和-void-指针"><a href="#nullptr-和-void-指针" class="headerlink" title="nullptr 和 void 指针"></a>nullptr 和 void 指针</h4><p>有两种指针需要特别注意：</p>
<ul>
<li>  nullptr 指针：nullptr 是 C++11 新标准刚引入的一种方法，它可以被转换成任意其他类型的指针；</li>
<li>void<br>  指针：这是一种特殊的指针类型，可用于存放任意对象的地址，这就很牛逼了。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> obj = <span class="number">3.14</span>, *pd = &amp;obj;</span><br><span class="line"><span class="keyword">void</span> *pv = &amp;obj                 <span class="comment">// obj 可以是任意类型的对象</span></span><br><span class="line">pv = pd;                        <span class="comment">// pv 是可以存放任意类型的指针</span></span><br></pre></td></tr></table></figure>

<h4 id="指向指针的指针"><a href="#指向指针的指针" class="headerlink" title="指向指针的指针"></a>指向指针的指针</h4><p>指针是内存的对象，像其他对象一样也有自己的地址，因此允许把<strong>指针的地址再存放到另一个指针当中。</strong>通过 <code>*</code> 的个数可以区分指针的级别，也就是说，<code>**</code> 表示指向指针的指针，<code>***</code> 表示指向指针的指针的指针，以此内推：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> ival = <span class="number">1024</span>;</span><br><span class="line"><span class="keyword">int</span> *pi = &amp;ival;     <span class="comment">// 一级指针 pi，它指向一个 int 的数</span></span><br><span class="line"><span class="keyword">int</span> **ppi = &amp;pi;     <span class="comment">// 二级指针 ppi，它指向一个 int 型的指针</span></span><br></pre></td></tr></table></figure>

<p>二级指针在实际工作中有很多用处，例如我在工作中就遇到过这样的代码：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">IOnnxSession *<span class="title">CreateOnnxSession</span><span class="params">(<span class="keyword">const</span> <span class="keyword">wchar_t</span> *model_path, <span class="keyword">int</span> num_threads, <span class="keyword">int</span> gpu_id)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="built_in">OnnxSession</span>(model_path, num_threads, gpu_id);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ReleaseOnnxSession</span><span class="params">(IOnnxSession **ptr)</span> </span>&#123; <span class="comment">// ptr 是一个二级指针</span></span><br><span class="line">    <span class="keyword">if</span> (ptr &amp;&amp; *ptr) &#123;</span><br><span class="line">        <span class="keyword">delete</span> *ptr;</span><br><span class="line">        *ptr = <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">wchar_t</span> *model_path = <span class="string">&quot;yolo.onnx&quot;</span>;</span><br><span class="line">yolo_session = <span class="built_in">CreateOnnxSession</span>(model_path, <span class="number">1</span>, <span class="number">0</span>);  <span class="comment">// 创建一个指向 IOnnxSession 的一级指针</span></span><br><span class="line"><span class="built_in">ReleaseOnnxSession</span>(&amp;yolo_session);                   <span class="comment">// 释放内存</span></span><br></pre></td></tr></table></figure>

<p>其实这里有个非常值得深思的地方，为什么用于销毁对象的 <code>ReleaseOnnxSession</code> 函数的形参要用一个二级指针呢，一级指针不行吗？我们来看看，假如我们用一级指针的话，那么该函数应该这样改写</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ReleaseOnnxSession</span><span class="params">(IOnnxSession *ptr)</span> </span>&#123; <span class="comment">// ptr 是一个一级指针</span></span><br><span class="line">    <span class="keyword">if</span> (ptr) &#123;</span><br><span class="line">        <span class="keyword">delete</span> ptr;</span><br><span class="line">        ptr = <span class="literal">NULL</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="built_in">ReleaseOnnxSession</span>(yolo_session);                   <span class="comment">// 释放内存</span></span><br></pre></td></tr></table></figure>

<p>看起来好像没什么问题，但其实这样做的安全隐患很大：指针 <code>yolo_session</code> 传入函数 <code>ReleaseOnnxSession</code> 中会<strong>发生拷贝，从而产生一个临时变量指针</strong> <code>_yolo_ssesion</code>，由于 <code>_yolo_session</code> 存放的地址和 <code>ptr</code> 是一样的，因此 <code>delete</code> 操作能够把对象 <code>yolo_session</code> 给销毁掉。但是却不会把 <code>yolo_ssesion</code> 指针置为 <code>nullptr</code> 指针，这就是使得 <code>yolo_session</code> 成了一个<a href="https://baike.baidu.com/item/%E9%87%8E%E6%8C%87%E9%92%88">野指针</a>。</p>
<h2 id="限定符"><a href="#限定符" class="headerlink" title="限定符"></a>限定符</h2><ul>
<li>  因为 const 对象一旦创建后就不能改变，<strong>所以 const 对象必须初始化</strong>；</li>
<li>  默认状态下，const 对象仅在文件内有效，如果需要被其他文件访问，则需要加 extern；</li>
</ul>
<h3 id="const-的引用"><a href="#const-的引用" class="headerlink" title="const 的引用"></a>const 的引用</h3><p>与普通引用不同的是，const 引用不能通过别名去改变它所绑定的对象。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> ci = <span class="number">1024</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> &amp;r1 = ci;     <span class="comment">// 不能通过别名 r1 去改变 ci 的值</span></span><br></pre></td></tr></table></figure>

<p>但是这并不意味着 ci 的值就不能改变了，只是不能通过 r1 去改变而已。</p>
<h3 id="指针和-const"><a href="#指针和-const" class="headerlink" title="指针和 const"></a>指针和 const</h3><p>如果我们要想存放常量对象的地址，就必须使用指向常量的指针：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="keyword">double</span> pi = <span class="number">3.14</span>;     <span class="comment">// pi 是个常量，它的值不能改变</span></span><br><span class="line"><span class="keyword">double</span> *ptr = &amp;pi;          <span class="comment">// 错误，普通指针不能存放常量的地址</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">double</span> *cptr = &amp;pi;   <span class="comment">// 正确</span></span><br></pre></td></tr></table></figure>

<p>还有一种指针是常量性的，即 const 指针：常量指针一旦初始化，就不能改变它的值了（即存放在指针中的那个地址），即不变的是指针本身而非指向的那个值。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> val = <span class="number">10</span>;</span><br><span class="line"><span class="keyword">int</span> *<span class="keyword">const</span> ptr = &amp;val;      <span class="comment">// 以后就不能改变 ptr 所指向的地址了</span></span><br></pre></td></tr></table></figure>

<p>这里值得注意的是，指针本身是一个常量并不意味着就不能通过该指针修改所指向对象的值。能否这样做完全取决于所指对象的类型，例如：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> pi = <span class="number">3.14</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">double</span> *<span class="keyword">const</span> pip = &amp;pi; <span class="comment">// 这里既不能改变指针 pip 的值，也不能通过 pip 去改变 pi 的值</span></span><br></pre></td></tr></table></figure>

<h3 id="顶层-const"><a href="#顶层-const" class="headerlink" title="顶层 const"></a>顶层 const</h3><p>指针本身是一个对象，它又可以指向另一个对象。因此，指针本身是不是常量以及指针所指向的是不是常量就是两个相互独立的问题。用名词<strong>顶层 const</strong> 表示指针本身就是个常量，而用名词<strong>底层 const</strong> 表示指针所指向的对象是一个常量。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">int</span>* <span class="keyword">const</span> p1 = &amp;i;       <span class="comment">// 不能改变 p1 的值，这是一个顶层 const</span></span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> ci = <span class="number">42</span>;</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> *p2 = &amp;ci;      <span class="comment">// p2 所指的对象是一个常量，而且 p2 可以改变，所以这是一个底层 const</span></span><br></pre></td></tr></table></figure>

<h3 id="constexpr-和常量表达式"><a href="#constexpr-和常量表达式" class="headerlink" title="constexpr 和常量表达式"></a>constexpr 和常量表达式</h3><p><strong>常量表达式（const expression)</strong> 是指值不会改变并且在<strong>编译过程</strong>中就能得到计算结果的表达式。C++规范在一些地方要求使用常量表达式，如声明数组的维数，以下这样是错误的：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">get_five</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">5</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">int</span> data[<span class="built_in">get_five</span>() + <span class="number">7</span>]; <span class="comment">// 创建包含12个整数的数组. 这是非法的，因为get_five() + 7不是常量表达式</span></span><br></pre></td></tr></table></figure>

<p>在实际中，我们很难判断是不是常量表达式，幸运的是 C++11 引入了关键字 constexpr，允许编程者保证函数或对象的构造函数是编译时常量。上述代码可以改写为：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">constexpr</span> <span class="keyword">int</span> <span class="title">get_five</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">5</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> data[<span class="built_in">get_five</span>() + <span class="number">7</span>]; <span class="comment">// Create an array of 12 integers. Valid C++11</span></span><br></pre></td></tr></table></figure>

<p>非常需要注意的是 constexpr 关键词是为了在编译期间进行优化用的，如果相关参数在运行期间才能确定的话，就不要用它了。</p>
<h2 id="处理类型"><a href="#处理类型" class="headerlink" title="处理类型"></a>处理类型</h2><p>有时候一些类型的名字难以拼写，我们无法明确体现其真实目的和含义。这时候如果用类型别名，就能很好帮助我们理解类型的语义信息。</p>
<h3 id="类型别名"><a href="#类型别名" class="headerlink" title="类型别名"></a>类型别名</h3><p>有两种方法定义类型别名。传统的方法是使用关键字 <code>typedef</code>:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="keyword">double</span> wages;       <span class="comment">// wages 是 double 的同义词</span></span><br><span class="line"><span class="keyword">typedef</span> wages base, *p;     <span class="comment">// base 是 double 的同义词，p 是 double* 的同义词</span></span><br></pre></td></tr></table></figure>

<p><code>C++11</code> 新标准规定了另一种新方法，使用别名声明来定义类型的别名:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">using</span> SI = Sales_item;    <span class="comment">// SI 是 Sales_item 的同义词</span></span><br></pre></td></tr></table></figure>

<h3 id="auto-类型说明符"><a href="#auto-类型说明符" class="headerlink" title="auto 类型说明符"></a>auto 类型说明符</h3><p>编程时常常需要把表达式的值赋给变量，这就要求在声明变量的时候清楚地知道表达式的类型，然而做到这一点并非那么容易。为了解决这个问题，C++11 新标准引入了 <code>auto</code> 类型说明符，用它就可以让编译器替我们去分析表达式所属的类别。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> val1 = <span class="number">10</span>, val2 = <span class="number">20</span>;</span><br><span class="line"><span class="keyword">auto</span> val3 = val1 + val2;       <span class="comment">// 自动推断 val3 的类型为 int</span></span><br></pre></td></tr></table></figure>

<p>使用 <code>auto</code> 也能在一条语句中声明多个变量:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> i=<span class="number">0</span>, *p=&amp;i;               <span class="comment">// 正确: i 时整数，p 是整型指针</span></span><br></pre></td></tr></table></figure>

<h3 id="decltype-类型指示符"><a href="#decltype-类型指示符" class="headerlink" title="decltype 类型指示符"></a>decltype 类型指示符</h3><p><code>auto</code> <strong>有个鸡肋的地方是，它定义的变量必须要初始化。而我们有时候希望从表达式的类型推断出要定义的变量类型，却不想用该表达式的值初始化变量。</strong>为了满足这一要求，C++11 新标准引入了第二种类型说明符 <code>decltype</code>，它的作用是选择并返回操作数的数据类型。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> ci = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">decltype</span>(ci) z;             <span class="comment">// 声明 z，z 的类型就是 ci 的类型 (int)</span></span><br></pre></td></tr></table></figure>

<h1 id="第三章-字符串、向量和数组"><a href="#第三章-字符串、向量和数组" class="headerlink" title="第三章 字符串、向量和数组"></a>第三章 字符串、向量和数组</h1><p>本章将介绍两种最重要的标准库类型：<code>string</code> 和 <code>vector</code>。<code>string</code> 表示可变长的字符串序列，<code>vector</code> 存放的是某种给定类型对象的可变长序列。在开始它们之前，我们先来学习一种访问库中名字的简单方法。</p>
<h2 id="命名空间的-using-声明"><a href="#命名空间的-using-声明" class="headerlink" title="命名空间的 using 声明"></a>命名空间的 using 声明</h2><p>我们通常用 <code>std::cin</code> 表示从标准输入中读取内容，这种方法会比较繁琐。其实我们可以使用<strong>using 声明</strong>来直接访问命名空间中的名字：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> std::cin;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> i;</span><br><span class="line">    cin &gt;&gt; i;</span><br><span class="line">    std::cout &lt;&lt; i &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>一般来说，位于头文件中的声明应该尽量避免使用 <code>using</code> 声明。这是因为头文件中的内容会拷贝到所有引用它的文件中去，可能会发生名字冲突，这点需要注意。</p>
</blockquote>
<h2 id="标准库类型-string"><a href="#标准库类型-string" class="headerlink" title="标准库类型 string"></a>标准库类型 string</h2><p>作为标准库的一部分，<code>string</code> 定义在命名空间 <code>std</code> 中。接下来的示例都假定已经包含了下述代码：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> std::string;</span><br></pre></td></tr></table></figure>

<h3 id="定义和初始化-string-对象"><a href="#定义和初始化-string-对象" class="headerlink" title="定义和初始化 string 对象"></a>定义和初始化 string 对象</h3><p>下面列出了初始化 <code>string</code> 对象最常使用的一些方式:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">string s1;              <span class="comment">// 默认初始化，s1 是一个空字符串</span></span><br><span class="line">string s2 = s1;         <span class="comment">// s2 是 s1 的副本</span></span><br><span class="line">string s3 = <span class="string">&quot;hiya&quot;</span>；    <span class="comment">// s3 是该字符串字面的副本</span></span><br><span class="line">string <span class="built_in">s4</span>(<span class="number">10</span>, <span class="string">&#x27;c&#x27;</span>);     <span class="comment">// s4 的内容是 cccccccccc</span></span><br></pre></td></tr></table></figure>

<p>C++ 语言有几种不同的初始化方式，通过 <code>string</code> 我们可以清楚地看到这些初始化方式之间有什么区别和联系。如果使用等号 <code>(=)</code> 初始化一个变量，实际上执行的是<strong>拷贝初始化</strong>，编译器把等号右侧的初始值拷贝到新创建的对象中去。与之相反，如果不使用等号，则执行的是<strong>直接初始化</strong>。 </p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    std::string s0 = <span class="string">&quot;hello&quot;</span>;           <span class="comment">// 拷贝初始化</span></span><br><span class="line">    <span class="function">std::string <span class="title">s1</span><span class="params">(<span class="string">&quot;hello&quot;</span>)</span></span>;            <span class="comment">// 直接初始化</span></span><br><span class="line">    std::string s2 = s1;                <span class="comment">// 拷贝初始化</span></span><br><span class="line"></span><br><span class="line">    s1[<span class="number">0</span>] = <span class="string">&#x27;n&#x27;</span>;</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; s0 &lt;&lt; std::endl;       <span class="comment">// hello</span></span><br><span class="line">    std::cout &lt;&lt; s1 &lt;&lt; std::endl;       <span class="comment">// nello</span></span><br><span class="line">    std::cout &lt;&lt; s2 &lt;&lt; std::endl;       <span class="comment">// hello</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="string-对象上的操作"><a href="#string-对象上的操作" class="headerlink" title="string 对象上的操作"></a>string 对象上的操作</h3><ul>
<li><code>empty</code> 和 <code>size</code> 操作</li>
</ul>
<p>顾名思义，<code>empty</code> 函数根据 <code>string</code> 对象是否为空返回一个对应的布尔值，<code>size</code> 函数返回 <code>string</code> 对象的长度（即 <code>string</code> 对象中字符的个数）。对于 <code>size</code> 函数来说，它返回的是一个 <code>string::size_type</code> 类型值，它是一个无符号的值而且足够存放任何 <code>string</code> 的大小。尽管我们不太清楚 <code>string::size_type</code> 类型的细节，但是 <code>C++11</code> 新标准中允许编译器通过 <code>auto</code> 或 <code>decltype</code> 来推断变量的类型:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> len = line.<span class="built_in">size</span>();        <span class="comment">// len 的类型是 string::size_type</span></span><br></pre></td></tr></table></figure>

<ul>
<li>两个 <code>string</code> 对象相加</li>
</ul>
<p>两个 <code>string</code> 对象相加得到一个新的 <code>string</code> 对象，内容是把左侧的运算对象与右侧对象串接而成。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">string s1 = <span class="string">&quot;hello, &quot;</span>;</span><br><span class="line">string s2 = <span class="string">&quot;world\n&quot;</span>;</span><br><span class="line">string s3 = s1 + s2;     <span class="comment">// s3 的内容是 hello, world\n</span></span><br><span class="line">s1 += s2;                <span class="comment">// 等价于 s1 = s1 + s2</span></span><br></pre></td></tr></table></figure>
<ul>
<li>字面值和 <code>string</code> 对象相加</li>
</ul>
<p>当 <code>string</code> 对象和字符字面值及字符串字面值混合在一条语句中使用时，必须确保每个加法运算符 <code>(+)</code> 的两侧的运算对象至少有一个是 <code>string</code>。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">string s4 = s1 + <span class="string">&quot;, &quot;</span>;             <span class="comment">// 正确</span></span><br><span class="line">string s5 = <span class="string">&quot;hello&quot;</span> + <span class="string">&quot;, &quot;</span>;        <span class="comment">// 错误</span></span><br><span class="line">string s6 = s1 + <span class="string">&quot;, &quot;</span> + <span class="string">&quot;world&quot;</span>;   <span class="comment">// 正确, s1 + &quot;, &quot; 返回的是一个 string 对象</span></span><br><span class="line">string s7 = <span class="string">&quot;hello&quot;</span> + <span class="string">&quot;, &quot;</span> + s2;   <span class="comment">// 错误</span></span><br></pre></td></tr></table></figure>
<h2 id="标准库类型-vector"><a href="#标准库类型-vector" class="headerlink" title="标准库类型 vector"></a>标准库类型 vector</h2><p>要想使用 <code>vector</code>，必须包含适当的头文件：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br></pre></td></tr></table></figure>
<p><strong>vector 是一个类模版</strong>，我们将在模版名字后面一对尖括号，在括号内存放对象的类型：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::vector&lt;<span class="keyword">int</span>&gt; ivec;                  <span class="comment">// ivec 保存 int 类型的对象</span></span><br><span class="line">std::vector&lt;std::vector&lt;<span class="keyword">int</span>&gt;&gt; file;  <span class="comment">// file 保存的是 vector 对象</span></span><br></pre></td></tr></table></figure>
<h3 id="定义和初始化-vector-对象"><a href="#定义和初始化-vector-对象" class="headerlink" title="定义和初始化 vector 对象"></a>定义和初始化 vector 对象</h3><p>和任何一种类类型一样，<code>vector</code> 模版控制着定义和初始化向量的方法，下表列出了定义 <code>vector</code> 对象的常用方法。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::vector&lt;T&gt; v1;                     <span class="comment">// v1 是一个空 vector，而且 capacity 也返回 0，意味着还没有分配内存空间</span></span><br><span class="line"><span class="function">std::vector&lt;T&gt; <span class="title">v2</span><span class="params">(v1)</span></span>;                 <span class="comment">// v2 中包含 v1 所有元素的副本</span></span><br><span class="line">std::vector&lt;T&gt; v2 = v1;                <span class="comment">// 等价于 v2(v1)，v2 中包含有 v1 所有元素的副本</span></span><br><span class="line"><span class="function">std::vector&lt;T&gt; <span class="title">v3</span><span class="params">(n, val)</span></span>;             <span class="comment">// v3 包含了 n 个重复元素，每个元素的值都是 val</span></span><br><span class="line"><span class="function">std::vector&lt;T&gt; <span class="title">v4</span><span class="params">(n)</span></span>;                  <span class="comment">// v4 包含了 n 个重复地执行了值初始化的对象</span></span><br><span class="line">std::vector&lt;T&gt; v5&#123;a,b,c, ...&#125;          <span class="comment">// v5 包含了初始值个数的元素，每个元素被赋予相应的初始值</span></span><br><span class="line">std::vector&lt;T&gt; v5=&#123;a,b,c ...&#125;          <span class="comment">// 相当于 v5&#123;a,b,c, ...&#125;</span></span><br></pre></td></tr></table></figure>

<p>另外，<code>.data()</code> 函数提供了一个能直接指向内存中存储 <code>vector</code> 元素位置的指针。由于 <code>vector</code> 里面的元素都是顺序连续存放的，该指针可以通过偏移量来访问数组内的所有元素。</p>
<ul>
<li>程序：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    std::vector&lt;<span class="keyword">int</span>&gt; vi = &#123;<span class="number">1</span>,<span class="number">20</span>,<span class="number">30</span>&#125;;</span><br><span class="line">    std::cout&lt;&lt; <span class="string">&quot;vi.capacity=&quot;</span> &lt;&lt; vi.<span class="built_in">capacity</span>() &lt;&lt;std::endl;</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">auto</span> p = vi.<span class="built_in">data</span>();</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;p=&quot;</span> &lt;&lt; p &lt;&lt; std::endl;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;*p=&quot;</span> &lt;&lt;*p &lt;&lt; std::endl;</span><br><span class="line">    std::cout&lt;&lt;<span class="string">&quot;*(p+2)=&quot;</span> &lt;&lt; *(p+<span class="number">2</span>)&lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>输出：</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">╭─yang@yangdeMacBook-Pro.local ~  </span><br><span class="line">╰─➤  ./a.out </span><br><span class="line">vi.capacity=3</span><br><span class="line">p=0x7ff2d2405790</span><br><span class="line">*p=1</span><br><span class="line">*(p+2)=30</span><br></pre></td></tr></table></figure>


<h3 id="向-vector-对象添加元素"><a href="#向-vector-对象添加元素" class="headerlink" title="向 vector 对象添加元素"></a>向 vector 对象添加元素</h3><p>向 <code>vector</code> 对象添加元素可以使用成员函数 <code>push_back</code> 进行添加，它负责把一个元素 “压” (<strong>push</strong>) 到 <code>vector</code> 对象到末端。例如：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::vector&lt;<span class="keyword">int</span>&gt; v2;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">100</span>; i++)&#123;</span><br><span class="line">    v2.<span class="built_in">push_back</span>(i);            <span class="comment">// 依次把整数放到 v2 尾端</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>但是我们其实还有一种更快的添加元素函数，它是 <code>C++11</code> 引入的新特性: <code>emplace_back</code> 方法。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::vector&lt;<span class="keyword">int</span>&gt; v2;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">100</span>; i++)&#123;</span><br><span class="line">    v2.<span class="built_in">emplace_back</span>(i);         <span class="comment">// 依次把整数放到 v2 尾端</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>C++11</code> 引入了右值引用（转移构造函数），<code>push_back</code> 会调用构造函数和右值引用，使用 <code>emplace_back</code> 替代 <code>push_back</code> 可以在这上面有进一步优化空间，它只调用构造函数不需要调用右值引用转移构造函数。如下面这个例子所示：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">A</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">A</span> (<span class="keyword">int</span> x_arg) : <span class="built_in">x</span> (x_arg) &#123; std::cout &lt;&lt; <span class="string">&quot;A (x_arg)\n&quot;</span>; &#125;           <span class="comment">// 构造函数</span></span><br><span class="line">        <span class="built_in">A</span> () &#123; x = <span class="number">0</span>; std::cout &lt;&lt; <span class="string">&quot;A ()\n&quot;</span>; &#125;</span><br><span class="line">        <span class="built_in">A</span> (<span class="keyword">const</span> A &amp;rhs) <span class="keyword">noexcept</span> &#123; x = rhs.x; std::cout &lt;&lt; <span class="string">&quot;A (A &amp;)\n&quot;</span>; &#125;</span><br><span class="line">        <span class="built_in">A</span> (A &amp;&amp;rhs) <span class="keyword">noexcept</span> &#123; x = rhs.x; std::cout &lt;&lt; <span class="string">&quot;A (A &amp;&amp;)\n&quot;</span>; &#125;      <span class="comment">// 右值引用</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="keyword">int</span> x;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    std::vector&lt;A&gt; a;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;call push_back:\n&quot;</span>;</span><br><span class="line">    a.<span class="built_in">push_back</span>(<span class="number">0</span>);</span><br><span class="line">    <span class="comment">// (1) create temp object and </span></span><br><span class="line">    <span class="comment">// (2) then move copy to vector and </span></span><br><span class="line">    <span class="comment">// (3) free temp object</span></span><br><span class="line">    </span><br><span class="line">    std::vector&lt;A&gt; b;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;call emplace_back:\n&quot;</span>;</span><br><span class="line">    b.<span class="built_in">emplace_back</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="comment">// (1) direct object creation inside vector</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">╭─yangyun@yangyundeMBP.lan ~ ‹system› </span><br><span class="line">╰─➤  g++ test.cpp -std=c++11</span><br><span class="line">╭─yangyun@yangyundeMBP.lan ~ ‹system› </span><br><span class="line">╰─➤  ./a.out </span><br><span class="line">call push_back:              # push_back 调用构造函数和右值引用</span><br><span class="line">A (x_arg)</span><br><span class="line">A (A &amp;&amp;)</span><br><span class="line">call emplace_back:           # emplace_back 只调用了构造函数</span><br><span class="line">A (x_arg)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>右值引用：以前我们对一个临时变量进行搬运的时候，通常调用的是拷贝构造函数，它需要重新创建一个新指针并指向一块新内存，然后将原来内存的内容拷贝过来。而现在右值引用是不会分配一块新的内存，而只是创建一个新的指针并指向原来那块内存，原指针就会被销毁掉。</p>
</blockquote>
<h3 id="向-vector-对象删除元素"><a href="#向-vector-对象删除元素" class="headerlink" title="向 vector 对象删除元素"></a>向 vector 对象删除元素</h3><p>假设我们想针对容器 <code>std::vector&lt;int&gt; vec = &#123;0,1,2,3,4,5,6,7&#125;</code> 删除掉大于 5 的数字，那么我们可以使用 <strong>iterator</strong> 进行遍历删除。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> iter = vec.<span class="built_in">begin</span>();</span><br><span class="line"><span class="keyword">while</span>(iter != vec.<span class="built_in">end</span>())&#123;</span><br><span class="line">    <span class="keyword">if</span>(*iter&gt;<span class="number">5</span>)&#123;           <span class="comment">// 如果值大于 5 则删除</span></span><br><span class="line">        vec.<span class="built_in">erase</span>(iter);</span><br><span class="line">    &#125; <span class="keyword">else</span>&#123;</span><br><span class="line">        iter++;            <span class="comment">// 否则继续遍历</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;vec.<span class="built_in">size</span>(); i++)&#123;</span><br><span class="line">    std::cout &lt;&lt; vec[i] &lt;&lt; <span class="string">&quot; &quot;</span>;             <span class="comment">// 0 1 2 3 4 5</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>但是我们切记不能通过通过以下 <code> i&lt;vec.size()</code> 的方法去遍历删除，这是因为容器 <code>vec</code> 在遍历删除的过程中，容器内的元素是变化的。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;vec.<span class="built_in">size</span>(); i++)&#123;</span><br><span class="line">    <span class="keyword">if</span>(vec[i]&gt;<span class="number">5</span>)</span><br><span class="line">        vec.<span class="built_in">erase</span>(vec.<span class="built_in">begin</span>()+i);            <span class="comment">// vec 删除元素 6 的时候便停止遍历了</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;vec.<span class="built_in">size</span>(); i++)&#123;</span><br><span class="line">    std::cout &lt;&lt; vec[i] &lt;&lt; <span class="string">&quot; &quot;</span>;             <span class="comment">// 0 1 2 3 4 5 7</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="vector-对象的越界检查"><a href="#vector-对象的越界检查" class="headerlink" title="vector 对象的越界检查"></a>vector 对象的越界检查</h3><p><code>STL</code> 实现者在对 <code>vector</code> 进行内存分配的时候，其实际的容量要比当前所需的空间要多一些。就是说，<code>vector</code> 容器<strong>预留了一些额外的存储区，用于存放新添加的元素。</strong>比如 <code>vec</code> 虽然只初始化了 8 个元素，但是它可能实际分配了 8000 个元素所需的空间。</p>
<ul>
<li><code>operator []</code> 是不会进行越界检查的，使用它可能会发生意想不到的访问错误，但是它的访问速度非常快；</li>
<li>使用成员函数 <code>at</code> 也可以进行访问，但是每次访问前都会对下标索引进行检查，这使得速度慢了两三倍。</li>
</ul>
<h2 id="迭代器介绍"><a href="#迭代器介绍" class="headerlink" title="迭代器介绍"></a>迭代器介绍</h2><p>对于容器 <code>vector</code> 或 <code>string</code> 对象，我们可以通过下标索引去直接访问元素。但是对于一些链表结构，我们只能通过节点中指向下一节点的指针去遍历访问，直到我们找到想要的元素为止。</p>
<ul>
<li>数组的 <code>find</code> 函数</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">double</span> *<span class="title">find_ar</span><span class="params">(<span class="keyword">double</span> *ar, <span class="keyword">int</span> n, <span class="keyword">const</span> <span class="keyword">double</span> &amp;val)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;n; i++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(arr[i] == val)</span><br><span class="line">            <span class="keyword">return</span> &amp;ar[i];</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>链表的 <code>find</code> 函数</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span>&#123;</span></span><br><span class="line">    <span class="keyword">double</span> item;</span><br><span class="line">    Node *p_next;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Node *<span class="title">find_ll</span><span class="params">(Node *head, <span class="keyword">const</span> <span class="keyword">double</span> &amp;val)</span></span>&#123;</span><br><span class="line">    Node *start;</span><br><span class="line">    <span class="keyword">for</span>(start == head; start != <span class="number">0</span>; start = start-&gt;p_next)</span><br><span class="line">        <span class="keyword">if</span>(start-&gt;item == val)</span><br><span class="line">            <span class="keyword">return</span> start;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果我们有一个迭代器能够直接通过 <code>p</code> 访问容器中某一元素，并且通过 <code>p++</code> 或 <code>++p</code> 去访问下一个元素就好了。（这里 <code>p</code> 相当于一个指针）这就是迭代器出现的原因之一。</p>
<h3 id="使用迭代器"><a href="#使用迭代器" class="headerlink" title="使用迭代器"></a>使用迭代器</h3><p>迭代器里经常使用的是 <code>begin</code> 和 <code>end</code> 方法：其中 <code>begin</code> 成员负责返回指向第一个元素的迭代器，<code>end</code> 成员负责返回指向容器 <strong>“尾元素的下一位置（on past the end)”</strong>，也就是说，该迭代器指示的是容器的一个本不存在的 <strong>“尾后”</strong> 元素。这样的迭代器根本没有什么实际含义，仅是个标记而已，表示我们已经处理完了容器中所有元素。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> iter=vec.<span class="built_in">begin</span>(); iter!=vec.<span class="built_in">end</span>(); iter++)</span><br><span class="line">    <span class="keyword">if</span>(*iter == val)</span><br><span class="line">        <span class="keyword">return</span> iter;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">nullptr</span>;</span><br></pre></td></tr></table></figure>
<h3 id="迭代器运算"><a href="#迭代器运算" class="headerlink" title="迭代器运算"></a>迭代器运算</h3><p><code>string</code> 和 <code>vector</code> 的迭代器提供了更多额外的运算符，一方面可使得迭代器的每次移动可以跨过多个元素，另外也支持迭代器进行关系运算。</p>
<table>
<thead>
<tr>
<th>运算</th>
<th>含义</th>
</tr>
</thead>
<tbody><tr>
<td><code>iter + n</code></td>
<td>迭代器向后移动了 n 个元素的位置</td>
</tr>
<tr>
<td><code>iter - n</code></td>
<td>迭代器向前移动了 n 个元素的位置</td>
</tr>
<tr>
<td><code>iter += n</code></td>
<td>迭代器的加法复合赋值语句，将 <code>iter</code> 加 n 的值赋给 <code>iter</code></td>
</tr>
<tr>
<td><code>iter -= n</code></td>
<td>迭代器的减法复合赋值语句，将 <code>iter</code> 减 n 的值赋给 <code>iter</code></td>
</tr>
<tr>
<td><code>&gt;、&gt;=、 &lt;、&lt;=</code></td>
<td>迭代器的关系运算符，如果某迭代器指向容器位置在另一个迭代器所指位置之前，则说明前者小于后者。</td>
</tr>
</tbody></table>
<p>使用迭代器运算的一个经典算法是二分搜索，二分搜索从有序序列中寻找某个给定的值。二分搜索从序列中间的位置开始搜索，如果中间位置元素正好就是要找的元素，搜索完成；如果不是，假如该元素小于要找的元素，则在序列的后半部分继续搜索；假如该元素大于要找的元素，则在序列的前半部分继续搜索。在缩小范围中计算一个新的中间元素并重复之前的过程，直至最终找到目标或没有元素可以继续搜索。</p>
<p>下面的程序使用迭代器完成了二分搜索。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// text 必须是有序的，beg 和 end 表示我们的搜索范围</span></span><br><span class="line"><span class="keyword">auto</span> beg = text.<span class="built_in">begin</span>(), end = text.<span class="built_in">end</span>();</span><br><span class="line"><span class="keyword">auto</span> mid = text.<span class="built_in">begin</span>() + (end - beg) / <span class="number">2</span>;   <span class="comment">// 初始状态的中间位置</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(mid != end &amp;&amp; *mid != sought)&#123;</span><br><span class="line">    <span class="keyword">if</span>(sought &lt; *mid)</span><br><span class="line">        end = mid;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        beg = mid + <span class="number">1</span>;                     <span class="comment">// 在 mid 之后寻找</span></span><br><span class="line">    mid = beg + (end - beg) / <span class="number">2</span>;           <span class="comment">// 新的中间点</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><p> 与 <code>vector</code> 相似的地方是，数组也是存放类型相同的对象的容器，这些对象本身没有名字，需要通过其所在的位置访问。与 <code>vector</code> 不同的地方是，数组的大小确定不变，不能随意向数组中增加元素。</p>
<h3 id="定义和初始化内置数组"><a href="#定义和初始化内置数组" class="headerlink" title="定义和初始化内置数组"></a>定义和初始化内置数组</h3><p>数组是一种复合类型，数组的声明形如 <code>a[d]</code>，其中 <code>a</code> 是数组的名字，<code>d</code> 是数组的维度。维度说明了数组中元素的个数，因此必须大于 0。一般而言，初始化数组通常会遇到有以下几种方式：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> a[] = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>&#125;;     <span class="comment">// a 含有 3 个整数元素</span></span><br><span class="line"><span class="keyword">int</span> *b[<span class="number">10</span>];            <span class="comment">// b 含有 10 个整数型指针的数组</span></span><br><span class="line"><span class="built_in"><span class="keyword">int</span></span> (*c)[<span class="number">10</span>];          <span class="comment">// c 指向一个含有 10 个整数的数组</span></span><br><span class="line"><span class="built_in">ing</span> (&amp;d)[<span class="number">10</span>];          <span class="comment">// d 引用一个含有 10 个整数的数组</span></span><br></pre></td></tr></table></figure>
<h3 id="访问数组元素"><a href="#访问数组元素" class="headerlink" title="访问数组元素"></a>访问数组元素</h3><p>与标准库类型 <code>vector</code> 和 <code>string</code> 一样，数组的元素也能使用 <code>for</code> 语句或下标运算符来访问。在使用数组下标的时候，通常将其定义为 <code>size_t</code> 类型。**<code>size_t</code> 是一种机器相关的无符号类型，它被设计得足够大以便能表示内存中任意对象的大小**。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> array[<span class="number">10</span>];</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">size_t</span> i=<span class="number">0</span>; i&lt;<span class="number">10</span>; i++)</span><br><span class="line">    array[i] = <span class="number">1</span>;</span><br></pre></td></tr></table></figure>
<h3 id="指针和数组"><a href="#指针和数组" class="headerlink" title="指针和数组"></a>指针和数组</h3><p>在 <code>C++</code> 语言中，指针和数组有非常紧密的联系。就如即将介绍的，使用数组的时候编译器一般会将它转换成指针。数组的元素也是对象，因此向其他对象一样，对数组元素取地址符就能得到指向该元素的指针。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">string nums[] = &#123;<span class="string">&quot;one&quot;</span>, <span class="string">&quot;two&quot;</span>, <span class="string">&quot;three&quot;</span>&#125;;</span><br><span class="line">string *p1 = &amp;nums[<span class="number">2</span>];                     <span class="comment">// p1 指向 nums 的第三个元素</span></span><br></pre></td></tr></table></figure>

<p>然而，数组还有一个特性：在很多用到数组名字的地方，编译器会自动地替换为一个指向数组首元素的指针：<code>string *p2 = nums;</code> 它等价于 <code>string *p2 = &amp;nums[0]</code>。</p>
<p>就像使用迭代器遍历 <code>vector</code> 对象中的元素一样，使用指针也能遍历数组中的元素。之前介绍过，通过数组的名字或者数组中首元素的地址都能得到指向首元素的指针。给指针加上一个整数，得到的新指针仍指向同一数组的其他元素。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> arr[] = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>&#125;;</span><br><span class="line"><span class="keyword">int</span> *ip1 = arr;             <span class="comment">// 等价于 int *ip1 = &amp;arr[0]</span></span><br><span class="line"><span class="keyword">int</span> *ip2 = ip1 + <span class="number">2</span>;         <span class="comment">// ip2 指向 arr 的第三个元素 arr[2]</span></span><br></pre></td></tr></table></figure>

<p>只要指针指向的是数组的元素，都可以执行下标运算：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> j = ip2[<span class="number">1</span>];             <span class="comment">// 等价于 j = arr[3]</span></span><br><span class="line"><span class="keyword">int</span> k = ip2[<span class="number">-2</span>];            <span class="comment">// 等价于 k = arr[0]</span></span><br></pre></td></tr></table></figure>
<h1 id="第四章-表达式"><a href="#第四章-表达式" class="headerlink" title="第四章 表达式"></a>第四章 表达式</h1><p>表达式是由一个或多个运算对象组成，对表达式求值将得到一个结果。字面值和变量是最简单的表达式，其结果就是字面值和变量的值。把一个运算符和一个或多个运算对象组合起来可以生成较为复杂的表达式。</p>
<h2 id="左值和右值"><a href="#左值和右值" class="headerlink" title="左值和右值"></a>左值和右值</h2><p><code>C++</code> 的表达式要不然是<strong>右值（rvalue, 读作 “are-value”）</strong>，要不然就是<strong>左值（lvalue, 读作 “ell-value”）</strong>。可以对它们作一个简单的归纳：当一个对象被用作右值的时候，用的是对象的值（内容）；当对象被用作左值的时候，用的是对象的身份（在内存中的位置）。</p>
<h3 id="通俗的说法"><a href="#通俗的说法" class="headerlink" title="通俗的说法"></a>通俗的说法</h3><p>还有另一种更容易理解的说法：<strong>在C++11中可以取地址的、有名字的就是左值，反之，不能取地址的、没有名字的就是右值</strong>。例如，<code>int a = b+c</code>, <code>a</code> 就是左值，其有变量名为 <code>a</code>，通过 <code>&amp;a</code> 可以获取该变量的地址；而表达式 <code>b+c</code>，我们不能通过变量名找到它，<code>＆(b+c)</code> 这样的操作则不会通过编译。</p>
<h3 id="左值引用"><a href="#左值引用" class="headerlink" title="左值引用"></a>左值引用</h3><p>左值引用通常也不能绑定到右值，而是绑定在已初始化的左值上：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> &amp;a = <span class="number">2</span>;       # 左值引用绑定到右值，编译失败</span><br><span class="line"><span class="keyword">int</span> b = <span class="number">2</span>;        # 非常量左值</span><br><span class="line"><span class="keyword">const</span> <span class="keyword">int</span> &amp;c = b; # 常量左值引用绑定到非常量左值，编译通过</span><br></pre></td></tr></table></figure>

<h3 id="右值引用"><a href="#右值引用" class="headerlink" title="右值引用"></a>右值引用</h3><p>右值值引用通常不能绑定到任何的左值，要想绑定一个左值到右值引用，通常需要 <code>std::move()</code> 将左值强制转换为右值，例如：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> a = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">int</span> &amp;&amp;r1 = a;             # 编译失败</span><br><span class="line"><span class="keyword">int</span> &amp;&amp;r2 = std::<span class="built_in">move</span>(a);  # 编译通过</span><br></pre></td></tr></table></figure>

<blockquote>
<p>右值引用和左值引用都是属于引用类型。无论是声明一个左值引用还是右值引用，都必须立即进行初始化。而其原因可以理解为是引用类型本身自己并不拥有所绑定对象的内存，只是该对象的一个别名。</p>
</blockquote>
<p>例如，C++11 给 <code>string</code> 类添加了移动语义，这意味着添加一个<strong>移动构造函数</strong>时，它使用右值引用而非左值引用：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in">basic_string</span>(basic_string &amp;&amp;str) <span class="keyword">noexcept</span>;</span><br></pre></td></tr></table></figure>

<p>在实参为临时对象时将调用这个构造函数：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">string <span class="title">one</span><span class="params">(<span class="string">&quot;din&quot;</span>)</span></span>;         <span class="comment">// C-style string constructor</span></span><br><span class="line"><span class="function">string <span class="title">two</span><span class="params">(one)</span></span>;           <span class="comment">// copy constructor - one is an lvalue</span></span><br><span class="line"><span class="function">string <span class="title">three</span><span class="params">(one+two)</span></span>;     <span class="comment">// move constructor - sum is an rvalue</span></span><br></pre></td></tr></table></figure>

<p>在上面中，<code>three</code> 将获取 <code>operator+()</code> 创建的对象的所有权，<strong>而不是将对象复制给 <code>three</code>，然后再销毁对象</strong>。</p>
<h2 id="各种运算符"><a href="#各种运算符" class="headerlink" title="各种运算符"></a>各种运算符</h2><h3 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h3><table>
<thead>
<tr>
<th>运算符</th>
<th>功能</th>
<th>用法</th>
</tr>
</thead>
<tbody><tr>
<td><code>&amp;&amp;</code></td>
<td>逻辑与</td>
<td><code>expr &amp;&amp; expr</code></td>
</tr>
<tr>
<td><code>!</code></td>
<td>逻辑非</td>
<td><code>!expr</code></td>
</tr>
</tbody></table>
<h3 id="递增和递减运算符"><a href="#递增和递减运算符" class="headerlink" title="递增和递减运算符"></a>递增和递减运算符</h3><p>递增和递减运算符有两种形式：前置版本和后置版本，它们的的区别在于返回值的不同。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i = j = <span class="number">0</span>, k;</span><br><span class="line">k = ++i;    <span class="comment">// k = 1, i = 1</span></span><br><span class="line">k = j++;    <span class="comment">// k = 0, j = 1</span></span><br></pre></td></tr></table></figure>

<p>举个例子，可以使用这种递增运算符来控制循环输出一个 <code>vector</code> 对象内容直至遇到（但不包括）第一个负值为止:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> pbeg = v.<span class="built_in">begin</span>();</span><br><span class="line"><span class="comment">// 输出元素直至遇到第一个负值为止</span></span><br><span class="line"><span class="keyword">while</span> (pbeg != v.<span class="built_in">end</span>() &amp;&amp; *pbeg &gt;= <span class="number">0</span>)</span><br><span class="line">    std::cout &lt;&lt; *pbeg++ &lt;&lt; std::endl; <span class="comment">// 输出当前值并将 pbeg 向前移动一个元素</span></span><br></pre></td></tr></table></figure>

<p>形如 <code>*pbeg++</code> 的表达式一开始可能不太容易理解，但其实这是一种被广泛使用的、有效的写法。当对这种形式熟悉之后，书写</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::cout &lt;&lt; *iter++ &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure>

<p>要比书写下面的等价语句更简洁、也更少出错</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::cout &lt;&lt; *iter &lt;&lt; std::endl;</span><br><span class="line">++iter;</span><br></pre></td></tr></table></figure>

<h3 id="条件运算符"><a href="#条件运算符" class="headerlink" title="条件运算符"></a>条件运算符</h3><p>条件运算符 <code>?:</code> 允许我们把简单的 <code>if-else</code> 逻辑潜入到单个表达式当中，条件运算符按照如下形式使用：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">cond? expr1: expr2;</span><br></pre></td></tr></table></figure>
<p>它执行的过程是：首先求 <code>cond</code> 的值，如果条件为真对 <code>expr1</code> 求值并返回该值，否则对 <code>expr2</code> 求值并返回该值。举个例子，我们可以使用条件运算符判断成绩是否合格：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">string final_grade1 = (grade &lt; <span class="number">60</span>)? <span class="string">&quot;fail&quot;</span>: <span class="string">&quot;pass&quot;</span>;</span><br><span class="line">string final_grade2 = (grade &gt; <span class="number">90</span>)? <span class="string">&quot;high pass&quot;</span></span><br><span class="line">                                  : (grade &lt; <span class="number">60</span>) ? <span class="string">&quot;fail&quot;</span>: <span class="string">&quot;pass&quot;</span>;</span><br></pre></td></tr></table></figure>

<h3 id="移位运算符"><a href="#移位运算符" class="headerlink" title="移位运算符"></a>移位运算符</h3><p>移位运算是对其运算对象执行基于二进制位的移动操作，首先令左侧运算对象的内容按照右侧运算对象的要求移动指定位数，然后将经过移动的左侧运算对象的拷贝作为求值结果。二进制位或者向左移<code>（&lt;&lt;)</code> 或者向右移<code>（&gt;&gt;）</code>，移出边界之外的位就被舍弃掉了。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">unsigned</span> <span class="keyword">char</span> bits = <span class="number">0233</span>;    </span><br></pre></td></tr></table></figure>
<p><code>unsigned char</code> 保存只有一个字节，即 8 位。但是它首先会将 <code>bits</code> 提升成 <code>int</code> 类型（32位），因此<code>0233</code> 的二进制表示如下：</p>
<p><code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> | <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> | <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> | <code>1</code> <code>0</code> <code>0</code> <code>1</code> <code>1</code> <code>0</code> <code>1</code> <code>1</code></p>
<ul>
<li>向左移动 8 位</li>
</ul>
<p><code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> | <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> | <code>1</code> <code>0</code> <code>0</code> <code>1</code> <code>1</code> <code>0</code> <code>1</code> <code>1</code> | <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code></p>
<ul>
<li>向左移动 31 位，左边超出边界的位丢弃掉了</li>
</ul>
<p><code>1</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> | <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> | <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> | <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code></p>
<ul>
<li>向右移动 3 位，最右边的 3 位舍弃掉了</li>
</ul>
<p><code>1</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> | <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> | <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> <code>0</code> | <code>0</code> <code>0</code> <code>0</code> <code>1</code> <code>0</code> <code>0</code> <code>1</code> <code>1</code></p>
<h2 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h2><p>举个例子，考虑下面这条表达式，它的目的是是将 <code>ival</code> 初始化为 <code>6</code>。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> ival = <span class="number">3.543</span> + <span class="number">3</span>;                         <span class="comment">// 编译器可能会警告该运算损失了精读</span></span><br></pre></td></tr></table></figure>

<p>加法的两个运算对象类型不同：3.543 的类型是 <code>double</code>，3 的类型是 <code>int</code>。C++ 语言不会将两个不同类型的对象相加，而是先根据类型转换规则设法将运算对象的类型统一后再求值。上述的类型是自动执行的，无须程序员的介入，它们被称为<strong>隐式转换</strong>。有时我们希望显示转换对象强制转换成另外一种类型，C++ 给我们提供了 4 种显示转换的方式。</p>
<h3 id="static-cast"><a href="#static-cast" class="headerlink" title="static_cast"></a>static_cast</h3><p>任何具有明确定义的类型转换，只要不包含底层 <code>const</code> ，都可以使用 <code>static_cast</code>。例如，通过将一个运算对象强制转换成 <code>double</code> 类型就能使表达式执行浮点数除法。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i = j = <span class="number">2</span>;</span><br><span class="line"><span class="keyword">double</span> slope = <span class="keyword">static_cast</span>&lt;<span class="keyword">double</span>&gt;(j) / i;       <span class="comment">// 编译器将不会发出警告信息</span></span><br></pre></td></tr></table></figure>

<p><code>static_cast</code> 对于编译器无法自动执行的类型转换也非常有用。例如，我们可以使用 <code>static_cast</code> 找回存在于 <code>void*</code> 指针中的值。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">void</span> *p = &amp;d;                              <span class="comment">// 正确：任何非常量对象的地址都可以存入 void*</span></span><br><span class="line"><span class="keyword">double</span> *dp = <span class="keyword">static_cast</span>&lt;<span class="keyword">double</span>*&gt;(p);      <span class="comment">// 正确：将 void* 指针转换回初始指针的类型</span></span><br></pre></td></tr></table></figure>
<h3 id="dynamic-cast"><a href="#dynamic-cast" class="headerlink" title="dynamic_cast"></a>dynamic_cast</h3><p><code>dynamic_cast</code> 是运行阶段类型识别（RunTime Type Identification，简称<strong>RTTI</strong>) 的一种，它不能回答“指针指向的是哪类对象”这样的问题，但能回答“是否可以安全地将对象的地址赋给特定类型的指针”这样的问题。先来看看下面一段程序：</p>
<p>程序：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Base</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span></span>&#123;</span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;调用基类方法&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Derived</span>:</span> <span class="keyword">public</span> Base&#123;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">foo</span><span class="params">()</span></span>&#123;</span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;调用子类方法&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// dynamic_cast 在运行时会进行检查，开销比 static_cast（没有开销）大一些</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    Base*    pg = <span class="keyword">new</span> Base;</span><br><span class="line">    Derived* ps = <span class="keyword">new</span> Derived;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 不能将基类指针转化成派生类指针，因为派生类的方法基类不一定有，因此转化失败，得到 NULL 指针</span></span><br><span class="line">    Derived* pa = <span class="keyword">dynamic_cast</span>&lt;Derived*&gt;(pg);</span><br><span class="line">    <span class="keyword">if</span>(pa == <span class="literal">NULL</span>)&#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;pa == NULL&quot;</span> &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 下面比较 dynamic_cast 和 static_cast 两种转换方式:</span></span><br><span class="line"></span><br><span class="line">    Base* pb = <span class="keyword">dynamic_cast</span>&lt;Base*&gt;(ps);</span><br><span class="line">    <span class="keyword">if</span>(pb != <span class="literal">NULL</span>)&#123;</span><br><span class="line">        std::cout &lt;&lt; pb &lt;&lt; std::endl;</span><br><span class="line">        pb-&gt;<span class="built_in">foo</span>();                            <span class="comment">// pb 虽然是基类指针，但是会根据 RTTI 原则调用子类的方法</span></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    Derived* pc = <span class="keyword">static_cast</span>&lt;Derived*&gt;(pg);  <span class="comment">// 在编译器进行转化，不会在运行期进行检查，访问的依然是 Base 的 foo 方法</span></span><br><span class="line">    <span class="keyword">if</span>(pc != <span class="literal">NULL</span>)&#123;</span><br><span class="line">        std::cout &lt;&lt; pc &lt;&lt; std::endl;</span><br><span class="line">        pc-&gt;<span class="built_in">foo</span>();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span>  <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">╭─yangyun@yangyundeMBP.lan ~ ‹system› </span><br><span class="line">╰─➤  ./a.out </span><br><span class="line">pa == NULL</span><br><span class="line">0x7faaf0d02720</span><br><span class="line">调用子类方法</span><br><span class="line">0x7faaf0d02710</span><br><span class="line">调用基类方法</span><br></pre></td></tr></table></figure>

<p>这里提出了这样的问题：基类指针 <code>pg</code> 的类型是否可以被安全地转换为 <code>Derived*</code>？如果可以，运算符将返回对象的地址，否则返回一个空指针。显然 <code>dynamic_cast</code> 这里对这个转换做了检查，认为这种转换非法，因此返回了一个 <code>NULL</code> 指针。</p>
<blockquote>
<p>将基类对象的地址赋给子类指针是非法的，这是因为子类可能会包含一些基类没有的数据成员和方法，然而将子类对象的地址赋值给基类指针是安全的。</p>
</blockquote>
<h3 id="const-cast"><a href="#const-cast" class="headerlink" title="const_cast"></a>const_cast</h3><p>提供 <code>const_cast</code> 运算符的原因是，有时候可能需要这样一个值，它在大多数的时候是常量，而有时又是可以修改的。在这种情况下，可以将这个值声明为 <code>const</code>，并在需要修改它的时候，使用 <code>const_cast</code>。</p>
<p>程序：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> const_val = <span class="number">26</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">int</span>* ptr = <span class="keyword">const_cast</span>&lt;<span class="keyword">int</span>*&gt;(&amp;const_val);   <span class="comment">// 将 const_val 的地址通过 const_cast 运算符赋值给指针 ptr</span></span><br><span class="line">    *ptr = <span class="number">3</span>;                                  <span class="comment">// 指针 ptr 可以修改它指向的值</span></span><br><span class="line"></span><br><span class="line">    std::cout&lt;&lt; <span class="string">&quot;constant:  &quot;</span> &lt;&lt; const_val &lt;&lt; std::endl;</span><br><span class="line">    std::cout&lt;&lt; <span class="string">&quot;    *ptr:  &quot;</span> &lt;&lt; *ptr      &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">╭─yangyun@yangyundeMBP.lan ~ ‹system› </span><br><span class="line">╰─➤  ./a.out </span><br><span class="line">constant:  26</span><br><span class="line">    *ptr:  3</span><br></pre></td></tr></table></figure>

<p>非常趣味的是：<code>C++</code> 还是很厚道的，对声明为 <code>const</code>的变量 <code>const_val</code> 来说，常量就是常量，任你各种转化，常量的值就是不会变，这是C++的一个承诺。</p>
<h3 id="reinterpret-cast"><a href="#reinterpret-cast" class="headerlink" title="reinterpret_cast"></a>reinterpret_cast</h3><p><code>reinterpret_cast</code> 通常为运算对象的位模式提供较低层次上的重新解释, 其作用为: <strong>允许将任何指针转换为任何其他指针类型。 也允许将任何整数类型转换为任何指针类型以及反向转换</strong>。举个例子，假设有如下的转换。</p>
<p>程序:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> a = <span class="number">65</span>;</span><br><span class="line">    <span class="keyword">char</span> *p1 = <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">char</span>*&gt;(&amp;a);</span><br><span class="line">    std::cout &lt;&lt; *p1 &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">╭─yangyun@yangyundeMBP.lan ~ ‹system› </span><br><span class="line">╰─➤  ./a.out </span><br><span class="line">A</span><br></pre></td></tr></table></figure>

<p>上述转化是可以的，因为它其实是将一个 <code>int</code> 类型的变量转化为 <code>char</code> 变量（<code>A</code> 的 <code>ASCII</code> 码为 <code>65</code>）。接下来再使用 <code>p1</code> 时就会认定它的值是 <code>char*</code> 类型，编译器没法知道它实际存放的是指向 <code>int</code> 的指针。这可能会引发一些严重的后果，而查找这类问题的原因会变得非常困难。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> b = <span class="number">0x00636261</span>;</span><br><span class="line"><span class="keyword">char</span> *p2 = <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">char</span>*&gt;(b);    <span class="comment">// 直接将整数 b 强行解释为 char 类型的地址</span></span><br></pre></td></tr></table></figure>

<p>如果我们想要访问指针 p2 指向的值 <code>std::cout &lt;&lt; *p2 &lt;&lt; std::endl;</code> 就会出现段错误(<code>segmentation fault</code>)。因为这块地址压根不存在，属于非法地址。</p>
<blockquote>
<p>reinterpret_cast 本质上非常依赖于机器，要想安全使用它，就必须对涉及的类型和编译器实现转换的过程非常了解，建议谨慎使用。</p>
</blockquote>
<h1 id="第五章-语句"><a href="#第五章-语句" class="headerlink" title="第五章 语句"></a>第五章 语句</h1><h2 id="简单语句和作用域"><a href="#简单语句和作用域" class="headerlink" title="简单语句和作用域"></a>简单语句和作用域</h2><p>C++ 语言中的大多数语句都以分号结束，一个表达式，比如 <code>ival + 5</code>，末尾加上分号就变成了表达式语句。表达式语句的作用是执行表达式并丢弃掉求值结果:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">ival + <span class="number">5</span>;                            <span class="comment">// 一条没什么实际用处的表达式语句</span></span><br><span class="line">std::cout &lt;&lt; ival;                   <span class="comment">// 一条有用的语句</span></span><br></pre></td></tr></table></figure>

<p>可以在 <code>if, switch, while</code> 和 <code>for</code> 语句的控制结构内定义变量。定义在控制结构当中的变量只在相应语句的内部可见，一旦语句结束，变量也就超出其作用范围了。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="keyword">int</span> i = <span class="built_in">get_num</span>())</span><br><span class="line">    std::cout &lt;&lt; i &lt;&lt; std::endl;         <span class="comment">// 每次迭代时创建并初始化 i</span></span><br><span class="line">i = <span class="number">0</span>;           <span class="comment">// 错误：在循环外部无法访问 i</span></span><br></pre></td></tr></table></figure>

<h2 id="条件语句"><a href="#条件语句" class="headerlink" title="条件语句"></a>条件语句</h2><p>C++ 语言提供了两种按条件执行的语句。一种是 <code>if</code> 语句，它根据条件决定控制流；另外一种是 <code>switch</code> 语句，它计算一个整型表达式的值，然后根据这个值从几条执行路径中选一条。</p>
<h3 id="if-语句"><a href="#if-语句" class="headerlink" title="if 语句"></a>if 语句</h3><p><code>if</code> 语句的作用是：判断一个指定的条件是否为真，根据判断的结果决定是否执行另外一条语句。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> grade = <span class="number">80</span>;</span><br><span class="line"></span><br><span class="line">    std::string lettergrade;</span><br><span class="line">    <span class="keyword">const</span> std::vector&lt;std::string&gt; scores = &#123;<span class="string">&quot;F&quot;</span>, <span class="string">&quot;D&quot;</span>, <span class="string">&quot;C&quot;</span>, <span class="string">&quot;B&quot;</span>, <span class="string">&quot;A&quot;</span>, <span class="string">&quot;A++&quot;</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span>(grade &lt; <span class="number">60</span>)</span><br><span class="line">        lettergrade += <span class="string">&quot;+&quot;</span>;</span><br><span class="line">    <span class="keyword">else</span>&#123;</span><br><span class="line">        lettergrade = scores[(grade<span class="number">-50</span>)/<span class="number">10</span>];</span><br><span class="line">        <span class="keyword">if</span>(grade % <span class="number">10</span> &gt; <span class="number">7</span>)</span><br><span class="line">            lettergrade += <span class="string">&quot;+&quot;</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(grade % <span class="number">10</span> &lt; <span class="number">3</span>)</span><br><span class="line">            lettergrade += <span class="string">&quot;-&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="switch-语句"><a href="#switch-语句" class="headerlink" title="switch 语句"></a>switch 语句</h3><p><code>switch</code> 语句提供了一条便利的途径使得我们能够在若干固定选项中做出选择。举个例子，假如我们想统计 5 个元音字母和其他字母在文本中出现的次数，程序逻辑应该如下所示：</p>
<p>程序：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    std::string str;</span><br><span class="line">    std::cin &gt;&gt; str;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">unsigned</span> aCnt = <span class="number">0</span>, eCnt = <span class="number">0</span>, iCnt = <span class="number">0</span>, oCnt = <span class="number">0</span>, uCnt = <span class="number">0</span>, otherCnt = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;str.<span class="built_in">size</span>(); i++)&#123;</span><br><span class="line">        <span class="keyword">char</span> ch = str[i];</span><br><span class="line">        <span class="built_in"><span class="keyword">switch</span></span>(ch)&#123;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;a&#x27;</span>:</span><br><span class="line">                ++aCnt;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;e&#x27;</span>:</span><br><span class="line">                ++eCnt;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;i&#x27;</span>:</span><br><span class="line">                ++iCnt;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;o&#x27;</span>:</span><br><span class="line">                ++oCnt;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">case</span> <span class="string">&#x27;u&#x27;</span>:</span><br><span class="line">                ++uCnt;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            <span class="keyword">default</span>:             <span class="comment">// 如果前面都不是，那就属于其他字母</span></span><br><span class="line">                ++otherCnt;</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Number of vowel a: \t&quot;</span> &lt;&lt; aCnt &lt;&lt; <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">              &lt;&lt; <span class="string">&quot;Number of vowel e: \t&quot;</span> &lt;&lt; eCnt &lt;&lt; <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">              &lt;&lt; <span class="string">&quot;Number of vowel i: \t&quot;</span> &lt;&lt; iCnt &lt;&lt; <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">              &lt;&lt; <span class="string">&quot;Number of vowel o: \t&quot;</span> &lt;&lt; oCnt &lt;&lt; <span class="string">&#x27;\n&#x27;</span></span><br><span class="line">              &lt;&lt; <span class="string">&quot;Number of vowel u: \t&quot;</span> &lt;&lt; uCnt &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>输出:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">╭─yangyun@yangyundeMBP.lan ~ ‹system› </span><br><span class="line">╰─➤  ./a.out </span><br><span class="line">hello world</span><br><span class="line">Number of vowel a: 	0</span><br><span class="line">Number of vowel e: 	1</span><br><span class="line">Number of vowel i: 	0</span><br><span class="line">Number of vowel o: 	1</span><br><span class="line">Number of vowel u: 	0</span><br></pre></td></tr></table></figure>

<h2 id="迭代语句"><a href="#迭代语句" class="headerlink" title="迭代语句"></a>迭代语句</h2><p>迭代语句通常称为循环，它重复执行操作直到满足某个条件才停下来。<code>while</code> 和 <code>for</code> 语句在执行循环体之前检查条件，<code>do while</code> 语句先执行循环体，然后再检查条件。</p>
<h3 id="while-语句"><a href="#while-语句" class="headerlink" title="while 语句"></a>while 语句</h3><p>只要条件为真，<code>while 语句</code> 就会重复地执行循环体，它的语法形式是:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">while (condition)</span><br><span class="line">    statement</span><br></pre></td></tr></table></figure>

<p>在 <code>while</code> 结构中，只要 <code>condition</code> 的求值结果为真就一直执行 <code>statement</code>。<code>condition</code> 不能为空，如果 <code>condition</code> 第一次求值就得 <code>false</code>，<code>statement</code> 一次都不执行。</p>
<h3 id="传统的-for-语句"><a href="#传统的-for-语句" class="headerlink" title="传统的 for 语句"></a>传统的 for 语句</h3><p>for 语句的语法形式是:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for (init-statement; condition; expression)</span><br><span class="line">    statement</span><br></pre></td></tr></table></figure>

<p>一般情况下，<code>init-statement</code> 负责初始化一个值，这个值将随着循环的进行二改变，<code>condition</code> 作为控制循环的条件，只要 <code>condition</code> 为真，就执行一次 <code>statement</code>。<code>expression</code> 负责修改 <code>init-statement</code> 初始化的变量，这个变量刚好是 <code>condition</code> 检查的对象。</p>
<h3 id="范围-for-语句"><a href="#范围-for-语句" class="headerlink" title="范围 for 语句"></a>范围 for 语句</h3><p>C++11 新标准引入了一种更简单的 <code>for</code> 语句，这种语句可以遍历容器和其他序列的所有元素。<strong>范围 for 语句</strong>的语法形式是:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for (declaration: expression)</span><br><span class="line">    statement</span><br></pre></td></tr></table></figure>

<p><code>expression</code> 表示的必须是一个序列，比如用花括号括起来的初始值列表、数组或者 <code>vector</code> 或 <code>string</code> 等类型的对象，这些类型的共同特点是拥有能返回迭代器的 <code>begin</code> 和 <code>end</code> 成员。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::vector&lt;<span class="keyword">int</span>&gt; v = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>&#125;;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> &amp;r: v)</span><br><span class="line">    r *= <span class="number">2</span>;             <span class="comment">// 将 v 中每个元素的值翻倍</span></span><br></pre></td></tr></table></figure>

<p><code>for</code> 语句头声明了循环控制变量 <code>r</code>，并把它和 <code>v</code> 关联在一起，我们使用 <code>auto</code> 令编译器为 <code>r</code> 指定正确的类型。<strong>由于准备修改 <code>v</code> 元素的值，因此将 <code>r</code> 声明成引用类型</strong>。此时，在循环内给 <code>r</code> 赋值，即改变了 <code>r</code> 所绑定元素的值。</p>
<h3 id="do-while-语句"><a href="#do-while-语句" class="headerlink" title="do while 语句"></a>do while 语句</h3><p><code>do while 语句</code> 和 <code>while</code> 语句非常相似，唯一的区别是：<code>do while</code> 语句先执行循环体后检查条件。<strong>不管条件的值如何，我们都至少执行一次循环</strong>。<code>do while</code> 语句的语法形式如下所示:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">do</span><br><span class="line">    statement</span><br><span class="line">while (condition)</span><br></pre></td></tr></table></figure>

<p>在 <code>do</code> 语句中，求 <code>condition</code> 的值之前首先执行一次 <code>statement</code>，<code>condition</code> 不能为空。如果 <code>condition</code> 的值为假，循环终止；否则，重复循环过程。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</span><br><span class="line">   <span class="keyword">int</span> a = <span class="number">10</span>;              <span class="comment">/* 局部变量定义 */</span></span><br><span class="line">   </span><br><span class="line">   <span class="comment">/* do 循环执行，在条件被测试之前至少执行一次 */</span></span><br><span class="line">   <span class="keyword">do</span>&#123;</span><br><span class="line">       <span class="built_in">printf</span>(<span class="string">&quot;a 的值： %d\n&quot;</span>, a);</span><br><span class="line">       a = a + <span class="number">1</span>;</span><br><span class="line">   &#125;<span class="keyword">while</span>( a &lt; <span class="number">20</span> );</span><br><span class="line">   </span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="try-语句块和异常处理"><a href="#try-语句块和异常处理" class="headerlink" title="try 语句块和异常处理"></a>try 语句块和异常处理</h2><p>程序的异常检测部分使用 <code>throw</code> 表达式引发一个异常，然后使用 <code>try-catch</code> 语句去捕获异常。先做一个实验：以一个计算两个数的调和平均数的函数为例。两个数的调和平均数的定义是：这两个数字倒数的平均值的倒数，因此程序可以写为：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">double</span> <span class="title">hmean</span><span class="params">(<span class="keyword">double</span> a, <span class="keyword">double</span> b)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(a == -b)&#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="string">&quot;bad hmean() arguments: a = -b not allowed&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">2.0</span> * a * b / (a + b);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">double</span> x, y, z;</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Enter two numbers: &quot;</span>;</span><br><span class="line">    <span class="keyword">while</span>(std::cin &gt;&gt; x &gt;&gt; y)&#123;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            z = <span class="built_in">hmean</span>(x, y);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in"><span class="keyword">catch</span></span>(<span class="keyword">const</span> <span class="keyword">char</span>* s)&#123;</span><br><span class="line">            std::cout &lt;&lt; s &lt;&lt; std::endl;</span><br><span class="line">            std::cout &lt;&lt; <span class="string">&quot;Enter a new pair of numbers: &quot;</span>;</span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Harmonic mean of &quot;</span> &lt;&lt; x &lt;&lt; <span class="string">&quot; and &quot;</span> &lt;&lt; y</span><br><span class="line">                  &lt;&lt; <span class="string">&quot; is &quot;</span> &lt;&lt; z &lt;&lt; std::endl;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Eneter next set of numbers &lt;q to quit&gt;: &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Bye!\n&quot;</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>当 <code>a==-b</code> 时，引发异常的是字符串 “bad hmean() arguments: a = -b not allowed”。程序会将它赋给变量 <code>s</code>，然后执行处理程序中的代码。</p>
<h1 id="第六章-函数"><a href="#第六章-函数" class="headerlink" title="第六章 函数"></a>第六章 函数</h1><h2 id="参数传递"><a href="#参数传递" class="headerlink" title="参数传递"></a>参数传递</h2><p>函数每次被调用的时候都会被创建它的<strong>形参</strong>，并用传入的<strong>实参</strong>对形参进行初始化。和其他变量一样，形参的类型决定了形参和实参交互的方式。如果形参是引用类型，它将绑定到对应的实参上；否则，将实参数的值拷贝后赋给形参。</p>
<blockquote>
<p>形参出现在函数定义中，在整个函数体内都可以使用， 离开该函数则不能使用。实参出现在主调函数中，进入被调函数后，实参变量也不能使用。形参和实参的功能是作数据传送。发生函数调用时， 主调函数把实参的值传送给被调函数的形参从而实现主调函数向被调函数的数据传送。</p>
</blockquote>
<h3 id="传值参数"><a href="#传值参数" class="headerlink" title="传值参数"></a>传值参数</h3><p>当初始化一个非引用类型的变量时，初始值被拷贝给变量。此时，对变量的改动不会影响初始的值。例如某个函数试图根据传值行为去改变某个指针，这是徒劳的。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reset</span><span class="params">(<span class="keyword">int</span> *ip)</span></span>&#123;</span><br><span class="line">    *ip = <span class="number">0</span>;      <span class="comment">// 改变指针 ip 所指对象的值，这个是可以的；</span></span><br><span class="line">    ip = <span class="number">0</span>;        <span class="comment">// 只改变了 ip 的局部拷贝，实参未被改变</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>调用 <code>reset</code> 函数之后，实参所指的对象被指为 0， 但是实参本身并未改变：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i = <span class="number">42</span>;</span><br><span class="line"><span class="built_in">reset</span>(&amp;i);                                              <span class="comment">// 只能改变 i 的值而非 i 的地址</span></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;i = &quot;</span> &lt;&lt; i &lt;&lt; std::endl;         <span class="comment">// 输出 i=0 </span></span><br></pre></td></tr></table></figure>

<h3 id="传引用参数"><a href="#传引用参数" class="headerlink" title="传引用参数"></a>传引用参数</h3><p>回忆过去所学的知识，我们知道对引用的操作实际上是作用在引用所引的对象上。引用传参的行为与之类似，通过使用引用传参，允许函数改变一个或多个实参的值。举个例子，我们可以改写上一个小节的 <code>reset</code> 程序，使其接受的参数是引用类型而非指针：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">reset</span><span class="params">(<span class="keyword">int</span> &amp;i)</span></span>&#123;</span><br><span class="line">    i = <span class="number">0</span>;                                <span class="comment">// 改变了 i 所引对象的值</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><strong>拷贝大的类类型对象或者容器对象比较低效</strong>，甚至有的类类型（包括 <code>IO</code> 类型在内）根本就不支持拷贝操作。当某种类型不支持拷贝操作时，函数只能通过引用形参访问该类型的对象。</p>
<h3 id="数组形参"><a href="#数组形参" class="headerlink" title="数组形参"></a>数组形参</h3><p>数组的两个特殊性质对我们定义和使用在数组上的函数有影响，这两个性质分别是：不允许拷贝数组以及使用数组时通常会将其转换成指针。因为不能拷贝数组，所以我们无法以值传递的方式使用数组参数。因为数组会被转换成指针，所以<strong>当我们为函数传递一个数组时，实际上传递的是指向数组首元素的指针</strong>。</p>
<p>尽管不能以值传递的方式传递数组，但是我们可以把形参写出类似数组的形式：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span>*)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> [])</span></span>;                 <span class="comment">// 可以看出来，函数的意图是作用于一个数组</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> [<span class="number">10</span>])</span></span>;               <span class="comment">// 这里的维度是我们期望数组含有多少个元素，实际不一定</span></span><br></pre></td></tr></table></figure>

<p>尽管表现方式不同，但上面的三个函数是等价的：每个函数的唯一形参都是 <code>const int*</code> 类型的。当编译器处理对 <code>print</code> 函数的调用时，只检查传入的参数是否是 <code>const int*</code> 类型:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> i=<span class="number">0</span>, j[<span class="number">2</span>] = &#123;<span class="number">0</span>, <span class="number">1</span>&#125;;</span><br><span class="line"><span class="built_in">print</span>(&amp;i);                              <span class="comment">// 正确：&amp;i 的类型是 int*</span></span><br><span class="line"><span class="built_in">print</span>(j);                                <span class="comment">// 正确：j 转换成 int* 并指向 j[0]</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>如果我们传给 <code>print</code> 函数的是一个数组，则实参自动地转换成指向数组首元素的指针，数组的大小对函数的调用没有影响。和其他使用数组的代码一样，以数组作为形参的函数也必须确保使用数组时不会越界。</p>
</blockquote>
<p>我们曾经介绍过，在 <code>C++</code> 语言中实际上没有真正的多维数组，所谓的多维数组其实是数组的数组。和所有数组一样，当将多维数组传递给函数时，真正传递的是指向数组首元素指针。因为我们处理的是数组的数组，所以首元素本身就是一个数组，指针就是一个指向数组的指针。数组的第二维大小都是数组类型的一部分，不能忽略：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">int</span> (*matrix)[<span class="number">10</span>], <span class="keyword">int</span> row_size)</span></span>&#123; <span class="comment">/* ... */</span>&#125;;</span><br></pre></td></tr></table></figure>
<p>等价定义</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">int</span> matrix[][<span class="number">10</span>], <span class="keyword">int</span> row_size)</span></span>&#123; <span class="comment">/* ... */</span>&#125;;</span><br></pre></td></tr></table></figure>

<p>再一次强调，<code>*matrix</code> 两端的括号必不可少：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> *matrix[<span class="number">10</span>];              <span class="comment">// 10 指针构成的数组</span></span><br><span class="line"><span class="built_in"><span class="keyword">int</span></span> (*matrix)[<span class="number">10</span>];            <span class="comment">// 指向含有 10 个整数的数组的指针</span></span><br></pre></td></tr></table></figure>

<h2 id="返回类型和-return-语句"><a href="#返回类型和-return-语句" class="headerlink" title="返回类型和 return 语句"></a>返回类型和 return 语句</h2><h3 id="无返回值函数"><a href="#无返回值函数" class="headerlink" title="无返回值函数"></a>无返回值函数</h3><p>没有返回值的 <code>return</code> 语句只能用在返回类型是 <code>void</code> 的函数中。返回 <code>void</code> 的函数不要求非得有 <code>return</code> 语句，因为这类函数的最后一句后面会隐式地执行 <code>return</code>。例如，可以编写一个 <code>swap</code> 函数，使其在参与交换的值相等时什么也不做就直接退出。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> &amp;v1, <span class="keyword">int</span> &amp;v2)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (v1 == v2)</span><br><span class="line">        <span class="keyword">return</span>;              <span class="comment">// 如果两个值是相等的，则无需交换就直接退出</span></span><br><span class="line">    <span class="keyword">int</span> tmp = v2;</span><br><span class="line">    v2 = v1;</span><br><span class="line">    v1 = tmp;</span><br><span class="line">    <span class="comment">// 此处无需显式的 return 语句</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="有返回值函数"><a href="#有返回值函数" class="headerlink" title="有返回值函数"></a>有返回值函数</h3><ul>
<li>a. 不要返回局部对象的引用或指针<br>函数完成后，它所占用的存储空间也随之被释放掉。因此函数终止意味着局部变量的引用将指向不再有效的内存区域：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">const</span> std::string &amp;<span class="title">mainp</span><span class="params">()</span></span>&#123;</span><br><span class="line">    std::string ret = <span class="string">&quot;hello&quot;</span>;</span><br><span class="line">    <span class="keyword">if</span> (!ret.<span class="built_in">empty</span>())</span><br><span class="line">        <span class="keyword">return</span> ret;              <span class="comment">// 错误，返回局部对象的引用</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;empty&quot;</span>;          <span class="comment">// 错误，&quot;empty&quot; 是一个局部临时量</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>b. 引用返回左值</li>
</ul>
<p>函数的返回类型决定函数调用的是否是左值。<strong>调用一个返回引用的函数得到左值，其他返回类型得到右值</strong>。可以像使用其他左值那样来使用返回引用的函数调用，特别是：我们能为返回类型是非常量引用的函数的结果赋值。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">char</span> &amp;<span class="title">getVal</span><span class="params">(std::string &amp;str, std::string::size_type ix)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> str[ix];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="function">std::string <span class="title">s</span><span class="params">(<span class="string">&quot;hello&quot;</span>)</span></span>;</span><br><span class="line">    std::cout &lt;&lt; s &lt;&lt; std::endl;           <span class="comment">// 输出 hello</span></span><br><span class="line">    <span class="built_in">getVal</span>(s, <span class="number">0</span>) = <span class="string">&#x27;A&#x27;</span>;</span><br><span class="line">    std::cout &lt;&lt; s &lt;&lt; std::endl;           <span class="comment">// 输出 Aello</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>c. 列表初始化返回值</li>
</ul>
<p>C++11 新标准规定，函数可以返回花括号包围的值的列表。类似于其他返回结果，此处的列表也用来对函数返回的临时量进行初始化。举个例子，在下面的函数中，我们返回一个 <code>vector</code> 对象，用它存放表示错误信息的 <code>string</code> 对象：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">vector&lt;string&gt; <span class="title">process</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="comment">// expected 和 actual 是 string 对象</span></span><br><span class="line">    <span class="keyword">if</span> (expected.<span class="built_in">empty</span>())</span><br><span class="line">        <span class="keyword">return</span> &#123;&#125;;                                         <span class="comment">// 返回一个空 vector 对象</span></span><br><span class="line">    <span class="keyword">else</span> <span class="keyword">if</span> (expected == actual)</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;functionX&quot;</span>, <span class="string">&quot;okay&quot;</span>&#125;;                      <span class="comment">// 返回列表初始化的 vector 对象</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;functionX&quot;</span>,  expected, actual&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>d. 主函数 main 的返回值<br>之前介绍过，如果函数的返回类型不是 <code>void</code>，那么它必须返回一个值。但是这条规定则有个例外：我们允许 <code>main</code> 函数没有 <code>return</code> 语句直接结束。<strong>如果控制达到了 <code>main</code> 函数的结尾处而没有 <code>return</code> 语句，编译器将自动隐式地插入一条返回 0 的 <code>return</code> 语句</strong>。</li>
</ul>
<h2 id="函数重载"><a href="#函数重载" class="headerlink" title="函数重载"></a>函数重载</h2><p>如果同一个作用域内的几个函数名字相同但形参列表不同，我们称之为<strong>重载（overloaded）函数</strong>。例如，在前面我们定义了几个名为 <code>print</code> 的函数：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">const</span> <span class="keyword">char</span> *cp)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> *beg, <span class="keyword">const</span> <span class="keyword">int</span> *end)</span></span>;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">const</span> <span class="keyword">int</span> ia[], <span class="keyword">size_t</span> size)</span></span>;</span><br></pre></td></tr></table></figure>

<p>这些函数的名字相同，但是接受的形参类型不一样。当调用这些函数时，编译器会根据传递的实参类型推断想要的是哪个函数：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">int</span> j[<span class="number">2</span>] = &#123;<span class="number">0</span>, <span class="number">1</span>&#125;;</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;hello world&quot;</span>);               <span class="comment">// 调用 print(const char *cp)</span></span><br><span class="line"><span class="built_in">print</span>(j, <span class="built_in">end</span>(j)-<span class="built_in">begin</span>(j));          <span class="comment">// 调用 print(const int ia[], size_t size)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">begin</span>(j), <span class="built_in">end</span>(j));             <span class="comment">// 调用 print(const int *beg, const int *end)</span></span><br></pre></td></tr></table></figure>

<h2 id="内联函数和-constexpr-函数"><a href="#内联函数和-constexpr-函数" class="headerlink" title="内联函数和 constexpr 函数"></a>内联函数和 constexpr 函数</h2><h3 id="内联函数"><a href="#内联函数" class="headerlink" title="内联函数"></a>内联函数</h3><p>假设我们需要编写一个小的函数，它的功能是比较两个 <code>string</code> 形参的长度并返回长度较小的 <code>string</code> 引用。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">const</span> string &amp;<span class="title">shorterString</span><span class="params">(<span class="keyword">const</span> string &amp;s1, <span class="keyword">const</span> string &amp;s2)</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> s1.<span class="built_in">size</span>() &lt;= s2.<span class="built_in">size</span>() ? s1 : s2;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如果我们将 <code>shorterString</code> 函数指定为<strong>内联函数（<code>inline</code>)，通常就是将它在每个调用点上“内联地”展开。例如，以下调用</strong>：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">cout &lt;&lt; <span class="built_in">shorterString</span>(s1, s2) &lt;&lt; endl;</span><br></pre></td></tr></table></figure>

<p>将在编译过程中展开类似下面的形式：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">cout &lt;&lt; (s1.<span class="built_in">size</span>() &lt;= s2.<span class="built_in">size</span>() ? s1 : s2) &lt;&lt; endl;</span><br></pre></td></tr></table></figure>

<p><strong>从而消除了 <code>shorterString</code> 函数的调用开销</strong>。我们只要在 <code>shorterString</code> 函数的返回类型前面加上关键字 <code>inline</code>，这样就可以将它声明成内联函数了。</p>
<h3 id="constexpr-函数"><a href="#constexpr-函数" class="headerlink" title="constexpr 函数"></a>constexpr 函数</h3><p><strong><code>constexpr</code> 函数</strong> 是指能用于常量表达式的函数。定义 <code>constexpr</code> 函数的方法与其他函数类似，不过要遵循几项约定：函数的返回类型及所有的形参类型都得是字面值类型。而且函数体中必须有且只有一条<code>return</code>语句：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">constexpr</span> <span class="keyword">int</span> <span class="title">new_sz</span><span class="params">()</span> </span>&#123;<span class="keyword">return</span> <span class="number">42</span>;&#125;</span><br><span class="line"><span class="keyword">constexpr</span> <span class="keyword">int</span> foo = <span class="built_in">new_sz</span>();              <span class="comment">// 正确：foo 是一个常量表达式</span></span><br></pre></td></tr></table></figure>

<p>我们把 <code>new_sz</code> 定义成无参数的 <code>constexpr</code> 函数，因为编译器能在程序编译时验证 <code>new_sz</code> 函数返回的是常量表达式，所以我们可以直接用 <code>new_sz</code> 函数初始化 <code>constexpr</code> 类型变量 <code>foo</code>。执行该初始化任务时，编译器对 <code>constexpr</code> 函数的调用替换成其结果值。<strong>为了能在编译过程中展开，<code>constexpr</code> 函数被隐式地指定为内联函数</strong>。</p>
<h2 id="函数指针和回调函数"><a href="#函数指针和回调函数" class="headerlink" title="函数指针和回调函数"></a>函数指针和回调函数</h2><p>函数指针指向的是函数而非对象，和其他指针一样，函数指针指向某种特定类型。<strong>函数的类型由它的返回类型和形参类型共同决定，与函数名无关</strong>。例如：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="built_in"><span class="keyword">void</span></span> (*pf)(<span class="keyword">int</span> );</span><br></pre></td></tr></table></figure>

<p>该函数的类型是 <code>void (int)</code>。要想声明一个可以指向该函数的指针，只需要用指针替换函数名就可以：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// pf 指向一个函数，该函数的参数是 int，返回的是 void 类型</span></span><br><span class="line"><span class="built_in"><span class="keyword">void</span></span> (*fp)(<span class="keyword">int</span> );    <span class="comment">// 未初始化</span></span><br></pre></td></tr></table></figure>

<p>从我们声明的名字开始观察，<code>pf</code> 前面有个<code>*</code>，因此 <code>pf</code> 是指针；右侧是形参列表，表示 <code>pf</code> 指向的是函数；再观察左侧，发现函数的返回类型是 <code>void</code> 值。因此 <code>pf</code> 就是一个指向函数的指针，其函数的参数为 <code>int</code> 类型，返回值是 <code>void</code> 类型。</p>
<blockquote>
<p><code>*pf</code> 两端的括号必不可少。如果不写这对括号，则 <code>pf</code> 是一个返回值为 <code>void</code> 指针的函数。</p>
</blockquote>
<p>例如，我们可以写这样一个程序：函数 <code>test</code> 的形参为一个数组 <code>array</code> 和一个函数指针 <code>*pf</code>，其功能是通过函数指针 <code>*pf</code> 将打印函数 <code>print</code> 回调执行打印出数组 <code>array</code> 的每一个值。</p>
<p>程序：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">print</span><span class="params">(<span class="keyword">int</span> number)</span></span>&#123;</span><br><span class="line">    std::cout &lt;&lt; number &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">test</span><span class="params">(<span class="keyword">int</span>* array, <span class="keyword">void</span> (*pf)(<span class="keyword">int</span> ))</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++)&#123;</span><br><span class="line">        (*pf)(array[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">int</span> array[] = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>&#125;;</span><br><span class="line">    <span class="built_in">test</span>(array, &amp;print);       <span class="comment">// 由于函数的名字即地址，因此 test(array, print) 也行</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">╭─yang@yangdeMacBook-Pro.local ~  </span><br><span class="line">╰─➤  ./a.out </span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td></tr></table></figure>

<blockquote>
<p>由于函数的名字就是它的地址，因此传入 <code>print</code> 和 <code>&amp;print</code> 给 <code>test</code> 函数都是一样的。</p>
</blockquote>
<p>在经常使用函数指针之后，我们很快就会发现，每次声明函数指针都要带上长长的形参和返回值，非常不便。这个时候，我们应该想到使用 <code>typedef</code>，即为某类型的函数指针起一个别名，使用起来就方便许多了。例如，对于前面提到的函数可以使用下面的方式声明：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">typedef</span> <span class="title">void</span> <span class="params">(*fp)</span><span class="params">(<span class="keyword">int</span> )</span></span>;          <span class="comment">// 为该函数指针类型起一个新的名字 fp</span></span><br><span class="line">fp p;                              <span class="comment">// 声明一个指向 fp 类型的函数指针 p</span></span><br></pre></td></tr></table></figure>

<p>如果不想用 <code>typedef</code>，也可以用 C++11 的新特性 <code>using</code> ，也是一样的效果：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">using</span> fp = <span class="built_in"><span class="keyword">void</span></span> (*)(<span class="keyword">int</span>);</span><br></pre></td></tr></table></figure>

<p>从而新 <code>test</code> 函数的写法就变得很简单了：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">test</span><span class="params">(<span class="keyword">int</span>* array, fp p)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">4</span>; i++)&#123;</span><br><span class="line">        (*p)(array[i]);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="第七章-类"><a href="#第七章-类" class="headerlink" title="第七章 类"></a>第七章 类</h1><h2 id="类的定义和对象的创建"><a href="#类的定义和对象的创建" class="headerlink" title="类的定义和对象的创建"></a>类的定义和对象的创建</h2><p>类是创建对象的模板，一个类可以创建多个对象，每个对象都是类类型的一个变量；创建对象的过程也叫类的实例化。每个对象都是类的一个具体实例（Instance），拥有类的成员变量和成员函数。与结构体一样，类只是一种复杂数据类型的声明，不占用内存空间。而对象是类这种数据类型的一个变量，或者说是通过类这种数据类型创建出来的一份实实在在的数据，所以占用内存空间。</p>
<p>一个简单类的定义：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="comment">// 成员变量</span></span><br><span class="line">        <span class="keyword">char</span> *name;</span><br><span class="line">        <span class="keyword">int</span> age;</span><br><span class="line">        <span class="keyword">float</span> score;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 成员函数</span></span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">say</span><span class="params">()</span></span>&#123;</span><br><span class="line">            std::cout&lt;&lt; name &lt;&lt; <span class="string">&quot;的年龄是&quot;</span>&lt;&lt; age &lt;&lt;<span class="string">&quot;，成绩是&quot;</span> &lt;&lt; score &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>有了 Student 类后，就可以通过它来创建对象了，例如：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">Student liLei;        <span class="comment">// 创建了一个对象</span></span><br><span class="line">Student allStu[<span class="number">100</span>];  <span class="comment">// 创建了一个 allStu 数组，它拥有 100 个元素，每个元素都是 Student 类型的对象</span></span><br></pre></td></tr></table></figure>

<h2 id="访问控制和封装"><a href="#访问控制和封装" class="headerlink" title="访问控制和封装"></a>访问控制和封装</h2><p>到目前为止，我们已经为类定义了借口，但并没有任何访问机制强制用户使用这些接口。我们的类还没有封装，也就是说，用户可以直达 Student 对象的内部并且控制它的实现细节。在 C++ 语言中，我们使用访问说明符加强类的封装性：</p>
<ul>
<li>定义 <strong>public</strong> 说明符之后的成员在整个程序内可被访问，public 成员定义类的接口；</li>
<li>定义 <strong>private</strong> 说明符之后的成员可以被类的成员函数访问，但是不能被使用该类的代码访问，private 部分封装了（即隐藏了）类的实现细节。</li>
</ul>
<p>再一次定义 Student 类，其新形式如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>&#123;</span></span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 成员变量</span></span><br><span class="line">        <span class="keyword">char</span> *name;</span><br><span class="line">        <span class="keyword">int</span> age;</span><br><span class="line">        <span class="keyword">float</span> score;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="comment">// 成员函数</span></span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">say</span><span class="params">()</span></span>&#123;</span><br><span class="line">            std::cout&lt;&lt; name &lt;&lt; <span class="string">&quot;的年龄是&quot;</span>&lt;&lt; age &lt;&lt;<span class="string">&quot;，成绩是&quot;</span> &lt;&lt; score &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>在 C++ 中，也可以使用 struct 关键字替代 class 。它们在大多数的情况下是相同的，区别在于：<strong>使用 class 时，类中的成员默认都是 private 属性的；而使用 struct 时，结构体中的成员默认都是 public 属性的。</strong></p>
<h3 id="构造函数和析构函数"><a href="#构造函数和析构函数" class="headerlink" title="构造函数和析构函数"></a>构造函数和析构函数</h3><p>每个类都定义了它的对象被初始化的方式，类则通过构造函数（constructor）来控制其对象的初始化过程。构造函数的任务是初始化类对象的数据成员，无论何时只要类的对象被创建，就会执行构造函数。<strong>构造函数的名字和类名字相同。和其他函数不一样的是，构造函数没有返回类型。</strong></p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>&#123;</span></span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 成员变量</span></span><br><span class="line">        <span class="keyword">char</span> *name_;</span><br><span class="line">        <span class="keyword">int</span> age_;</span><br><span class="line">        <span class="keyword">float</span> score_;</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="comment">// 成员函数</span></span><br><span class="line">        <span class="built_in">Student</span>(<span class="keyword">char</span> *name, <span class="keyword">int</span> age, <span class="keyword">float</span> score):</span><br><span class="line">        	  <span class="built_in">name_</span>(name), <span class="built_in">age_</span>(age), <span class="built_in">score_</span>(score)&#123;&#125;;</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">say</span><span class="params">()</span></span>&#123;</span><br><span class="line">            std::cout&lt;&lt; name_ &lt;&lt; <span class="string">&quot;的年龄是&quot;</span>&lt;&lt; age_ &lt;&lt;<span class="string">&quot;，成绩是&quot;</span> &lt;&lt; score_ &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>创建对象时系统会自动调用构造函数进行初始化工作，同样，销毁对象时系统也会自动调用一个函数来进行清理工作，例如释放分配的内存、关闭打开的文件等，这个函数就是析构函数。</p>
<p>析构函数（Destructor）也是一种特殊的成员函数，没有返回值，不需要程序员显式调用（程序员也没法显式调用），而是在销毁对象时自动执行。构造函数的名字和类名相同，而析构函数的名字是在类名前面加一个 <code>~</code> 符号。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="comment">// 成员函数</span></span><br><span class="line">        ~<span class="built_in">Student</span>()&#123;&#125;:</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<blockquote>
<p>注意：析构函数没有参数，不能被重载，因此一个类只能有一个析构函数。如果用户没有定义，编译器会自动生成一个默认的析构函数。</p>
</blockquote>
<h3 id="友元"><a href="#友元" class="headerlink" title="友元"></a>友元</h3><p>类可以允许其他类或者函数访问它的非公有成员，方法是令其他类或者函数成为它的**友元（friend)**。如果类想把一个函数作为它的友元，只需要增加一条以 friend 关键字开始的函数声明语句即可：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>&#123;</span></span><br><span class="line">    <span class="function"><span class="keyword">friend</span> <span class="keyword">void</span> <span class="title">printName</span><span class="params">(Student &amp;stu)</span></span>;</span><br><span class="line">    ...</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>需要注意的是，<strong>友元不是类的成员</strong>。并且友元的声明只能出现在类定义的内部，但是在类内出现的具体位置不限。一般来说，最好在类定义开始或结束前的位置集中声明友元。</p>
<h3 id="this-指针详解"><a href="#this-指针详解" class="headerlink" title="this 指针详解"></a>this 指针详解</h3><p><code>this</code> 是 C++ 中的一个关键字，也是一个 const 指针，它指向当前对象，通过它可以访问当前对象的所有成员。所谓当前对象，是指正在使用的对象。例如对于 <code>stu.show()</code>;，<code>stu</code> 就是当前对象，<code>this</code> 就指向 <code>stu</code>。</p>
<p>下面是使用 this 的一个完整示例：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>&#123;</span></span><br><span class="line">	...</span><br><span class="line">	</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">say</span><span class="params">()</span> <span class="keyword">const</span></span>;       <span class="comment">// 加 const 表示该函数不会改变成员变量</span></span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Student::say</span><span class="params">()</span> <span class="keyword">const</span></span>&#123;</span><br><span class="line">    std::cout&lt;&lt; <span class="keyword">this</span>-&gt;name_ &lt;&lt; <span class="string">&quot;的年龄是&quot;</span>&lt;&lt; <span class="keyword">this</span>-&gt;age_ &lt;&lt;<span class="string">&quot;，成绩是&quot;</span> &lt;&lt; <span class="keyword">this</span>-&gt;score_ &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>this 只能用在类的内部，通过 this 可以访问类的所有成员，包括 private、protected、public 属性的。this 虽然用在类的内部，但是只有在对象被创建以后才会给 this 赋值，并且这个赋值的过程是编译器自动完成的，不需要用户干预，用户也不能显式地给 this 赋值。几点需要注意：</p>
<ul>
<li><p>this 是 const 指针，它的值是不能被修改的，一切企图修改该指针的操作，如赋值、递增、递减等都是不允许的；</p>
</li>
<li><p>this 只能在成员函数内部使用，用在其他地方没有意义，也是非法的；</p>
</li>
<li><p>只有当对象被创建后 this 才有意义，因此不能在 static 成员函数中使用（后续会讲到 static 成员）。</p>
</li>
<li><ol>
<li>this 到底是什么?</li>
</ol>
</li>
</ul>
<p><strong>this 实际上是成员函数的一个形参</strong>，在调用成员函数时将对象的地址作为实参传递给 this。不过 this 这个形参是隐式的，它并不出现在代码中，而是在编译阶段由编译器默默地将它添加到参数列表中。</p>
<ul>
<li><ol start="2">
<li>返回 *this 的成员函数</li>
</ol>
</li>
</ul>
<p>我们现在需要添加一个能改变学生分数的函数，完整的代码实现如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>&#123;</span></span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="comment">// 成员变量</span></span><br><span class="line">        <span class="keyword">char</span> *name_;</span><br><span class="line">        <span class="keyword">int</span> age_;</span><br><span class="line">        <span class="keyword">float</span> score_;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="comment">// 成员函数</span></span><br><span class="line">        <span class="built_in">Student</span>(<span class="keyword">char</span> *name, <span class="keyword">int</span> age, <span class="keyword">float</span> score):</span><br><span class="line">        	    <span class="built_in">name_</span>(name), <span class="built_in">age_</span>(age), <span class="built_in">score_</span>(score)&#123;&#125;;</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">say</span><span class="params">()</span> <span class="keyword">const</span></span>;</span><br><span class="line">        <span class="function">Student &amp;<span class="title">setScore</span><span class="params">(<span class="keyword">float</span> score)</span></span>;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Student::say</span><span class="params">()</span> <span class="keyword">const</span></span>&#123;</span><br><span class="line">    std::cout &lt;&lt; <span class="keyword">this</span>-&gt;name_ &lt;&lt; <span class="string">&quot;的年龄是&quot;</span>&lt;&lt; <span class="keyword">this</span>-&gt;age_ &lt;&lt;<span class="string">&quot;，成绩是&quot;</span> &lt;&lt; <span class="keyword">this</span>-&gt;score_ &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">Student &amp;<span class="title">Student::setScore</span><span class="params">(<span class="keyword">float</span> score)</span></span>&#123;</span><br><span class="line">    <span class="keyword">this</span>-&gt; score_ = score;</span><br><span class="line">    <span class="keyword">return</span> *<span class="keyword">this</span>;                             <span class="comment">// 将 this 对象作为左值返回</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    Student *pstu = <span class="keyword">new</span> <span class="built_in">Student</span>(<span class="string">&quot;李华&quot;</span>, <span class="number">23</span>, <span class="number">87.5f</span>);</span><br><span class="line">    pstu-&gt;<span class="built_in">say</span>();</span><br><span class="line">    pstu-&gt;<span class="built_in">setScore</span>(<span class="number">96.5f</span>).<span class="built_in">say</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>输出结果为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">╭─yangyun@yangyundeMBP.lan ~ ‹system› </span><br><span class="line">╰─➤  ./a.out </span><br><span class="line">李华的年龄是23，成绩是87.5</span><br><span class="line">李华的年龄是23，成绩是96.5</span><br></pre></td></tr></table></figure>

<p>这里的 <code>setScore</code> 成员函数的返回值是调用 <code>setScore</code> 的对象的引用。返回引用的函数是左值的，<strong>这意味着这些函数返回的是对象本身而非对象的副本</strong>。如果我们把一系列这样的操作连接在一条表达式的话：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">pstu-&gt;<span class="built_in">setScore</span>(<span class="number">96.5f</span>).<span class="built_in">say</span>();</span><br></pre></td></tr></table></figure>

<p>这些操作将在同一个对象上执行。在上面的表达式中，我们首先重置学生的分数，然后打印出结果。也就是说，上述语句等价于：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">pstu-&gt;<span class="built_in">setScore</span>(<span class="number">96.5f</span>);</span><br><span class="line">pstu-&gt;<span class="built_in">say</span>();</span><br></pre></td></tr></table></figure>

<h2 id="构造函数再探"><a href="#构造函数再探" class="headerlink" title="构造函数再探"></a>构造函数再探</h2><p>对于任何 C++ 的类来说，构造函数都是其中重要的组成部分。我们已经在 7.2.1 节中介绍了构造函数的基础知识，本节将继续介绍构造函数的一些其他功能，并对之前已经介绍的内容进行一些更深入的讨论。</p>
<h3 id="构造函数初始值列表"><a href="#构造函数初始值列表" class="headerlink" title="构造函数初始值列表"></a>构造函数初始值列表</h3><p>一般来说，构造函数有两种初始化赋值的方式：</p>
<ul>
<li>直接初始化数据成员 (效率更高）</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>&#123;</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">Student</span>(<span class="keyword">char</span> *name, <span class="keyword">int</span> age, <span class="keyword">float</span> score): <span class="built_in">name_</span>(name), <span class="built_in">age_</span>(age), <span class="built_in">score_</span>(score)&#123;&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<ul>
<li>先初始化再赋值</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Student</span>&#123;</span></span><br><span class="line">    ...</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">Student</span>(<span class="keyword">char</span> *name, <span class="keyword">int</span> age, <span class="keyword">float</span> score)&#123;</span><br><span class="line">            name_ = name;</span><br><span class="line">            age_  = age;</span><br><span class="line">            score_= score;</span><br><span class="line">        &#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="委托构造函数"><a href="#委托构造函数" class="headerlink" title="委托构造函数"></a>委托构造函数</h3><p>C++11 新标准扩展了构造函数初始值的功能，使得我们可以定义所谓的委托构造函数（delegating constructor)。<strong>一个委托构造函数使用它所属的类的其他构造函数执行它自己的初始化过程，或者说它把它自己的一些或者全部职责委托给了其他构造函数</strong>。</p>
<p>举个例子：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Sales_data</span>&#123;</span></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="comment">// 非委托构造函数使用对应的实参初始化成员</span></span><br><span class="line">        <span class="built_in">Sales_data</span>(std::string s, <span class="keyword">unsigned</span> cnt, <span class="keyword">double</span> price):</span><br><span class="line">            <span class="built_in">bookNo</span>(s), <span class="built_in">units_sold</span>(cnt), <span class="built_in">revenue</span>(cnt*price) &#123;&#125;</span><br><span class="line">        </span><br><span class="line">        <span class="comment">//  其余构造函数全都委托给第一个构造函数</span></span><br><span class="line">        <span class="built_in">Sales_data</span>(): <span class="built_in">Sales_data</span>(<span class="string">&quot;&quot;</span>, <span class="number">0</span>, <span class="number">0</span>) &#123;&#125;</span><br><span class="line">        <span class="built_in">Sales_data</span>(std::string s): <span class="built_in">Sales_data</span>(s, <span class="number">0</span>, <span class="number">0</span>) &#123;&#125;</span><br><span class="line">        <span class="built_in">Sales_data</span>(std::istream &amp;is): <span class="built_in">Sales_data</span>()&#123; <span class="built_in">read</span>(is, *<span class="keyword">this</span>); &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>在这个 Sales_data 类中，除了第一个构造函数以外其他三个都委托了它们的工作。第一个构造函数接受三个实参，使用这些实参初始化数据成员，然后结束工作。我们定义默认构造函数令其使用三个参数的构造函数来完成初始化过程，它也无须执行其他任务，这一点从空构造函数体能看得出来。</p>
<h3 id="explict-构造函数"><a href="#explict-构造函数" class="headerlink" title="explict 构造函数"></a>explict 构造函数</h3><p>C++ 中的 explicit 关键字用来修饰类的构造函数，表明该构造函数是显式的，既然有”显式”那么必然就有”隐式”，那么什么是显示而什么又是隐式的呢？</p>
<p>例如，我们构造了一个这样的类：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyClass</span>&#123;</span></span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        <span class="keyword">int</span> val_;</span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="built_in">MyClass</span>(<span class="keyword">int</span> val): <span class="built_in">val_</span>(val) &#123;&#125;</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">add</span><span class="params">(MyClass m)</span></span>&#123; val_ += m.val_; &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>然后我们这样构造了一个 <code>MyClass</code> 类：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">MyClass m = <span class="number">10</span>;       <span class="comment">// 隐式转换，convert int to MyClass</span></span><br><span class="line">m.<span class="built_in">add</span>(<span class="number">5</span>);             <span class="comment">// 同上</span></span><br></pre></td></tr></table></figure>

<p>在上面两行操作中，编译器默认都执行了一次隐式转换。例如，<code>add</code> 函数的形参本来应该是一个 <code>MyClass</code> 对象，但是这里它把 <code>int</code> 类型的 5 作为实参，实例化了一个 <code>MyClass</code> 类的临时对象再作为实参传给 <code>add</code> 函数。</p>
<p>隐式转换总是在我们没有察觉的情况下悄悄发生，除非心有所为，隐式转换常常是我们所不希望发生的。如果要避免这种自动转换的功能，我们该怎么做呢？嘿嘿这就是关键字 explicit 的作用了，将类的构造函数声明为”显式”（ 即在构造函数前面加上 explicit )，这样就可以防止这种自动的转换操作啦。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">explicit</span> <span class="title">MyClass</span><span class="params">(<span class="keyword">int</span> val)</span>: val_(val) &#123;</span>&#125;</span><br></pre></td></tr></table></figure>

<p>构造函数加上 explicit 关键字之后，之前那两种隐式转换的操作就是违法的了。通过将构造函数声明为 explicit（显式）的方式可以抑制隐式转换。<strong>也就是说，explicit 构造函数必须显式调用</strong>。</p>
<h2 id="类的静态成员"><a href="#类的静态成员" class="headerlink" title="类的静态成员"></a>类的静态成员</h2><p>有的时候类需要它的一些成员与类本身直接相关，而不是与类的各个对象保持关联。例如，一个银行账户类可能需要一个数据成员来表示当前的基准利率。在此例中，我们希望利率与类关联，而非与每个类对象关联。从实现效率的角度来看，没必要每个对象都存储利率信息。而且更重要的是，一旦利率浮动，我们希望所有的对象都能使用新值。</p>
<ul>
<li><strong>声明静态成员</strong></li>
</ul>
<p>我们通过在成员的声明之前加上关键字 static 使得其与类关联在一起。和其他成员一样，静态成员可以是 public 的或 private 的。静态数据成员的类型可以是常量，引用，指针等等。</p>
<p>举个例子，我们定义一个类，用它表示银行的账户记录：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Account</span>&#123;</span></span><br><span class="line">    <span class="keyword">private</span>:</span><br><span class="line">        std::string owner;</span><br><span class="line">        <span class="keyword">double</span> amount;</span><br><span class="line">        <span class="keyword">static</span> <span class="keyword">double</span> interest_rate;</span><br><span class="line">        <span class="function"><span class="keyword">static</span> <span class="keyword">double</span> <span class="title">initRate</span><span class="params">()</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span>:</span><br><span class="line">        <span class="function"><span class="keyword">void</span> <span class="title">calculate</span><span class="params">()</span></span>&#123; amount += amount * interest_rate; &#125;</span><br><span class="line">        <span class="function"><span class="keyword">static</span> <span class="keyword">double</span> <span class="title">rate</span><span class="params">()</span> </span>&#123;<span class="keyword">return</span> interest_rate;&#125;</span><br><span class="line">        <span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">rate</span><span class="params">(<span class="keyword">double</span>)</span></span>;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p><strong>类的静态成员存在于任何对象之外，对象中不包含任何与静态数据成员有关的数据</strong>。因此，每个 <code>Account</code> 对象将包含两个数据成员：owner 和 amount。只存在一个 interest_rate 对象而且它被所有 <code>Account</code> 对象共享。</p>
<p>类似的，静态成员函数也不与任何对象绑定在一起，它们不包含 <code>this</code> 指针。作为结果，静态成员函数不能声明 const 的，而且<strong>我们也不能在 static 函数体内使用 this 指针</strong>。</p>
<ul>
<li><strong>使用静态成员</strong></li>
</ul>
<p>我们使用作用域运算符能直接访问静态成员：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">double</span> r;</span><br><span class="line">r = Account::<span class="built_in">rate</span>();             <span class="comment">// 使用作用域运算符访问静态成员</span></span><br></pre></td></tr></table></figure>

<p><strong>虽然静态成员不属于类的某个对象，但是我们仍然可以使用类的对象、引用或者指针来访问静态成员</strong>：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">Account ac1;</span><br><span class="line">Account *ac2 = &amp;ac1;</span><br><span class="line"></span><br><span class="line">r = ac1.<span class="built_in">rate</span>();</span><br><span class="line">r = ac2-&gt;<span class="built_in">rate</span>();</span><br></pre></td></tr></table></figure>

<h1 id="第八章-文件的输入输出"><a href="#第八章-文件的输入输出" class="headerlink" title="第八章 文件的输入输出"></a>第八章 文件的输入输出</h1><h2 id="文本文件和二进制文件"><a href="#文本文件和二进制文件" class="headerlink" title="文本文件和二进制文件"></a>文本文件和二进制文件</h2><p>从文件编码的方式来看，文件可分为 ASCII 码文件和二进制文件两种。ASCII 文件也称为文本文件，<strong>这种文件在磁盘中存放时每个字符对应一个字节，用于存放对应的 ASCII 码</strong>。二进制文件则是按二进制的编码方式来存放文件的。例如以浮点数 <code>0.375</code> 为对象，使用这两种格式对其存储：</p>
<ul>
<li>小数 <code>0.375</code> 一共有 5 个字符：<code>&#39;0&#39;</code>、<code>&#39;.&#39;</code>、<code>&#39;3&#39;</code>、<code>&#39;7&#39;</code> 和 <code>&#39;5&#39;</code>，它们的 ASCII 码分别对应为 <code>48</code>、<code>46</code>、<code>51</code>、<code>55</code> 和 <code>53</code>，则存储的二进制流为：<code>00110000</code> <code>00101110</code> <code>00110011</code> <code>00110111</code> <code>00110111</code>。</li>
<li>二进制文件则是根据数据结构存储，它既可以存储浮点数，也可以存储整数、字符甚至结构体。浮点数 <code>0.375</code> 需要 4 个字节存储，也就是需要32位的宽度。如果我们将它转化成二进制编码，则为：<code>00111110110000000000000000000000</code>。</li>
</ul>
<p>从上面的内容来看：文本文件是以字符 (char) 结构来存储， 而二进制文件不仅能以 char 存储，还能以 int，float，double 甚至 struct 的类型来存储。因此可以说，<strong>文本文件只不过是一种特殊的二进制文件罢了</strong>。要想打开二进制文件，就必须要知道该文件所对应的编码规范。例如对于文本文件，则可以用 Notepad++ 打开，对于 bmp 文件则需要图像查看器。</p>
<h2 id="文件的读写操作"><a href="#文件的读写操作" class="headerlink" title="文件的读写操作"></a>文件的读写操作</h2><p>每种格式都有自己的优点。文本格式便于读取，可以使用文件编辑器来修改文本文件。二进制格式对于数字来说比较精确，因为它存储的是值的内部表示，因此不会有转换误差或舍入误差。以二进制格式保存数据的速度更快，因为不需要转换，并且通常占用的空间较小。</p>
<h3 id="写文件"><a href="#写文件" class="headerlink" title="写文件"></a>写文件</h3><ul>
<li>文本格式<br>来看一个具体的例子，考虑下面的结构定义和声明：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">student</span>&#123;</span></span><br><span class="line">    <span class="keyword">char</span> name[<span class="number">20</span>];</span><br><span class="line">    <span class="keyword">int</span> age;</span><br><span class="line">&#125;;</span><br><span class="line">student stu = &#123;<span class="string">&quot;Yang Yun&quot;</span>, <span class="number">26</span>&#125;;</span><br></pre></td></tr></table></figure>
<p>要将结构 stu 的内容以文本格式保存，可以这样做：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="function">std::fstream <span class="title">fout</span><span class="params">(<span class="string">&quot;text.dat&quot;</span>, std::ios::out)</span></span>;</span><br><span class="line">    fout &lt;&lt; stu.name &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; stu.age &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">    fout.<span class="built_in">close</span>()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>必须使用成员运算符显式地提供每个结构成员，还必须将相邻的数据分隔开，以便区分。如果结构有 30 个成员，则这项工作将很乏味。我们使用 vim 打开 text.dat 后：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Yang Yun 26</span><br></pre></td></tr></table></figure>

<ul>
<li>二进制格式<br>要用二进制格式存储相同的信息，可以这样做：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="function">std::fstream <span class="title">fout</span><span class="params">(<span class="string">&quot;binary.dat&quot;</span>, std::ios::out | std::ios::binary)</span></span>;</span><br><span class="line">    fout.<span class="built_in">write</span>((<span class="keyword">char</span> *) &amp;stu, <span class="built_in"><span class="keyword">sizeof</span></span>(stu));     </span><br><span class="line">    fout.<span class="built_in">close</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>上述代码使用计算机的内部数据表示，将整个结构作为一个整体保存。不能将该文件作为文本读取，但与文本相比，信息的保存更为紧凑、精确。它相对于文本格式保存，主要做了两个修改：</p>
<ul>
<li>在原有基础上添加了二进制模式，<code>std::ios::binary</code>；</li>
<li>不再使用 <code>&lt;&lt;</code> 写入数据，而是使用了 <code>ostream&amp; write (const char* s, streamsize n)</code> 成员函数；</li>
</ul>
<p>write 函数的第 1 个参数为指向 char 型的常量指针，它是<strong>内存的首地址</strong>（由于 stu 的类型是结构体，因此我们需要它的地址强制转换成 char* 指针)；第 2 个参数是<strong>整块内存的长度</strong>，因此我们使用了 sizeof 运算符进行计算。</p>
<blockquote>
<p>有个问题： 该程序是否可以使用 string 对象或者 char* 指针存储 student 的成员 name ？ 答案是否定的，问题在于 <strong>string 对象本身实际上并没有包含字符串，而是包含了一个指向存储了字符串的内存单元的指针</strong>。同理，char* 指针也是这样的。因此，文件并没保存字符串的内容，而是它的地址。下次你用程序读取该文件时，<strong>这段地址是没有意义的</strong>。</p>
</blockquote>
<h3 id="读文件"><a href="#读文件" class="headerlink" title="读文件"></a>读文件</h3><ul>
<li>文本格式<br>前面提到过，文本文件是一个字符一个字符地存储。但是在读取文本文件时，我们可以直接使用 <strong>getline</strong> 函数逐行进行读取。依旧以之前生成的 text.dat 文件为例，程序如下：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">char</span> *images_file = <span class="string">&quot;text.dat&quot;</span>;</span><br><span class="line">    <span class="function">std::fstream <span class="title">fin</span><span class="params">(images_file, std::ios::in)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (fin.<span class="built_in">is_open</span>()) &#123;</span><br><span class="line">        std::string line;</span><br><span class="line">        <span class="keyword">while</span> (std::<span class="built_in">getline</span>(fin, line)) &#123;       <span class="comment">// 一行一行地读取打印</span></span><br><span class="line">            std::cout &lt;&lt; line &lt;&lt; std::endl;</span><br><span class="line">        &#125;</span><br><span class="line">        fin.<span class="built_in">close</span>();</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        std::cout &lt;&lt; <span class="string">&quot;Unable to open &quot;</span> &lt;&lt; images_file &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>二进制格式<br>C++ 通过成员函数 <code>istream&amp; read (char* s, streamsize n)</code> 可以读取二进制文件的内容，并且该函数的两个形参意义与 write 函数的相同，它的使用方法如下：</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    student stu;</span><br><span class="line">    <span class="function">std::fstream <span class="title">fin</span><span class="params">(<span class="string">&quot;binary.dat&quot;</span>, std::ios::in | std::ios::binary)</span></span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> s = <span class="keyword">reinterpret_cast</span>&lt;<span class="keyword">char</span>*&gt;(&amp;stu);</span><br><span class="line">    fin.<span class="built_in">read</span>(s, <span class="built_in"><span class="keyword">sizeof</span></span>(student));</span><br><span class="line"></span><br><span class="line">    std::cout &lt;&lt; stu.name &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; stu.age &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>上面程序是假设我们已经获得了结构体 student 声明的情况下发生的。那么<strong>如果我们什么声明都没获得，在只有一个二进制文件 <code>binary.dat</code> 的情况下</strong>，能不能读取它的内容呢？答案是肯定的，但是我们将无法解码它的内容，从而无法获得像 name 和 age 这样具体的信息。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="function">std::fstream <span class="title">fin</span><span class="params">(<span class="string">&quot;binary.dat&quot;</span>, std::ios::in | std::ios::binary)</span></span>;</span><br><span class="line"></span><br><span class="line">    fin.<span class="built_in">seekg</span>(<span class="number">0</span>, std::ios::end);</span><br><span class="line">    <span class="keyword">int</span> size = fin.<span class="built_in">tellg</span>();                <span class="comment">// 获取文件内存的字节长度</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> str = (<span class="keyword">char</span> *)<span class="built_in">malloc</span>(size);</span><br><span class="line">    fin.<span class="built_in">seekg</span>(<span class="number">0</span>, std::ios::beg);</span><br><span class="line">    fin.<span class="built_in">read</span>(str, size);                  <span class="comment">// 读取内容，并复制内容给 str</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="seekp-和-seekg-函数用法"><a href="#seekp-和-seekg-函数用法" class="headerlink" title="seekp 和 seekg 函数用法"></a>seekp 和 seekg 函数用法</h2><p>文件流对象有两个成员函数，分别是 <a href="http://www.cplusplus.com/reference/ostream/ostream/seekp/">seekp</a> 和 <a href="http://www.cplusplus.com/reference/istream/istream/seekg/">seekg</a>。它们可以用于将读写位置移动到文件中的任何字节。seekp 函数用于已经打开要进行写入的文件，而 seekg 函数则用于已经打开要进行读取的文件。可以将 “p” 理解为 “put”，将 “g” 理解为 “get”。</p>
<table>
<thead>
<tr>
<th>语 句</th>
<th>如何影响读/写位置</th>
</tr>
</thead>
<tbody><tr>
<td>file.seekp(32L, ios::beg);</td>
<td>将写入位置设置为从文件开头开始的第 33 个字节</td>
</tr>
<tr>
<td>file.seekp(-10L, ios::end);</td>
<td>将写入位置设置为从文件末尾开始的第 11 个字节</td>
</tr>
<tr>
<td>file.seekp(120L, ios::cur);</td>
<td>将写入位置设置为从当前位置开始的第 121 个字节</td>
</tr>
<tr>
<td>file.seekg(2L, ios::beg);</td>
<td>将读取位置设置为从文件开头开始的第 3 个字节</td>
</tr>
<tr>
<td>file.seekg(-100L, ios::end);</td>
<td>将读取位置设置为从文件末尾开始的第 101 个字节</td>
</tr>
<tr>
<td>file.seekg(0L, ios:beg);</td>
<td>将读取位置设置为文件开头</td>
</tr>
<tr>
<td>file.seekg(0L, ios:end);</td>
<td>将读取位置设置为文件末尾</td>
</tr>
</tbody></table>
<p>我们可以利用 seekg 函数来计算二进制文件的大小：首先将利用读取的光标位置放在文件的末尾，然后使用 <a href="http://www.cplusplus.com/reference/istream/istream/tellg/">tellg</a> 函数返回当前字符的位置，也就文件内存的长度，以字节为单位。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">std::fstream <span class="title">fin</span><span class="params">(<span class="string">&quot;binary.dat&quot;</span>, std::ios::in | std::ios::binary)</span></span>;</span><br><span class="line"></span><br><span class="line">fin.<span class="built_in">seekg</span>(<span class="number">0</span>, std::ios::end);</span><br><span class="line"><span class="keyword">int</span> size = fin.<span class="built_in">tellg</span>();</span><br></pre></td></tr></table></figure>

<h1 id="第九章-顺序容器"><a href="#第九章-顺序容器" class="headerlink" title="第九章 顺序容器"></a>第九章 顺序容器</h1><p>顺序容器为程序员提供了控制元素存储和访问顺序的能力。这种顺序不依赖于元素的值，而是与元素加入容器时的位置相对应。与之对应的，有序和无序关联容器，则根据关键字的值来存储元素。</p>
<h2 id="顺序容器概述"><a href="#顺序容器概述" class="headerlink" title="顺序容器概述"></a>顺序容器概述</h2><ul>
<li><strong>vector</strong>：可变大小数组，支持快速随机访问。在尾部之外的位置插入或删除元素可能很慢。</li>
<li><strong>deque</strong>：双端队列，支持快速随机访问。在头尾位置进行插入/删除速度很快。</li>
<li><strong>list</strong>：双向链表，只支持双向顺序访问。在 list 中任何位置进行插入/删除操作速度都很快。</li>
<li><strong>forward_list</strong>：单向链表，只支持单向顺序访问。在链表任何位置进行插入/删除速度都很快。</li>
<li><strong>array</strong>：固定大小数组，支持快速随机顺序访问，不能添加或删除元素。</li>
<li><strong>string</strong>：与 vector 相似的容器，但专门用于保存字符。随机访问快，在尾部插入/删除速度很快。</li>
</ul>
<p><strong>优劣分析：</strong></p>
<p>string 和 vector 将元素保存在连续的内存空间中。由于元素是连续存储的，因此通过元素下标来计算地址是非常快速的。但是，在这两种容器的中间位置添加或者删除元素就会非常耗时，因为每次插入和删除元素后，都需要移动后面所有的元素。</p>
<p>list 和 forward_list 两个容器的设计目的是令容器任何位置的添加和删除操作都很快速。作为代价，这两个容器不支持元素的随机访问：为了访问一个元素，我们只能遍历整个容器。而且，与 vector、deque 和 array 相比，这两个容器的额外内存开销也很大。</p>
<p><strong>哪种容器？</strong></p>
<blockquote>
<p>通常，使用 vector 是最好的选择，除非你有很好的理由选择其他容器。</p>
</blockquote>
<h2 id="顺序容器操作"><a href="#顺序容器操作" class="headerlink" title="顺序容器操作"></a>顺序容器操作</h2><h3 id="添加元素"><a href="#添加元素" class="headerlink" title="添加元素"></a>添加元素</h3><p>除了 array 外，所有标准容器都提供灵活的内存管理。在运行时可以动态添加或删除元素来改变容器大小。</p>
<ul>
<li><strong>push_back</strong></li>
</ul>
<p>push_back 可以将一个元素追加至一个 vector 尾部，除 array 和 forward_list 之外，每个顺序容器（包含 string 类型）都支持 push_back。例如，下面的循环每次读取一个 string 到 word 中，然后追加到尾部：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">string word;</span><br><span class="line"><span class="keyword">while</span> (cin &gt;&gt; word)</span><br><span class="line">    container.<span class="built_in">push_back</span>(word);</span><br></pre></td></tr></table></figure>

<p>对 push_back 的调用在 container  尾部创建了一个新元素，将 container 的 size 增大了 1。该元素的值为 word 的一个拷贝。container 的类型可以是 list、vector 或 deque。</p>
<ul>
<li><strong>insert</strong></li>
</ul>
<p>insert 提供了更加一般的功能， 它允许我们在容器中任意位置插入 0 个或多个元素。 vector、deque、list 和 string 都支持 insert 成员。每个 insert 函数都接受一个迭代器作为第一个参数。迭代器指出了在容器中什么位置放置新元素。由于迭代器可以指向容器尾部之后不存在的元素的位置，<strong>所以 insert 函数将元素插入到迭代器所指定的位置之前</strong>。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">vector&lt;string&gt; svec;</span><br><span class="line">svec.<span class="built_in">insert</span>(svec.<span class="built_in">begin</span>(), <span class="string">&quot;hello!&quot;</span>);   <span class="comment">// 插入到 begin 之前</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>将元素插入到 vector、deque 和 string 中的任何位置都是合法的。然而，这样做可能很耗时。</p>
</blockquote>
<ul>
<li><strong>emplace_back</strong></li>
</ul>
<p><strong>当我们调用 push_back 函数时，我们将元素类的对象传递给它们，这些对象被拷贝到容器中。而当我们调用一个 emplace_back 函数时，则是将参数传递给元素类型的构造函数</strong>，并使用这些参数直接在容器管理的内存空间中直接构造元素。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">vector&lt;Sales_data&gt; c;</span><br><span class="line">c.<span class="built_in">emplace_back</span>(<span class="string">&quot;978&quot;</span>, <span class="number">25</span>, <span class="number">15.99</span>);</span><br><span class="line">c.<span class="built_in">push_back</span>(<span class="built_in">Sale_data</span>(<span class="string">&quot;978&quot;</span>, <span class="number">25</span>, <span class="number">15.99</span>));</span><br></pre></td></tr></table></figure>

<p>这两个方法都会创建新的 Sales_data 对象。在调用 emplace_back 时，会在容器管理的内存空间中直接创建对象。而调用 push_back 则会先创建一个局部对象，然后再在容器管理的内存空间中创建 Sale_data 对象并将临时对象里的内容拷贝过来。</p>
<h3 id="访问元素"><a href="#访问元素" class="headerlink" title="访问元素"></a>访问元素</h3><ul>
<li><strong>访问成员函数返回的是引用</strong></li>
</ul>
<p>在容器中访问元素的成员函数（即，front、back、下标和 at）返回的都是引用。如果容器是一个 const 对象，则返回值是 const 的引用。如果容器不是 const 的，则返回值是普通引用，我们可以用来改变元素的值。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    std::vector&lt;<span class="keyword">int</span>&gt; c = &#123;<span class="number">10</span>, <span class="number">12</span>&#125;;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (!c.<span class="built_in">empty</span>())&#123;</span><br><span class="line">        c.<span class="built_in">front</span>() = <span class="number">42</span>;             <span class="comment">// c = &#123;42, 12&#125;</span></span><br><span class="line">        <span class="keyword">auto</span> &amp;v = c.<span class="built_in">back</span>();</span><br><span class="line">        v = <span class="number">1024</span>;                   <span class="comment">// c = &#123;42, 1024&#125;, 此时 v 是 c 最后一个元素的引用</span></span><br><span class="line">        <span class="keyword">auto</span> v2 = c.<span class="built_in">back</span>();</span><br><span class="line">        v2 = <span class="number">0</span>;                     <span class="comment">// c = &#123;42, 1024&#125;, 此时 v2 是 c 最后一个元素的拷贝</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>下标操作和安全的随机访问</strong></li>
</ul>
<p>顺序容器可以提供 <code>[]</code> 提供元素的随机访问，这种访问的优点在于速度极快，但是不会对下标参数进行越界检查。使用 <code>.at</code> 成员函数可以进行越界检查，但是它的访问速度会下降很多。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">vector&lt;string&gt; svec;              <span class="comment">// 空 vector</span></span><br><span class="line">cout &lt;&lt; svec[<span class="number">0</span>];                  <span class="comment">// 运行时错误，svec 中没有元素</span></span><br><span class="line">cout &lt;&lt; svec.<span class="built_in">at</span>(<span class="number">0</span>);               <span class="comment">// 抛出一个 out of range 异常</span></span><br></pre></td></tr></table></figure>

<h3 id="删除元素"><a href="#删除元素" class="headerlink" title="删除元素"></a>删除元素</h3><ul>
<li><strong>pop_back</strong></li>
</ul>
<p>pop_back 成员函数删除容器的尾元素，并返回 void。如果你需要弹出元素的值，就必须在执行弹出操作之前保存它：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::vector&lt;<span class="keyword">int</span>&gt; c = &#123;<span class="number">10</span>, <span class="number">24</span>, <span class="number">26</span>, <span class="number">25</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> (!c.<span class="built_in">empty</span>())&#123;</span><br><span class="line">	<span class="keyword">int</span> b = c.<span class="built_in">back</span>();           <span class="comment">// 删除前取出最后一个元素</span></span><br><span class="line">    c.<span class="built_in">pop_back</span>();               <span class="comment">// 删除最后一个元素</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>erase</strong></li>
</ul>
<p>erase 成员函数可以从容器指定位置删除元素。我们可以删除由一个迭代器指定的单个元素，也可以删除右一对迭代器指定范围的所有元素。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::vector&lt;<span class="keyword">int</span>&gt; c = &#123;<span class="number">10</span>, <span class="number">24</span>, <span class="number">26</span>, <span class="number">25</span>&#125;;</span><br><span class="line"></span><br><span class="line">c.<span class="built_in">erase</span>(c.<span class="built_in">begin</span>());                   <span class="comment">// 删除第一个元素，c = &#123;24, 26, 25&#125;</span></span><br><span class="line">c.<span class="built_in">erase</span>(c.<span class="built_in">end</span>()<span class="number">-2</span>, c.<span class="built_in">end</span>());          <span class="comment">// 删除最后2元素 ，c = &#123;24&#125;</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>clear</strong></li>
</ul>
<p>clear 成员函数会清空 vector 中所有的元素，但是<strong>并不会释放所占用的内存</strong>。如果想真正地释放所删除的内存，应该在 clear 或 erase 后面接  <strong>shrink_to_fit</strong> 函数。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">std::vector&lt;<span class="keyword">int</span>&gt; <span class="title">c</span><span class="params">(<span class="number">10</span>, <span class="number">42</span>)</span></span>;                    </span><br><span class="line">std::cout &lt;&lt; c.<span class="built_in">size</span>() &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; c.<span class="built_in">capacity</span>() &lt;&lt; std::endl;       <span class="comment">// 10 10</span></span><br><span class="line">c.<span class="built_in">clear</span>();</span><br><span class="line">std::cout &lt;&lt; c.<span class="built_in">size</span>() &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; c.<span class="built_in">capacity</span>() &lt;&lt; std::endl;       <span class="comment">// 0  10</span></span><br><span class="line"></span><br><span class="line">c.<span class="built_in">shrink_to_fit</span>();</span><br><span class="line">std::cout &lt;&lt; c.<span class="built_in">size</span>() &lt;&lt; <span class="string">&quot; &quot;</span> &lt;&lt; c.<span class="built_in">capacity</span>() &lt;&lt; std::endl;       <span class="comment">// 0  0</span></span><br></pre></td></tr></table></figure>

<h3 id="改变容器大小"><a href="#改变容器大小" class="headerlink" title="改变容器大小"></a>改变容器大小</h3><p>我们可以使用 resize 来增大或缩小容器：如果当前 size 大于所要求的 size，容器后部的元素会被删除；如果当前 size 小于所要求的 size，则会将新元素添加到容器后部。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">std::vector&lt;<span class="keyword">int</span>&gt; <span class="title">c</span><span class="params">(<span class="number">10</span>, <span class="number">42</span>)</span></span>;       <span class="comment">// 10 个 int，每个元素都是 42</span></span><br><span class="line"></span><br><span class="line">c.<span class="built_in">resize</span>(<span class="number">15</span>);                     <span class="comment">// 将 5 个默认值为 0 的元素添加到末尾</span></span><br><span class="line">c.<span class="built_in">resize</span>(<span class="number">5</span>);                      <span class="comment">// 从末尾删除 20 个元素</span></span><br></pre></td></tr></table></figure>

<p>此外，resize 操作还支持接受一个可选的元素值参数，用来初始化添加到容器中的元素。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function">std::vector&lt;<span class="keyword">int</span>&gt; <span class="title">c</span><span class="params">(<span class="number">10</span>, <span class="number">42</span>)</span></span>;</span><br><span class="line">c.<span class="built_in">resize</span>(<span class="number">15</span>, <span class="number">-1</span>);                     <span class="comment">// 将 5 个值为 -1 的元素添加到末尾</span></span><br></pre></td></tr></table></figure>

<p>我们可以更深入地了解一下 reisze 操作内部发生的事，不妨先打印容器 resize 后存储元素的首地址：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">std::vector&lt;int&gt; c(10, 42);</span><br><span class="line">std::cout &lt;&lt; c.data() &lt;&lt; std::endl;        // 0x7f8bd1c05930</span><br><span class="line">c.resize(15);                              // 扩大</span><br><span class="line">std::cout &lt;&lt; c.data() &lt;&lt; std::endl;        // 0x7f8bd1c05960</span><br><span class="line">c.resize(5);                               // 缩小</span><br><span class="line">std::cout &lt;&lt; c.data() &lt;&lt; std::endl;        // 0x7f8bd1c05960</span><br></pre></td></tr></table></figure>

<p>我们发现：容器元素的首地址在缩小后没有改变，而在容器扩大后发生了变化。这是由于容器扩充后需要重新分配内存，并且还需要把重新移动所有元素，因此地址发生了改变。</p>
<h2 id="vector-对象是如何增长的"><a href="#vector-对象是如何增长的" class="headerlink" title="vector 对象是如何增长的"></a>vector 对象是如何增长的</h2><p>为了支持快速随机访问， vector 将元素连续存储，即每个元素紧挨着前一个元素进行存储。假定容器中元素是连续存储的，且容器的大小可变。<strong>考虑向 vector 添加元素，如果没有空间容纳新元素，那么容器只能重新申请一块更大的新空间，并且必须把已有元素从旧空间移动到新空间，然后添加新元素，释放旧空间。如果我们每添加一个元素，那么 vector 就得执行一次这样的内存分配和释放操作，性能就会慢到不可接受</strong>。</p>
<p>为了尽量减少容器在添加元素时重新分配内存的次数，容器在每次分配内存时都会申请比新空间更大的内存空间。容器预留这些空间作为备用，可用来保存更多的新元素。这样就不需要每次添加元素都重新分配容器的内存空间了。</p>
<ul>
<li><strong>capacity 和 size 的区别</strong></li>
</ul>
<p>理解 capacity 和 size 的区别非常重要。容器的 size 是指它已经保存元素的数目，而 capacity 则是在不分配新的内存空间的前提下最多可以保存多少个元素。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::vector&lt;<span class="keyword">int</span>&gt; ivec;</span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;ivec: size &quot;</span> &lt;&lt; ivec.<span class="built_in">size</span>()</span><br><span class="line">          &lt;&lt; <span class="string">&quot; capacity &quot;</span>  &lt;&lt; ivec.<span class="built_in">capacity</span>() &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">24</span>; i++)</span><br><span class="line">    ivec.<span class="built_in">push_back</span>(i);</span><br><span class="line"></span><br><span class="line">std::cout &lt;&lt; <span class="string">&quot;ivec: size &quot;</span> &lt;&lt; ivec.<span class="built_in">size</span>()</span><br><span class="line">          &lt;&lt; <span class="string">&quot; capacity &quot;</span>  &lt;&lt; ivec.<span class="built_in">capacity</span>() &lt;&lt; std::endl;</span><br></pre></td></tr></table></figure>

<p>当我们的程序运行时，输出的结果如下所示：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ivec: size 0 capacity 0</span><br><span class="line">ivec: size 24 capacity 32</span><br></pre></td></tr></table></figure>

<p>我们知道一个 vector 的 size 为 0，显然在我们的标准库实现一个空 vector 的 capacity 也为 0。当向 vector 添加元素时，我们知道 size 与添加的元素数目相等。而 capacity 至少与 size 一样大，具体会分配多少额外空间则视标准库的具体实现而定。</p>
<p>可以想象 ivec 的当前状态如下图所示：</p>
<p><code>0</code>|<code>1</code>|<code>2</code>|<code>3</code>|<code>...</code>|<code>23</code>|<code>预留空间</code></p>
<ul>
<li><strong>容器怎么重新申请空间？</strong></li>
</ul>
<p>前面讲到容器 vector 为了减少重新分配内存的次数，而会保留一些预留空间。因此出现 ivec 的 size=24，capacity=32 的情况，那么每次内存不够而需要重新申请空间的时候又是怎么进行的呢？依旧以前面的 push_back 过程举例，我们打印出容器每次添加元素后的容量：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>; i&lt;<span class="number">24</span>; i++)&#123;</span><br><span class="line">    ivec.<span class="built_in">push_back</span>(i);</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;ivec: size &quot;</span> &lt;&lt; ivec.<span class="built_in">size</span>()</span><br><span class="line">              &lt;&lt; <span class="string">&quot; capacity &quot;</span>  &lt;&lt; ivec.<span class="built_in">capacity</span>() &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ivec: size 1 capacity 1</span><br><span class="line">ivec: size 2 capacity 2          /* 重新申请空间 */</span><br><span class="line">ivec: size 3 capacity 4          /* 重新申请空间 */</span><br><span class="line">ivec: size 4 capacity 4</span><br><span class="line">ivec: size 5 capacity 8</span><br><span class="line">ivec: size 6 capacity 8</span><br><span class="line">ivec: size 7 capacity 8</span><br><span class="line">ivec: size 8 capacity 8</span><br><span class="line">ivec: size 9 capacity 16         /* 重新申请空间 */</span><br><span class="line">ivec: size 10 capacity 16</span><br><span class="line">ivec: size 11 capacity 16</span><br><span class="line">ivec: size 12 capacity 16</span><br><span class="line">ivec: size 13 capacity 16</span><br><span class="line">ivec: size 14 capacity 16</span><br><span class="line">ivec: size 15 capacity 16</span><br><span class="line">ivec: size 16 capacity 16</span><br><span class="line">ivec: size 17 capacity 32        /* 重新申请空间 */</span><br><span class="line">ivec: size 18 capacity 32</span><br><span class="line">ivec: size 19 capacity 32</span><br><span class="line">ivec: size 20 capacity 32</span><br><span class="line">ivec: size 21 capacity 32</span><br><span class="line">ivec: size 22 capacity 32</span><br><span class="line">ivec: size 23 capacity 32</span><br><span class="line">ivec: size 24 capacity 32 </span><br></pre></td></tr></table></figure>

<p>我们发现：只要容器当前的 size &lt; capacity 时，每次往容器内 push_back 元素时，都不会重新申请空间。但是如果 vector 的容量不够时，那么每次需要分配新内存时将当前的容量翻倍。</p>
<h1 id="第十章-关联容器"><a href="#第十章-关联容器" class="headerlink" title="第十章 关联容器"></a>第十章 关联容器</h1><p>关联容器支持高效的关键字查找和访问。两个主要的关联容器类型是 map 和 set。其中 map 的元素是一些 key-value 对：关键字起到索引的作用，值则表示与索引相关联的数据。set 中每一个元素只包含一个关键字；set 支持高效的关键字查询操作，检查一个给定的关键字是否在 set 中。</p>
<h2 id="使用关联容器"><a href="#使用关联容器" class="headerlink" title="使用关联容器"></a>使用关联容器</h2><ul>
<li><strong>使用 map</strong></li>
</ul>
<p>一个经典的使用关联容器来进行单词计数的程序：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;map&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    std::map&lt;std::string, <span class="keyword">size_t</span>&gt; word_count;</span><br><span class="line"></span><br><span class="line">    std::string word;</span><br><span class="line">    <span class="keyword">while</span>(std::cin&gt;&gt;word)&#123;</span><br><span class="line">        word_count[word]++;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">const</span> <span class="keyword">auto</span> &amp;w: word_count)&#123;</span><br><span class="line">        std::cout &lt;&lt; w.first &lt;&lt; <span class="string">&quot;: &quot;</span> &lt;&lt; w.second &lt;&lt; std::endl;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p><code>while</code> 循环每次从标准输入读取一个单词。它使用每个单词对 <code>word_count</code> 进行下标操作。如果 <code>word</code> 还未在 <code>map</code> 中，下标运算符会创建一个新元素，其关键字为 <code>word</code>，值为 0. 不管元素是否是新创建的，我们将其值加 1.</p>
<p>一旦读取完所有的输入，范围 for 语句就会遍历 map，打印每个单词和对应的计数器。当从 map 中提取一个元素时，会得到一个 <strong>pair</strong> 类型的对象。<code>map</code> 所使用的 <code>pair</code> 用 <code>first</code> 成员保存关键字，用 <code>second</code> 保存对应的值。</p>
<ul>
<li><strong>使用 set</strong></li>
</ul>
<p>我们可以使用 set 容器来判断输入的单词是否在集合里面：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;set&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    std::set&lt;std::string&gt; data = &#123;<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>, <span class="string">&quot;but&quot;</span>, <span class="string">&quot;c++&quot;</span>, <span class="string">&quot;fuck&quot;</span>&#125;;</span><br><span class="line">    std::string world;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span>(std::cin&gt;&gt;world)</span><br><span class="line">        std::cout &lt;&lt; world &lt;&lt; <span class="string">&quot;: &quot;</span> &lt;&lt; (data.<span class="built_in">find</span>(world) != data.<span class="built_in">end</span>()) &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>我们发现，程序是通过以下方式判断单词是否在集合中：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">(data.<span class="built_in">find</span>(world) != data.<span class="built_in">end</span>())</span><br></pre></td></tr></table></figure>

<p><strong><code>find</code> 调用返回一个迭代器，如果给定关键字在 <code>set</code> 中，迭代器则指向该关键字。否则，<code>find</code> 返回尾后迭代器</strong>。</p>
<h2 id="关联容器概述"><a href="#关联容器概述" class="headerlink" title="关联容器概述"></a>关联容器概述</h2><h3 id="定义关联容器"><a href="#定义关联容器" class="headerlink" title="定义关联容器"></a>定义关联容器</h3><ul>
<li><strong>初始化 map 和 set</strong></li>
</ul>
<p>如前所示，当定义一个 map 时，必须既指明关键字类型又指明值类型；而定义一个 set 时，只需指明关键字类型。在 C++11 新标准下，我们也可以对关联容器进行值初始化：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::set&lt;std::string&gt; data = &#123;<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>, <span class="string">&quot;but&quot;</span>, <span class="string">&quot;c++&quot;</span>, <span class="string">&quot;fuck&quot;</span>&#125;;</span><br><span class="line">std::map&lt;std::string, <span class="keyword">size_t</span>&gt; word_count = &#123; &#123;<span class="string">&quot;hello&quot;</span>, <span class="number">2</span>&#125;,</span><br><span class="line">                                             &#123;<span class="string">&quot;word&quot;</span>,  <span class="number">0</span>&#125;,</span><br><span class="line">                                             &#123;<span class="string">&quot;fuck&quot;</span>,  <span class="number">1</span>&#125;,</span><br><span class="line">                                             &#123;<span class="string">&quot;but&quot;</span>,   <span class="number">0</span>&#125;,</span><br><span class="line">                                             &#123;<span class="string">&quot;c++&quot;</span>,   <span class="number">0</span>&#125;&#125;;</span><br></pre></td></tr></table></figure>

<p>当初始化一个 map 时，必须提供关键字类型和值类型。我们将每个关键字-值对包围在花括号中：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;key, value&#125;</span><br></pre></td></tr></table></figure>

<p>来指出它们一起构成了 map 中的一个元素。<strong>在每个花括号中，关键字是第一个元素，值是第二个元素</strong>。</p>
<ul>
<li><strong>初始化 multimap 和 multiset</strong></li>
</ul>
<p>一个 map 或 set 中的关键字必须是唯一的，即对于一个给定的关键字，只能有一个元素的关键字等于它。容器 multimap 和 multiset 没有此限制，它们都允许多个元素具有相同的关键字。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::multimap&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt; first;</span><br><span class="line"></span><br><span class="line">first.<span class="built_in">insert</span>(std::pair&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt;(<span class="string">&#x27;a&#x27;</span>,<span class="number">10</span>));</span><br><span class="line">first.<span class="built_in">insert</span>(std::pair&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt;(<span class="string">&#x27;b&#x27;</span>,<span class="number">15</span>));</span><br><span class="line">first.<span class="built_in">insert</span>(std::pair&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt;(<span class="string">&#x27;b&#x27;</span>,<span class="number">20</span>));</span><br><span class="line">first.<span class="built_in">insert</span>(std::pair&lt;<span class="keyword">char</span>,<span class="keyword">int</span>&gt;(<span class="string">&#x27;c&#x27;</span>,<span class="number">25</span>));</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> myints[]= &#123;<span class="number">10</span>,<span class="number">20</span>,<span class="number">30</span>,<span class="number">20</span>,<span class="number">20</span>&#125;;</span><br><span class="line"><span class="function">std::multiset&lt;<span class="keyword">int</span>&gt; <span class="title">second</span> <span class="params">(myints,myints+<span class="number">5</span>)</span></span>;       <span class="comment">// pointers used as iterators</span></span><br></pre></td></tr></table></figure>
<h3 id="pair-类型"><a href="#pair-类型" class="headerlink" title="pair 类型"></a>pair 类型</h3><p>在介绍关联容器操作之前，我们需要了解名为 pair 的标准库类型。它定义在头文件 utility 中。一个 pair 对象只保存两个数据成员，其初始化方式如下:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;utility&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</span><br><span class="line">    std::pair&lt;<span class="keyword">int</span>, <span class="keyword">float</span>&gt; p1;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Value-initialized: &quot;</span></span><br><span class="line">              &lt;&lt; p1.first &lt;&lt; <span class="string">&quot;, &quot;</span> &lt;&lt; p1.second &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;       <span class="comment">// Value-initialized: 0, 0</span></span><br><span class="line"></span><br><span class="line">    <span class="function">std::pair&lt;<span class="keyword">int</span>, <span class="keyword">double</span>&gt; <span class="title">p2</span><span class="params">(<span class="number">42</span>, <span class="number">0.123</span>)</span></span>;</span><br><span class="line">    std::cout &lt;&lt; <span class="string">&quot;Initialized with two values: &quot;</span></span><br><span class="line">              &lt;&lt; p2.first &lt;&lt; <span class="string">&quot;, &quot;</span> &lt;&lt; p2.second &lt;&lt; <span class="string">&#x27;\n&#x27;</span>;       <span class="comment">// Initialized with two values: 42, 0.123</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>与其他标准库类型不同，pair 的数据成员是 public 的。两个成员分别命名为 first 和 second，可以直接访问。除了上面两种创建方式以外，我们还可以通过 <strong>make_pair</strong> 函数创建：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="keyword">auto</span> p3 = std::<span class="built_in">make_pair</span>(<span class="number">3</span>, <span class="number">3.14</span>);</span><br></pre></td></tr></table></figure>
<h2 id="关联容器操作"><a href="#关联容器操作" class="headerlink" title="关联容器操作"></a>关联容器操作</h2><h3 id="关联容器迭代器"><a href="#关联容器迭代器" class="headerlink" title="关联容器迭代器"></a>关联容器迭代器</h3><ul>
<li><strong>map 的迭代器</strong></li>
</ul>
<p>我们可以获得 map 中一个元素的迭代器，并通过该迭代器修改元素对应的值：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::map&lt;std::string, <span class="keyword">size_t</span>&gt; word_count = &#123; &#123;<span class="string">&quot;hello&quot;</span>, <span class="number">2</span>&#125;,</span><br><span class="line">                                             &#123;<span class="string">&quot;word&quot;</span>,  <span class="number">0</span>&#125;&#125;;</span><br><span class="line">                                             </span><br><span class="line"><span class="keyword">auto</span> map_it = word_count.<span class="built_in">begin</span>();      <span class="comment">// *map_it 是指向 pair&lt;const string, size_t&gt; 对象的引用</span></span><br><span class="line">std::cout &lt;&lt; map_it-&gt;first &lt;&lt; <span class="string">&quot;: &quot;</span> &lt;&lt; map_it-&gt;second &lt;&lt; std::endl;     <span class="comment">// hello: 2</span></span><br><span class="line"></span><br><span class="line">++map_it-&gt;second;                      <span class="comment">// 修改元素的 value</span></span><br><span class="line">std::cout &lt;&lt; map_it-&gt;first &lt;&lt; <span class="string">&quot;: &quot;</span> &lt;&lt; map_it-&gt;second &lt;&lt; std::endl;     <span class="comment">// hello: 3</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>set 的迭代器</strong></li>
</ul>
<p>set 也提供了迭代器来访问元素，但与 map 不同的是：它允许只读性质地访问 set 中的元素，并不能改变它的值。</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::set&lt;std::string&gt; data = &#123;<span class="string">&quot;hello&quot;</span>, <span class="string">&quot;world&quot;</span>, <span class="string">&quot;but&quot;</span>, <span class="string">&quot;c++&quot;</span>, <span class="string">&quot;fuck&quot;</span>&#125;;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">auto</span> it = data.<span class="built_in">begin</span>(); it != data.<span class="built_in">end</span>(); it++)&#123;</span><br><span class="line">    <span class="comment">// *it = &quot;yun&quot;;   // 错误 ！ set 中的关键字是只读的</span></span><br><span class="line">    std::cout &lt;&lt; *it &lt;&lt; std::endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="添加元素-1"><a href="#添加元素-1" class="headerlink" title="添加元素"></a>添加元素</h3><p>对一个 map 进行 insert 操作时，必须记住元素类型是 pair。通常，对于想要插入的数据，并没有一个现成的 pair 对象。可以在 insert 的参数列表中创建一个 pair：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">std::map&lt;std::string, <span class="keyword">size_t</span>&gt; word_count = &#123; &#123;<span class="string">&quot;hello&quot;</span>, <span class="number">2</span>&#125; &#125;;</span><br><span class="line"></span><br><span class="line">word_count.<span class="built_in">insert</span>(&#123;<span class="string">&quot;world&quot;</span>, <span class="number">1</span>&#125;);</span><br><span class="line">word_count.<span class="built_in">insert</span>(std::<span class="built_in">make_pair</span>(<span class="string">&quot;but&quot;</span>, <span class="number">2</span>));</span><br><span class="line">word_count.<span class="built_in">insert</span>(std::pair&lt;std::string, <span class="keyword">size_t</span>&gt;(<span class="string">&quot;huya&quot;</span>, <span class="number">1</span>));</span><br><span class="line">word_count.<span class="built_in">insert</span>(std::map&lt;std::string, <span class="keyword">size_t</span>&gt;::<span class="built_in">value_type</span>(<span class="string">&quot;next&quot;</span>, <span class="number">3</span>));</span><br></pre></td></tr></table></figure>

<h3 id="删除元素-1"><a href="#删除元素-1" class="headerlink" title="删除元素"></a>删除元素</h3><figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="comment">// 1. 删除键为 &quot;bfff&quot; 指向的元素</span></span><br><span class="line">cmap.<span class="built_in">erase</span>(<span class="string">&quot;bfff&quot;</span>);</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 2. 删除迭代器 key 所指向的元素</span></span><br><span class="line">map&lt;string,<span class="keyword">int</span>&gt;::iterator key = cmap.<span class="built_in">find</span>(<span class="string">&quot;mykey&quot;</span>);</span><br><span class="line"><span class="keyword">if</span>(key!=cmap.<span class="built_in">end</span>())&#123;</span><br><span class="line">    cmap.<span class="built_in">erase</span>(key);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line"><span class="comment">// 3. 删除所有元素</span></span><br><span class="line">cmap.<span class="built_in">erase</span>(cmap.<span class="built_in">begin</span>(),cmap.<span class="built_in">end</span>());</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>杂七杂八</category>
      </categories>
      <tags>
        <tag>C++ 编程学习</tag>
      </tags>
  </entry>
  <entry>
    <title>修改 YOLOv5 源码在 DOTAv1.5 遥感数据集上进行旋转目标检测</title>
    <url>/2021/04/20/%E4%BF%AE%E6%94%B9-YOLOv5-%E6%BA%90%E7%A0%81%E5%9C%A8-DOTAv1.5-%E9%81%A5%E6%84%9F%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%97%8B%E8%BD%AC%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/</url>
    <content><![CDATA[<p><a href="https://github.com/ultralytics/yolov5">YOLOv5</a> 发布已经有一段时间了，但是我一直还没有怎么去用过它。机会终于来了，最近需要做一个「旋转目标检测」的项目。于是我想到用它来进行魔改，使其能输出目标的 <code>rotated bounding boxes</code>。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/修改-YOLOv5-源码在-DOTAv1.5-遥感数据集上进行旋转目标检测-20210509005417.jpg">
</p>

<span id="more"></span>

<h2 id="1-DOTA-v1-5-遥感数据集"><a href="#1-DOTA-v1-5-遥感数据集" class="headerlink" title="1. DOTA-v1.5 遥感数据集"></a>1. DOTA-v1.5 遥感数据集</h2><p><a href="https://captain-whu.github.io/DOTA/index.html">DOTA</a> 是武汉大学制作的一个关于航拍遥感数据集，里面的每个目标都由一个任意的四边形边界框标注。这个数据集目前一共有 3 个版本，这里我们只使用和介绍其中的 DOTA-v1.5 版本。</p>
<h3 id="1-1-图片类别"><a href="#1-1-图片类别" class="headerlink" title="1.1 图片类别"></a>1.1 图片类别</h3><p>一共有 2806 张图片，40 万个实例，分为 16 个类别：<em><strong>飞机，轮船，储罐，棒球场，网球场，篮球场，地面跑道，港口，桥梁，大型车辆，小型车辆，直升机，环形交叉路口，足球场，游泳池，起重机。</strong></em></p>
<h3 id="1-2-标注方式"><a href="#1-2-标注方式" class="headerlink" title="1.2 标注方式"></a>1.2 标注方式</h3><p>每个目标都被一个四边框 <strong>oriented bounding box (OBB)</strong> 标注，其 4 个顶点的坐标表示为（x1, y1, x2, y2, x3, y3, x4, y4）。标注框的起始顶点为黄色，其余 3 个顶点则按照顺时针顺序排列。</p>
<p align="center">
    <img width="35%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/修改-YOLOv5-源码在-DOTAv1.5-遥感数据集上进行旋转目标检测-20210509005422.jpg">
</p>

<p>每张图片的标注内容为：在第一行 <code>imagesource</code> 表示图片的来源，<code>GoogleEarth</code> 或者 <code>GF-2</code>；第二行 <code>gsd</code> 表示的是<a href="https://zh.wikipedia.org/wiki/%E5%9C%B0%E9%9D%A2%E9%87%87%E6%A0%B7%E8%B7%9D%E7%A6%BB">地面采样距离（Ground Sample Distance，简称 GSD）</a>，如果缺失，则为 <code>null</code>；第三行以后则标注的是每个实例的四边框、类别和识别难易程度。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#x27;imagesource&#x27;:imagesource</span><br><span class="line">&#x27;gsd&#x27;:gsd</span><br><span class="line">x1, y1, x2, y2, x3, y3, x4, y4, category, difficult</span><br><span class="line">x1, y1, x2, y2, x3, y3, x4, y4, category, difficult</span><br><span class="line">...</span><br></pre></td></tr></table></figure>

<h3 id="1-3-数据下载"><a href="#1-3-数据下载" class="headerlink" title="1.3 数据下载"></a>1.3 数据下载</h3><ul>
<li>百度云盘：<a href="https://pan.baidu.com/s/1kWyRGaz">Training set</a>，<a href="https://pan.baidu.com/s/1qZCoF72">Validation set</a>，<a href="https://pan.baidu.com/s/1i6ly9Id">Testing images</a></li>
<li>谷歌云盘：<a href="https://drive.google.com/drive/folders/1gmeE3D7R62UAtuIFOB9j2M5cUPTwtsxK?usp=sharing">Training set</a>，<a href="https://drive.google.com/drive/folders/1n5w45suVOyaqY84hltJhIZdtVFD9B224?usp=sharing">Validation set</a>，<a href="https://drive.google.com/drive/folders/1mYOf5USMGNcJRPcvRVJVV1uHEalG5RPl?usp=sharing">Testing images</a></li>
</ul>
<p>建议通过百度云盘下载，得到的数据容量为：<code>train</code>，9.51G；<code>val</code>，3.11G。</p>
<h2 id="2-数据集预处理"><a href="#2-数据集预处理" class="headerlink" title="2. 数据集预处理"></a>2. 数据集预处理</h2><h3 id="2-1-加载显示图片"><a href="#2-1-加载显示图片" class="headerlink" title="2.1 加载显示图片"></a>2.1 加载显示图片</h3><p>我们需要用到官方发布的 <a href="https://github.com/CAPTAIN-WHU/DOTA_devkit">DOTA_devkit</a> 来对数据集进行预处理，不妨根据 <code>README</code> 先下载安装该工具。然后我们可以使用 <a href="https://github.com/CAPTAIN-WHU/DOTA_devkit/blob/master/DOTA.py"><code>DOTA.py</code></a> 来加载指定的图片并显示目标的 obb 框。如果你还想将数据格式转换成 COCO 格式，那么就可以使用 <a href="https://github.com/CAPTAIN-WHU/DOTA_devkit/blob/master/DOTA2COCO.py">DOTA2COCO.py</a>。</p>
<h3 id="2-2-分割数据集"><a href="#2-2-分割数据集" class="headerlink" title="2.2 分割数据集"></a>2.2 分割数据集</h3><p>数据集里的图片分辨率都很高（最高达到了 <code>20000x20000</code>），显然我们的 GPU 不能满足这样的运算要求。如果我们 resize 图片，则会损失图片的信息，尤其是那种大量的小目标（低于 <code>20x20</code>）可能会直接消失。因此我们可以考虑使用 <a href="https://github.com/CAPTAIN-WHU/DOTA_devkit/blob/master/ImgSplit.py#L241"><code>ImgSplit.py</code></a> 将单张遥感图像裁剪切割成多张图片：</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/修改-YOLOv5-源码在-DOTAv1.5-遥感数据集上进行旋转目标检测-20210509005429.jpg">
</p>

<p>由于切割图片时会有重叠区域（gap），一般 gap 设为切割图像尺寸的 20% 为宜。分割后会将裁剪的位置信息保留在裁剪后的图片名称中，例如图片 <code>P0770__1__586___334.png</code> 就是从原图 <code>P0770.png</code> 中 <code>x=586, y=334</code> 的位置处开始裁剪。</p>
<h3 id="2-3-最小外接矩形"><a href="#2-3-最小外接矩形" class="headerlink" title="2.3 最小外接矩形"></a>2.3 最小外接矩形</h3><p>DOTA 图片里的标注框为任意四边形，而我们需要的是带旋转角度的标准矩形，这就要用到 OpenCV 的 <a href="https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_contours/py_contour_features/py_contour_features.html#b-rotated-rectangle">cv2.minAreaRect()</a> 来求任意四边形的最小外接矩形，示例代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">image = cv2.imread(<span class="string">&quot;demo.png&quot;</span>)</span><br><span class="line">poly  = [[<span class="number">462.0</span>, <span class="number">785.0</span>],        <span class="comment"># 任意四边形的顶点坐标</span></span><br><span class="line">         [<span class="number">630.0</span>, <span class="number">787.0</span>],</span><br><span class="line">         [<span class="number">623.0</span>, <span class="number">952.0</span>],</span><br><span class="line">         [<span class="number">467.0</span>, <span class="number">953.0</span>]]</span><br><span class="line">poly  = np.array(poly, dtype=np.float32)</span><br><span class="line"></span><br><span class="line">rect  = cv2.minAreaRect(poly)</span><br><span class="line"><span class="comment"># 返回中心坐标 x, y 和长宽 w, h 以及与 x 轴的夹角 Q</span></span><br><span class="line"></span><br><span class="line">box   = cv2.boxPoints(rect).astype(np.<span class="built_in">int</span>)</span><br><span class="line"><span class="comment"># 返回四个顶点的坐标 (x1, y1), (x2, y2), (x3, y3) 和 (x4, y4)</span></span><br><span class="line"></span><br><span class="line">image = cv2.drawContours(image, [box], <span class="number">0</span>, (<span class="number">255</span>, <span class="number">0</span>, <span class="number">0</span>), <span class="number">5</span>)</span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/修改-YOLOv5-源码在-DOTAv1.5-遥感数据集上进行旋转目标检测-20210509005434.png">
</p>

<blockquote>
<p>绿色框为任意四边形，红色框是它的最小外接矩形。</p>
</blockquote>
<h2 id="3-修改算法的思路"><a href="#3-修改算法的思路" class="headerlink" title="3. 修改算法的思路"></a>3. 修改算法的思路</h2><p>可能会有人要问，为什么针对遥感图片的目标就需要进行旋转检测呢，水平检测难道就不行吗？<font color=red>如果采用水平检测的方法，那么得到的检测框就容易高度重叠，而目前绝大多数的目标检测算法对于这种高度重叠的目标都容易发生漏检。</font></p>
<p align="center">
    <img width="35%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/修改-YOLOv5-源码在-DOTAv1.5-遥感数据集上进行旋转目标检测20210524144517.png">
</p>

<p>我们想到：假如在原有的水平目标检测上，给预测框（boudning boxes) 加个角度 theta，那不就实现了旋转目标检测嘛。最简单的思想是，将这个角度预测当作是分类任务去处理，即一共有 180 个类别，便实现了 0~179 个角度。 在模型结构中，我们只需要修改 yolov5 的 Detect 层：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Detect</span>(<span class="params">nn.Module</span>):</span>  <span class="comment"># 定义检测网络</span></span><br><span class="line">    stride = <span class="literal">None</span>  <span class="comment"># strides computed during build</span></span><br><span class="line">    export = <span class="literal">False</span>  <span class="comment"># onnx export</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, nc=<span class="number">16</span>, anchors=(<span class="params"></span>), ch=(<span class="params"></span>)</span>):</span>  <span class="comment"># detection layer</span></span><br><span class="line">        <span class="built_in">super</span>(Detect, self).__init__()</span><br><span class="line">        <span class="comment"># number of classes</span></span><br><span class="line">        self.nc = nc</span><br><span class="line"></span><br><span class="line">        <span class="comment"># number of outputs per anchor   （xywh + score + num_classes + num_angle）</span></span><br><span class="line">        self.angle = <span class="number">180</span></span><br><span class="line">        self.no = nc + <span class="number">5</span> + self.angle</span><br><span class="line">        </span><br><span class="line">        self.nl = <span class="built_in">len</span>(anchors)</span><br><span class="line">        self.na = <span class="built_in">len</span>(anchors[<span class="number">0</span>]) // <span class="number">2</span></span><br><span class="line">        self.grid = [torch.zeros(<span class="number">1</span>)] * self.nl  <span class="comment"># init grid   [tensor([0.]), tensor([0.]), tensor([0.])] 初始化网格</span></span><br><span class="line">        a = torch.tensor(anchors).<span class="built_in">float</span>().view(self.nl, -<span class="number">1</span>, <span class="number">2</span>)  <span class="comment"># shape(3, ?(3), 2)</span></span><br><span class="line">        </span><br><span class="line">        self.register_buffer(<span class="string">&#x27;anchors&#x27;</span>, a)  <span class="comment"># shape(nl,na,2) = (3, 3, 2)</span></span><br><span class="line">        self.register_buffer(<span class="string">&#x27;anchor_grid&#x27;</span>, a.clone().view(self.nl, <span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>))</span><br><span class="line">        </span><br><span class="line">        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, <span class="number">1</span>) <span class="keyword">for</span> x <span class="keyword">in</span> ch) <span class="comment"># 最后一层卷基层</span></span><br><span class="line">        <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        m(</span></span><br><span class="line"><span class="string">            (0) :  nn.Conv2d(in_ch[0]（17）, (nc + 5 + self.angle) * na, kernel_size=1)</span></span><br><span class="line"><span class="string">            (1) :  nn.Conv2d(in_ch[1]（20）, (nc + 5 + self.angle) * na, kernel_size=1)</span></span><br><span class="line"><span class="string">            (2) :  nn.Conv2d(in_ch[2]（23）, (nc + 5 + self.angle) * na, kernel_size=1)</span></span><br><span class="line"><span class="string">        )</span></span><br><span class="line"><span class="string">        &#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>






]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>rotated object detection</tag>
      </tags>
  </entry>
  <entry>
    <title>随手用 Python 撸一个单目视觉里程计的例子</title>
    <url>/2020/12/19/%E7%94%A8-Python-%E6%89%8B%E6%92%B8%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E5%8D%95%E7%9B%AE-Slam-%E4%BE%8B%E5%AD%90/</url>
    <content><![CDATA[<p>最近因工作需要，开始接触到一些关于 SLAM（Simultaneous Localization and Mapping）的研究。网上关于 slam 的资料有很多，譬如高博的十四讲，github 上的 VINS 等等。但是他们大多是用 C++ 写的，并且环境依赖复杂。今天， 我使用 Python 手撸了一个简单的单目 slam，对 slam 有了一个初步的认识。完整的代码在<a href="https://github.com/YunYang1994/openwork/tree/master/MonocularSlam">这里</a>。</p>
<p align="center">
<iframe src="//player.bilibili.com/player.html?aid=245798532&bvid=BV1Tv411t7aN&cid=270731969&page=1"  width="400" height="300"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</p>

<span id="more"></span>

<h2 id="1-ORB-特征点检测"><a href="#1-ORB-特征点检测" class="headerlink" title="1. ORB 特征点检测"></a>1. ORB 特征点检测</h2><p>ORB 特征由<strong><font color=Red>关键点</font></strong>和<strong><font color=Red>描述子</font></strong>两部分组成，它的关键点称为 “Oriented FAST”，是一种改进的 FAST 角点，而描述子则称为 BRIEF。在 OpenCV 中，我们可以这样：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">orb = cv2.ORB_create()</span><br><span class="line">image = cv2.cvtColor(frame.image, cv2.COLOR_BGR2GRAY)</span><br><span class="line"><span class="comment"># detection corners</span></span><br><span class="line">pts = cv2.goodFeaturesToTrack(image, <span class="number">3000</span>, qualityLevel=<span class="number">0.01</span>, minDistance=<span class="number">3</span>)</span><br><span class="line"><span class="comment"># extract features</span></span><br><span class="line">kps = [cv2.KeyPoint(x=pt[<span class="number">0</span>][<span class="number">0</span>], y=pt[<span class="number">0</span>][<span class="number">1</span>], _size=<span class="number">20</span>) <span class="keyword">for</span> pt <span class="keyword">in</span> pts]</span><br><span class="line">kps, des = orb.compute(image, kps)</span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509003217.gif">
</p>

<p>我们首先需要将图片转成灰度图， 然后利用 <code>goodFeaturesToTrack</code> 找出图片中的高质量的角点， 接着使用 <code>orb</code> 里的 <code>compuete</code> 函数计算出这些角点的特征：它会返回 <code>kps</code> 和 <code>des</code>，<code>kps</code> 给出了角点在图像中坐标，而 <code>des</code> 则是这些角点的描述子，一般为 32 维的特征向量。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">frame 1: kps[0]=(294.0, 217.0), des[0]=[ 66 245  18 ...  39 206]</span><br></pre></td></tr></table></figure>

<h2 id="2-特征点匹配"><a href="#2-特征点匹配" class="headerlink" title="2. 特征点匹配"></a>2. 特征点匹配</h2><p>特征点匹配的意思就是将本帧检测的所有角点和上一帧的角点进行匹配，因此需要将上一帧的角点 <code>last_kps</code>  和描述子 <code>last_des</code>  存储起来。此外还需要 <code>idx</code> 记录每帧的序列号，并且从第二帧才开始做匹配。我们构造了一个 Frame 类，并将它们定义为类的属性，在实例初始化的时候再将这些属性传递给对象。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Frame</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    idx = <span class="number">0</span></span><br><span class="line">    last_kps, last_des, last_pose = <span class="literal">None</span>, <span class="literal">None</span>, <span class="literal">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, image</span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        只要一经初始化，Frame 就会把上一帧的信息传递给下一帧</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        Frame.idx += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        self.image = image</span><br><span class="line">        self.idx   = Frame.idx</span><br><span class="line">        self.last_kps  = Frame.last_kps</span><br><span class="line">        self.last_des  = Frame.last_des</span><br><span class="line">        self.last_pose = Frame.last_pose</span><br></pre></td></tr></table></figure>

<p>我直接使用了暴力匹配（Brute-Force）的方法对两帧图片的角点进行配准，通过 <code>cv2.BFMatcher</code> 可以创建一个匹配器 <code>bfmatch</code>，它有两个可选的参数：</p>
<ul>
<li><code>normType</code>：度量两个角点之间距离的方式，由于 ORB 是一种基于二进制字符串的描述符，因此可以选择汉明距离 (<code>cv2.NORM_HAMMING</code>)。</li>
<li><code>crossCheck</code>：为布尔变量，默认值为 False。如果设置为 True，匹配条件就会更加严格，只有当两个特征点互相为最佳匹配时才可以。</li>
</ul>
<p>使用 <code>knnMatch()</code>  可以为每个关键点返回 k 个最佳匹配（将序排列之后取前 k 个），其中 k 是用户自己设定的，这里设置成 k=2。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bfmatch = cv2.BFMatcher(cv2.NORM_HAMMING)</span><br><span class="line">matches = bfmatch.knnMatch(frame.curr_des, frame.last_des, k=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<p>将 <code>frame.curr_des</code> 、 <code>frame.last_des</code> 和 <code>matches</code> 的数量打印出来：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">frame: 16, curr_des: 1660, last_des: 1597, matches: 1660</span><br><span class="line">frame: 17, curr_des: 1484, last_des: 1660, matches: 1484</span><br></pre></td></tr></table></figure>

<p>我们发现 <code>matches</code> 的数量始终与 <code>frame.curr_des</code> 相等，这是因为这里是从上一帧 <code>frame.last_des</code> 给当前帧 <code>frame.curr_des</code> 找最佳匹配点，并且每个 <code>match</code> 返回的是 2 个 <code>DMatch</code> 对象，它们具有以下属性：</p>
<ul>
<li><code>DMatch.distance</code> ：关键点之间的距离，越小越好。</li>
<li><code>DMatch.trainIdx</code> ：目标图像中描述符的索引。</li>
<li><code>DMatch.queryIdx</code> ：查询图像中描述符的索引。</li>
<li><code>DMatch.imgIdx</code>：目标图像的索引。</li>
</ul>
<p>如果第一名的距离小于第二名距离的 75%，那么将认为第一名大概率是匹配上了，此时 <code>m.queryIdx</code> 为当前帧关键点的索引，<code>m.trainIdx</code> 为上一帧关键点的索引，<code>match_kps</code> 返回的是每对配准点的位置。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> m,n <span class="keyword">in</span> matches:</span><br><span class="line">    <span class="keyword">if</span> m.distance &lt; <span class="number">0.75</span>*n.distance:</span><br><span class="line">        idx1.append(m.queryIdx)</span><br><span class="line">        idx2.append(m.trainIdx)</span><br><span class="line"></span><br><span class="line">        p1 = frame.curr_kps[m.queryIdx]     <span class="comment"># 当前帧配准的角点位置</span></span><br><span class="line">        p2 = frame.last_kps[m.trainIdx]     <span class="comment"># 上一帧配置的角点位置</span></span><br><span class="line">        match_kps.append((p1, p2))</span><br></pre></td></tr></table></figure>

<p>在下图中：红色的是当前帧的关键点，蓝色的是当前帧关键点的位置与上一帧关键点位置的连线。由于 🚗 是向前行驶，因此关键点相对 🚗 是往后运动的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> kp1, kp2 <span class="keyword">in</span> <span class="built_in">zip</span>(frame.curr_kps, frame.last_kps):</span><br><span class="line">    u1, v1 = <span class="built_in">int</span>(kp1[<span class="number">0</span>]), <span class="built_in">int</span>(kp1[<span class="number">1</span>])</span><br><span class="line">    u2, v2 = <span class="built_in">int</span>(kp2[<span class="number">0</span>]), <span class="built_in">int</span>(kp2[<span class="number">1</span>])</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 用圆圈画出当前帧角点的位置</span></span><br><span class="line">    cv2.circle(frame.image, (u1, v1), color=(<span class="number">0</span>,<span class="number">0</span>,<span class="number">255</span>), radius=<span class="number">3</span>)</span><br><span class="line">    <span class="comment"># 用直线追踪角点的行动轨迹</span></span><br><span class="line">    cv2.line(frame.image, (u1, v1), (u2, v2), color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509003302.jpg">
</p>

<h2 id="3-RANSAC-去噪和本质矩阵"><a href="#3-RANSAC-去噪和本质矩阵" class="headerlink" title="3. RANSAC 去噪和本质矩阵"></a>3. RANSAC 去噪和本质矩阵</h2><p>RANSAC (RAndom SAmple Consensus, 随机采样一致) 算法是从一组含有 “外点” (outliers) 的数据中正确估计数学模型参数的迭代算法。RANSAC 算法有 2 个基本的假设：</p>
<ul>
<li>假设数据是由“内点”和“外点”组成的。“内点”就是组成模型参数的数据，“外点”就是不适合模型的异常值，通常是那些估计曲线以外的离群点。</li>
<li>假设在给定一组含有少部分“内点”的数据中，存在一个模型可以估计出符合“内点”变化的规律。</li>
</ul>
<p>具体的细节这里不再展开，感兴趣的话可以看<a href="https://zhuanlan.zhihu.com/p/62238520">这里</a>，这里是直接使用三方库里的 <code>scikit-image</code> 里的 <code>ransac</code> 算法进行求解。由于我们在求解本质矩阵的时候，<strong><font color=Red>需要利用相机内参将角点的像素坐标进行归一化：</font></strong></p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509003338.png">
</p>

<p>其中 <code>p1</code> 和 <code>p2</code> 分别为配对角点在图片上的像素位置，那么归一化的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span>(<span class="params">pts</span>):</span></span><br><span class="line">    Kinv = np.linalg.inv(K)</span><br><span class="line">    <span class="comment"># turn [[x,y]] -&gt; [[x,y,1]]</span></span><br><span class="line">    add_ones = <span class="keyword">lambda</span> x: np.concatenate([x, np.ones((x.shape[<span class="number">0</span>], <span class="number">1</span>))], axis=<span class="number">1</span>)</span><br><span class="line">    norm_pts = np.dot(Kinv, add_ones(pts).T).T[:, <span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line">    <span class="keyword">return</span> norm_pts</span><br></pre></td></tr></table></figure>

<p>slam 知识里给出了本质矩阵和归一化坐标之间的关系，它可以用一个简洁的公式来表达：</p>
<p align="center">
    <img width="14%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509003438.jpg">
</p>

<p>其中本质矩阵 <strong>E</strong> 是平移向量 <strong>t</strong> 和旋转矩阵 <strong>R</strong> 的外积：</p>
<p align="center">
    <img width="11%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509003533.jpg">
</p>

<p>本质矩阵 <code>E</code> 是一个 <code>3x3</code> 的矩阵，有 9 个未知元素。然而，上面的公式中 <code>x</code> 使用的是齐次坐标（已经有一个已知的 <code>1</code>）。而齐次坐标在相差一个常数因子下是相等，因此在单位尺度下只需 8 个点即可求解。</p>
<p align="center">
    <img width="42%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509003615.jpg">
</p>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">fit_essential_matrix</span>(<span class="params">match_kps</span>):</span></span><br><span class="line">    match_kps = np.array(match_kps)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 使用相机内参对角点坐标归一化</span></span><br><span class="line">    norm_curr_kps = normalize(match_kps[:, <span class="number">0</span>])</span><br><span class="line">    norm_last_kps = normalize(match_kps[:, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 求解本质矩阵和内点数据</span></span><br><span class="line">    model, inliers = ransac((norm_curr_kps, norm_last_kps),</span><br><span class="line">                            EssentialMatrixTransform,</span><br><span class="line">                            min_samples=<span class="number">8</span>,              <span class="comment"># 最少需要 8 个点</span></span><br><span class="line">                            residual_threshold=<span class="number">0.005</span>,</span><br><span class="line">                            max_trials=<span class="number">200</span>)</span><br><span class="line"></span><br><span class="line">    frame.curr_kps = frame.curr_kps[inliers]   <span class="comment"># 保留当前帧的内点数据</span></span><br><span class="line">    frame.last_kps = frame.last_kps[inliers]   <span class="comment"># 保留上一帧的内点数据</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> model.params       <span class="comment"># 返回本质矩阵</span></span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509003729.jpg">
</p>

<blockquote>
<p>可以看到，经过 RANSAC 去燥后，噪点数据消失了很多，角点的追踪情况基本稳定。但是经过筛选后，角点的数量只有原来的三分之一左右了。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">frame: 46, curr_des: 1555, last_des: 1467, match_kps: 549</span><br><span class="line">---------------- Essential Matrix ----------------</span><br><span class="line">[[-2.86637732e-04 -1.16930419e+00  1.12798916e-01]</span><br><span class="line"> [ 1.16673848e+00 -2.40819717e-03 -2.60028204e-01]</span><br><span class="line"> [-1.10221539e-01  2.67480554e-01 -1.20159639e-03]]</span><br></pre></td></tr></table></figure>

<h2 id="4-本质矩阵分解"><a href="#4-本质矩阵分解" class="headerlink" title="4. 本质矩阵分解"></a>4. 本质矩阵分解</h2><p>接下来的问题是如何根据已经估计得到的本质矩阵 <strong>E</strong>，恢复出相机的运动 <strong>R</strong>，<strong>t</strong>。这个过程是由奇异值分解得到的：</p>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509003827.png">
</p>

<p>我们发现对角矩阵 <code>diag([1, 1, 0])</code> 可以由 <code>Z</code> 和 <code>W</code> 拆分得到。</p>
<p align="center">
    <img width="36%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509003941.png">
</p>

<p align="center">
    <img width="51%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509004030.png">
</p>

<p>将 <code>Z</code> 和 <code>W</code> 代入进来，令 <code>E = S R</code>。可以分解成两种情况：</p>
<ul>
<li>情况 1:</li>
</ul>
<p align="center">
    <img width="65%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509004128.jpg">
</p>

<p align="center">
    <img width="32%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509004216.jpg">
</p>

<ul>
<li>情况 2:</li>
</ul>
<p align="center">
    <img width="78%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509004257.jpg">
</p>

<p align="center">
    <img width="37%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509004328.jpg">
</p>

<p>我们发现，此时已经将旋转矩阵 <code>R</code> 分离出来了，它有两种情况：分别等于 <code>R1</code> 和 <code>R2</code>。接下来我们需要考虑平移向量 <strong>t</strong>，可以证明出 <strong>t</strong> 其实是在 <strong><code>S</code></strong> 的零向量空间里，因为：</p>
<p align="center">
    <img width="18%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509004422.jpg">
</p>

<p>结合线性代数的知识，不难求出 <code>t = U * (0, 0, 1) = u3</code> (即 <code>U</code> 的最后一列)。考虑到给 <code>t</code> 乘以一个非零尺度因子 <code>λ</code>， 对于 <code>E</code> 而言这种情况依旧有效，而对于 <code>t</code> 而言， 当 <code>λ = ± 1</code> 时，它们物理的意义（方向）却是不同的。综上，在已知第一个相机矩阵 <code>P = [ I ∣ 0 ]</code> 的情况下，第二个相机矩阵 <code>P′</code> 有如下 4 种可能的解：</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509004507.jpg">
</p>

<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509004604.png">
</p>

<blockquote>
<p>我们发现上面 4 种解其实是 2 种 R 和 2 种 t 之间的排列组合，只有当点 P 位于两个相机前方时才具有正深度，即 (1) 才是唯一正确解。</p>
</blockquote>
<p><a href="https://github.com/opencv/opencv/blob/3.1.0/modules/calib3d/src/five-point.cpp#L617">OpenCV</a> 提供了从本质矩阵中恢复相机的 <code>Rt</code> 的方法：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">cv::decomposeEssentialMat</span><span class="params">( InputArray _E, OutputArray _R1, OutputArray _R2, OutputArray <span class="keyword">_t</span> )</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    Mat E = _E.<span class="built_in">getMat</span>().<span class="built_in">reshape</span>(<span class="number">1</span>, <span class="number">3</span>);</span><br><span class="line">	<span class="built_in">CV_Assert</span>(E.cols == <span class="number">3</span> &amp;&amp; E.rows == <span class="number">3</span>);</span><br><span class="line">	</span><br><span class="line">    Mat D, U, Vt;</span><br><span class="line">	SVD::<span class="built_in">compute</span>(E, D, U, Vt);</span><br><span class="line">	</span><br><span class="line">	<span class="keyword">if</span> (<span class="built_in">determinant</span>(U) &lt; <span class="number">0</span>) U *= <span class="number">-1.</span>;</span><br><span class="line">	<span class="keyword">if</span> (<span class="built_in">determinant</span>(Vt) &lt; <span class="number">0</span>) Vt *= <span class="number">-1.</span>;</span><br><span class="line">	</span><br><span class="line">    Mat W = (Mat_&lt;<span class="keyword">double</span>&gt;(<span class="number">3</span>, <span class="number">3</span>) &lt;&lt; <span class="number">0</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">-1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>);</span><br><span class="line">    W.<span class="built_in">convertTo</span>(W, E.<span class="built_in">type</span>());</span><br><span class="line">    Mat R1, R2, t;</span><br><span class="line">    </span><br><span class="line">    R1 = U * W * Vt;</span><br><span class="line">    R2 = U * W.<span class="built_in">t</span>() * Vt;</span><br><span class="line">    t = U.<span class="built_in">col</span>(<span class="number">2</span>) * <span class="number">1.0</span>;</span><br><span class="line">    </span><br><span class="line">    R1.<span class="built_in">copyTo</span>(_R1);</span><br><span class="line">    R2.<span class="built_in">copyTo</span>(_R2);</span><br><span class="line">    t.<span class="built_in">copyTo</span>(<span class="keyword">_t</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>可以看出  <a href="https://docs.opencv.org/master/d9/d0c/group__calib3d.html#ga54a2f5b3f8aeaf6c76d4a31dece85d5d">cv::decomposeEssentialMat</a>  函数输出了 <code>R1</code>、<code>R2</code> 和 <code>t</code>，因此 4 种可能的解分别为：<code>[R1,t]</code>, <code>[R1,−t]</code>, <code>[R2,t]</code>, <code>[R2,−t]</code>， ORB_SLAM2  里使用了 <a href="https://gitee.com/paopaoslam/ORB-SLAM2/blob/wubo&jiajia/src/Initializer.cpp?dir=0&filepath=src/Initializer.cpp&oid=ebe440148231a2c288d0aa11425db799468a92ab&sha=3ccff875e95723673258573b665ee2e33511f843#L1021">CheckRT</a> 函数对它们进行判断。考虑到 demo 视频里  🚗 是一直往前行驶，且没有转弯。因此相机 <code>t = (x, y, z)</code> 里的 <code>z &gt; 0</code>，并且相机 <code>R</code> 的对角矩阵将接近 <code>diag([1, 1, 1])</code> ，从而我们可以直接过滤出唯一解。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extract_Rt</span>(<span class="params">E</span>):</span></span><br><span class="line">    W = np.mat([[<span class="number">0</span>,-<span class="number">1</span>,<span class="number">0</span>],[<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>],[<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>]],dtype=<span class="built_in">float</span>)</span><br><span class="line">    U,d,Vt = np.linalg.svd(E)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> np.linalg.det(U)  &lt; <span class="number">0</span>: U  *= -<span class="number">1.0</span></span><br><span class="line">    <span class="keyword">if</span> np.linalg.det(Vt) &lt; <span class="number">0</span>: Vt *= -<span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 相机没有转弯，因此 R 的对角矩阵非常接近 diag([1,1,1])</span></span><br><span class="line">    R = (np.dot(np.dot(U, W), Vt))</span><br><span class="line">    <span class="keyword">if</span> np.<span class="built_in">sum</span>(R.diagonal()) &lt; <span class="number">0</span>:</span><br><span class="line">        R = np.dot(np.dot(U, W.T), Vt)</span><br><span class="line"></span><br><span class="line">    t = U[:, <span class="number">2</span>]     <span class="comment"># 相机一直向前，分量 t[2] &gt; 0</span></span><br><span class="line">    <span class="keyword">if</span> t[<span class="number">2</span>] &lt; <span class="number">0</span>:</span><br><span class="line">        t *= -<span class="number">1</span></span><br><span class="line"></span><br><span class="line">    Rt = np.eye(<span class="number">4</span>)</span><br><span class="line">    Rt[:<span class="number">3</span>, :<span class="number">3</span>] = R</span><br><span class="line">    Rt[:<span class="number">3</span>, <span class="number">3</span>] = t</span><br><span class="line">    <span class="keyword">return</span> Rt          <span class="comment"># Rt 为从相机坐标系的位姿变换到世界坐标系的位姿</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>由于平移向量的分量 t[2] &gt; 0，我们很容易知道 Rt 为从相机坐标系的位姿变换到世界坐标系的位姿</p>
</blockquote>
<h2 id="5-三角测量"><a href="#5-三角测量" class="headerlink" title="5. 三角测量"></a>5. 三角测量</h2><p>下一步我们需要用相机的运动估计特征点的空间位置，在单目 SLAM 中仅通过单目图像是无法获得像素的深度信息，我们需要通过<strong>三角测量（Triangulation）</strong>的方法估计图像的深度，然后通过直接线性变化（DLT）进行求解。 </p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509004644.png">
</p>


<p>假设点 <code>P</code> 的世界坐标为 <code>X_&#123;w&#125;</code>，图像坐标为 <code>X_&#123;uv&#125;</code>，相机的内参和位姿分别为 <code>K</code> 和 <code>P_&#123;cw&#125;</code>，那么得到：</p>
<p align="center">
    <img width="23%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509004725.jpg">
</p>

<p>将下标去掉，使用相机内参将两个匹配的角点像素坐标进行归一化，代入到上述方程中便得到：</p>
<p align="center">
    <img width="11%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509004936.jpg">
</p>

<p>使用 DLT 的话我们对上面两个公式进行一个简单的变换，对等式两边分别做外积运算：</p>
<p align="center">
    <img width="23%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509005026.jpg">
</p>

<p>由于 <code>x=&#123;u, v, 1&#125;</code> ，结合外积运算的知识（详见 slam 十四讲 75 页），我们便得到以下方程：</p>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509005120.jpg">
</p>

<p>我们不妨令：</p>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509005146.jpg">
</p>

<p>将两个匹配的角点和相机位姿代入上述方程中便得到 <code>A</code>：</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/用-Python-手撸一个简单的单目-Slam-例子-20210509005240.jpg">
</p>

<p>因此便可以简化成 <code>AX=0</code>，从而可以使用最小二乘法来求解出 <code>X</code>，<a href="https://github.com/raulmur/ORB_SLAM2/blob/f2e6f51cdc8d067655d90a78c06261378e07e8f3/src/Initializer.cc#L734">ORB_SLAM2</a> 中的求解过程如下：</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Initializer::Triangulate</span><span class="params">(<span class="keyword">const</span> cv::KeyPoint &amp;kp1, <span class="keyword">const</span> cv::KeyPoint &amp;kp2, <span class="keyword">const</span> cv::Mat &amp;P1, <span class="keyword">const</span> cv::Mat &amp;P2, cv::Mat &amp;x3D)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="function">cv::Mat <span class="title">A</span><span class="params">(<span class="number">4</span>,<span class="number">4</span>,CV_32F)</span></span>;</span><br><span class="line"></span><br><span class="line">    A.<span class="built_in">row</span>(<span class="number">0</span>) = kp1.pt.x*P1.<span class="built_in">row</span>(<span class="number">2</span>)-P1.<span class="built_in">row</span>(<span class="number">0</span>);</span><br><span class="line">    A.<span class="built_in">row</span>(<span class="number">1</span>) = kp1.pt.y*P1.<span class="built_in">row</span>(<span class="number">2</span>)-P1.<span class="built_in">row</span>(<span class="number">1</span>);</span><br><span class="line">    A.<span class="built_in">row</span>(<span class="number">2</span>) = kp2.pt.x*P2.<span class="built_in">row</span>(<span class="number">2</span>)-P2.<span class="built_in">row</span>(<span class="number">0</span>);</span><br><span class="line">    A.<span class="built_in">row</span>(<span class="number">3</span>) = kp2.pt.y*P2.<span class="built_in">row</span>(<span class="number">2</span>)-P2.<span class="built_in">row</span>(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    cv::Mat u,w,vt;</span><br><span class="line">    cv::SVD::<span class="built_in">compute</span>(A,w,u,vt,cv::SVD::MODIFY_A| cv::SVD::FULL_UV);</span><br><span class="line">    x3D = vt.<span class="built_in">row</span>(<span class="number">3</span>).<span class="built_in">t</span>();</span><br><span class="line">    x3D = x3D.<span class="built_in">rowRange</span>(<span class="number">0</span>,<span class="number">3</span>)/x3D.at&lt;<span class="keyword">float</span>&gt;(<span class="number">3</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// Camera 1 Projection Matrix K[I|0]                  # 这里假设世界坐标系为相机 1 坐标系</span></span><br><span class="line"><span class="function">cv::Mat <span class="title">P1</span><span class="params">(<span class="number">3</span>,<span class="number">4</span>,CV_32F,cv::Scalar(<span class="number">0</span>))</span></span>;</span><br><span class="line">K.<span class="built_in">copyTo</span>(P1.<span class="built_in">rowRange</span>(<span class="number">0</span>,<span class="number">3</span>).<span class="built_in">colRange</span>(<span class="number">0</span>,<span class="number">3</span>));</span><br><span class="line"></span><br><span class="line"><span class="comment">// Camera 2 Projection Matrix K[R|t]                  # 相机 2 与 相机的位姿 R，t</span></span><br><span class="line"><span class="function">cv::Mat <span class="title">P2</span><span class="params">(<span class="number">3</span>,<span class="number">4</span>,CV_32F)</span></span>;</span><br><span class="line">R.<span class="built_in">copyTo</span>(P2.<span class="built_in">rowRange</span>(<span class="number">0</span>,<span class="number">3</span>).<span class="built_in">colRange</span>(<span class="number">0</span>,<span class="number">3</span>));</span><br><span class="line">t.<span class="built_in">copyTo</span>(P2.<span class="built_in">rowRange</span>(<span class="number">0</span>,<span class="number">3</span>).<span class="built_in">col</span>(<span class="number">3</span>));</span><br><span class="line">P2 = K*P2;</span><br><span class="line"></span><br><span class="line"><span class="keyword">const</span> cv::KeyPoint &amp;kp1 = vKeys1[vMatches12[i].first];</span><br><span class="line"><span class="keyword">const</span> cv::KeyPoint &amp;kp2 = vKeys2[vMatches12[i].second];</span><br><span class="line">cv::Mat p3dC1;</span><br><span class="line"></span><br><span class="line"><span class="built_in">Triangulate</span>(kp1,kp2,P1,P2,p3dC1);</span><br></pre></td></tr></table></figure>

<p>如下所示，我使用了 Python 对整个三角测量的计算过程进行了复现。值得注意的是，上述的相机位姿是指从空间点 P 从世界坐标系变换到相机坐标下点变换矩阵。如果你不清楚相机位姿的概念，请看<a href="https://yunyang1994.gitee.io/2019/12/27/CameraPose/">什么是相机位姿？</a></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">triangulate</span>(<span class="params">pts1, pts2, pose1, pose2</span>):</span></span><br><span class="line">    pose1 = np.linalg.inv(pose1)            <span class="comment"># 从世界坐标系变换到相机坐标系的位姿, 因此取逆</span></span><br><span class="line">    pose2 = np.linalg.inv(pose2)</span><br><span class="line"></span><br><span class="line">    pts1 = normalize(pts1)                 <span class="comment"># 使用相机内参对角点坐标归一化</span></span><br><span class="line">    pts2 = normalize(pts2)</span><br><span class="line"></span><br><span class="line">    points4d = np.zeros((pts1.shape[<span class="number">0</span>], <span class="number">4</span>))</span><br><span class="line">    <span class="keyword">for</span> i, (kp1, kp2) <span class="keyword">in</span> <span class="built_in">enumerate</span>(<span class="built_in">zip</span>(pts1, pts2)):</span><br><span class="line">        A = np.zeros((<span class="number">4</span>,<span class="number">4</span>))</span><br><span class="line">        A[<span class="number">0</span>] = kp1[<span class="number">0</span>] * pose1[<span class="number">2</span>] - pose1[<span class="number">0</span>]</span><br><span class="line">        A[<span class="number">1</span>] = kp1[<span class="number">1</span>] * pose1[<span class="number">2</span>] - pose1[<span class="number">1</span>]</span><br><span class="line">        A[<span class="number">2</span>] = kp2[<span class="number">0</span>] * pose2[<span class="number">2</span>] - pose2[<span class="number">0</span>]</span><br><span class="line">        A[<span class="number">3</span>] = kp2[<span class="number">1</span>] * pose2[<span class="number">2</span>] - pose2[<span class="number">1</span>]</span><br><span class="line">        _, _, vt = np.linalg.svd(A)         <span class="comment"># 对 A 进行奇异值分解</span></span><br><span class="line">        points4d[i] = vt[<span class="number">3</span>]</span><br><span class="line"></span><br><span class="line">    points4d /= points4d[:, <span class="number">3</span>:]            <span class="comment"># 归一化变换成齐次坐标 [x, y, z, 1]</span></span><br><span class="line">    <span class="keyword">return</span> points4d</span><br></pre></td></tr></table></figure>

<h2 id="6-pipeline-流程"><a href="#6-pipeline-流程" class="headerlink" title="6. pipeline 流程"></a>6. pipeline 流程</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">process_frame</span>(<span class="params">frame</span>):</span></span><br><span class="line">    <span class="comment"># 提取当前帧的角点和描述子特征</span></span><br><span class="line">    frame.curr_kps, frame.curr_des = extract_points(frame)</span><br><span class="line">    <span class="comment"># 将角点位置和描述子通过类的属性传递给下一帧作为上一帧的角点信息</span></span><br><span class="line">    Frame.last_kps, Frame.last_des = frame.curr_kps, frame.curr_des</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> frame.idx == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 设置第一帧为初始帧，并以相机坐标系为世界坐标系</span></span><br><span class="line">        frame.curr_pose = np.eye(<span class="number">4</span>)</span><br><span class="line">        points4d = [[<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">1</span>]]      <span class="comment"># 原点为 [0, 0, 0] , 1 表示颜色</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 角点配准, 此时会用 RANSAC 过滤掉一些噪声</span></span><br><span class="line">        match_kps = match_points(frame)</span><br><span class="line">        <span class="comment"># 使用八点法拟合出本质矩阵</span></span><br><span class="line">        essential_matrix = fit_essential_matrix(match_kps)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;---------------- Essential Matrix ----------------&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(essential_matrix)</span><br><span class="line">        <span class="comment"># 利用本质矩阵分解出相机的位姿 Rt</span></span><br><span class="line">        Rt = extract_Rt(essential_matrix)</span><br><span class="line">        <span class="comment"># 计算出当前帧相对于初始帧的相机位姿</span></span><br><span class="line">        frame.curr_pose = np.dot(Rt, frame.last_pose)</span><br><span class="line">        <span class="comment"># 三角测量获得角点的深度信息</span></span><br><span class="line">        points4d = triangulate(frame.last_kps, frame.curr_kps, frame.last_pose, frame.curr_pose)</span><br><span class="line">		<span class="comment"># 判断3D点是否在两个摄像头前方</span></span><br><span class="line">        good_pt4d = check_points(points4d)</span><br><span class="line">        points4d = points4d[good_pt4d]</span><br><span class="line"></span><br><span class="line">        draw_points(frame)</span><br><span class="line">    mapp.add_observation(frame.curr_pose, points4d)     <span class="comment"># 将当前的 pose 和点云放入地图中</span></span><br><span class="line">    <span class="comment"># 将当前帧的 pose 信息存储为下一帧的 last_pose 信息</span></span><br><span class="line">    Frame.last_pose = frame.curr_pose</span><br><span class="line">    <span class="keyword">return</span> frame</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>立体视觉</category>
      </categories>
      <tags>
        <tag>本质矩阵</tag>
      </tags>
  </entry>
  <entry>
    <title>2D人体姿态估计的总结和梳理</title>
    <url>/2020/10/10/2D%E4%BA%BA%E4%BD%93%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E7%9A%84%E6%80%BB%E7%BB%93%E5%92%8C%E6%A2%B3%E7%90%86/</url>
    <content><![CDATA[<p>最近在虎牙直播做了一些关于人体姿态估计的工作，也看了蛮多这方面的文章，于是对这个内容做了一些总结和梳理，希望能抛砖引玉吧。我们不妨先把问题抛出来，人体姿态估计是做什么？从名字的角度来看，可以理解为对“人体”的姿态（关键点，比如头，左手，右脚等）的位置估计。根据 RGB 图片里人体的数量，又可以分为<strong>单人姿态估计</strong>和<strong>多人姿态估计</strong>。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509001617.jpg">
</p>

<span id="more"></span>

<h2 id="1-单人姿态估计"><a href="#1-单人姿态估计" class="headerlink" title="1. 单人姿态估计"></a>1. 单人姿态估计</h2><h3 id="1-1-问题"><a href="#1-1-问题" class="headerlink" title="1.1 问题"></a>1.1 问题</h3><p>对于单人姿态估计，输入是一个 crop 出来的行人，然后在行人区域位置内找出需要的关键点，比如头部，左手，右膝等。对于<strong>多人姿态估计</strong>，目前主要有 2 种主流思路，分别是 <strong>top-down</strong> 以及 <strong>bottom-up</strong> 方法。对于 top-down 方法，往往先找到图片中所有行人，然后对每个行人做姿态估计，寻找每个人的关键点。单人姿态估计往往可以被直接用于这个场景。对于 bottom-up，思路正好相反，先是找图片中所有 parts （关键点），比如所有头部，左手，膝盖等，然后把这些 parts（关键点）组装成一个个行人。</p>
<h3 id="1-2-数据集"><a href="#1-2-数据集" class="headerlink" title="1.2 数据集"></a>1.2 数据集</h3><ul>
<li><a href="https://sam.johnson.io/research/lsp.html">LSP（Leeds Sports Pose Dataset）</a>：单人人体关键点检测数据集，关键点个数为14，样本数2K，在目前的研究中作为第二数据集使用。</li>
<li><a href="https://bensapp.github.io/flic-dataset.html">FLIC（Frames Labeled In Cinema）</a>：单人人体关键点检测数据集，关键点个数为9，样本数2W，在目前的研究中作为第二数据集使用。</li>
<li><a href="http://human-pose.mpi-inf.mpg.de/">MPII（MPII Human Pose Dataset）</a>：单人/多人人体关键点检测数据集，关键点个数为16，样本数25K，是单人人体关键点检测的主要数据集。它是 2014 年由马普所创建的，目前可以认为是单人姿态估计中最常用的 benchmark， 使用的是 <a href="http://human-pose.mpi-inf.mpg.de/#results">PCKh</a> 的指标。</li>
<li><a href="https://cocodataset.org/#home">MSCOCO</a>：多人人体关键点检测数据集，关键点个数为17，样本数量多于30W。目前是多人关键点检测的主要数据集，使用的是 <a href="https://cocodataset.org/#keypoints-eval">AP 和 OKS</a> 指标。</li>
<li><a href="http://vision.imar.ro/human3.6m/description.php">human3.6M</a>：是 3D 人体姿势估计的最大数据集，由 360 万个姿势和相应的视频帧组成，这些视频帧包含11 位演员从4个摄像机视角执行 15 项日常活动的过程。数据集庞大将近100G。</li>
<li><a href="https://posetrack.net/">PoseTrack</a>：最新的关于人体骨骼关键点的数据集，多人人体关键点跟踪数据集，包含单帧关键点检测、多帧关键点检测、多人关键点跟踪三个人物，多于500个视频序列，帧数超过20K，关键点个数为15。</li>
</ul>
<h3 id="1-3-评估指标"><a href="#1-3-评估指标" class="headerlink" title="1.3 评估指标"></a>1.3 评估指标</h3><p><code>Keypoint detection</code> 度量方法的核心思想就是模仿 <code>Object detection</code> 的度量方法。在 <code>Object detection</code> 中，<code>IoU</code> 是作为一种相似度度量，它通过计算检测框之间的重合度来定义真实目标和预测值目标之间的距离。而在 <code>Keypoint detection</code> 则是根据<font color=Red>预测关键点和真实关键点之间的欧式距离来评判的</font>。</p>
<ul>
<li>PCK(Percentage of Correct Keypoints)</li>
</ul>
<p><font color=Red>关键点正确估计的百分比，计算检测的关键点与其对应的 groundtruth 间的归一化距离小于设定阈值的比例</font>。这是比较老的人体姿态估计指标，在17年以前广泛使用，现在基本不再使用。但是如果仅是用于工程项目中来评价训练模型的好坏还是蛮方便的，因此这里也记录下：</p>
<p align="center">
    <img width="25%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509001841.png">
</p>

<p>其中： <code>i</code> 表示关节点的编号， <code>di</code> 表示第i个关节点的预测值和 groundtruth 的欧氏距离。 <code>d</code> 是一个人体的尺度因子，在不同的数据集里的计算方法不同。例如 MPII 中 数据集是以头部长度作为归一化参考，即 <strong>PCKh</strong>。</p>
<ul>
<li>oks (object keypoint similarity)</li>
</ul>
<p><font color=Red>oks 表示关键点的相似度，它和预测关键点和真实关键点之间的欧式距离有关，其范围值为 [0, 1]。当它们的欧式距离为 0 时，其 oks 相似度等于 1</font></p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509001908.png"></p>
 
<p> 其中：<code>i</code> 为关键点的编号，<code>di</code> 表示预测的关键点和 groundtruth 之间的欧式距离，<code>S</code> 是一个尺度因子，为人体检测框面积的平方根， <code>oi</code> 是一个归一化因子，和关键点标注的难易有关，是通过对所有样本的人工标注和真实值的统计标准差。 <code>vi</code> 表示当前关键点是否可见。</p>
<ul>
<li>AP(Average Precision)</li>
</ul>
<p><font color=Red>这个和目标检测里的 <code>AP</code> 概念是一样的，只不过度量方式 <code>iou</code> 替换成了 <code>oks</code>。如果 oks 大于阈值 T，则认为该关键点被成功检测到</font>。单人姿态估计和多人姿态估计的计算方式不同。对于单人姿态估计的AP，目标图片中只有一个人体，所以计算方式为：</p>
<p align="center">
    <img width="27%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509001945.png"></p>

<p>对于多人姿态估计而言，由于一张图像中有 <code>M</code> 个目标，假设总共预测出 <code>N</code> 个人体，那么groundtruth和预测值之间能构成一个 <code>MxN</code> 的矩阵，然后将每一行的最大值作为该目标的 oks，则：</p>
<p align="center">
    <img width="35%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509001952.png"></p>

<h2 id="2-1-过去和现在"><a href="#2-1-过去和现在" class="headerlink" title="2.1 过去和现在"></a>2.1 过去和现在</h2><p>在过去，传统方法一般是基于图结构和形变部件模型，设计 2D 人体部件检测器，使用图模型建立各部件的连通性，然后结合关键点之间的 pair-wise 关系来恢复人体的姿态。传统方法虽然拥有较高的时间效率，但是提取的都是人工设定的浅层特征（如 HOG，SIFT 等）。而在现在的深度学习时代，姿态估计的特征提取，分类，以及空间位置的建模都可以在一个网络中直接建模，不再需要独立的进行拆解，整个过程完全可以端到端进行。</p>
<h3 id="2-2-过去的思路"><a href="#2-2-过去的思路" class="headerlink" title="2.2 过去的思路"></a>2.2 过去的思路</h3><p>在 2014 年以前，很多论文讲的都是利用传统方法去解决单人姿态估计的问题。这些工作都是在深度学习爆发之前，我们是如何处理人体姿态估计这个问题。从算法角度来讲，这部分的工作主要是希望解决单人的人体姿态估计问题，也有部分工作已经开始尝试做 3D 的人体姿态估计。可以粗略的方法分成两类。</p>
<p>第一类是直接通过一个全局 feature，把姿态估计问题当成分类或者回归问题直接求解。但是这类方法的问题在于精度一般，并且可能比较适用于背景干净的场景。第二类是基于一个图模型，比如常用pictorial structure model。一般包含 unary term, 是指对单个 part 进行 feature 的表示，单个 part 的位置往往可以使用DPM (Deformable Part-based model) 来获得。同时需要考虑 pair-wise 关系来优化关键点之间的关联。</p>
<p>总结一下，在传统方法里面，需要关注的两个维度是： feature representation 以及关键点的空间位置关系。特征维度来讲，传统方法一般使用的 HOG, Shape Context, SIFT 等浅层特征。 空间位置关系的表示也有很多形式，上面的 Pictorial structure model 可能只是一种。</p>
<h3 id="2-3-现在的方法"><a href="#2-3-现在的方法" class="headerlink" title="2.3 现在的方法"></a>2.3 现在的方法</h3><p>自从 2012 年 AlexNet 开始，深度学习开始快速发展，从最早的图片分类问题，到后来的检测，分割问题。<font color=Red>第一次有人在 2014 年成功使用 CNN 来解决单人的姿态估计问题</font>。受限于当时的时代背景，整体网络结构比较简单并且同时也沿用了传统思路：首先是通过滑动窗口的方式，来对每个 patch 进行分类，找到相应的人体关键点。因为直接使用滑动窗口缺少了很多 context 信息，所以会有很多 FP 的出现。所以在 pipeline 中加了一个后处理的步骤，希望能抑制部分FP，具体的实现方式是类似一个空间位置的模型。从这个工作来看，有一定的传统姿态估计方法的惯性，改进的地方是把原来的传统的特征表示改成了深度学习的网络，同时把空间位置关系当成是后处理来做处理。总体性能在当时已经差不多跑过了传统的姿态估计方法。</p>
<p><font color=Red>2014 年的另外一个重要的进展是引入了 <code>MPII</code> 的数据集</font>。此前的大部分 paper 都是基于 FLIC 以及 LSP 来做评估的，但是在深度学习时代，数据量还是相对偏少（K 级别）。MPII 把数据量级提升到 W 级别，同时因为数据是互联网采集，同时是针对 activity 来做筛选的，所以无论从难度还是多样性角度来讲，都比原来的数据集有比较好的提升。</p>
<p>现在几乎所有的主流方法都是围绕着下面两大块进行的：改善监督信息和网络结构。</p>
<h2 id="3-改善监督信息"><a href="#3-改善监督信息" class="headerlink" title="3. 改善监督信息"></a>3. 改善监督信息</h2><p>根据真值标签 (Ground Truth) 的类型和监督训练的方式，单人姿态估计主要有 2 种思路：基于坐标回归和基于热图检测，它们各有优缺点。</p>
<h3 id="3-1-基于坐标回归（代表作：Deep-Pose"><a href="#3-1-基于坐标回归（代表作：Deep-Pose" class="headerlink" title="3.1 基于坐标回归（代表作：Deep Pose)"></a>3.1 基于坐标回归（代表作：Deep Pose)</h3><p>基于坐标回归的算法是将关节点的二维坐标 (<code>coordinate</code>) 作为 Ground Truth，训练网络直接回归得到每个关节点的坐标，这样的好处在于可以得到 sub-pixel 级别的精度，而且速度会比较快（不需要后处理）。例如在一些人脸关键点检测算法（如 mtcnn）中，会在最后一层使用全连接层直接回归出 landmark 的坐标。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509002136.png">
</p>

<p>在人体姿态估计领域中，这类方法的代表作是谷歌大佬提出的 <a href="https://github.com/mitmul/deeppose"><code>Deep Pose</code></a> 网络。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509002102.jpg"></p>

<blockquote>
<p>在上图中：<font color=Red>蓝色部分是卷积层，绿色部分是全连接层</font>。Deep Pose 算法主要是通过训练一个级联的姿态回归器。在第一个阶段先粗略地估计出部分的姿态轮廓，然后在下个阶段将通过已知关键点的位置不断去优化其他关键点的位置。每个 stage 都使用已经预测的关键点来 crop 出基于这个关键点的邻域子图像并用于后续的网络输入，从而得到一个更加精准的位置信息。</p>
</blockquote>
<p>但是值得注意的是：一方面，全连接层（<code>fully connected layer</code>）容易抹掉人体关键点在图像中的空间位置信息和 context 信息。如果缺乏 context 信息，会使得模型很难区分左右手，导致 FP 容易高。另一方面，人体姿态估计这个问题本身的自由度很大。直接 regression 的方式对自由度小的问题比如人脸 landmark 可能是比较适合的，但是这会对自由度较大的姿态估计问题整体的建模能力会比较弱。</p>
<blockquote>
<p>人体姿态估计的自由度较大的地方在于：例如，人的左手腕关节点既可以出现在人体的左边，也可以出现在人体的右边，因此 context 和空间位置信息就显得很重要。</p>
</blockquote>
<h3 id="3-2-基于热图检测（代表作：Simple-Baseline）"><a href="#3-2-基于热图检测（代表作：Simple-Baseline）" class="headerlink" title="3.2 基于热图检测（代表作：Simple Baseline）"></a>3.2 基于热图检测（代表作：Simple Baseline）</h3><p><code>Heatmap</code> 将每个骨骼节点的坐标分别都用一个概率图来表示，这个概率图的分辨率往往是原图的等比例缩放图（一般为 64x48），channel 的个数等于关键节点的数目。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509002216.jpg"></p>
    
<p>热图中的每个像素位置都会给出一个概率，表示该点属于对应类别关键点的概率，比较自然的是，距离关键点位置越近的像素点的概率越接近 1，而距离关键点越远的像素点的概率越接近 0，具体可以通过相应函数进行模拟，如 Gaussian 函数等。</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509002230.jpg"></p>

<p>微软亚洲研究院的 xiao bin 于 2018 年提出了一种基于热图检测的极其简单的单人姿态估计网络。由于它简单有效，所以作者称之为 <a href="https://github.com/microsoft/human-pose-estimation.pytorch">simple baseline</a>。该网络只是在 ResNet 后面添加一些反卷积层，甚至都没有 skip connection，这种结构可以说是从 deep 和 low 分辨率特征生成热图的最简单也是最熟悉的方法。</p>
<p align="center">
    <img width="38%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509002336.jpg"></p>
    
<p>最后加入 1×1 的卷积层，生成 k 个关键点的预测热图，与 ground truth 热图计算 MSE 损失。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">JointsMSELoss</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, use_target_weight</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(JointsMSELoss, self).__init__()</span><br><span class="line">        self.criterion = nn.MSELoss(size_average=<span class="literal">True</span>)</span><br><span class="line">        self.use_target_weight = use_target_weight</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, output, target, target_weight</span>):</span></span><br><span class="line">        batch_size = output.size(<span class="number">0</span>)</span><br><span class="line">        num_joints = output.size(<span class="number">1</span>)</span><br><span class="line">        heatmaps_pred = output.reshape((batch_size, num_joints, -<span class="number">1</span>)).split(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        heatmaps_gt = target.reshape((batch_size, num_joints, -<span class="number">1</span>)).split(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">        loss = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> idx <span class="keyword">in</span> <span class="built_in">range</span>(num_joints):</span><br><span class="line">            heatmap_pred = heatmaps_pred[idx].squeeze()</span><br><span class="line">            heatmap_gt = heatmaps_gt[idx].squeeze()</span><br><span class="line">            <span class="keyword">if</span> self.use_target_weight:</span><br><span class="line">                loss += <span class="number">0.5</span> * self.criterion(</span><br><span class="line">                    heatmap_pred.mul(target_weight[:, idx]),</span><br><span class="line">                    heatmap_gt.mul(target_weight[:, idx])</span><br><span class="line">                )</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                loss += <span class="number">0.5</span> * self.criterion(heatmap_pred, heatmap_gt)</span><br><span class="line">        <span class="keyword">return</span> loss / num_joints</span><br></pre></td></tr></table></figure>
<h2 id="4-改善网络结构"><a href="#4-改善网络结构" class="headerlink" title="4. 改善网络结构"></a>4. 改善网络结构</h2><p>后续 2D 人体姿态估计方法几乎都是围绕 heatmap 这种形式来做的：通过使用神经网络来获得更好的特征表示，同时把关键点的空间位置关系隐式地 encode 在 heatmap 中进行监督学习。随着基于热图检测的方法成为标准，往后越来越多的工作聚焦在了网络结构设计上。</p>
<h3 id="4-1-CPM（Convolutional-Pose-Machines）"><a href="#4-1-CPM（Convolutional-Pose-Machines）" class="headerlink" title="4.1 CPM（Convolutional Pose Machines）"></a>4.1 CPM（Convolutional Pose Machines）</h3><p>经典的卷积姿态机（Convolutional Pose Machines，CPM）是CMU Yaser Sheikh组的工作，后续非常有名的 openpose 也是他们的工作。CPM 在初始阶段 (stage 1) 只对输入图片进行卷积，输出所有关节点的 heatmap。在后面的每个阶段 中，CPM 首先设计了一个特征提取器 (FeatureExtractor) 将上一个阶段输出的 heatmap 和原始图像的 feature map 级联起来，然后将这种预处理过的融合 feature map 输入 本阶段的 FCN 进行处理，最终得到新的关节点 heatmap。 </p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509002418.jpg"></p>

<blockquote>
<p>CPM 由多个 stage 网络级联而成，每个 stage 设计一个小型网络，用于提取 feature。中间层的信息可以给后续层提供 context，后续 stage 可以认为是基于前面的 stage 去做 refinement。这个 refinement 过程需要感受野提供更多的 context 信息，因此感受野会越来越大。</p>
</blockquote>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509002502.jpg"></p>

<p>但是通过不断增加卷积层来改变感受野会给网络产生较大的训练负担，造成梯度消失等问题。为避免加大感受野带来的副作用，CPM 采用中继监督训练，将各个阶段产生的 heatmap 与 Ground Truth 产生的误差累加起来作为总误差进行迭代，同时将梯度从各个阶段网络的输 出层反向传播，避免梯度消失，最后得到各个阶段修正后的响应 feature map，即置信图 (belief map)。CPM 在测试时以最后一个阶段的响应图输出为准。</p>
<h3 id="4-2-Stacked-Hourglass-Network"><a href="#4-2-Stacked-Hourglass-Network" class="headerlink" title="4.2 Stacked Hourglass Network"></a>4.2 Stacked Hourglass Network</h3><p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509002540.png"></p>

<p>在 2016 年的 7 月份，Princeton 的 Deng Jia 组放出了另外一个非常棒的人体姿态估计工作，堆叠式沙漏网络（Stacked Hourglass Network）。它最大的特点就是，网络既简单优美又准确高效。从上图可以看出，网络由很多重复堆叠的 u-shape 模块（如下图所示）所组成。并且在每个 u-shape 模块的旁路都添加了残差模块（Residual Module）分支，它在网络的深层梯度传导和防止过拟合方面起到关键性作用。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509002615.png"></p>

<p>作者在整个网络结构中堆叠了许多 hourglass 模块，从而使得网络能够不断重复自底向上和自顶向下的过程。类似于 CPM 的多阶段学习过程，堆叠式沙漏结构 同样采用了“配套的”中继训练。但它是对每一个阶段得到的关节点 heatmap 立即根据 Ground Truth 进行重绘 (remap)，并得到当前的 belief map，而不是像 CPM 累 加所有阶段的总误差再进行迭代反馈。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509002654.jpg"></p>

<blockquote>
<p>Illustration of the intermediate supervision process. The network splits and produces a set of heatmaps (outlined in blue) where a loss can be applied. A 1x1 convolution remaps the heatmaps to match the number of channels of the intermediate features. These are added together along with the features from the preceding hourglass.</p>
</blockquote>
<h3 id="4-3-HRNet（High-Resolution-Network）"><a href="#4-3-HRNet（High-Resolution-Network）" class="headerlink" title="4.3 HRNet（High-Resolution Network）"></a>4.3 HRNet（High-Resolution Network）</h3><p>从2012年以来随着 AlexNet 横空出世，神经网络在计算机视觉领域成为主流的方法。2014年谷歌发明出了 GoogleNet，牛津大学发明了 VGGNet，2015 年微软发明了 ResNet，2016 年康奈尔大学和清华大学发明了 DenseNet，以上都是围绕分类任务而发明的网络结构。这些网络结构的一个共同的特征便是：逐步减小空间的大小，最终得到一个低分辨率的表征。低分辨率的表征在图像分类任务中是足够的，因为在图像分类里面，只需要给一个全局的标签，而不需要详细的空间信息，我们称之为空间粗粒表征的学习。</p>
<p>但是在其它任务中，比如检测，我们需要知道检测框的空间位置，比如分割，我们需要每个像素的标签，在人脸和人体的关键点的检测中，我们需要关键点的空间位置，这样一系列的任务实际上需要空间精度比较高的表征，我们称之为高分辨率表征。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509002725.jpg"></p>

<p>到了 2019 年， MSRA 的 wang jingdong 组出了一个很好的工作，提出了 spatial resolution 的重要性。他认为以前网络的套路都是 feature map 的分辨率一开始虽然很高，但是会慢慢降低，然后又慢慢升高。在这个过程中，先失去了空间精度，然后慢慢恢复，最终学到的特征空间精度较弱。</p>
<p><font color=Red>因此作者提出了一种新的网络结构：分成多个层级，但是始终保留着最精细的 spaital 那一层的信息，通过 fuse 从高分辨率到低分辨率的子网络输出，来获得更多的 context 以及语义层面信息。</font>它能够在整个过程中保持高分辨率的表示。以高分辨率子网络开始作为第一阶段，逐步增加高分辨率到低分辨率的子网络。以此内推形成更多阶段，并将多分辨率子网络并行连接。在整个过程中，通过在并行的多分辨率子网络上反复交换信息来进行多尺度的重复融合。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509002926.jpg"></p>

<blockquote>
<p>一直保持高分辨率的特征能够很好地保留空间位置信息，而逐步增加高分辨率到低分辨率的子网络是为了添加更多丰富的语义信息。<font color=Red>在低分辨率方面，它可以学习到很好的语义信息；在高分辨率里，它的空间精度非常强。在整个过程中，高中低分辨率不停地交互，使得高分辨率可以拿到低分辨率语义性比较强的表征，低分辨率可以拿到高分辨率的空间精度比较强的表征，不停地融合，最终取得更强的高分辨率表征。</font></p>
</blockquote>
<h2 id="5-多人姿态估计"><a href="#5-多人姿态估计" class="headerlink" title="5. 多人姿态估计"></a>5. 多人姿态估计</h2><p>通过单人体态估计的方法可以得到人体的2D关节点坐标，但是在一张多人图像中，模型在区别不同人体 的关节点，避免不同人体的关节点之间进行误连时，需 要额外的策略作为指导。为此，多人姿态估计的相关研究大致提供了两种思路: 自顶向下(Top-Down) 和自底向上(Bottom-Up)的。</p>
<h3 id="5-1-自底向上（Bottom-Up）"><a href="#5-1-自底向上（Bottom-Up）" class="headerlink" title="5.1 自底向上（Bottom-Up）"></a>5.1 自底向上（Bottom-Up）</h3><p>自底向上的思路为：首先用单人姿态估计的方法构建部件检测器将图片中所有的人体关节点全部检测出来，然后在第二个阶段对不同人体的关节点聚成一类并拼接在一起。这类的代表作为 Open Pose，它在 2016 年的 COCO 比赛中一举夺得第一名。 CMU 团队基于 CPM 为组件，先找到图片中每个 joint 的位置，然后提出部件亲和场（Part Affinity Field，PAF) 来做人体关键点的组装。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509002952.jpg"></p>

<p>PAF 的基本原理是在两个相邻关键点之间，建立一个有向场，比如左手腕，左手肘。我们把 CPM 找到的所有的左手腕以及左手肘拿出来建立一个二分图，边权就是基于 PAF 场来计算的。然后进行匹配，匹配成功就认为是同一个人的关节。依次类别，对所有相邻点做此匹配操作，最后就得到每个人的所有关键点。</p>
<h3 id="5-2-自顶向下（Top-Down）"><a href="#5-2-自顶向下（Top-Down）" class="headerlink" title="5.2 自顶向下（Top-Down）"></a>5.2 自顶向下（Top-Down）</h3><p>虽然 2016 年 bottom-up 是一个丰富时间点，但是从 2017 年开始，越来的工作开始围绕top-down 展开，一个直接的原因是 top-down 的效果往往更有潜力。top-down 相比bottom-up 效果好的原因可以认为有两点。首先是人的 recall 往往更好。因为 top-down 是先做人体检测，人体往往会比 part 更大，所以从检测角度来讲会更简单，相应找到的recall 也会更高。其次是关键点的定位精度会更准，这部分原因是基于 crop 的框，对空间信息有一定的 align，同时因为在做单人姿态估计的时候，可以获得一些中间层的 context 信息，这对于点的定位是很有帮助的。当然，top-down 往往会被认为速度比 bottom-up 会更慢（特别是人数较多的场景）。所以在很多要求实时速度，特别是手机端上的很多算法都是基于 openpose 来做修改的。不过这个也要例外，我们自己也有做手机端上的多人姿态估计，但是我们是基于 top-down 来做的，主要原因是人体检测器可以做的非常快。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li><a href="https://jishuin.proginn.com/p/763bfbd299d2">[1] 姿态估计：人体骨骼关键点检测综述（2016-2020）</a></li>
<li><a href="https://blog.csdn.net/ZXF_1991/article/details/104279387">[2] 人体姿态估计－评价指标（一）</a></li>
<li><a href="https://arxiv.org/abs/2006.01423">[3] Monocular Human Pose Estimation: A Survey of Deep Learning-based Methods</a></li>
<li><a href="https://arxiv.org/abs/1910.06278">[4] Distribution-Aware Coordinate Representation for Human Pose Estimation</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/85506259">[5] 人体姿态估计的过去，现在，未来</a></li>
<li><a href="https://arxiv.org/abs/1804.06208">[6] Simple Baselines for Human Pose Estimation and Tracking. ECCV 2018</a></li>
<li><a href="https://arxiv.org/pdf/1602.00134.pdf">[7] Convolutional Pose Machines. CVPR 2016</a></li>
<li><a href="https://arxiv.org/abs/1603.06937">[8] Stacked Hourglass Networks for Human Pose Estimation. ECCV 2016</a></li>
<li><a href="https://arxiv.org/abs/1902.09212">[9] Deep High-Resolution Representation Learning for Human Pose Estimation. CVPR 2019</a></li>
<li><a href="https://arxiv.org/abs/1812.08008">[10] OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields. CVPR 2017</a></li>
<li><a href="https://www.msra.cn/zh-cn/news/features/a-universal-architecture-for-visual-recognition">[11] 王井东：下一代视觉识别的通用网络结构是什么样的？</a></li>
<li><a href="https://www.msra.cn/zh-cn/news/features/cvpr-2019-hrnet">[12] 告别低分辨率网络，微软提出高分辨率深度神经网络HRNet</a></li>
</ul>
]]></content>
      <categories>
        <category>姿态估计</category>
      </categories>
      <tags>
        <tag>hourglass 网络</tag>
      </tags>
  </entry>
  <entry>
    <title>人脸识别之人脸矫正</title>
    <url>/2020/02/16/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E4%B9%8B%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3/</url>
    <content><![CDATA[<p>一般来说，使用 <code>mtcnn</code> 网络检测到人脸后，都需要进行矫正。而对于人脸矫正，最简单的可以通过使用仿射变换来实现。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/人脸识别之人脸矫正-20210509001447.jpg">
</p>

<span id="more"></span>

<p>思路：</p>
<ul>
<li>通过 mtcnn 模型检测到人脸的 5 个特征点：左眼，右眼，鼻子，左嘴角，右嘴角；</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">bounding_boxes = &#123;</span><br><span class="line">        <span class="string">&#x27;box&#x27;</span>: [<span class="built_in">int</span>(bounding_box[<span class="number">0</span>]), <span class="built_in">int</span>(bounding_box[<span class="number">1</span>]),</span><br><span class="line">                <span class="built_in">int</span>(bounding_box[<span class="number">2</span>]), <span class="built_in">int</span>(bounding_box[<span class="number">3</span>])],</span><br><span class="line">        <span class="string">&#x27;confidence&#x27;</span>: bounding_box[-<span class="number">1</span>],</span><br><span class="line">        <span class="string">&#x27;keypoints&#x27;</span>: &#123;</span><br><span class="line">            <span class="string">&#x27;left_eye&#x27;</span>: (<span class="built_in">int</span>(keypoints[<span class="number">0</span>]), <span class="built_in">int</span>(keypoints[<span class="number">5</span>])),</span><br><span class="line">            <span class="string">&#x27;right_eye&#x27;</span>: (<span class="built_in">int</span>(keypoints[<span class="number">1</span>]), <span class="built_in">int</span>(keypoints[<span class="number">6</span>])),</span><br><span class="line">            <span class="string">&#x27;nose&#x27;</span>: (<span class="built_in">int</span>(keypoints[<span class="number">2</span>]), <span class="built_in">int</span>(keypoints[<span class="number">7</span>])),</span><br><span class="line">            <span class="string">&#x27;mouth_left&#x27;</span>: (<span class="built_in">int</span>(keypoints[<span class="number">3</span>]), <span class="built_in">int</span>(keypoints[<span class="number">8</span>])),</span><br><span class="line">            <span class="string">&#x27;mouth_right&#x27;</span>: (<span class="built_in">int</span>(keypoints[<span class="number">4</span>]), <span class="built_in">int</span>(keypoints[<span class="number">9</span>])),</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">bounding_box = bounding_boxes[<span class="string">&#x27;box&#x27;</span>]</span><br><span class="line">keypoints = bounding_boxes[<span class="string">&#x27;keypoints&#x27;</span>]</span><br></pre></td></tr></table></figure>

<ul>
<li>计算双眼中心点的位置 <code>eye_center</code> 和双眼连线的倾斜角度 <code>angle</code>；</li>
<li>通过 <code>eye_center</code> 和 <code>angle</code> 得到仿射变换矩阵 <code>rot_matrix</code>；</li>
<li>将整张图片进行<a href="https://yunyang1994.github.io/posts/AffineTransformation/"><font color=red>仿射变换</font></a>得到 <code>align_image</code>；</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">align_face</span>(<span class="params">image, keypoints, scale=<span class="number">1.0</span></span>):</span></span><br><span class="line">    eye_center = (</span><br><span class="line">            (keypoints[<span class="string">&#x27;left_eye&#x27;</span>][<span class="number">0</span>] + keypoints[<span class="string">&#x27;right_eye&#x27;</span>][<span class="number">0</span>]) * <span class="number">0.5</span>,</span><br><span class="line">            (keypoints[<span class="string">&#x27;left_eye&#x27;</span>][<span class="number">1</span>] + keypoints[<span class="string">&#x27;right_eye&#x27;</span>][<span class="number">1</span>]) * <span class="number">0.5</span>,</span><br><span class="line">            )</span><br><span class="line">    dx = keypoints[<span class="string">&#x27;right_eye&#x27;</span>][<span class="number">0</span>] - keypoints[<span class="string">&#x27;left_eye&#x27;</span>][<span class="number">0</span>]</span><br><span class="line">    dy = keypoints[<span class="string">&#x27;right_eye&#x27;</span>][<span class="number">1</span>] - keypoints[<span class="string">&#x27;left_eye&#x27;</span>][<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    angle = cv2.fastAtan2(dy, dx)</span><br><span class="line">    rot_matrix = cv2.getRotationMatrix2D(eye_center, angle, scale=scale)</span><br><span class="line">    rot_image = cv2.warpAffine(image, rot_matrix, dsize=(image.shape[<span class="number">1</span>], image.shape[<span class="number">0</span>]))</span><br><span class="line">    <span class="keyword">return</span> rot_image</span><br><span class="line"></span><br><span class="line">align_image = align_face(image, keypoints)</span><br></pre></td></tr></table></figure>

<ul>
<li>根据从 <font color=red>原图检测的 2D 框</font>从 <code>align_image</code> 图片中抠出人脸并保存。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">xmin = bounding_box[<span class="number">0</span>]</span><br><span class="line">ymin = bounding_box[<span class="number">1</span>]</span><br><span class="line">xmax = bounding_box[<span class="number">2</span>]</span><br><span class="line">ymax = bounding_box[<span class="number">3</span>]</span><br><span class="line">crop_image = align_image[ymin:ymax, xmin:xmax, :]</span><br><span class="line">cv2.imwrite(<span class="string">&quot;align_face.jpg&quot;</span>, crop_image)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>人脸矫正</tag>
        <tag>仿射变换</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorFlow 的多卡 GPU 训练机制</title>
    <url>/2020/02/07/TensorFlow-%E7%9A%84%E5%A4%9A%E5%8D%A1-GPU-%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<p>武汉疫情还没过去，这几天窝在家里琢磨了下 TensorFlow 的多卡 GPU 分布式训练的机制。本文将使用流行的 MNIST 数据集上训练一个 MobileNetV2 模型，并利用 <code>tf.distribute.Strategy</code> 函数实现多卡 GPU 对训练方式。 详细代码见 <a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/blob/master/7-Utils/multi_gpu_train.py"><font color=Red>TensorFlow2.0-Example</font></a></p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/TensorFlow-的多卡-GPU-训练机制-20210509000745.jpg">
</p>

<span id="more"></span>

<h2 id="1-下载-MNIST-数据集"><a href="#1-下载-MNIST-数据集" class="headerlink" title="1. 下载 MNIST 数据集"></a>1. 下载 MNIST 数据集</h2><p>点击<a href="https://github.com/YunYang1994/yymnist/releases/download/v1.0/mnist.zip"><font color=Red>这里</font></a>可以下载到 mnist.zip，将它们解压得到以下目录结构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">├── test</span><br><span class="line">│   ├── 0</span><br><span class="line">│   ├── 1</span><br><span class="line">│   ├── 2</span><br><span class="line">│   ├── 3</span><br><span class="line">│   ├── 4</span><br><span class="line">│   ├── 5</span><br><span class="line">│   ├── 6</span><br><span class="line">│   ├── 7</span><br><span class="line">│   ├── 8</span><br><span class="line">│   └── 9</span><br><span class="line">└── train</span><br><span class="line">    ├── 0</span><br><span class="line">    ├── 1</span><br><span class="line">    ├── 2</span><br><span class="line">    ├── 3</span><br><span class="line">    ├── 4</span><br><span class="line">    ├── 5</span><br><span class="line">    ├── 6</span><br><span class="line">    ├── 7</span><br><span class="line">    ├── 8</span><br><span class="line">    └── 9</span><br><span class="line"></span><br><span class="line">22 directories, 0 files</span><br></pre></td></tr></table></figure>

<h2 id="2-创建一个分发变量和图的策略"><a href="#2-创建一个分发变量和图的策略" class="headerlink" title="2. 创建一个分发变量和图的策略"></a>2. 创建一个分发变量和图的策略</h2><p>接下来将会使用到 <code>tf.distribute.MirroredStrategy</code> ，它是如何运作的？</p>
<ul>
<li>所有变量和模型图都复制在副本上；</li>
<li>输入都均匀分布在副本中；</li>
<li>每个副本在收到输入后计算输入的损失和梯度；</li>
<li>通过求和，每一个副本上的梯度都能同步；</li>
<li>同步后，每个副本上的复制的变量都可以同样更新。</li>
</ul>
<p>你可以这样创建一个策略：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">strategy = tf.distribute.MirroredStrategy()</span><br></pre></td></tr></table></figure>
<p>或者指定使用特定的 GPU</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">strategy = tf.distribute.MirroredStrategy(devices=[<span class="string">&quot;/gpu:0&quot;</span>, <span class="string">&quot;/gpu:2&quot;</span>, <span class="string">&quot;/gpu:3&quot;</span>])</span><br></pre></td></tr></table></figure>

<h2 id="3-构建-MobileNetV2"><a href="#3-构建-MobileNetV2" class="headerlink" title="3. 构建 MobileNetV2"></a>3. 构建 MobileNetV2</h2><p>使用 <code>tf.keras.applications.mobilenet_v2.MobileNetV2</code> 创建一个模型。你也可以使用模型子类化 API 来完成这个。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Defining Model</span></span><br><span class="line"><span class="keyword">with</span> strategy.scope():</span><br><span class="line">    model = applications.mobilenet_v2.MobileNetV2(include_top=<span class="literal">False</span>, weights=<span class="literal">None</span>,</span><br><span class="line">                                                  input_shape=(IMG_SIZE,IMG_SIZE,<span class="number">3</span>))</span><br><span class="line">    x = tf.keras.layers.Input(shape=(IMG_SIZE,IMG_SIZE,<span class="number">3</span>))</span><br><span class="line">    y = model(x)</span><br><span class="line">    y = tf.keras.layers.AveragePooling2D()(y)</span><br><span class="line">    y = tf.keras.layers.Flatten()(y)</span><br><span class="line">    y = tf.keras.layers.Dense(<span class="number">512</span>,  activation=<span class="literal">None</span>)(y)</span><br><span class="line">    y = tf.keras.layers.Dense(<span class="number">10</span>,   activation=<span class="string">&#x27;softmax&#x27;</span>)(y)</span><br><span class="line">    model = tf.keras.models.Model(inputs=x, outputs=y)</span><br><span class="line">    optimizer = tf.keras.optimizers.Adam(<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>

<h2 id="4-定义损失函数"><a href="#4-定义损失函数" class="headerlink" title="4. 定义损失函数"></a>4. 定义损失函数</h2><p>在多卡 GPU 的训练方式中，<code>tf.distribute.Strategy</code> 是如何计算损失的呢？</p>
<ul>
<li>举一个例子，假设您有 4 个 GPU，批量大小为 64. 输入的一个批次分布在各个副本（ 4个 GPU）上，每个副本获得的输入大小为 16。</li>
<li>每个副本上的模型使用其各自的输入执行正向传递并计算损失, 使用 <code>tf.nn.compute_average_loss</code> 来获取每张 GPU 卡的训练损失，并通过 <code>global_batch_size</code> 返回缩放损失。（相当于<code>scale_loss = tf.reduce_sum(loss) * (1. / GLOBAL_BATCH_SIZE)</code>）</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Defining Loss and Metrics</span></span><br><span class="line"><span class="keyword">with</span> strategy.scope():</span><br><span class="line">    loss_object = tf.keras.losses.CategoricalCrossentropy(</span><br><span class="line">        reduction=tf.keras.losses.Reduction.NONE</span><br><span class="line">    )</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">compute_loss</span>(<span class="params">labels, predictions</span>):</span></span><br><span class="line">        per_example_loss = loss_object(labels, predictions)</span><br><span class="line">        <span class="keyword">return</span> tf.nn.compute_average_loss(per_example_loss, global_batch_size=BATCH_SIZE)</span><br><span class="line"></span><br><span class="line">    train_accuracy = tf.keras.metrics.CategoricalAccuracy(</span><br><span class="line">        name=<span class="string">&#x27;train_accuracy&#x27;</span></span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<h2 id="5-训练循环"><a href="#5-训练循环" class="headerlink" title="5. 训练循环"></a>5. 训练循环</h2><ul>
<li>我们使用 <code>for x in ...</code> 迭代构造 train_dataset ；</li>
<li>缩放损失是 <code>distributed_train_step</code> 的返回值。 这个值会在各个副本使用<code>tf.distribute.Strategy.reduce</code> 的时候合并，然后通过 <code>tf.distribute.Strategy.reduce</code> 叠加各个返回值来跨批次。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Defining Training Loops</span></span><br><span class="line"><span class="keyword">with</span> strategy.scope():</span><br><span class="line"><span class="meta">    @tf.function</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">distributed_train_step</span>(<span class="params">dataset_inputs</span>):</span></span><br><span class="line">        per_replica_losses = strategy.experimental_run_v2(train_step,</span><br><span class="line">                                                          args=(dataset_inputs,))</span><br><span class="line">        <span class="keyword">return</span> strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,</span><br><span class="line">                               axis=<span class="literal">None</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">        batchs_per_epoch = <span class="built_in">len</span>(train_generator)</span><br><span class="line">        train_dataset    = <span class="built_in">iter</span>(train_generator)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tqdm(total=batchs_per_epoch,</span><br><span class="line">                  desc=<span class="string">&quot;Epoch %2d/%2d&quot;</span> %(epoch+<span class="number">1</span>, EPOCHS)) <span class="keyword">as</span> pbar:</span><br><span class="line">            <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(batchs_per_epoch):</span><br><span class="line">                batch_loss = distributed_train_step(<span class="built_in">next</span>(train_dataset))</span><br><span class="line">                batch_acc  = train_accuracy.result()</span><br><span class="line">                pbar.set_postfix(&#123;<span class="string">&#x27;loss&#x27;</span> : <span class="string">&#x27;%.4f&#x27;</span> %batch_loss,</span><br><span class="line">                                  <span class="string">&#x27;accuracy&#x27;</span> : <span class="string">&#x27;%.6f&#x27;</span> %batch_acc&#125;)</span><br><span class="line">                train_accuracy.reset_states()</span><br><span class="line">                pbar.update(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>多卡GPU训练</tag>
      </tags>
  </entry>
  <entry>
    <title>说说图像的仿射变换</title>
    <url>/2020/01/22/%E8%AF%B4%E8%AF%B4%E5%9B%BE%E5%83%8F%E7%9A%84%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2/</url>
    <content><![CDATA[<p>仿射变换（<strong>Affine Transformation</strong>）是图像处理中很常见的操作，它在数学上可以表述为乘以一个矩阵 (线性变换) 接着再加上一个向量 (平移)。</p>
<p align="center">
    <img width="25%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/说说图像的仿射变换-20210509001001.jpg">
</p>

<p>其中：</p>
<p align="center">
    <img width="35%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/说说图像的仿射变换-20210509001008.jpg">
</p>

<span id="more"></span>

<h2 id="1-更紧凑的表示"><a href="#1-更紧凑的表示" class="headerlink" title="1. 更紧凑的表示"></a>1. 更紧凑的表示</h2><p>在学术上，更习惯用一个 2x3 的 M 矩阵来表示这层关系，因此得到:</p>
<p align="center">
    <img width="18%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/说说图像的仿射变换-20210509001013.jpg">
</p>

<p>其中：</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/说说图像的仿射变换-20210509001019.jpg">
</p>


<h2 id="2-如何求-M-？"><a href="#2-如何求-M-？" class="headerlink" title="2. 如何求 M ？"></a>2. 如何求 M ？</h2><p>如果用线性方程表示它们之间的转换关系，便得到：</p>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/说说图像的仿射变换-20210509001023.jpg">
</p>


<p>方程中有 6 个未知的参数，如果我们需要求解它们，则至少需要 6 个方程。由于每个像素点都包含了 2 个方程，因此只需要 3 个像素点。好在 OpenCV 提供了函数 <font color=Red><code>cv2.getAffineTransform</code></font>来根据变换前后 3 个点的对应关系来自动求解 M，例如对于图片</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/说说图像的仿射变换-20210509001031.jpg">
</p>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">image = cv2.imread(<span class="string">&quot;./dog.jpg&quot;</span>)</span><br><span class="line">h, w = image.shape[:<span class="number">2</span>]</span><br></pre></td></tr></table></figure>

<p>我们选取图片的三个顶点进行仿射变换，它们分别是左上角：[0, 0]，左下角：[0, h-1]，右上角：[w-1, 0]。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">src_points = np.float32([[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">0</span>, h-<span class="number">1</span>], [w-<span class="number">1</span>, <span class="number">0</span>]]) </span><br><span class="line">dst_points = np.float32([[<span class="number">50</span>, <span class="number">50</span>], [<span class="number">200</span>, h-<span class="number">100</span>], [w-<span class="number">100</span>, <span class="number">200</span>]]) </span><br><span class="line">matAffine = cv2.getAffineTransform(src_points, dst_points)</span><br></pre></td></tr></table></figure>

<p>变量<code>matAffine</code>就是仿射变换矩阵 <code>M</code>，如果将它打印出来：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">array([[9.38086304e-01, 4.14937759e-02, 5.00000000e+01],</span><br><span class="line">       [3.12695435e-02, 9.17842324e-01, 5.00000000e+01]])</span><br></pre></td></tr></table></figure>

<h2 id="3-仿射变换"><a href="#3-仿射变换" class="headerlink" title="3. 仿射变换"></a>3. 仿射变换</h2><p>现在可以将刚才求出的仿射变换应用至源图像，使用的是 <code>cv2.warpAffine</code> 函数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">affine_result = cv2.warpAffine(image, matAffine, (w,h)) </span><br><span class="line">cv2.imwrite(<span class="string">&quot;affine_result.jpg&quot;</span>, affine_result)</span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/说说图像的仿射变换-20210509001034.jpg">
</p>





]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>仿射变换</tag>
      </tags>
  </entry>
  <entry>
    <title>能不能用梯度下降法求解平方根 ？</title>
    <url>/2020/01/21/%E8%83%BD%E4%B8%8D%E8%83%BD%E7%94%A8%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95%E6%B1%82%E8%A7%A3%E5%B9%B3%E6%96%B9%E6%A0%B9/</url>
    <content><![CDATA[<p>2020 年春节将至，大部分同事已经回家。回顾下自己的 2019，似乎收获颇丰：不仅顺利毕业，还找了份谋生的工作。这期间看了很多复杂的算法，有监督 or 无监督，目标检测 or 深度估计。而人一旦徜徉在其中，就会渐渐忘记一些基础的东西。是时候回顾一下梯度下降法了….</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/能不能用梯度下降法求解平方根-20210509014415.png">
</p>

<p>问题：请尝试使用梯度下降法求解 <code>sqrt&#123;2020&#125;</code> 的值，并精确到小数点后 4 位。</p>
<span id="more"></span>

<p>思路：该问题等价于求函数 <code>f(x) = x^&#123;2&#125; - 2020</code> 的根，也就等价于求 <code>g(x) = (x^&#123;2&#125; - 2020)^2</code> 的最小值。所以，我们可以建立损失函数：</p>
<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/能不能用梯度下降法求解平方根-20210509014608.png">
</p>

<table><tr><td bgcolor= LightSalmon><strong>梯度下降法:

<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/能不能用梯度下降法求解平方根-20210509014535.png">
</p>

<p></strong></td></tr></table></p>
<p>其中 <code>a</code> 为学习率，整个过程的代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">epochs = <span class="number">100</span></span><br><span class="line">lr = <span class="number">1e-5</span></span><br><span class="line">x  = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">grad = <span class="keyword">lambda</span> x: <span class="number">4</span> * x * (np.power(x, <span class="number">2</span>) - <span class="number">2020</span>)</span><br><span class="line">loss = <span class="keyword">lambda</span> x: (np.power(x, <span class="number">2</span>) - <span class="number">2020</span>)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(epochs):</span><br><span class="line">    x = x - lr * grad(x)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=&gt; epoch %2d, x=%.4f, loss = %.4f&quot;</span> %(epoch, x, loss(x)))</span><br></pre></td></tr></table></figure>

<p><strong><font color=Red>在整个过程中，我们只需要不断利用梯度下降法更新参数就可以了</font></strong>。最后训练损失曲线逐渐下降至 0， 此时得到的 $x$ 已经收敛至 44.9444，满足要求。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/能不能用梯度下降法求解平方根-20210509014506.png">
</p>

<p>但事情并不总是一帆风顺，我也尝试了一些失败的案例：</p>
<ul>
<li><p>学习率过大的情况，当 <code>x=10</code> 而且 <code>lr=1e-3</code> 时</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">=&gt; epoch  0, x=86.8000, loss = 30406842.7776</span><br><span class="line">=&gt; epoch  1, x=-1827.7441, loss = 11146440911634.0312</span><br><span class="line">...</span><br><span class="line">=&gt; epoch 99, x=nan, loss = nan</span><br></pre></td></tr></table></figure></li>
<li><p>x 的初始值过大的情况，当 <code>x=2020</code> 而且 <code>lr=1e-5</code> 时</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">=&gt; epoch  0, x=-327513.1040, loss = 11505744027749453922304.0000</span><br><span class="line">=&gt; epoch  1, x=1405225186080.3201, loss = 3899273520282849001736422898828492926803876249600.0000</span><br><span class="line">...</span><br><span class="line">=&gt; epoch 99, x=nan, loss = nan</span><br></pre></td></tr></table></figure></li>
</ul>
<p>希望能给大家调参带来一些启示。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>梯度下降</tag>
      </tags>
  </entry>
  <entry>
    <title>手写双目立体匹配 SGM 算法（下)</title>
    <url>/2020/01/20/%E6%89%8B%E5%86%99%E5%8F%8C%E7%9B%AE%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D-SGM-%E7%AE%97%E6%B3%95-%E4%B8%8B/</url>
    <content><![CDATA[<p>上节的内容主要对 SGM 算法的匹配代价体 (Cost Volume) 进行了详细介绍，发现如果只寻找逐个像素匹配代价的最优解会使得视差图对噪声特别敏感。因此在能量方程中考虑使用该点像素的邻域视差数据来构造惩罚函数以增加平滑性约束, 这个求解过程也称为<strong>代价聚合 (Cost Aggregation) </strong>的过程。 </p>
<h2 id="1-能量方程"><a href="#1-能量方程" class="headerlink" title="1. 能量方程"></a>1. 能量方程</h2><p>SGM 算法建立了能量方程，并引入了视差约束条件，以对此进行优化：</p>
<p align="center">
    <img width="80%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/手写双目立体匹配-SGM-算法-上-20210509000059.jpg">
</p>

<span id="more"></span>

<p>等式右边第一项表示像素点 <code>p</code> 在视差范围内所以匹配代价之和; 第二项和第三项是指当前像素 <code>p</code> 和其邻域内所有像素 <code>q</code> 之间的平滑性约束，增加了惩罚因子 <code>P1</code> 和 <code>P2</code>: 若 <code>p</code> 和 <code>q</code> 的视差的差值等于 1，则惩罚因子 <code>P1</code>，若差值大于 1，则惩罚因子为 <code>P2</code>。 </p>
<p>为了高效地求解它，SGM 提出一种路径代价聚合的思路，即将像素所有视差下的匹配代价进行像素周围所有路径上的一维聚合得到路径下的路径代价值，然后将所有路径代价值相加得到该像素聚合后的匹配代价值。</p>
<h2 id="2-路径代价"><a href="#2-路径代价" class="headerlink" title="2. 路径代价"></a>2. 路径代价</h2><p>设 <code>L_&#123;r&#125;</code> 表示穿过 <code>r</code> 方向的扫描路径代价，其计算方式如下所示：</p>
<p align="center">
    <img width="80%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/手写双目立体匹配-SGM-算法-上-20210509000240.jpg">
</p>

<p>等号右边第一项表示像素点 <code>p</code> 的初始匹配代价；第二项表示 <code>p</code> 的前一个像素点 <code>p − r</code> 的最小匹配代价：若和 <code>p</code> 的视差差值为 0，无需加任何惩罚因子，差值为 1，加惩罚因子 <code>P1</code> ，若差值大于 1，则惩罚因子为 <code>P2</code>；第三项表示前一个像素点 <code>p − r</code> 沿 <code>r</code> 路径上的最小匹配代价，加入该项的目的是抑制 <code>L_&#123;r&#125;( p, d )</code> 的数值过大，并不会影响视差空间。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_path_cost</span>(<span class="params"><span class="built_in">slice</span>, offset</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    part of the aggregation step, finds the minimum costs in a D x M slice (where M = the number of pixels in the</span></span><br><span class="line"><span class="string">    given direction)</span></span><br><span class="line"><span class="string">    :param slice: M x D array from the cost volume.</span></span><br><span class="line"><span class="string">    :param offset: ignore the pixels on the border.</span></span><br><span class="line"><span class="string">    :return: M x D array of the minimum costs for a given slice in a given direction.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    P1 = <span class="number">5</span></span><br><span class="line">    P2 = <span class="number">70</span></span><br><span class="line"></span><br><span class="line">    slice_dim, disparity_dim = <span class="built_in">slice</span>.shape</span><br><span class="line">    disparities = [d <span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(disparity_dim)] * disparity_dim</span><br><span class="line">    disparities = np.array(disparities).reshape(disparity_dim, disparity_dim)</span><br><span class="line">    penalties = np.zeros(shape=(disparity_dim, disparity_dim), dtype=np.uint32)</span><br><span class="line"></span><br><span class="line">    penalties[np.<span class="built_in">abs</span>(disparities - disparities.T) == <span class="number">1</span>] = P1</span><br><span class="line">    penalties[np.<span class="built_in">abs</span>(disparities - disparities.T)  &gt; <span class="number">1</span>] = P2</span><br><span class="line"></span><br><span class="line">    minimum_cost_path = np.zeros(shape=(other_dim, disparity_dim), dtype=np.uint32)</span><br><span class="line">    minimum_cost_path[offset - <span class="number">1</span>, :] = <span class="built_in">slice</span>[offset - <span class="number">1</span>, :]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(offset, other_dim):</span><br><span class="line">        previous_cost = minimum_cost_path[i - <span class="number">1</span>, :]</span><br><span class="line">        current_cost = <span class="built_in">slice</span>[i, :]</span><br><span class="line">        costs = np.repeat(previous_cost, repeats=disparity_dim, axis=<span class="number">0</span>).reshape(disparity_dim, disparity_dim)</span><br><span class="line">        costs = np.amin(costs + penalties, axis=<span class="number">0</span>)</span><br><span class="line">        minimum_cost_path[i, :] = current_cost + costs - np.amin(previous_cost)</span><br><span class="line">    <span class="keyword">return</span> minimum_cost_path</span><br></pre></td></tr></table></figure>

<h2 id="3-代价聚合"><a href="#3-代价聚合" class="headerlink" title="3. 代价聚合"></a>3. 代价聚合</h2><h3 id="3-1-单路聚合"><a href="#3-1-单路聚合" class="headerlink" title="3.1 单路聚合"></a>3.1 单路聚合</h3><p>如果我们只考虑单路扫描会是什么样的结果呢？假设代价聚合路线为从上至下，即 south 方向（2 号路线）。如下图所示，那么</p>
<p align="center">
    <img width="25%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/手写双目立体匹配-SGM-算法-上-20210509000326.png">
</p>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">main_aggregation   = np.zeros(shape=(image_h, image_w, max_disparity), dtype=np.uint32)</span><br><span class="line">aggregation_volume = np.zeros(shape=(image_h, image_w, max_disparity, <span class="number">1</span>), dtype=np.uint32)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, image_w):</span><br><span class="line">    south = cost_volume[<span class="number">0</span>:image_h, x, :]</span><br><span class="line">    main_aggregation[:, x, :] = get_path_cost(south, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">aggregation_volume[:, :, :, <span class="number">0</span>] = main_aggregation</span><br></pre></td></tr></table></figure>

<p>便得到了<strong>代价聚合体（aggregation_volume）</strong>进行视差计算，找到该路径下的聚合最小匹配代价值：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">select_disparity</span>(<span class="params">aggregation_volume</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    last step of the sgm algorithm, corresponding to equation 14 followed by winner-takes-all approach.</span></span><br><span class="line"><span class="string">    :param aggregation_volume: H x W x D x N array of matching cost for all defined directions.</span></span><br><span class="line"><span class="string">    :return: disparity image.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    volume = np.<span class="built_in">sum</span>(aggregation_volume, axis=<span class="number">3</span>)</span><br><span class="line">    disparity_map = np.argmin(volume, axis=<span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> disparity_map</span><br></pre></td></tr></table></figure>
<p>最后通过最小化该路径在一维聚合下的匹配代价，得到了视差图如下图所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">disparity_map = select_disparity(aggregation_volume)</span><br><span class="line">disparity_map = normalize(disparity_map)</span><br><span class="line">cv2.imwrite(<span class="string">&quot;scan_south_disp.png&quot;</span>, disparity_map)</span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/手写双目立体匹配-SGM-算法-上-20210509000358.png">
</p>

<h3 id="3-2-多路聚合"><a href="#3-2-多路聚合" class="headerlink" title="3.2 多路聚合"></a>3.2 多路聚合</h3><p>从单路扫描的结果可以看出，一维扫描线优化仅仅只受一个方向约束，容易造成“条纹效应”，所以在 SGM 算法中，聚合了多个扫描路径上的匹配代价。</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/手写双目立体匹配-SGM-算法-上-20210509000416.png">
</p>

<p>一共有八个方向：south 和 north，east 和 west，south_east 和 north_west， south_west 和 north_east。刚刚实现了 south 方向单路扫描聚合代价的最优求解，而其他路扫描聚合代价的过程和它是类似的。限于篇幅，在这里就不补充了，最后得到的视差图如下所示：</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/手写双目立体匹配-SGM-算法-上-20210509000431.png">
</p>


]]></content>
      <categories>
        <category>立体视觉</category>
      </categories>
      <tags>
        <tag>视差估计</tag>
      </tags>
  </entry>
  <entry>
    <title>手写双目立体匹配 SGM 算法（上)</title>
    <url>/2020/01/17/%E6%89%8B%E5%86%99%E5%8F%8C%E7%9B%AE%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D-SGM-%E7%AE%97%E6%B3%95-%E4%B8%8A/</url>
    <content><![CDATA[<p><strong>SGM（Semi-Global Matching）</strong>是一个基于双目视觉的半全局立体匹配算法，专门用于计算图像的视差。在 SGM 算法中，匹配代价计算是双目立体匹配的第一步，本文将使用 <strong>Census Transform</strong> 方法对此进行介绍。</p>
<h2 id="1-读取图片"><a href="#1-读取图片" class="headerlink" title="1. 读取图片"></a>1. 读取图片</h2><p>首先使用 OpenCV 将左图和右图读取进来，并需要将它们转成单通道的灰度图输出。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">left_image  = cv2.imread(<span class="string">&quot;./left.png&quot;</span>,  <span class="number">0</span>)</span><br><span class="line">right_image = cv2.imread(<span class="string">&quot;./right.png&quot;</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/手写双目立体匹配-SGM-算法-上-20210508235656.jpg">
</p>

<span id="more"></span>

<blockquote>
<p>left.png 和 right.png 可以从<font color=Red><a href="https://github.com/YunYang1994/YunYang1994.github.io/tree/master/images/SGM">这里</a></font>进行下载。</p>
</blockquote>
<h2 id="2-高斯平滑"><a href="#2-高斯平滑" class="headerlink" title="2. 高斯平滑"></a>2. 高斯平滑</h2><p>为了减小双目图片的噪声和细节的层次感，有必要使用高斯平滑算法对它们进行预处理。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">left_image  = cv2.GaussianBlur(left_image,  (<span class="number">3</span>,<span class="number">3</span>), <span class="number">0</span>, <span class="number">0</span>)</span><br><span class="line">right_image = cv2.GaussianBlur(right_image, (<span class="number">3</span>,<span class="number">3</span>), <span class="number">0</span>, <span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<h2 id="3-Census-变换"><a href="#3-Census-变换" class="headerlink" title="3. Census 变换"></a>3. Census 变换</h2><p>最早的匹配测度算法使用的是互信息法：对于两幅配准好的影像来说，它们的联合熵是很小的，因为其中一张影像可以通过另外一张影像预测，这表示两者之间的相关性最大，从而互信息也最大。但是它的数学原理非常复杂，且计算需要迭代，计算效率不高。在实际应用中，有一种更简单高效的方法叫 Census 变换更容易收到青睐（OpenCV 里用的就是这种方法）。</p>
<p>Census 变换的基本原理：在图像区域定义一个矩形窗口，用这个矩形窗口遍历整幅图像。选取中心像素作为参考像素，将矩形窗口中每个像素的灰度值与参考像素的灰度值进行比较，灰度值小于参考值的像素标记为 0，大于或等于参考值的像素标记为 1，最后再将它们按位连接，得到变换后的结果，变换后的结果是由 0 和 1 组成的二进制码流。<strong>Census 变换的实质是将邻域像素灰度值相对于中心像素灰度值的差异编码成二进制码流。</strong></p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/手写双目立体匹配-SGM-算法-上-20210508235752.png">
</p>

<p>我们不妨首先定义矩形窗口的大小为 7x7，由于不会对图像边界进行填充，因此计算图像的补偿尺寸：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">image_h, image_w = left_image.shape[:<span class="number">2</span>]      <span class="comment"># 获取图片尺寸</span></span><br><span class="line">census_ksize = <span class="number">7</span></span><br><span class="line">x_offset = y_offset = census_ksize // <span class="number">2</span>      <span class="comment"># 补偿尺寸 = 3</span></span><br></pre></td></tr></table></figure>
<p>计算好这些必要的参数后，根据 Census 的变换原理可以获得它们的二进制编码，并将二进制编码存储为十进制数字。整个过程如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">CensusTransform</span>(<span class="params">image</span>):</span></span><br><span class="line">    <span class="keyword">global</span> image_h, image_w, census_ksize, x_offset, y_offset</span><br><span class="line">    census  = np.zeros(shape=(image_h, image_w), dtype=np.uint64)</span><br><span class="line">    <span class="keyword">for</span> y <span class="keyword">in</span> <span class="built_in">range</span>(y_offset, image_h-y_offset):</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(x_offset, image_w-x_offset):</span><br><span class="line">            center_pixel = image[y, x]</span><br><span class="line">            reference = np.full(shape=(census_ksize, census_ksize), fill_value=center_pixel, dtype=np.int64)</span><br><span class="line">            <span class="comment"># 定义二进制编码流</span></span><br><span class="line">            binary_pattern = []</span><br><span class="line">            <span class="comment"># 定义矩形窗口</span></span><br><span class="line">            window_image = image[(y - y_offset):(y + y_offset + <span class="number">1</span>), (x - x_offset):(x + x_offset + <span class="number">1</span>)]</span><br><span class="line">            <span class="comment"># 比较矩形窗口其他像素和中心像素的大小</span></span><br><span class="line">            comparison = window_image - reference</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(comparison.shape[<span class="number">0</span>]):</span><br><span class="line">                <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(comparison.shape[<span class="number">1</span>]):</span><br><span class="line">                    <span class="keyword">if</span> (i, j) != (y_offset, x_offset):</span><br><span class="line">                        <span class="comment"># 如果比中心像素小则编码为 1， 否则为 0</span></span><br><span class="line">                        <span class="keyword">if</span> comparison[j, i] &lt; <span class="number">0</span>:</span><br><span class="line">                            bit = <span class="number">1</span></span><br><span class="line">                        <span class="keyword">else</span>:</span><br><span class="line">                            bit = <span class="number">0</span></span><br><span class="line">                        binary_pattern.append(<span class="built_in">str</span>(bit))</span><br><span class="line"></span><br><span class="line">            binary_pattern = <span class="string">&quot;&quot;</span>.join(binary_pattern)</span><br><span class="line">            <span class="comment"># 将二进制编码存储为十进制数字</span></span><br><span class="line">            decimal_number = <span class="built_in">int</span>(binary_pattern, base=<span class="number">2</span>)</span><br><span class="line">            census[y, x] = decimal_number</span><br><span class="line">    <span class="keyword">return</span> census</span><br></pre></td></tr></table></figure>

<p>现在利用 CensusTransform 函数对左右图进行变换得到它们的 census 特征</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">left_census  = CensusTransform(left_image)</span><br><span class="line">right_census = CensusTransform(right_image)</span><br></pre></td></tr></table></figure>

<p>我们可以对左图的 Census 特征进行可视化，得到下图所示。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">cv2.imwrite(<span class="string">&quot;left_census.png&quot;</span>, left_census.astype(np.uint8))</span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/手写双目立体匹配-SGM-算法-上-20210508235826.png">
</p>

<h2 id="4-Cost-Volume"><a href="#4-Cost-Volume" class="headerlink" title="4. Cost Volume"></a>4. Cost Volume</h2><p>经过census变换后的图像可以使用汉明距离来计算左右两个匹配点之间相似度，这里并没有使用它们的灰度值，而是它们的 census 序列。这是因为单个像素点的灰度差异进行比较没有多大意义，而用该像素点领域范围内的纹理特征（census 序列）进行比较更具有代表性。</p>
<h3 id="4-1-汉明距离"><a href="#4-1-汉明距离" class="headerlink" title="4.1 汉明距离"></a>4.1 汉明距离</h3><p>两个 census 序列之间的相似度比较使用的是 Hamming 距离，它的度量方式为：<strong>两个字符串对应位置的不同字符的个数</strong>，它本身是一个异或问题，可以使用 <code>numpy.bitwise_xor</code> 进行求解。</p>
<table><tr><td bgcolor=Bisque>异或（xor）问题：如果 a、b 两个值不相同，则异或结果为 1。如果 a、b 两个值相同，异或结果为 0。</td></tr></table>

<p>Examples：数字 13 的二进制编码为 <code>00001101</code>， 17 则为 <code>00010001</code>，那么它们之间的 Hamming 距离为：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>np.bitwise_xor(<span class="number">13</span>, <span class="number">17</span>)</span><br><span class="line"><span class="number">28</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>xor = np.binary_repr(<span class="number">28</span>)</span><br><span class="line"><span class="string">&#x27;11100&#x27;</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>xor.count(<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line"><span class="number">3</span></span><br></pre></td></tr></table></figure>

<blockquote>
<p>13 和 17 的二进制编码有 3 个字符不同，所以它们的 Hamming 距离为 3。综上来说，Hamming 距离的计算代码如下：</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">HanMingDistance</span>(<span class="params">a, b</span>):</span></span><br><span class="line">    xor = np.int64(np.bitwise_xor(a, b))</span><br><span class="line">    xor = np.binary_repr(xor)</span><br><span class="line">    distance = xor.count(<span class="string">&#x27;1&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> distance</span><br></pre></td></tr></table></figure>

<h3 id="4-2-代价计算"><a href="#4-2-代价计算" class="headerlink" title="4.2 代价计算"></a>4.2 代价计算</h3><p>在极线约束下，我们会对右图从左至右进行扫描: 在右图 u 的位置得到该像素的 census 序列，然后与左图 u+d 位置处进行比较。由于我们事先不知道该处的视差到底有多大，因此我们会假设一个最大视差值 <code>max_disparity</code>，并计算 <code>0, 1, 2, ..., max_disparity</code> 处所有的 Hamming 距离。这个过程称为代价计算，如下图所示：</p>
<p><img src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/%E6%89%8B%E5%86%99%E5%8F%8C%E7%9B%AE%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D-SGM-%E7%AE%97%E6%B3%95-%E4%B8%8A-20210508235905.jpg" alt="image"></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">max_disparity = <span class="number">64</span></span><br><span class="line">cost_volume = np.zeros(shape=(image_h, image_w, max_disparity), dtype=np.uint32)</span><br><span class="line"><span class="keyword">for</span> d <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, max_disparity):</span><br><span class="line">    shift_census = np.zeros(shape=(image_h, image_w), dtype=np.int64)</span><br><span class="line">    shift_census[:, x_offset:(image_w - x_offset - d)] = left_census[:, (x_offset + d):(image_w - x_offset)]</span><br><span class="line">    shift_census[:, (image_w - x_offset - d):(image_w - x_offset)] = \</span><br><span class="line">            left_census[:, (image_w - x_offset - max_disparity):(image_w - x_offset - max_disparity + d)]</span><br><span class="line"></span><br><span class="line">    f = np.frompyfunc(HanMingDistance, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">    distance = f(shift_census, right_census)</span><br><span class="line">    cost_volume[:, :, d] = distance</span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="35%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/手写双目立体匹配-SGM-算法-上-20210508235937.png">
</p>

<p>既然现在已经计算出了每个像素在不同视差 d 时的汉明距离，那么其最小值对应的视差理应最接近该像素的真实视差，从而我们可以得到它的视差图并将其进行归一化：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize</span>(<span class="params">disparity_map, max_disparity=<span class="number">64</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    transforms values from the range (0, 64) to (0, 255).</span></span><br><span class="line"><span class="string">    :param volume: n dimension array to normalize.</span></span><br><span class="line"><span class="string">    :param max_disparity: maximuim value of disparity</span></span><br><span class="line"><span class="string">    :return: normalized array.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">255.0</span> * disparity_map / max_disparity</span><br><span class="line">    </span><br><span class="line">disp = np.argmin(cost_volume, -<span class="number">1</span>).astype(np.uint8)</span><br><span class="line">disp = normalize(disp)</span><br><span class="line">cv2.imwrite(<span class="string">&quot;cost_volume_disp.png&quot;</span>, disp)</span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/手写双目立体匹配-SGM-算法-上-20210509000006.png">
</p>

<p>我们可以发现视差图中出现了很多椒盐噪声，因此可以考虑使用中值滤波算法进行去燥，得到下图：</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/手写双目立体匹配-SGM-算法-上-20210509000032.png">
</p>

<p>图中的一些连续平面区域依然出现了很多噪声，而且对于视差不连续的区域其效果特别差。因此我们还需要在此基础上加入一些平滑处理，并构造出了一个能量方程。从而使得立体匹配问题可以转换成寻找最优视差图 <code>D</code>，让能量方程 <code>E(D)</code> 取得最小值。</p>
<p align="center">
    <img width="80%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/手写双目立体匹配-SGM-算法-上-20210509000059.jpg">
</p>

<p>该能量方程由两部分组成：等式右边第一项表示像素点 <code>p</code> 在视差范围内所以匹配代价之和; 第二项和第三项是指当前像素 <code>p</code> 和其邻域内所有像素 <code>q</code> 之间的平滑性约束, 它是 SGM 算法的核心，将在下节对此进行讲述。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li>[1] Heiko Hirschmuller. <a href="https://core.ac.uk/download/pdf/11134866.pdf">stereo Processing by Semi-Global Matching and Mutual Information</a>. CVPR 2005</li>
<li>[2] <a href="http://lunokhod.org/?p=1356">LUNOKHOD SGM Blog Post</a></li>
</ul>
]]></content>
      <categories>
        <category>立体视觉</category>
      </categories>
      <tags>
        <tag>视差估计</tag>
        <tag>立体匹配</tag>
        <tag>汉明距离</tag>
      </tags>
  </entry>
  <entry>
    <title>双目测距和三维重建</title>
    <url>/2019/12/29/%E5%8F%8C%E7%9B%AE%E6%B5%8B%E8%B7%9D%E5%92%8C%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/</url>
    <content><![CDATA[<p>双目相机通过同步采集左右相机的图像，计算图像间视差，来估计每一个像素的深度。一旦我们获取了物体在图像上的每个像素深度，我们便能重构出一些它的三维信息。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/双目测距和三维重建-20210508235103.gif">
</p>

<p>双目相机一般由左眼和右眼两个水平放置的相机组成，其距离称为双目相机的基线(Baseline, 记作 b)，是双目的重要参数。由于左右两个相机之间有一定距离，因此同一个物体在左右图上的横坐标会有一些差异，称为<font color=red><strong>视差(Disparity)</strong></font>。</p>
<span id="more"></span>

<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/双目测距和三维重建-20210508235112.png">
</p>


<p>根据视差，我们可以估计一个像素离相机的距离。</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/双目测距和三维重建-20210508235118.png">
</p>

<p align="center">
    <img width="28%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/双目测距和三维重建-20210508235217.jpg">
</p>

<p>根据相机坐标系点 <code>P</code> 坐标为 <code>(X, Y, Z)</code> 到图像坐标系 <code>(u, v)</code> 之间的投影关系：</p>
<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/双目测距和三维重建-20210508235222.jpg">
</p>

<p>从而反推得到点 <code>P</code> 的坐标信息</p>
<p align="center">
    <img width="17%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/双目测距和三维重建-20210508235226.jpg">
</p>

<p>例如，以下图片为例：</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><img src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/%E5%8F%8C%E7%9B%AE%E6%B5%8B%E8%B7%9D%E5%92%8C%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA-20210508235337.jpg" alt="原图"></td>
<td align="center"><img src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/%E5%8F%8C%E7%9B%AE%E6%B5%8B%E8%B7%9D%E5%92%8C%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA-20210508235341.png" alt="视差图"></td>
</tr>
</tbody></table>
<blockquote>
<p>视差图采用十六位 (uint16) 整数来存取，并将视差值扩大了 256 倍，所以在读取时需要除以256。</p>
</blockquote>
<p>鼠标右键将原图和视差图下载下来，然后安装好第三方库 PyOpenGL==3.1.0 和 <a href="https://github.com/uoip/pangolin">pangolin</a> 即可执行以下程序便得到了动图的结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> pangolin</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> OpenGL.GL <span class="keyword">as</span> gl</span><br><span class="line"></span><br><span class="line">fx = <span class="number">721.5377</span></span><br><span class="line">fy = <span class="number">721.5377</span></span><br><span class="line">cx = <span class="number">607.1928</span></span><br><span class="line">cy = <span class="number">185.2157</span></span><br><span class="line">B  = <span class="number">0.54</span></span><br><span class="line"></span><br><span class="line">img_disp = cv2.imread(<span class="string">&#x27;000004_10_disp.png&#x27;</span>, -<span class="number">1</span>) / <span class="number">256.</span></span><br><span class="line">imgL = cv2.imread(<span class="string">&#x27;000004_10.jpg&#x27;</span>)</span><br><span class="line">imgL = cv2.cvtColor(imgL, cv2.COLOR_BGR2RGB)</span><br><span class="line"></span><br><span class="line">h, w = imgL.shape[:<span class="number">2</span>]</span><br><span class="line">f = <span class="number">0.5</span> * w</span><br><span class="line">points, colors = [], []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">range</span>(h):</span><br><span class="line">    <span class="keyword">for</span> u <span class="keyword">in</span> <span class="built_in">range</span>(w):</span><br><span class="line">        disp = img_disp[v, u]</span><br><span class="line">        <span class="keyword">if</span> disp &gt; <span class="number">0.</span>:</span><br><span class="line">            depth = B * fx / disp</span><br><span class="line">            z_w = depth</span><br><span class="line">            x_w = (u - cx) * z_w / fx</span><br><span class="line">            y_w = (v - cy) * z_w / fy</span><br><span class="line">            points.append([x_w, y_w, z_w])</span><br><span class="line">            colors.append(imgL[v, u])</span><br><span class="line">points = np.array(points)</span><br><span class="line">colors = np.array(colors) / <span class="number">255.</span></span><br><span class="line"></span><br><span class="line">pangolin.CreateWindowAndBind(<span class="string">&#x27;Main&#x27;</span>, <span class="number">640</span>, <span class="number">480</span>)</span><br><span class="line">gl.glEnable(gl.GL_DEPTH_TEST)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define Projection and initial ModelView matrix</span></span><br><span class="line">scam = pangolin.OpenGlRenderState(</span><br><span class="line">    pangolin.ProjectionMatrix(<span class="number">640</span>, <span class="number">480</span>, <span class="number">2000</span>, <span class="number">2000</span>, <span class="number">320</span>, <span class="number">240</span>, <span class="number">0.1</span>, <span class="number">1000</span>),</span><br><span class="line">    pangolin.ModelViewLookAt(<span class="number">0</span>, <span class="number">0</span>, -<span class="number">20</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, -<span class="number">1</span>, <span class="number">0</span>))</span><br><span class="line">handler = pangolin.Handler3D(scam)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create Interactive View in window</span></span><br><span class="line">dcam = pangolin.CreateDisplay()</span><br><span class="line">dcam.SetBounds(<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>, -<span class="number">640.0</span>/<span class="number">480.0</span>)</span><br><span class="line">dcam.SetHandler(handler)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">not</span> pangolin.ShouldQuit():</span><br><span class="line">    gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)</span><br><span class="line">    gl.glClearColor(<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>)</span><br><span class="line">    dcam.Activate(scam)</span><br><span class="line">    gl.glPointSize(<span class="number">3</span>)</span><br><span class="line">    pangolin.DrawPoints(points, colors)</span><br><span class="line">    pangolin.FinishFrame()</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>立体视觉</category>
      </categories>
      <tags>
        <tag>三维重建</tag>
      </tags>
  </entry>
  <entry>
    <title>什么是相机的位姿 ？</title>
    <url>/2019/12/27/%E4%BB%80%E4%B9%88%E6%98%AF%E7%9B%B8%E6%9C%BA%E7%9A%84%E4%BD%8D%E5%A7%BF/</url>
    <content><![CDATA[<p>在视觉 slam 领域里，相机的位姿是一个特别重要的概念。简单来说，相机的位姿（pose）就是相机的位置和姿态的合称，它描述了世界坐标系与相机坐标系之间的转换关系。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/什么是相机的位姿-20210508233035.png">
</p>

<span id="more"></span>

<p>如上图所示：点 <code>P</code> 的世界坐标为 <code>P_&#123;w&#125;</code>，可以通过相机的位姿矩阵 <code>T</code> 转换到相机坐标系下为 <code>P_&#123;c&#125;</code> ：</p>
<p align="center">
    <img width="17%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/什么是相机的位姿-20210508233142.jpg">
</p>

<p>当然你可以将点 <code>P</code> 从相机坐标系转换到世界坐标系中：</p>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/什么是相机的位姿-20210508233318.jpg">
</p>

<p>其中 <code>T_&#123;cw&#125;</code> 为该点从世界坐标系变换到相机坐标系的变换矩阵， <code>T_&#123;wc&#125;</code> 为该点从相机坐标系变换到世界坐标系的变换矩阵。<strong>它们二者都可以用来表示相机的位姿，前者称为相机的外参</strong>。</p>
<blockquote>
<p>实践当中使用 <code>T_&#123;cw&#125;</code> 来表示相机位姿更加常见。然而在可视化程序中使用 <code>T_&#123;wc&#125;</code> 来表示相机位姿更为直观，因为此时它的平移向量即为相机原点在世界坐标系中的坐标。视觉 Slam 十四讲中的第五讲的 joinMap 使用的就是 <code>T_&#123;wc&#125;</code> 来表示相机位姿进行点云拼接。</p>
</blockquote>
<p>相机位姿矩阵 <code>T</code> 其实主要由旋转矩阵 <code>R</code> 和平移向量 <code>t</code> 组成：</p>
<p align="center">
    <img width="22%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/什么是相机的位姿-20210508233403.png">
</p>

<p>其中旋转矩阵 <code>R</code> 一共有 9 个量，但是一次旋转只有 3 个自由度，因此这种表达方式是冗余的。可以使用欧拉角来描述这种旋转行为，它使用了 3 个分离的转角，把一个旋转分解成了3次绕不同轴的旋转，如下所示：</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/什么是相机的位姿-20210508233445.jpg">
</p>

<p>因此旋转矩阵 <code>R</code> 可以由三个转角来表示，它们分别是：</p>
<ul>
<li>偏航角 yaw，绕物体的 <code>Z</code> 轴旋转的角度, 用 <code>gamma</code> 表示；</li>
<li>俯仰角 pitch，<font color=Red><strong>旋转之后</strong></font>绕 <code>Y</code> 轴旋转的角度, 用 <code>alpha</code> 表示；</li>
<li>滚转角 roll，<font color=Red><strong>旋转之后</strong></font>绕 <code>X</code> 轴旋转的角度, 用 <code>beta</code> 表示；</li>
</ul>
<p>既然欧拉角可以表示物体的旋转状态，那么旋转矩阵 <code>R</code> 应该也能被这个三个角度所表示:首先，旋转矩阵 R 可以被三个矩阵分解得到</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/什么是相机的位姿-20210508233528.jpg">
</p>

<p>其中：</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/什么是相机的位姿-20210508233658.jpg">
</p>


<p>因此它们三者相乘便得到旋转矩阵 <code>R</code> 的表达形式:</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/什么是相机的位姿-20210508233742.jpg">
</p>

<p>使用这种方法表示的一个重大缺点就是会碰到著名的<font color=red>万向锁问题</font>：在俯仰角为正负 90 度时，第一次旋转与第三次旋转将会使用同一个轴，使得系统失去了一个自由度（由 3 次旋转变成了 2 次旋转）。理论上可以证明，只要想用 3 个实数来表达三维旋转，都不可避免遇到这种问题。</p>
<p align="center">
    <img width="80%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/什么是相机的位姿-20210508233747.png">
</p>


<p>参考文献：</p>
<ul>
<li><a href="https://blog.csdn.net/CharmingSun/article/details/97445425">《视觉SLAM十四讲》相机位姿与相机外参的区别与联系</a></li>
</ul>
]]></content>
      <categories>
        <category>立体视觉</category>
      </categories>
      <tags>
        <tag>相机位姿</tag>
        <tag>视觉 Slam</tag>
      </tags>
  </entry>
  <entry>
    <title>相机的内参和外参</title>
    <url>/2019/12/23/%E7%9B%B8%E6%9C%BA%E7%9A%84%E5%86%85%E5%8F%82%E5%92%8C%E5%A4%96%E5%8F%82/</url>
    <content><![CDATA[<p>相机的内参和外参是立体视觉的基础，今天做个笔记记录下。</p>
<h2 id="1-相机模型"><a href="#1-相机模型" class="headerlink" title="1. 相机模型"></a>1. 相机模型</h2><p>照片的本质是真实的 3D 场景在相机的成像平面上留下的一个投影，最早的相机是在小孔成像的基础上发展起来的，下面这幅图简单地解释了相机的成像过程。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/相机的内参和外参-20210508231736.png">
</p>

<span id="more"></span>

<p>现在来对这个简单的针孔模型进行几何建模。设 <code>O − x − y − z</code> 为相机坐标系，习惯上我们让 <code>z</code> 轴指向相机前方，<code>x</code> 向右，<code>y</code> 向下。<code>O</code> 为摄像机的光心，也是针孔模型中的针孔。现实世界的空间点 <code>P</code> 经过小孔 <code>O</code> 投影之后，落在物理成像平面 <code>O&#39;-x&#39;-y&#39;</code> 上，成像点为 <code>P&#39;</code>。设 <code>P</code> 的坐标为 <code>[X, Y, Z]</code>，<code>P&#39;</code> 为 <code>[x&#39;, Y&#39;, Z&#39;]</code> 并且设物理成像平面到小孔的距离为 <code>f</code>(焦距)。那么根据三角形相似关系</p>
<p align="center">
    <img width="21%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/相机的内参和外参-20210508231750.jpg">
</p>

<p>通过整理便得到：</p>
<p align="center">
    <img width="12%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/相机的内参和外参-20210508231755.jpg">
</p>

<h2 id="2-相机内参"><a href="#2-相机内参" class="headerlink" title="2. 相机内参"></a>2. 相机内参</h2><p>上式描述了点 P 和它的像之间的空间关系。不过在相机中，我们最终获得的是 一个个的像素，这需要在成像平面上对像进行采样和量化。</p>
<p>像素坐标系通常的定义方式是：原点 <code>O&#39;</code> 位于图像的左上角，<code>u</code> 轴向右与 <code>x</code> 轴平行，<code>v</code> 轴向下与 <code>y</code> 轴平行。<font color=OrangeRed>因此，像素坐标系与成像平面之间，相差了一个缩放和一个原点的平移。</font></p>
<p>我们设像素坐标在 $u$ 轴上缩放了 <code>α</code> 倍，在 <code>v</code> 上缩放了 <code>β</code> 倍。同时，原点平移了 <code>[c_x, c_y]</code>。那么，<code>P&#39;</code> 的坐标与像素坐标 <code>[u, v]</code> 的关系为:</p>
<p align="center">
    <img width="18%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/相机的内参和外参-20210508231801.jpg">
</p>

<p>把 <code>αf</code> 合并成 <code>f_&#123;x&#125;</code>，<code>βf</code> 合并成 <code>f_&#123;y&#125;</code>，得:</p>
<p align="center">
    <img width="21%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/相机的内参和外参-20210508231810.jpg">
</p>

<p>其中，<code>f</code> 的单位为米，<code>α, β</code> 的单位为像素每米，所以 <code>fx , fy</code> 的单位为像素。把该式写成矩阵形式，会更加简洁，不过左侧需要用到齐次坐标:</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/相机的内参和外参-20210508231814.jpg">
</p>

<p>综上，可以整理得到一个非常简洁的公式如下：</p>
<p align="center">
    <img width="15%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/相机的内参和外参-20210508232247.jpg">
</p>

<p align="center">
    <img width="44%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/相机的内参和外参-20210508232305.jpg">
</p>

<p>其中，我们把矩阵 K 称为<font color=OrangeRed>相机的内参(Camera Intrinsics)，它描述了相机坐标系到图像坐标系之间的投影关系。</font></p>
<h2 id="3-相机外参"><a href="#3-相机外参" class="headerlink" title="3. 相机外参"></a>3. 相机外参</h2><p>在上面的推导过程中，我们使用的是 <code>P_&#123;c&#125;</code> 在相机坐标系下的坐标。如果我们使用世界坐标系下的 <code>P_&#123;w&#125;</code> 的话，那么就应该使用相机的当前位姿变换到相机坐标系下：</p>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/相机的内参和外参-20210508232404.jpg">
</p>

<p>其中，<font color=OrangeRed>相机的位姿 <code>R, t</code> 又称为相机的外参数 (Camera Extrinsics)，它描述了点 P 的世界坐标到相机坐标的投影关系。</font>因此世界坐标系下点 P 投影到图像坐标系的整个过程为：</p>
<p align="center">
    <img width="31%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/相机的内参和外参-20210508232409.jpg">
</p>]]></content>
      <categories>
        <category>立体视觉</category>
      </categories>
      <tags>
        <tag>立体视觉</tag>
        <tag>相机参数</tag>
      </tags>
  </entry>
  <entry>
    <title>基于卷积神经网络的 2D-to-3D 视频转换</title>
    <url>/2019/12/10/%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84-2D-to-3D-%E8%A7%86%E9%A2%91%E8%BD%AC%E6%8D%A2/</url>
    <content><![CDATA[<p>目前制作 3D 电影的方法有两种：一种是直接用昂贵的立体相机设备进行拍摄，这种制作成本非常庞大。另一种则是通过图像处理技术将 2D 电影转化成 3D 格式，这种转换处理通常依赖于“深度艺术家”，他们手工地为每一帧创造深度图，然后利用标准的基于深度图像的渲染算法将与原始图像相结合，得到一个立体的图像对，这需要大量的人力成本。现在来说，每年只有 20 左右部新的 3D 电影发行。</p>
<p><img src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84-2D-to-3D-%E8%A7%86%E9%A2%91%E8%BD%AC-20210508231215.png" alt="Deep3D 网络"></p>
<span id="more"></span>

<p>在这样强烈需求的工业背景下，这篇文章的目的虽然是为了解决如何利用神经网络将 2D 电影转化成具有立体感的 3D 视频的问题，并且不需要人力来标注图片的深度信息。但是它提出的方法太新颖(很多论文都引用了，可见影响力)，所以也把它拎出来讲。</p>
<h2 id="1-网络结构"><a href="#1-网络结构" class="headerlink" title="1. 网络结构"></a>1. 网络结构</h2><p>作者的网络如上图所示：双目图片的左图作为模型的输入，每经过一次卷积和池化层后都会有两个分支：分支 1 会进行下一个卷积池化层进行特征提取，而分支 2 会进入反卷积层进行上采样得到一个与原图分辨率一致的视差图 (disparity map)，如此反复经过 5 层循环，得到 5 个视差图。最终作者会将这 5 个视差图相加，然后再经过一层卷积层并使用 softmax 激活函数，最后会输出一个与原图分辨率一致的视差概率分布 (probalistic disparity map)。</p>
<p>其实该网络的结构设计和其他语义分割类型的网络大同小异，这里没什么讲的。关键是它的损失函数设计以及 image-to-image 的方法，揭开了深度估计无监督学习的序幕。所以让我们直奔主题，给你一张左图和视差图，你如何去重构出右图？</p>
<h2 id="2-重构右图"><a href="#2-重构右图" class="headerlink" title="2. 重构右图"></a>2. 重构右图</h2><p>我们的直觉做法是将左视角点向右平移视差 D 个单位，然后便得到了右视角点。由于受极线约束，因此计算复杂度为 o(n)。但是这个方法在神经网络里无法进行反向传播，因为它对视差 D 是不可导的，因此我们无法训练。针对这个问题，作者引入了视差的概率分布对网络进行优化。利用左视角点和视差概率分布对右视角点进行重构的过程如下公式所示：</p>
<p align="center">
    <img width="22%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/基于卷积神经网络的-2D-to-3D-视频转-20210508231226.jpg">
</p>

<ul>
<li><code>O_&#123;i, j&#125;</code> 表示在图片坐标 (i, j) 上重构的右视角点</li>
<li><code>I_&#123;i, j&#125;^&#123;d&#125;</code> 表示左视角点 (i, j) 平移 d 个位置后得到的右视角</li>
<li><code>D_&#123;i, j&#125;^&#123;d&#125;</code> 表示左视角点 (i, j) 的视差概率分布在视差 d 时的概率值</li>
</ul>
<h2 id="3-代码实践"><a href="#3-代码实践" class="headerlink" title="3. 代码实践"></a>3. 代码实践</h2><p>上述公式有点晦涩难懂，我琢磨了半天，写了个小程序进行实践：假如我们现在有一对分辨率为 200x200 的双目图片，整张图片上的像素视差都是 20。为了感受视差的偏移性质，我们在图片的中间区域设置了一块 10x10 的白点。可以看到从左图到右图，小白点很明显地移动了一小段距离，这就是视差造成的。</p>
<p align="center">
    <img width="37%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/基于卷积神经网络的-2D-to-3D-视频转-20210508231223.png">
</p>

<p>我们假定整张图片的最大视差值为 30， 那么就需要划分 0,1,…,30 共 31 个等级。因此图片的视差概率分布的形状为 [200， 200， 31]，由于真实的视差值为 20， 因此该等级属于 onehot 状态，接着左图上每个像素点在每个等级 i 上都会向右平移 i 个单位，这样一来我们便总共得到了 31 张图片， 程序里用 shift_images 表示，最后再将它与视差的概率分布相乘并求和便得到重构的右图。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">l_img = np.zeros([<span class="number">200</span>, <span class="number">200</span>])</span><br><span class="line">l_img[<span class="number">95</span>:<span class="number">105</span>, <span class="number">95</span>:<span class="number">105</span>] = <span class="number">255</span></span><br><span class="line"></span><br><span class="line">r_img = np.zeros([<span class="number">200</span>, <span class="number">200</span>])</span><br><span class="line">r_img[<span class="number">95</span>:<span class="number">105</span>, <span class="number">115</span>:<span class="number">125</span>] = <span class="number">255</span></span><br><span class="line"></span><br><span class="line">cv2.imwrite(<span class="string">&quot;l_img.jpg&quot;</span>, l_img)</span><br><span class="line">cv2.imwrite(<span class="string">&quot;r_img.jpg&quot;</span>, r_img)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 假设整张图片的视差都是20</span></span><br><span class="line">gt_disp = np.ones([<span class="number">200</span>, <span class="number">200</span>]) * <span class="number">20</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># construct disparity map</span></span><br><span class="line">max_disp = <span class="number">30</span></span><br><span class="line">prob_disp = np.zeros([<span class="number">200</span>, <span class="number">200</span>, max_disp])</span><br><span class="line">prob_disp[:, :, <span class="number">20</span>] = <span class="number">1.0</span></span><br><span class="line"></span><br><span class="line">shift_images = np.zeros(shape=[<span class="number">200</span>, <span class="number">200</span>, max_disp])</span><br><span class="line"><span class="keyword">for</span> disp <span class="keyword">in</span> <span class="built_in">range</span>(max_disp):</span><br><span class="line">    shift_images[:, :, disp] = np.roll(l_img, disp, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">pred_r_img = np.<span class="built_in">sum</span>(shift_images * prob_disp, axis=<span class="number">2</span>)</span><br><span class="line">cv2.imwrite(<span class="string">&quot;pred_r_img.jpg&quot;</span>, pred_r_img)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;reconstruction loss: &quot;</span>, np.<span class="built_in">sum</span>(pred_r_img - r_img)) <span class="comment"># 0.0</span></span><br></pre></td></tr></table></figure>

<p>由于我们给的是真实的视差概率分布，因此重构损失(reconstruction loss)的值为0. 反过来：如果重构损失不为 0， 那么神经网络将会朝着预测正确的视差概率分布去优化。最后我们将预测出来的右图和真实的右图进行了对比，结果一致。</p>
<p align="center">
    <img width="37%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/基于卷积神经网络的-2D-to-3D-视频转-20210508231230.png">
</p>

<p>总结： 这篇文章的新颖之处在于，通过 image-to-image 训练的方式，打开了深度估计网络通往无监督训练的大门。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li>[1] Junyuan Xie, Ross Girshick, Ali Farhadi. <a href="https://arxiv.org/abs/1604.03650">Deep3D: Fully Automatic 2D-to-3D Video Conversion with Deep Convolutional Neural Networks</a>, CVPR 2016</li>
<li>[2] Deep3D: <a href="https://github.com/piiswrong/deep3d">Automatic 2D-to-3D Video Conversion with CNNs</a></li>
</ul>
]]></content>
      <categories>
        <category>立体视觉</category>
      </categories>
      <tags>
        <tag>深度估计</tag>
      </tags>
  </entry>
  <entry>
    <title>可变形卷积网络：计算机新“视”界</title>
    <url>/2019/11/18/%E5%8F%AF%E5%8F%98%E5%BD%A2%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%96%B0%E8%A7%86%E7%95%8C/</url>
    <content><![CDATA[<p>2017年，微软亚洲研究院视觉计算组的研究员在 arXiv 上公布了一篇题为 <a href="https://arxiv.org/pdf/1703.06211.pdf">“Deformable Convolutional Networks”（可变形卷积网络）</a> 的论文，首次在卷积神经网络（convolutional neutral networks，CNN）中引入了学习空间几何形变的能力，得到可变形卷积网络（deformable convolutional networks），从而更好地解决了具有空间形变的图像识别任务。</p>
<p align="center">
    <img width="55%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/可变形卷积网络-计算机新视界-20210508230745.png">
</p>

<p>研究员们通过大量的实验结果验证了该方法在复杂的计算机视觉任务（如目标检测和语义分割）上的有效性，首次表明在深度卷积神经网络（deep CNN）中学习空间上密集的几何形变是可行的。</p>
<span id="more"></span>

<h2 id="1-卷积神经网络的成功和局限"><a href="#1-卷积神经网络的成功和局限" class="headerlink" title="1. 卷积神经网络的成功和局限"></a>1. 卷积神经网络的成功和局限</h2><p>由于同样的物体在图像中可能呈现出不同的大小、姿态、视角变化甚至非刚体形变，因此如何适应这些复杂的几何形变是物体识别的主要难点，同时也是计算机视觉领域多年来关注的核心问题。很多传统经典方法，如尺度不变的特征变换（scale invariant feature transform, or SIFT）和可变形部件模型（deformable part models）等，都旨在解决这一问题。然而，由于人工设计特征的局限性，传统视觉方法在物体识别问题上多年来并未取得突破性的进展。</p>
<p>由于强大的建模能力和自动的端到端的学习方式，深度卷积神经网络可以从大量数据中学习到有效特征，避免了传统方法人工设计特征的弊端。然而，现有的网络模型对于物体几何形变的适应能力几乎完全来自于数据本身所具有的多样性，其模型内部并不具有适应几何形变的机制。究其根本，是因为卷积操作本身具有固定的几何结构，而由其层叠搭建而成的卷积网络的几何结构也是固定的，所以不具有对于几何形变建模的能力。</p>
<p>举个例子，想要识别出同一图像中不同大小的物体（比如远近不同的两个人），理想的结果是，在对应于每个物体的位置网络需要具有相应大小的感受野（receptive field）。直观的说，为了识别更大的物体网络需要看到更大的图像区域。然而，在现有的卷积网络架构中，图像中任何位置的感受野大小都是相同的，其取决于事先设定的网络参数（卷积核的大小、步长和网络深度等），无法根据图像内容自适应调整，从而限制了识别精度。</p>
<h2 id="2-消除网络难以适应几何变形的“罪魁祸首”"><a href="#2-消除网络难以适应几何变形的“罪魁祸首”" class="headerlink" title="2. 消除网络难以适应几何变形的“罪魁祸首”"></a>2. 消除网络难以适应几何变形的“罪魁祸首”</h2><p>追根溯源，上述局限来自于卷积网络的基本构成单元，即卷积操作。该操作在输入图像的每个位置时会进行基于规则格点位置的采样，然后对于采样到的图像值做卷积并作为该位置的输出。通过端到端的梯度反向传播学习，系统将会得到一个用矩阵表示的卷积核的权重。这就是自卷积网络诞生之初，已使用二十多年的基本单元结构。</p>
<p>微软亚洲研究院的研究员们发现，标准卷积中的规则格点采样是导致网络难以适应几何形变的“罪魁祸首”。为了削弱这个限制，研究员们对卷积核中每个采样点的位置都增加了一个偏移的变量。通过这些变量，卷积核就可以在当前位置附近随意的采样，而不再局限于之前的规则格点。这样扩展后的卷积操作被称为可变形卷积（deformable convolution）。标准卷积和可变形卷积在图1中有简要的展示。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/可变形卷积网络-计算机新视界-20210508230736.jpg">
</p>

<blockquote>
<p>图1：展示了卷积核大小为 3x3 的正常卷积和可变形卷积的采样方式，(a) 所示的正常卷积规律的采样 9 个点（绿点），(b)(c)(d) 为可变形卷积，在正常的采样坐标上加上一个位移量（蓝色箭头），其中(c)(d) 作为 (b) 的特殊情况，展示了可变形卷积可以作为尺度变换，比例变换和旋转变换的特殊情况</p>
</blockquote>
<p>事实上，可变形卷积单元中增加的偏移量是网络结构的一部分，通过另外一个平行的标准卷积单元计算得到，进而也可以通过梯度反向传播进行端到端的学习。加上该偏移量的学习之后，可变形卷积核的大小和位置可以根据当前需要识别的图像内容进行动态调整，其直观效果就是不同位置的卷积核采样点位置会根据图像内容发生自适应的变化，从而适应不同物体的形状、大小等几何形变，如图2、图3中所展示。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/可变形卷积网络-计算机新视界-20210508230748.png">
</p>

<blockquote>
<p>图2：两层3*3的标准卷积和可变形卷积的区别。(a) 标准卷积中固定的感受野和卷积核采样点。(b) 可变性卷积中自适应的感受野和卷积核采样点。</p>
</blockquote>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/可变形卷积网络-计算机新视界-20210508230752.jpg">
</p>

<blockquote>
<p>图 3：更多可变形卷积的示例。每个图像三元组显示了三层 3x3 可变形卷积核的采样点位置（共 729 个点），对应于三个不同的图像区域（从左至右，背景，小物体，大物体）。</p>
</blockquote>
<h2 id="3-可变形卷积神经网络：简明深刻的网络结构革新"><a href="#3-可变形卷积神经网络：简明深刻的网络结构革新" class="headerlink" title="3. 可变形卷积神经网络：简明深刻的网络结构革新"></a>3. 可变形卷积神经网络：简明深刻的网络结构革新</h2><p>可变形卷积单元具有诸多良好的性质。它不需要任何额外的监督信号，可以直接通过目标任务学习得到。它可以方便地取代任何已有视觉识别任务的卷积神经网络中的若干个标准卷积单元，并通过标准的反向传播进行端到端的训练。由此得到的网络则称为“可变形卷积网络”。</p>
<p>可变形卷积网络是对于传统卷积网络简明而又意义深远的结构革新，具有重要的学术和实践意义。它适用于所有待识别目标具有一定几何形变的任务（几乎所有重要的视觉识别任务都有此特点，人脸、行人、车辆、文字、动物等），可以直接由已有网络结构扩充而来，无需重新预训练。它仅增加了很少的模型复杂度和计算量，且显著提高了识别精度。例如，在用于自动驾驶的图像语义分割数据集（CityScapes）上，可变形卷积神经网络将准确率由70%提高到了75%。</p>
<p>此外，通过增加偏移量来学习几何形变的思想还可方便地扩展到其它计算单元中去。例如，目前业界最好的物体检测方法都使用了基于规则块采样的兴趣区域（region of interests, ROI）池化（pooling）。在该操作中，对于每个采样的规则块增加类似的偏移量，从而得到可变形兴趣区域池化 (deformable ROI pooling）。由此所获得的新的物体检测方法也取得了显著的性能提升。</p>
<h2 id="4-卷积网络的新思路"><a href="#4-卷积网络的新思路" class="headerlink" title="4. 卷积网络的新思路"></a>4. 卷积网络的新思路</h2><p>近年来，与神经网络结构相关的研究工作层出不穷，大多是对于各种基本网络单元连接关系的研究。不同于大部分已有的工作，可变形卷积网络首次表明了可以在卷积网络中显式地学习几何形变。它修改了已使用二十余年的基本卷积单元结构，在重要的物体检测和语义分割等计算机视觉任务上获得了重大的性能提升。</p>
<p>可以想象，在不远的未来，在更多的计算机视觉识别任务中（如文字检测、视频物体检测跟踪等）都将看到它的成功应用。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>可变形卷积网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Faster-rcnn 里的区域生成网络（RPN）</title>
    <url>/2019/09/27/Faster-rcnn-%E9%87%8C%E7%9A%84%E5%8C%BA%E5%9F%9F%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9CRPN/</url>
    <content><![CDATA[<p>我觉得 RPN 是目标检测领域里最经典也是最容易入门的网络了。如果你想学好目标检测，那一定不能不知道它！今天讲的 RPN 是来一篇来自 CVPR 2017 的论文 Expecting the Unexpected: Training Detectors for Unusual Pedestrians with Adversarial Imposters， 作者在 Faster-rcnn 的 RPN 基础上进行了改进，用于行人检测。</p>
<p align="center">
    <img width="65%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Faster-rcnn-里的区域生成网络RPN-20210508221255.png">
</p>

<span id="more"></span>

<h2 id="1-网络结构"><a href="#1-网络结构" class="headerlink" title="1. 网络结构"></a>1. 网络结构</h2><p>上图是 RPN 的网络结构，它采用了 VGG16 网络进行特征提取。从 VGG16 的整体架构来看，作者为了提高 RPN 在不同分辨率图片下的检测率，分别将 Pool3 层、Pool4 层和 Pool5 层的输出进行卷积和融合得到了一个 45 x 60 x 1280 尺寸的 feature map。最后将这个 feature map 分别输入两个卷积层中得到 softmax 分类层与 bboxes 回归层。</p>
<h2 id="2-Anchor-机制"><a href="#2-Anchor-机制" class="headerlink" title="2. Anchor 机制"></a>2. Anchor 机制</h2><p>目标检测其实是生产很多框，然后在消灭无效框的过程。生产很多框的过程利用的是 Anchor 机制，消灭无效框则采用非极大值抑制过程进行处理。RPN 网络输入的图片为 720 x 960，输出的 feature map 尺寸为 45 x 60，由于它们每个点上会产生 9 个 anchor boxes，因此最终一共会得到 45 x 60 x 9 个 anchor boxes。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Faster-rcnn-里的区域生成网络RPN-20210508221316.png">
</p>

<p>直接利用这些 anchor boxes 对真实框进行预测会有些困难，因此作者采用了 <strong><font color=red>anchor boxes 与 ground-truth boxes 的偏移量机制</font></strong>进行回归预测。</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Faster-rcnn-里的区域生成网络RPN-20210508221322.jpg">
</p>

<p><code>x, y, w, h</code> 分别表示 boxes 的中心坐标和宽高；变量 <code>x, x_&#123;a&#125;, x^&#123;*&#125;</code> 则分别代表预测框，anchor 框和 ground-truth 框的中心坐标 <code>x</code></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_regression</span>(<span class="params">box1, box2</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    box1: predicted boxes</span></span><br><span class="line"><span class="string">    box2: anchor boxes</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    target_reg = np.zeros(shape=[<span class="number">4</span>,])</span><br><span class="line">    w1 = box1[<span class="number">2</span>] - box1[<span class="number">0</span>]</span><br><span class="line">    h1 = box1[<span class="number">3</span>] - box1[<span class="number">1</span>]</span><br><span class="line">    w2 = box2[<span class="number">2</span>] - box2[<span class="number">0</span>]</span><br><span class="line">    h2 = box2[<span class="number">3</span>] - box2[<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    target_reg[<span class="number">0</span>] = (box1[<span class="number">0</span>] - box2[<span class="number">0</span>]) / w2</span><br><span class="line">    target_reg[<span class="number">1</span>] = (box1[<span class="number">1</span>] - box2[<span class="number">1</span>]) / h2</span><br><span class="line">    target_reg[<span class="number">2</span>] = np.log(w1 / w2)</span><br><span class="line">    target_reg[<span class="number">3</span>] = np.log(h1 / h2)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> target_reg</span><br></pre></td></tr></table></figure>

<h2 id="3-损失函数"><a href="#3-损失函数" class="headerlink" title="3. 损失函数"></a>3. 损失函数</h2><p>RPN 的损失函数和 YOLO 非常像，不过从发表论文时间顺序来看，应该是 YOLO 借鉴了 RPN 。在 Faster-rcnn 论文里，RPN 的损失函数是这样的:</p>
<ul>
<li>为了训练 RPN， 我们首先给每个 anchor boxes 设置了两个标签，分别为 0: 背景, 1: 前景；</li>
<li>与 ground-truth boxes 重合度 (iou) 最高的那个 anchor boxes 设置为正样本;</li>
<li>只要这个 anchor boxes 与任何一个 ground-truth boxes 的 iou 大于 0.7，那么它也是一个正样本；</li>
<li>如果 anchor boxes 与所有的 ground-truth boxes 的 iou 都小于 0.3， 那么它就是一个负样本，表示不包含物体；</li>
<li>在前面这几种情况下，已经能够产生足够多的正、负样本了，剩下的则既不是正样本，也不是负样本，它们不会参与到 RPN 的 loss 的计算中去。</li>
</ul>
<p>在我的代码 <a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/blob/master/4-Object_Detection/RPN/demo.py">demo.py</a> 里将正负样本都可视化出来了，大家只要配置好 image 和 label 的路径然后直接执行 python demo.py 就可以看到以下图片。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Faster-rcnn-里的区域生成网络RPN-20210508221332.png">
</p>

<p>在上图中，蓝色框为 anchor boxes，它们就是正样本，红点为这些正样本 anchor boxes 的中心位置，黑点表示的是负样本 anchor boxes 的中心位置。从图中可以看出：在有人的区域，正样本框的分布比较密集，并且红点都在人体中心区域；而在没有人的区域则布满了黑点,它们表示的是负样本，都属于背景。</p>
<p>在前面讲到，RPN 网络预测的是 <strong><font color=red>anchor boxes 与 ground-truth boxes 的偏移量</font></strong>，那如果我们将这些正样本 anchor boxes 的偏移量映射回去的话：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">=&gt; Decoding positive sample: 20, 20, 0</span><br><span class="line">=&gt; Decoding positive sample: 20, 20, 7</span><br><span class="line">...</span><br><span class="line">=&gt; Decoding positive sample: 36, 31, 1</span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Faster-rcnn-里的区域生成网络RPN-20210508221338.png">
</p>

<p>你会发现，这就是 ground-truth boxes 框（绿色框）和物体中心点（红色点）的位置。事实上，RPN 的损失是一个多任务的 loss function，集合了分类损失与回归框损失，它们两者之间的优化可以通过 λ 系数去实现平衡。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Faster-rcnn-里的区域生成网络RPN-20210508221630.jpg">
</p>

<p>初次看这个损失函数有点迷，<strong><font color=red>它其实是一个 smooth-L1 损失函数, 它的优点在于解决了 L1 损失函数在 0 点附近的不可导问题，而且相比于 L2 损失函数而言，它在训练初始阶段的梯度回传会更加稳定</font></strong>。如下图所示，正负样本都会参与到分类损失的反向传播中去（因为你需要告诉网络什么是正样本和负样本），而回归框的损失只有正样本参与计算（只有正样本才有回归框损失，负样本作为背景是没有回归框损失的)。</p>
<p align="center">
    <img width="47%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Faster-rcnn-里的区域生成网络RPN-20210508221635.jpg">
</p>

<p>其中：</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Faster-rcnn-里的区域生成网络RPN-20210508221744.jpg">
</p>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_loss</span>(<span class="params">target_scores, target_bboxes, target_masks, pred_scores, pred_bboxes</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    target_scores shape: [1, 45, 60, 9, 2],  pred_scores shape: [1, 45, 60, 9, 2]</span></span><br><span class="line"><span class="string">    target_bboxes shape: [1, 45, 60, 9, 4],  pred_bboxes shape: [1, 45, 60, 9, 4]</span></span><br><span class="line"><span class="string">    target_masks  shape: [1, 45, 60, 9]</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    score_loss = tf.nn.softmax_cross_entropy_with_logits(labels=target_scores, logits=pred_scores)</span><br><span class="line">    foreground_background_mask = (np.<span class="built_in">abs</span>(target_masks) == <span class="number">1</span>).astype(np.<span class="built_in">int</span>)</span><br><span class="line">    score_loss = tf.reduce_sum(score_loss * foreground_background_mask, axis=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]) / np.<span class="built_in">sum</span>(foreground_background_mask)</span><br><span class="line">    score_loss = tf.reduce_mean(score_loss)</span><br><span class="line"></span><br><span class="line">    boxes_loss = tf.<span class="built_in">abs</span>(target_bboxes - pred_bboxes)</span><br><span class="line">    boxes_loss = <span class="number">0.5</span> * tf.<span class="built_in">pow</span>(boxes_loss, <span class="number">2</span>) * tf.cast(boxes_loss&lt;<span class="number">1</span>, tf.float32) + (boxes_loss - <span class="number">0.5</span>) * tf.cast(boxes_loss &gt;=<span class="number">1</span>, tf.float32)</span><br><span class="line">    boxes_loss = tf.reduce_sum(boxes_loss, axis=-<span class="number">1</span>)</span><br><span class="line">    foreground_mask = (target_masks &gt; <span class="number">0</span>).astype(np.float32)</span><br><span class="line">    boxes_loss = tf.reduce_sum(boxes_loss * foreground_mask, axis=[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]) / np.<span class="built_in">sum</span>(foreground_mask)</span><br><span class="line">    boxes_loss = tf.reduce_mean(boxes_loss)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> score_loss, boxes_loss</span><br></pre></td></tr></table></figure>

<h2 id="4-k-means-造框"><a href="#4-k-means-造框" class="headerlink" title="4. k-means 造框"></a>4. k-means 造框</h2><p>如果 Anchor boxes 的尺寸选得好，那么就使得网络更容易去学习。刚开始我以为反正网络预测的都是 Bounding Boxes 的偏移量，那么 Anchor boxes 尺寸就没那么重要了。但我在复现算法和写代码的过程中发现，看来我还是太年轻了。我使用的是 synthetic_dataset 数据集进行训练，该数据集里所有检测的目标都为 “person”，假如我直接用作者论文里的原始 anchor，那么得到的正样本为如下左图；而如果我使用 k-means算法对该数据集所有的 ground-truth boxes 进行聚类得到的 anchor，那么效果就如下右图所示，显然后者的效果比前者好得多。</p>
<table>
<thead>
<tr>
<th align="center">论文原始 anchor</th>
<th align="center">k-means 的 anchor</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><img src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Faster-rcnn-%E9%87%8C%E7%9A%84%E5%8C%BA%E5%9F%9F%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9CRPN-20210508221346.png" alt="论文原始 anchor"></td>
<td align="center"><img src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Faster-rcnn-%E9%87%8C%E7%9A%84%E5%8C%BA%E5%9F%9F%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9CRPN-20210508221350.png" alt="k-means 的 anchor"></td>
</tr>
</tbody></table>
<p>不仅如此，事实上一些其他超参数也会影响正负样本的分布情况，从而直接影响到网络的学习过程。所有这些事实都告诉我们，学习神经网络不能靠从网上看一些浅显的教程就够了的，关键还得自己去多多看源码并实践，才能成为一名合格的深度学习炼丹师。</p>
<table>
<thead>
<tr>
<th align="center">pos_thresh=0.2, neg_thresh=0.1</th>
<th align="center">pos_thresh=0.7, neg_thresh=0.2</th>
</tr>
</thead>
<tbody><tr>
<td align="center"><img src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Faster-rcnn-%E9%87%8C%E7%9A%84%E5%8C%BA%E5%9F%9F%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9CRPN-20210508221358.png" alt="pos_thresh=0.2, neg_thresh=0.1"></td>
<td align="center"><img src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Faster-rcnn-%E9%87%8C%E7%9A%84%E5%8C%BA%E5%9F%9F%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9CRPN-20210508221405.png" alt="pos_thresh=0.7, neg_thresh=0.2"></td>
</tr>
</tbody></table>
<p>最后在测试集上的效果，还是非常赞的! 训练的 score loss基本降到了零，boxes loss 也是非常非常低。但是由于是 RPN 网络，所以我们又不能对它抱太大期望，不然 Faster-RCNN 后面更精确的回归层和分类层意义就不大了。按照对这个算法的理解，我用 TensorFlow 对它进行了复现，感兴趣的话可以看看<a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/4-Object_Detection/RPN">这里</a>。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li>[1] Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun. <a href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a>, CVPR 2016</li>
<li>[2] Shiyu Huang. <a href="https://arxiv.org/pdf/1703.06283.pdf">Expecting the Unexpected:Training Detectors for Unusual Pedestrians with Adversarial Imposters</a>, CVPR 2017</li>
</ul>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>Faster-rcnn</tag>
      </tags>
  </entry>
  <entry>
    <title>全卷积神经网络（FCN)</title>
    <url>/2019/07/12/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CFCN/</url>
    <content><![CDATA[<p>在我还是实习生的时候，我们组的 leader 讲了 FCN 网络。由于当时对图像分割还不是很了解，所以也没太听懂，只记得他当时讲这篇文章拿了 CVPR-2015 的最佳论文奖。现在学习 FCN 就觉得，这应该是图像分割领域里最经典也是最适合入门的网络了吧。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/全卷积神经网络FCN-20210508214559.png">
</p>

<span id="more"></span>

<h2 id="1-分割思想"><a href="#1-分割思想" class="headerlink" title="1. 分割思想"></a>1. 分割思想</h2><p>在我的代码里，使用了 VGG16 作为 backbone 来提取图片特征（其实作者也使用了 VGG19 作为backbone，但是发现效果和 VGG16 差不多)。如果把 FCN 看成是一个黑箱子，那么我们只要关心网络的输入和输出就行了。如果我们使用 VOC 数据集进行训练，输入图片的维度为 [H,W,C]，那么 FCN 输出的 feature map 形状则为 [H, W, 21]。其中，数字 21 代表的 VOC 的 20 个类别还有 1 个背景。</p>
<p>FCN 解决的实际问题就是针对图片里的每个像素进行分类，从而完成精确分割。按照以往 CNN 解决分类问题的思路，一般都会在 feature map 后面接一个全连接层，这个全连接层应该有 21 个神经元，每个神经元输出各个类别的概率。但是由于全连接的特征是一个二维的矩阵，因此我们在全连接层之前会使用 Flatten 层将三维的 feature map 展平。这就带来了2个问题：</p>
<ul>
<li>使用了 Flatten 层抹平了图片的空间信息；</li>
<li>一旦网络训练好，图片的输入尺寸将无法改变。</li>
</ul>
<p>FCN 网络很好地解决了这两个问题，它可以接受任意尺寸的输入图像，并保留了原始输入图像中的空间信息，最后直接在 feature map 上对像素进行分类。</p>
<h2 id="2-跳跃连接"><a href="#2-跳跃连接" class="headerlink" title="2. 跳跃连接"></a>2. 跳跃连接</h2><p>在刚开始的时候，作者将输入图片经过卷积和下采样操作一头走到尾，最后宽和高都被缩放了 32 倍。为了将 feature map 上采样到原来的尺寸，因此作者将 vgg16 的输出扩大了 32 倍，并将该模型称为 FCN-32s。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/全卷积神经网络FCN-20210508214722.jpg">
</p>

<p>但是发现FCN-32s的分割效果并不够好，如下图所示。尽管最后的 feature map 输出经过了 32 倍的上采样操作，但是图片里的边缘细节信息还是被 VGG16 网络里的卷积和下采样操作所模糊掉了。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/全卷积神经网络FCN-20210508214800.png">
</p>

<p>作者把它称作是一个<strong>what</strong>和<strong>where</strong>的问题，请看下面作者的原话：</p>
<blockquote>
<p>Semantic segmentation faces an inherent tension between semantics and location: global information resolves what while local information resolves where.</p>
</blockquote>
<p>说白了就是<strong>全局信息能够预测这个物体是哪个类别，而局部的细粒度信息能够实现对物体的定位与检测</strong>。为了解决这个问题，作者通过缓慢地（分阶段地）对编码特征进行上采样，从浅层添加了“skip connections(跳跃连接)”，并将这两个特征映射相加，并最终将它上采样 8 或者 16 倍进行输出，分别称为 FCN-8s 和 FCN-16s 模型。</p>
<p><img src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9CFCN-20210508214822.png" alt="image"></p>
<p>添加 skip connections 结构后，就能将深层的，粗糙的语义信息与浅层的，精细的表面信息融合起来，从而在一定程度上解决图像边缘分割效果较差的问题。</p>
<blockquote>
<p>We define a skip architecture to take advantage of this feature spectrum that combines deep, coarse, semantic information and shallow, fine, appearance information</p>
</blockquote>
<p><strong>这里需要抛出一个问题，为什么这个 “跳跃连接” 这么牛逼有效?</strong></p>
<p>这还得从感受野(Receptive Field)说起，卷积神经网络中感受野的定义是卷积神经网络每一层输出的特征图（feature map）上的像素点在输入图片上映射的区域大小。再通俗点的解释是，特征图上的一个点对应输入原来图片上的区域。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/全卷积神经网络FCN-20210508214830.png">
</p>

<p>前面讲到深层的特征图在空间尺寸上往往会越来越小，这就意味着它的感受野区域会越来越大，从而更富含图片的全局信息，能较好地解决 what 问题；浅层特征图的空间尺寸较大，这就意味着它的感受野会更小，因而容易捕捉到物体的边缘信息和丰富的细粒特征,能较好地解决 where 问题。感受野大的特征，可以很容易的识别出大物体的，但是在实际分割中，<strong>大物体边缘信息和小物体本身是很容易被深层网络一次次的降采样和一次次升采样给弄丢的，这个时候就可能需要感受野小的特征来帮助</strong>。</p>
<blockquote>
<p>在上图中，如果把 conv1 和 conv2 分别比作浅层特征和深层特征的话。那么深层特征里一个数字 “5” 的感受野尺寸就是 3x3，而浅层特征里 4 个 数字 “3” 的感受野也是这个区域，但是平均下来 1 个数字 “3” 的感受野尺寸则 1x1 都不到。</p>
</blockquote>
<p><strong>深层特征的感受野较大，浅层特征的感受野较小，它们分别解决 what 和 where 问题。反正如果将它们联合起来，那就牛逼了！</strong></p>
<h2 id="3-反卷积层"><a href="#3-反卷积层" class="headerlink" title="3. 反卷积层"></a>3. 反卷积层</h2><p>FCN的上采样层使用的是反卷积层，反卷积也称为转置卷积操作(Transposed convolution)。要了解反卷积是怎么回事，得先回顾一下正向卷积的实现过程。假设输入的图片 input 尺寸为 4x4，元素矩阵为:</p>
<p align="center">
    <img width="37%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/全卷积神经网络FCN-20210508214844.jpg">
</p>

<p>卷积核的尺寸为 3x3，其元素矩阵为：</p>
<p align="center">
    <img width="23%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/全卷积神经网络FCN-20210508214850.jpg">
</p>

<p>正向卷积操作：步长 strides = 1, 填充 padding = 0,输出形状为 2x2，该过程如下图所示：</p>
<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/全卷积神经网络FCN-20210508214920.gif">
</p>

<p>在上面这幅图中，底端为输入，上端为输出，卷积核为 3x3。如果我们用矩阵乘法去描述这个过程: 把 input 元素矩阵展开成一个列向量 X</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/全卷积神经网络FCN-20210508214856.jpg">
</p>

<p>把输出图像 output 的元素矩阵展开成一个列向量 Y</p>
<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/全卷积神经网络FCN-20210508214901.jpg">
</p>

<p>对于输入元素矩阵 X 和输出元素矩阵 Y ，用矩阵运算描述这个过程:</p>
<p align="center">
    <img width="9%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/全卷积神经网络FCN-20210508214904.jpg">
</p>

<p>通过推导，我们可以获得稀疏矩阵 C</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/全卷积神经网络FCN-20210508214908.jpg">
</p>

<p>稀疏矩阵 C 的形状为 4x16, X 形状为 16x1，Y 的形状为 4x1，将 Y 进行 reshape 后便是我们的期望输出形状 2x2。那么，反卷积的操作就是要对这个矩阵运算过程进行转置，通过输出 Y 得到输入 X：</p>
<p align="center">
    <img width="9%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/全卷积神经网络FCN-20210508214904.jpg">
</p>

<p>从矩阵元素形状的角度出发，可以理解为：16x1=16x4x4x1，下面这个动画比较生动地描述了反卷积过程:</p>
<p align="center">
    <img width="10%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/全卷积神经网络FCN-20210508214910.jpg">
</p>

<p>值得注意的是，反卷积操作并不是卷积操作的可逆过程，也就是说图像经过卷积操作后是不能通过反卷积操作恢复原来的样子。这是因为反卷积只是转置运算，并非可逆运算。</p>
<h2 id="4-数据处理"><a href="#4-数据处理" class="headerlink" title="4. 数据处理"></a>4. 数据处理</h2><p>在 PASCAL VOC 数据集中，每个类别对应一个色彩【RGB】, 因此我们需要对SegmentationClass文件夹里的每张 mask 图片根据像素的色彩来标定其类别，在代码 parser_voc.py是这样进行处理的。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(H):</span><br><span class="line">   write_line = []</span><br><span class="line">   <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(W):</span><br><span class="line">   	pixel_color = label_image[i, j].tolist() <span class="comment"># 得到该像素点的 RGB 值</span></span><br><span class="line">        <span class="keyword">if</span> pixel_color <span class="keyword">in</span> colormap:</span><br><span class="line">       	    cls_idx = colormap.index(pixel_color) <span class="comment"># 索引该 RGB 值的类别</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            cls_idx = <span class="number">0</span></span><br></pre></td></tr></table></figure>


<blockquote>
<p>考虑到在批量训练图片时的 batch_size &gt;= 1，因此必须将图片 resize 成相同的尺寸，这里采用的是最近邻插值法，从而保证新插值的像素分类问题。</p>
</blockquote>
<h2 id="5-模型训练"><a href="#5-模型训练" class="headerlink" title="5. 模型训练"></a>5. 模型训练</h2><p>如果你要训练 FCN-8s 的话，还是推荐你加载 VGG16 模型的，否则会变得非常耗时。还有一点的就是，其实训练图片里的像素类别是非常不均衡的。例如 75% 的图片像素都属于背景（见上图），因此你会发现在训练时其精度很快就达到了80%，但此时的预测结果却是一片黑，即预测的类别都为背景。</p>
<p>一般对于语义分割的训练，学术界有两种办法： Patchwise training 和类别损失加权的方法来进行训练。</p>
<ul>
<li>Patchwise training: 补丁式训练方法，它旨在避免全图像训练的冗余。在语义分割中，由于要对图像中的每个像素进行分类，如果输入整个图像可能会有大量的冗余。因此在训练分割网络时，避免这种情况的一种标准方法是从训练集而不是完整图像中给网络提供成批的随机补丁（感兴趣对象周围的小图像区域）。从另一种角度出发，我们也可以使得这些补丁区域尽量减少背景信息，从而缓解类别不均衡问题。</li>
<li>类别损失加权: 根据类别数量的分布比例对各自的损失函数进行加权，比如有些样本的数量较少，我就给它的损失函数比重增大一些。</li>
</ul>
<p>对此，作者根据实验结果非常霸气地放话了：</p>
<blockquote>
<p> explore training with sampling in Section 4.3, and do not find that it yields faster or better convergence for dense prediction. Whole image training is effective and efficient.</p>
</blockquote>
<p>补丁式训练完全没有必要，训练 FCN 还是输入整张图片比较好。并且解决这种类别不均衡的问题，只需要给损失函数按比例加权重就行。最后作者还对此进行了学术上的解释，我这里就不讲了，话讲多了你们会觉得我在胡言乱语…</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li>[1] Jonathan Long, Evan Shelhamer, Trevor Darrell. <a href="https://arxiv.org/abs/1411.4038">Fully Convolutional Networks for Semantic Segmentation</a>. CVPR 2015</li>
<li>[2] TensorFlow2.0-Example code: <a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/5-Image_Segmentation/FCN">FCN</a></li>
</ul>
]]></content>
      <categories>
        <category>图像分割</category>
      </categories>
      <tags>
        <tag>全卷积网络</tag>
        <tag>Skip Connection</tag>
      </tags>
  </entry>
  <entry>
    <title>批量归一化层（Batch Normalization)</title>
    <url>/2019/07/09/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96%E5%B1%82Batch-Normalization/</url>
    <content><![CDATA[<p>通常来说，数据标准化预处理对于浅层模型就足够有效了。<font color=red>但随着模型训练的进行，当每层中参数更新时，靠近输出层的输出容易出现剧烈变化。这令我们难以训练出有效的深度模型，而批量归一化（batch normalization）的提出正是为了应对这种挑战。</font></p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/批量归一化层Batch-Normalization-20210508220832.jpg"></p>

<span id="more"></span>

<h2 id="1-BN-来源"><a href="#1-BN-来源" class="headerlink" title="1. BN 来源"></a>1. BN 来源</h2><p>在机器学习领域中，满足一个很重要的假设，即独立同分布的假设：就是假设训练数据和测试数据是满足相同分布的，这样通过训练数据获得的模型就能够在测试集获得一个较好的效果。而在实际的神经网络模型训练中，隐层的每一层数据分布老是变来变去的，这就是所谓的 <font color=red><strong>“Internal Covariate Shift”</strong></font>。</p>
<p>在这种背景下，然后就提出了 BatchNorm 的基本思想：<strong>能不能让每个隐层节点的<font color=red>激活输入分布</font>固定下来呢？</strong></p>
<p>BN不是凭空拍脑袋拍出来的好点子，它是有启发来源的：之前的研究表明如果在图像处理中对输入图像进行白化（Whiten）操作的话 —— <font color=red><strong>所谓白化，就是对输入数据分布变换到 0 均值，单位方差的正态分布</strong></font> —— 因此 BN 作者推断，如果对神经网络的每一层输出做白化操作的话，模型应该也会较快收敛。</p>
<h2 id="2-计算过程"><a href="#2-计算过程" class="headerlink" title="2. 计算过程"></a>2. 计算过程</h2><p>首先对小批量的样本数据求均值和方差：</p>
<p align="center">
    <img width="35%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/批量归一化层Batch-Normalization-20210508220839.jpg"></p>


<p>接下来，使用按元素开方和按元素除法对样本数据进行标准化:</p>
<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/批量归一化层Batch-Normalization-20210508220842.jpg"></p>

<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/批量归一化层Batch-Normalization-20210508220845.jpg"></p>

<p>这里 ε &gt; 0是一个很小的常数，保证分母大于 0。在上面标准化的基础上，批量归一化层引入了<strong>两个需要学习的参数：拉伸(scale)参数 γ 和偏移(shift)参数 β。</strong><font color=red>这两个参数会把标准正态分布左移或者右移一点并长胖一点或者变瘦一点，从而使得网络每一层的数据分布保持相似。</font></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> d2lzh <span class="keyword">as</span> d2l</span><br><span class="line"><span class="keyword">from</span> mxnet <span class="keyword">import</span> autograd, gluon, init, nd</span><br><span class="line"><span class="keyword">from</span> mxnet.gluon <span class="keyword">import</span> nn</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">batch_norm</span>(<span class="params">X, gamma, beta, moving_mean, moving_var, eps, momentum</span>):</span></span><br><span class="line">    <span class="comment"># 通过autograd来判断当前模式是训练模式还是预测模式</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> autograd.is_training():</span><br><span class="line">        <span class="comment"># 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差</span></span><br><span class="line">        X_hat = (X - moving_mean) / nd.sqrt(moving_var + eps)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">len</span>(X.shape) <span class="keyword">in</span> (<span class="number">2</span>, <span class="number">4</span>)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(X.shape) == <span class="number">2</span>:</span><br><span class="line">            <span class="comment"># 使用全连接层的情况，计算特征维上的均值和方差</span></span><br><span class="line">            mean = X.mean(axis=<span class="number">0</span>)</span><br><span class="line">            var = ((X - mean) ** <span class="number">2</span>).mean(axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 使用二维卷积层的情况，计算通道维上(axis=1)的均值和方差。这里我们需要保持</span></span><br><span class="line">            <span class="comment"># X的形状以便后面可以做广播运算</span></span><br><span class="line">            mean = X.mean(axis=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">            var = ((X - mean) ** <span class="number">2</span>).mean(axis=(<span class="number">0</span>, <span class="number">2</span>, <span class="number">3</span>), keepdims=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 训练模式下用当前的均值和方差做标准化</span></span><br><span class="line">        X_hat = (X - mean) / nd.sqrt(var + eps)</span><br><span class="line">        <span class="comment"># 更新移动平均的均值和方差</span></span><br><span class="line">        moving_mean = momentum * moving_mean + (<span class="number">1.0</span> - momentum) * mean</span><br><span class="line">        moving_var = momentum * moving_var + (<span class="number">1.0</span> - momentum) * var</span><br><span class="line"></span><br><span class="line">    Y = gamma * X_hat + beta <span class="comment"># 拉伸和偏移</span></span><br><span class="line">    <span class="keyword">return</span> Y, moving_mean, moving_var</span><br></pre></td></tr></table></figure>

<h2 id="3-BN-位置"><a href="#3-BN-位置" class="headerlink" title="3. BN 位置"></a>3. BN 位置</h2><p>在 <a href="https://arxiv.org/pdf/1502.03167.pdf">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a> 一文中，作者指出，“we would like to ensure that for any parameter values, the network always produces activations with the desired distribution”（produces activations with the desired distribution，<font color=red><strong>为激活层提供期望的分布</strong></font>）。</p>
<table><tr><td bgcolor= LightSalmon><strong>因此 `Batch Normalization` 层恰恰插入在 conv 层或全连接层之后，而在 relu 等激活层之前。</strong></td></tr></table>

<h2 id="4-BN-优点"><a href="#4-BN-优点" class="headerlink" title="4. BN 优点"></a>4. BN 优点</h2><ul>
<li><strong><font color=red>解决了 Internal Covariate Shift 的问题</font></strong>：模型训练会更加稳定，学习率也可以设大一点，同时也减少了对权重参数初始化的依赖；</li>
<li><strong><font color=red>对防止 gradient vanish 有帮助</font></strong>：一旦有了 Batch Normalization，激活函数的 input 都在零附近，都是斜率比较大的地方，能有效减少梯度消失；</li>
<li><strong><font color=red>能有效减少过拟合</font></strong>：据我所知，自从有了 Batch Normaliztion 后，就没有人用 Dropout 了。直观的理解是：对网络的每一层 layer 做了 BN 处理来强制它们的数据分布相似，这相当于对每一层的输入做了约束（regularization）。</li>
</ul>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li>[1] 李沐，动手深度学习. 2019.9.12</li>
<li>[2] <a href="https://arxiv.org/pdf/1502.03167.pdf">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>Batch Normalization</tag>
      </tags>
  </entry>
  <entry>
    <title>TensorFlow 模型转化 tflite</title>
    <url>/2019/05/16/Tensorflow-%E6%A8%A1%E5%9E%8B%E8%BD%AC%E5%8C%96-tflite/</url>
    <content><![CDATA[<p>自从有了TensorFlow Lite，应用开发者可以在移动设备上很轻松地部署神经网络。</p>
<p align="center">
    <img width="90%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Tensorflow-模型转化-tflite-20210508220505.jpg">
</p>

<span id="more"></span>

<p>Tensorflow Lite 转化器可以将我们的训练模型转化成 <code>.tflite</code> 文件，它分别支持 <a href="https://tensorflow.google.cn/guide/saved_model"><font color=Red>SavedModel directories</font></a>, <a href="https://tensorflow.org/guide/concrete_function"><font color=Red>concrete functions</font></a> 和 <a href="https://tensorflow.google.cn/guide/keras/overview"><font color=Red>tf.keras models</font></a>三种结构。由于我经常使用的是 <code>tf.keras.model</code> 结构，因此只对它进行详细介绍。</p>
<p>以 mtcnn 网络的 rnet 模型为例：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RNet</span>(<span class="params">tf.keras.Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.conv1 = tf.keras.layers.Conv2D(<span class="number">28</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&#x27;conv1&#x27;</span>)</span><br><span class="line">        self.prelu1 = tf.keras.layers.PReLU(shared_axes=[<span class="number">1</span>,<span class="number">2</span>], name=<span class="string">&quot;prelu1&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.conv2 = tf.keras.layers.Conv2D(<span class="number">48</span>, <span class="number">3</span>, <span class="number">1</span>, name=<span class="string">&#x27;conv2&#x27;</span>)</span><br><span class="line">        self.prelu2 = tf.keras.layers.PReLU(shared_axes=[<span class="number">1</span>,<span class="number">2</span>], name=<span class="string">&quot;prelu2&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.conv3 = tf.keras.layers.Conv2D(<span class="number">64</span>, <span class="number">2</span>, <span class="number">1</span>, name=<span class="string">&#x27;conv3&#x27;</span>)</span><br><span class="line">        self.prelu3 = tf.keras.layers.PReLU(shared_axes=[<span class="number">1</span>,<span class="number">2</span>], name=<span class="string">&quot;prelu3&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.dense4 = tf.keras.layers.Dense(<span class="number">128</span>, name=<span class="string">&#x27;conv4&#x27;</span>)</span><br><span class="line">        self.prelu4 = tf.keras.layers.PReLU(shared_axes=<span class="literal">None</span>, name=<span class="string">&quot;prelu4&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.dense5_1 = tf.keras.layers.Dense(<span class="number">2</span>, name=<span class="string">&quot;conv5-1&quot;</span>)</span><br><span class="line">        self.dense5_2 = tf.keras.layers.Dense(<span class="number">4</span>, name=<span class="string">&quot;conv5-2&quot;</span>)</span><br><span class="line"></span><br><span class="line">        self.flatten = tf.keras.layers.Flatten()</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x, training=<span class="literal">False</span></span>):</span></span><br><span class="line">        out = self.prelu1(self.conv1(x))</span><br><span class="line">        out = tf.nn.max_pool2d(out, <span class="number">3</span>, <span class="number">2</span>, padding=<span class="string">&quot;SAME&quot;</span>)</span><br><span class="line">        out = self.prelu2(self.conv2(out))</span><br><span class="line">        out = tf.nn.max_pool2d(out, <span class="number">3</span>, <span class="number">2</span>, padding=<span class="string">&quot;VALID&quot;</span>)</span><br><span class="line">        out = self.prelu3(self.conv3(out))</span><br><span class="line">        out = self.flatten(out)</span><br><span class="line">        out = self.prelu4(self.dense4(out))</span><br><span class="line">        score = tf.nn.softmax(self.dense5_1(out), -<span class="number">1</span>)</span><br><span class="line">        boxes = self.dense5_2(out)</span><br><span class="line">        <span class="keyword">return</span> boxes, score</span><br></pre></td></tr></table></figure>

<p>接下来就是对模型进行转化和量化了，转换器可以配置为应用各种优化措施（optimizations），这些优化措施可以提高性能，减少文件大小。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rnet.predict(tf.ones(shape=[<span class="number">1</span>, <span class="number">24</span>, <span class="number">24</span>, <span class="number">3</span>]))</span><br><span class="line">rnet_converter = tf.lite.TFLiteConverter.from_keras_model(rnet)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 量化（quantization）可以减小模型的大小和推理所需的时间</span></span><br><span class="line">rnet_converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存 tflite 模型</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;rnet.tflite&quot;</span>, <span class="string">&quot;wb&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    rnet_tflite_model = rnet_converter.convert()</span><br><span class="line">    f.write(rnet_tflite_model)</span><br></pre></td></tr></table></figure>

<p>参考文献:</p>
<ul>
<li>[1] <a href="https://tensorflow.google.cn/lite/guide/get_started#4_optimize_your_model_optional">TensorFlow 中文开发指南</a></li>
<li>[2] <a href="https://github.com/YunYang1994/TensorFlow2.0-Examples/blob/master/4-Object_Detection/MTCNN/mtcnn.py">TensorFlow2.0-Example</a></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>移动端部署</tag>
      </tags>
  </entry>
  <entry>
    <title>YOLOv3 算法的一点理解</title>
    <url>/2018/12/28/YOLOv3-%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%80%E7%82%B9%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<p>今天讲一讲 YOLOv3, 目标检测网络的巅峰之作, 疾如风，快如闪电。</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508222438.jpg">
</p>

<span id="more"></span>

<h2 id="1-算法背景"><a href="#1-算法背景" class="headerlink" title="1. 算法背景"></a>1. 算法背景</h2><p>假设我们想对下面这张 416 X 416 大小的图片进行预测，把图中 dog、bicycle 和 car 三种物体给框出来，这涉及到以下三个过程：</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508222628.png">
</p>

<ul>
<li>怎么在图片上找出很多有价值的候选框？</li>
<li>接着判断候选框里有没有物体？</li>
<li>如果有物体的话，那么它属于哪个类别？</li>
</ul>
<p>听起来就像把大象装进冰箱，分三步走。事实上，目前的 anchor-based 机制算法例如 RCNN、Faster rcnn 以及 YOLO 算法都是这个思想。最早的时候，RCNN 是这么干的，它首先利用 Selective Search 的方法通过图片上像素之间的相似度和纹理特征进行区域合并，然后提出很多候选框并喂给 CNN 网络提取出特征向量 (embeddings)，最后利用特征向量训练 SVM 来对目标和背景进行分类。</p>
<p><img src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%80%E7%82%B9%E7%90%86%E8%A7%A3-20210508222725.jpg" alt="RCNN 结构"></p>
<p>这是最早利用神经网络进行目标检测的开山之作，虽然现在看来有不少瑕疵，例如：</p>
<ul>
<li>Selective Search 会在图片上提取2000个候选区域，每个候选区域都会喂给 CNN 进行特征提取，这个过程太冗余啦，其实这些候选区域之间很多特征其实是可以共享的；</li>
<li>由于 CNN 最后一层是全连接层，因此输入图片的尺寸大小也有限制，只能进行 Crop 或者 Warp，这样一来图片就会扭曲、变形和失真；</li>
<li>在利用 SVM 分类器对候选框进行分类的时候，每个候选框的特征向量都要保留在磁盘上，很浪费空间！</li>
</ul>
<p>尽管如此，但仍不可否认它具有划时代的意义，至少告诉后人我们是可以利用神经网络进行目标检测的。后面，一些大神们在此基础上提出了很多改进，从 Fast RCNN 到 Faster RCNN 再到 Mask RCNN, 目标检测的 region proposal 过程变得越来越有针对性，并提出了著名的 RPN 网络去学习如何给出高质量的候选框，然后再去判断所属物体的类别。简单说来就是: 提出候选框，然后分类，这就是我们常说的 two-stage 算法。two-stage 算法的好处就是精度较高，但是检测速度满足不了实时性的要求。</p>
<p>在这样的背景下，YOLO 算法横空出世，江湖震惊！</p>
<h2 id="2-YOLO-算法简介"><a href="#2-YOLO-算法简介" class="headerlink" title="2. YOLO 算法简介"></a>2. YOLO 算法简介</h2><h3 id="2-1-发展历程"><a href="#2-1-发展历程" class="headerlink" title="2.1 发展历程"></a>2.1 发展历程</h3><p>2015 年 Redmon J 等提出 YOLO 网络, 其特点是将生成候选框与分类回归合并成一个步骤, 预测时特征图被分成 7x7 个 cell, 对每个 cell 进行预测, 这就大大降低了计算复杂度, 加快了目标检测的速度, 帧率最高可达 45 fps！</p>
<p>时隔一年，Redmon J 再次提出了YOLOv2, 与前代相比, 在VOC2007 测试集上的 mAP 由 67.4% 提高到 78.6%, 然而由于一个 cell 只负责预测一个物体, 面对重叠性的目标的识别得并不够好。</p>
<p>最终在 2018 年 4 月, 作者又发布了第三个版本 YOLOv3, 在 COCO 数据集上的 mAP-50 由 YOLOv2 的 44.0% 提高到 57.9%, 与 mAP 61.1% 的 RetinaNet 相比, RetinaNet 在输入尺寸 500×500 的情况下检测速度约 98 ms/帧, 而 YOLOv3 在输入尺寸 416×416 时检测速 度可达 29 ms/帧。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508223027.jpg">
</p>

<p>上面这张图足以秒杀一切, 说明 YOLOv3 在保证速度的前提下, 也达到了很高的准确率。</p>
<h3 id="2-2-基本思想"><a href="#2-2-基本思想" class="headerlink" title="2.2 基本思想"></a>2.2 基本思想</h3><p>作者在YOLO算法中把物体检测（object detection）问题处理成回归问题，并将图像分为S×S的网格。如果一个目标的中心落入格子，该格子就负责检测该目标。</p>
<blockquote>
<p>If the center of an object falls into a grid cell, that grid cell is responsible for detecting that object.</p>
</blockquote>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508223111.jpg">
</p>

<p>每个网格都会输出 bounding box，confidence 和 class probability map。其中：</p>
<ul>
<li>bounding box 包含4个值：x，y，w，h，（x，y）代表 box 的中心。（w，h）代表 box 的宽和高；</li>
<li>confidence 表示这个预测框中包含物体的概率，其实也是预测框与真实框之间的 iou 值;</li>
<li>class probability 表示的是该物体的类别概率，在 YOLOv3 中采用的是二分类的方法。</li>
</ul>
<h2 id="3-网络结构"><a href="#3-网络结构" class="headerlink" title="3. 网络结构"></a>3. 网络结构</h2><p>下面这幅图就是 YOLOv3 网络的整体结构，在图中我们可以看到：尺寸为 416X416 的输入图片进入 Darknet-53 网络后得到了 3 个分支，这些分支在经过一系列的卷积、上采样以及合并等操作后最终得到了三个尺寸不一的 feature map，形状分别为 [13, 13, 255]、[26, 26, 255] 和 [52, 52, 255]。</p>
<p><img src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%80%E7%82%B9%E7%90%86%E8%A7%A3-20210508223144.png" alt="YOLOv3 的网络结构"></p>
<p>讲了这么多，还是不如看代码来得亲切。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">YOLOv3</span>(<span class="params">input_layer</span>):</span></span><br><span class="line">    <span class="comment"># 输入层进入 Darknet-53 网络后，得到了三个分支</span></span><br><span class="line">    route_1, route_2, conv = backbone.darknet53(input_layer)</span><br><span class="line">    <span class="comment"># 见上图中的橘黄色模块(DBL)，一共需要进行5次卷积操作</span></span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>,  <span class="number">512</span>))</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">3</span>, <span class="number">3</span>,  <span class="number">512</span>, <span class="number">1024</span>))</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>,  <span class="number">512</span>))</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">3</span>, <span class="number">3</span>,  <span class="number">512</span>, <span class="number">1024</span>))</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>,  <span class="number">512</span>))</span><br><span class="line">    conv_lobj_branch = common.convolutional(conv, (<span class="number">3</span>, <span class="number">3</span>, <span class="number">512</span>, <span class="number">1024</span>))</span><br><span class="line">    <span class="comment"># conv_lbbox 用于预测大尺寸物体，shape = [None, 13, 13, 255]</span></span><br><span class="line">    conv_lbbox = common.convolutional(conv_lobj_branch, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">1024</span>, <span class="number">3</span>*(NUM_CLASS + <span class="number">5</span>)), </span><br><span class="line">                                                            activate=<span class="literal">False</span>, bn=<span class="literal">False</span>)</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">1</span>, <span class="number">1</span>,  <span class="number">512</span>,  <span class="number">256</span>))</span><br><span class="line">    <span class="comment"># 这里的 upsample 使用的是最近邻插值方法，这样的好处在于上采样过程不需要学习，从而减少了网络参数</span></span><br><span class="line">    conv = common.upsample(conv)</span><br><span class="line">    conv = tf.concat([conv, route_2], axis=-<span class="number">1</span>)</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">768</span>, <span class="number">256</span>))</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">512</span>))</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">512</span>, <span class="number">256</span>))</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">512</span>))</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">512</span>, <span class="number">256</span>))</span><br><span class="line">    conv_mobj_branch = common.convolutional(conv, (<span class="number">3</span>, <span class="number">3</span>, <span class="number">256</span>, <span class="number">512</span>))</span><br><span class="line">    <span class="comment"># conv_mbbox 用于预测中等尺寸物体，shape = [None, 26, 26, 255]</span></span><br><span class="line">    conv_mbbox = common.convolutional(conv_mobj_branch, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">512</span>, <span class="number">3</span>*(NUM_CLASS + <span class="number">5</span>)),</span><br><span class="line">                                                            activate=<span class="literal">False</span>, bn=<span class="literal">False</span>)</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">128</span>))</span><br><span class="line">    conv = common.upsample(conv)</span><br><span class="line">    conv = tf.concat([conv, route_1], axis=-<span class="number">1</span>)</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">384</span>, <span class="number">128</span>))</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">3</span>, <span class="number">3</span>, <span class="number">128</span>, <span class="number">256</span>))</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">128</span>))</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">3</span>, <span class="number">3</span>, <span class="number">128</span>, <span class="number">256</span>))</span><br><span class="line">    conv = common.convolutional(conv, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">128</span>))</span><br><span class="line"></span><br><span class="line">    conv_sobj_branch = common.convolutional(conv, (<span class="number">3</span>, <span class="number">3</span>, <span class="number">128</span>, <span class="number">256</span>))</span><br><span class="line">    <span class="comment"># conv_sbbox 用于预测小尺寸物体，shape = [None, 52, 52, 255]</span></span><br><span class="line">    conv_sbbox = common.convolutional(conv_sobj_branch, (<span class="number">1</span>, <span class="number">1</span>, <span class="number">256</span>, <span class="number">3</span>*(NUM_CLASS +<span class="number">5</span>)), </span><br><span class="line">                                                            activate=<span class="literal">False</span>, bn=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">return</span> [conv_sbbox, conv_mbbox, conv_lbbox]</span><br></pre></td></tr></table></figure>

<h3 id="3-1-Darknet53-结构"><a href="#3-1-Darknet53-结构" class="headerlink" title="3.1 Darknet53 结构"></a>3.1 Darknet53 结构</h3><p>Darknet-53 的主体框架如下图所示，它主要由 Convolutional 和 Residual 结构所组成。需要特别注意的是，最后三层 Avgpool、Connected 和 softmax layer 是用于在 Imagenet 数据集上作分类训练用的。当我们用 Darknet-53 层对图片提取特征时，是不会用到这三层的。</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508223229.png">
</p>

<p>Darknet-53 有多牛逼？看看下面这张图，作者进行了比较，得出的结论是 Darknet-53 在精度上可以与最先进的分类器进行媲美，同时它的浮点运算更少，计算速度也最快。和 ReseNet-101 相比，Darknet-53 网络的速度是前者的1.5倍；虽然 ReseNet-152 和它性能相似，但是用时却是它的2倍以上。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508223238.png">
</p>


<p>此外，Darknet-53 还可以实现每秒最高的测量浮点运算，这就意味着网络结构可以更好地利用 GPU，从而使其测量效率更高，速度也更快。</p>
<h3 id="3-2-Convolutional-结构"><a href="#3-2-Convolutional-结构" class="headerlink" title="3.2 Convolutional 结构"></a>3.2 Convolutional 结构</h3><p>Convolutional 结构其实很简单，就是普通的卷积层，其实没啥讲的。但是对于 if downsample 的情况，初学者可能觉得有点陌生， ZeroPadding2D 是什么层？</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">convolutional</span>(<span class="params">input_layer, filters_shape, downsample=<span class="literal">False</span>, activate=<span class="literal">True</span>, bn=<span class="literal">True</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> downsample:</span><br><span class="line">        input_layer = tf.keras.layers.ZeroPadding2D(((<span class="number">1</span>, <span class="number">0</span>), (<span class="number">1</span>, <span class="number">0</span>)))(input_layer)</span><br><span class="line">        padding = <span class="string">&#x27;valid&#x27;</span></span><br><span class="line">        strides = <span class="number">2</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        strides = <span class="number">1</span></span><br><span class="line">        padding = <span class="string">&#x27;same&#x27;</span></span><br><span class="line">    conv = tf.keras.layers.Conv2D(filters=filters_shape[-<span class="number">1</span>], </span><br><span class="line">                        kernel_size = filters_shape[<span class="number">0</span>], </span><br><span class="line">                        strides=strides, padding=padding, use_bias=<span class="keyword">not</span> bn, </span><br><span class="line">                        kernel_regularizer=tf.keras.regularizers.l2(<span class="number">0.0005</span>),</span><br><span class="line">                        kernel_initializer=tf.random_normal_initializer(stddev=<span class="number">0.01</span>),</span><br><span class="line">                        bias_initializer=tf.constant_initializer(<span class="number">0.</span>))(input_layer)</span><br><span class="line">    <span class="keyword">if</span> bn: conv = BatchNormalization()(conv)</span><br><span class="line">    <span class="keyword">if</span> activate == <span class="literal">True</span>: conv = tf.nn.leaky_relu(conv, alpha=<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">return</span> conv</span><br></pre></td></tr></table></figure>

<p>讲到 ZeroPadding2D层，我们得先了解它是什么，为什么有这个层。对于它的定义，Keras 官方给了很好的解释:</p>
<blockquote>
<p>keras.layers.convolutional.ZeroPadding2D(padding=(1, 1), data_format=None) 说明: 对2D输入（如图片）的边界填充0，以控制卷积以后特征图的大小</p>
</blockquote>
<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508223350.gif">
</p>

<p>其实就是对图片的上下左右四个边界填充0而已，padding=((top_pad, bottom_pad), (left_pad, right_pad))。 很简单吧，快打开你的 ipython 试试吧！</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">In [<span class="number">2</span>]: x=tf.keras.layers.Input([<span class="number">416</span>,<span class="number">416</span>,<span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">In [<span class="number">3</span>]: tf.keras.layers.ZeroPadding2D(padding=((<span class="number">1</span>,<span class="number">0</span>),(<span class="number">1</span>,<span class="number">0</span>)))(x)</span><br><span class="line">Out[<span class="number">3</span>]: &lt;tf.Tensor <span class="string">&#x27;zero_padding2d/Identity:0&#x27;</span> shape=(<span class="literal">None</span>, <span class="number">417</span>, <span class="number">417</span>, <span class="number">3</span>) dtype=float32&gt;</span><br><span class="line"></span><br><span class="line">In [<span class="number">4</span>]: tf.keras.layers.ZeroPadding2D(padding=((<span class="number">1</span>,<span class="number">1</span>),(<span class="number">1</span>,<span class="number">1</span>)))(x)</span><br><span class="line">Out[<span class="number">4</span>]: &lt;tf.Tensor <span class="string">&#x27;zero_padding2d_1/Identity:0&#x27;</span> shape=(<span class="literal">None</span>, <span class="number">418</span>, <span class="number">418</span>, <span class="number">3</span>) dtype=float32&gt;</span><br></pre></td></tr></table></figure>

<h3 id="3-3-Residual-残差模块"><a href="#3-3-Residual-残差模块" class="headerlink" title="3.3 Residual 残差模块"></a>3.3 Residual 残差模块</h3><p>残差模块最显著的特点是使用了 short cut 机制（有点类似于电路中的短路机制）来缓解在神经网络中增加深度带来的梯度消失问题，从而使得神经网络变得更容易优化。它通过恒等映射(identity mapping)的方法使得输入和输出之间建立了一条直接的关联通道，从而使得网络集中学习输入和输出之间的残差。</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508223443.png">
</p>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">residual_block</span>(<span class="params">input_layer, input_channel, filter_num1, filter_num2</span>):</span></span><br><span class="line">    short_cut = input_layer</span><br><span class="line">    conv = convolutional(input_layer, filters_shape=(<span class="number">1</span>, <span class="number">1</span>, input_channel, filter_num1))</span><br><span class="line">    conv = convolutional(conv       , filters_shape=(<span class="number">3</span>, <span class="number">3</span>, filter_num1,   filter_num2))</span><br><span class="line">    residual_output = short_cut + conv</span><br><span class="line">    <span class="keyword">return</span> residual_output</span><br></pre></td></tr></table></figure>

<h2 id="4-提取特征"><a href="#4-提取特征" class="headerlink" title="4. 提取特征"></a>4. 提取特征</h2><p>要想详细地知道 YOLO 的预测过程，就非常有必要先来了解一下什么是特征映射 (feature map) 和特征向量 (embeddings)。</p>
<h3 id="4-1-特征映射"><a href="#4-1-特征映射" class="headerlink" title="4.1 特征映射"></a>4.1 特征映射</h3><p>当我们谈及 CNN 网络，总能听到 feature map 这个词。它也叫<em>特征映射，简单说来就是输入图像在与卷积核进行卷积操作后得到图像特征</em>。</p>
<p>一般而言，CNN 网络在对图像自底向上提取特征时，feature map 的数量(其实也对应的就是卷积核的数目) 会越来越多，而空间信息会越来越少，其特征也会变得越来越抽象。比如著名的 VGG16 网络，它的 feature map 变化就是这个样子。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508223524.jpg">
</p>

<blockquote>
<p>feature map 在空间尺寸上越来越小，但在通道尺寸上变得越来越深，这就是 VGG16 的特点。</p>
</blockquote>
<h3 id="4-2-特征向量"><a href="#4-2-特征向量" class="headerlink" title="4.2 特征向量"></a>4.2 特征向量</h3><p>讲到 feature map 哦，就不得不提一下人脸识别领域里经常提到的 embedding. 一般来说，它其实就是 feature map 被最后一层全连接层所提取到特征向量。早在2006年，深度学习鼻祖 hinton 就在《SCIENCE》上发表了一篇论文，首次利用自编码网络对 mnist 手写数字提取出了特征向量(一个2维或3维的向量)。值得一提的是，也是这篇论文揭开了深度学习兴起的序幕。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508223557.jpg">
</p>

<p>下面就是上面这张图片里的数字在 CNN 空间里映射后得到的特征向量在2维空间里的样子(假如你对这块感兴趣可以看我<a href="https://github.com/YunYang1994/SphereFace">之前的工作</a>):</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508223850.png">
</p>


<p>前面我们提到：CNN 网络在对图像自底向上提取特征时，得到的 feature map 一般都是在空间尺寸上越来越小，而在通道尺寸上变得越来越深。 那么，为什么要这么做？</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508223605.jpg">
</p>

<p>其实，这就与 ROI (感兴趣区域)映射到 Feature Map 有关。在上面这幅图里：原图里的一块 ROI 在 CNN 网络空间里映射后，在 feature map 上空间尺寸会变得更小，甚至是一个点, 但是这个点的通道信息会很丰富，这些通道信息是 ROI 区域里的图片信息在 CNN 网络里映射得到的特征表示。由于图像中各个相邻像素在空间上的联系很紧密，这在空间上造成具有很大的冗余性。因此，我们往往会通过在空间上降维，而在通道上升维的方式来消除这种冗余性，尽量以最小的维度来获得它最本质的特征。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508224137.jpg">
</p>


<blockquote>
<p>原图左上角红色 ROI 经 CNN 映射后在 feature map 空间上只得到了一个点，但是这个点有85个通道。那么，ROI的维度由原来的 [32, 32, 3] 变成了现在的 85 维，这难道又不是降维打击么？👊</p>
</blockquote>
<p>按照我的理解，这其实就是 CNN 网络对 ROI 进行特征提取后得到的一个 85 维的特征向量。这个特征向量前4个维度代表的是候选框信息，中间这个维度代表是判断有无物体的概率，后面80个维度代表的是对 80 个类别的分类概率信息。</p>
<h2 id="5-如何检测"><a href="#5-如何检测" class="headerlink" title="5. 如何检测"></a>5. 如何检测</h2><h3 id="5-1-多尺度检测"><a href="#5-1-多尺度检测" class="headerlink" title="5.1 多尺度检测"></a>5.1 多尺度检测</h3><p>YOLOv3 对输入图片进行了粗、中和细网格划分，以便分别实现对大、中和小物体的预测。假如输入图片的尺寸为 416X416, 那么得到粗、中和细网格尺寸分别为 13X13、26X26 和 52X52。这样一算，那就是在长宽尺寸上分别缩放了 32、16 和 8 倍。</p>
<p><img src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-%E7%AE%97%E6%B3%95%E7%9A%84%E4%B8%80%E7%82%B9%E7%90%86%E8%A7%A3-20210508224220.png" alt="image"></p>
<h3 id="5-2-decode-处理"><a href="#5-2-decode-处理" class="headerlink" title="5.2 decode 处理"></a>5.2 decode 处理</h3><p>YOLOv3 网络的三个分支输出会被送入 decode 函数中对 Feature Map 的通道信息进行解码。 在下面这幅图里：黑色虚线框代表先验框(anchor)，蓝色框表示的是预测框.</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508224237.png">
</p>


<ul>
<li>$b_{h}$ 和 $b_{w}$ 分别表示预测框的长宽，$P_{h}$ 和 $P_{w}$ 分别表示先验框的长和宽。</li>
<li>$t_{x}$ 和 $t_{y}$ 表示的是物体中心距离网格左上角位置的偏移量，$C_{x}$ 和 $C_{y}$ 则代表网格左上角的坐标。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">decode</span>(<span class="params">conv_output, i=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="comment"># 这里的 i=0、1 或者 2， 以分别对应三种网格尺度</span></span><br><span class="line">    conv_shape  = tf.shape(conv_output)</span><br><span class="line">    batch_size  = conv_shape[<span class="number">0</span>]</span><br><span class="line">    output_size = conv_shape[<span class="number">1</span>]</span><br><span class="line">    conv_output = tf.reshape(conv_output, (batch_size, output_size, </span><br><span class="line">                                           output_size, <span class="number">3</span>, <span class="number">5</span> + NUM_CLASS))</span><br><span class="line">    conv_raw_dxdy = conv_output[:, :, :, :, <span class="number">0</span>:<span class="number">2</span>] <span class="comment"># 中心位置的偏移量</span></span><br><span class="line">    conv_raw_dwdh = conv_output[:, :, :, :, <span class="number">2</span>:<span class="number">4</span>] <span class="comment"># 预测框长宽的偏移量</span></span><br><span class="line">    conv_raw_conf = conv_output[:, :, :, :, <span class="number">4</span>:<span class="number">5</span>] <span class="comment"># 预测框的置信度</span></span><br><span class="line">    conv_raw_prob = conv_output[:, :, :, :, <span class="number">5</span>: ] <span class="comment"># 预测框的类别概率</span></span><br><span class="line">    <span class="comment"># 好了，接下来需要画网格了。其中，output_size 等于 13、26 或者 52</span></span><br><span class="line">    y = tf.tile(tf.<span class="built_in">range</span>(output_size, dtype=tf.int32)[:, tf.newaxis], [<span class="number">1</span>, output_size])</span><br><span class="line">    x = tf.tile(tf.<span class="built_in">range</span>(output_size, dtype=tf.int32)[tf.newaxis, :], [output_size, <span class="number">1</span>])</span><br><span class="line">    xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-<span class="number">1</span>)</span><br><span class="line">    xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], [batch_size, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>])</span><br><span class="line">    xy_grid = tf.cast(xy_grid, tf.float32) <span class="comment"># 计算网格左上角的位置</span></span><br><span class="line">    <span class="comment"># 根据上图公式计算预测框的中心位置</span></span><br><span class="line">    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * STRIDES[i]</span><br><span class="line">    <span class="comment"># 根据上图公式计算预测框的长和宽大小</span></span><br><span class="line">    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS[i]) * STRIDES[i]</span><br><span class="line">    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-<span class="number">1</span>) </span><br><span class="line">    pred_conf = tf.sigmoid(conv_raw_conf) <span class="comment"># 计算预测框里object的置信度</span></span><br><span class="line">    pred_prob = tf.sigmoid(conv_raw_prob) <span class="comment"># 计算预测框里object的类别概率</span></span><br><span class="line">    <span class="keyword">return</span> tf.concat([pred_xywh, pred_conf, pred_prob], axis=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<h3 id="5-3-NMS-处理"><a href="#5-3-NMS-处理" class="headerlink" title="5.3 NMS 处理"></a>5.3 NMS 处理</h3><p>非极大值抑制（Non-Maximum Suppression，NMS），顾名思义就是抑制不是极大值的元素，说白了就是去除掉那些重叠率较高并且 score 评分较低的边界框。 NMS 的算法非常简单，迭代流程如下:</p>
<ul>
<li>流程1: 判断边界框的数目是否大于0，如果不是则结束迭代；</li>
<li>流程2: 按照 socre 排序选出评分最大的边界框 A 并取出；</li>
<li>流程3: 计算这个边界框 A 与剩下所有边界框的 iou 并剔除那些 iou 值高于阈值的边界框，重复上述步骤；</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 流程1: 判断边界框的数目是否大于0</span></span><br><span class="line"><span class="keyword">while</span> <span class="built_in">len</span>(cls_bboxes) &gt; <span class="number">0</span>:</span><br><span class="line">    <span class="comment"># 流程2: 按照 socre 排序选出评分最大的边界框 A</span></span><br><span class="line">    max_ind = np.argmax(cls_bboxes[:, <span class="number">4</span>])</span><br><span class="line">    <span class="comment"># 将边界框 A 取出并剔除</span></span><br><span class="line">    best_bbox = cls_bboxes[max_ind]</span><br><span class="line">    best_bboxes.append(best_bbox)</span><br><span class="line">    cls_bboxes = np.concatenate([cls_bboxes[: max_ind], cls_bboxes[max_ind + <span class="number">1</span>:]])</span><br><span class="line">    <span class="comment"># 流程3: 计算这个边界框 A 与剩下所有边界框的 iou 并剔除那些 iou 值高于阈值的边界框</span></span><br><span class="line">    iou = bboxes_iou(best_bbox[np.newaxis, :<span class="number">4</span>], cls_bboxes[:, :<span class="number">4</span>])</span><br><span class="line">    weight = np.ones((<span class="built_in">len</span>(iou),), dtype=np.float32)</span><br><span class="line">    iou_mask = iou &gt; iou_threshold</span><br><span class="line">    weight[iou_mask] = <span class="number">0.0</span></span><br><span class="line">    cls_bboxes[:, <span class="number">4</span>] = cls_bboxes[:, <span class="number">4</span>] * weight</span><br><span class="line">    score_mask = cls_bboxes[:, <span class="number">4</span>] &gt; <span class="number">0.</span></span><br><span class="line">    cls_bboxes = cls_bboxes[score_mask]</span><br></pre></td></tr></table></figure>

<p>最后所有取出来的边界框 A 就是我们想要的。不妨举个简单的例子：假如5个边界框及评分为: A: 0.9，B: 0.08，C: 0.8, D: 0.6，E: 0.5，设定的评分阈值为 0.3，计算步骤如下。</p>
<ul>
<li>步骤1: 边界框的个数为5，满足迭代条件；</li>
<li>步骤2: 按照 socre 排序选出评分最大的边界框 A 并取出；</li>
<li>步骤3: 计算边界框 A 与其他 4 个边界框的 iou，假设得到的 iou 值为：B: 0.1，C: 0.7, D: 0.02, E: 0.09, 剔除边界框 C;</li>
<li>步骤4: 现在只剩下边界框 B、D、E，满足迭代条件；</li>
<li>步骤5: 按照 socre 排序选出评分最大的边界框 D 并取出；</li>
<li>步骤6: 计算边界框 D 与其他 2 个边界框的 iou，假设得到的 iou 值为：B: 0.06，E: 0.8，剔除边界框 E；</li>
<li>步骤7: 现在只剩下边界框 B，满足迭代条件；</li>
<li>步骤8: 按照 socre 排序选出评分最大的边界框 B 并取出；</li>
<li>步骤9: 此时边界框的个数为零，结束迭代。</li>
</ul>
<p>最后我们得到了边界框 A、B、D，但其中边界框 B 的评分非常低，这表明该边界框是没有物体的，因此应当抛弃掉。在代码中:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># # (5) discard some boxes with low scores</span></span><br><span class="line">classes = np.argmax(pred_prob, axis=-<span class="number">1</span>)</span><br><span class="line">scores = pred_conf * pred_prob[np.arange(<span class="built_in">len</span>(pred_coor)), classes]</span><br><span class="line">score_mask = scores &gt; score_threshold</span><br></pre></td></tr></table></figure>

<blockquote>
<p>在 YOLO 算法中，NMS 的处理有两种情况：一种是所有的预测框一起做 NMS 处理，另一种情况是分别对每个类别的预测框做 NMS 处理。后者会出现一个预测框既属于类别 A 又属于类别 B 的现象，这比较适合于一个小单元格中同时存在多个物体的情况。</p>
</blockquote>
<h2 id="6-anchor-响应机制"><a href="#6-anchor-响应机制" class="headerlink" title="6. anchor 响应机制"></a>6. anchor 响应机制</h2><h3 id="6-1-K-means-聚类"><a href="#6-1-K-means-聚类" class="headerlink" title="6.1 K-means 聚类"></a>6.1 K-means 聚类</h3><p>首先需要抛出一个问题：先验框 anchor 是怎么来的？对于这点，作者在 YOLOv2 论文里给出了很好的解释：</p>
<blockquote>
<p>we run k-means clustering on the training set bounding boxes to automatically find good priors.</p>
</blockquote>
<p>其实就是使用 k-means 算法对训练集上的 boudnding box 尺度做聚类。此外，考虑到训练集上的图片尺寸不一，因此对此过程进行归一化处理。</p>
<p>k-means 聚类算法有个坑爹的地方在于，类别的个数需要人为事先指定。这就带来一个问题，先验框 anchor 的数目等于多少最合适？一般来说，anchor 的类别越多，那么 YOLO 算法就越能在不同尺度下与真实框进行回归，但是这样就会导致模型的复杂度更高，网络的参数量更庞大。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508224254.png">
</p>

<blockquote>
<p>We choose k = 5 as a good tradeoff between model complexity and high recall. If we use 9 centroids we see a much higher average IOU. This indicates that using k-means to generate our bounding box starts the model off with a better representation and makes the task easier to learn.</p>
</blockquote>
<p>在上面这幅图里，作者发现 k = 5 时就能较好地实现高召回率与模型复杂度之间的平衡。由于在 YOLOv3 算法里一共有3种尺度预测，因此只能是3的倍数，所以最终选择了 9 个先验框。这里还有个问题需要解决，k-means 度量距离的选取很关键。距离度量如果使用标准的欧氏距离，大框框就会比小框产生更多的错误。在目标检测领域，我们度量两个边界框之间的相似度往往以 IOU 大小作为标准。因此，这里的度量距离也和 IOU 有关。需要特别注意的是，这里的IOU计算只用到了 boudnding box 的长和宽。在我的代码里，是认为两个先验框的左上角位置是相重合的。(其实在这里偏移至哪都无所谓，因为聚类的时候是不考虑 anchor 框的位置信息的。)</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508224506.jpg">
</p>

<p>如果两个边界框之间的IOU值越大，那么它们之间的距离就会越小。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kmeans</span>(<span class="params">boxes, k, dist=np.median,seed=<span class="number">1</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    Calculates k-means clustering with the Intersection over Union (IoU) metric.</span></span><br><span class="line"><span class="string">    :param boxes: numpy array of shape (r, 2), where r is the number of rows</span></span><br><span class="line"><span class="string">    :param k: number of clusters</span></span><br><span class="line"><span class="string">    :param dist: distance function</span></span><br><span class="line"><span class="string">    :return: numpy array of shape (k, 2)</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    rows = boxes.shape[<span class="number">0</span>]</span><br><span class="line">    distances     = np.empty((rows, k)) <span class="comment">## N row x N cluster</span></span><br><span class="line">    last_clusters = np.zeros((rows,))</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    <span class="comment"># initialize the cluster centers to be k items</span></span><br><span class="line">    clusters = boxes[np.random.choice(rows, k, replace=<span class="literal">False</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="comment"># 为每个点指定聚类的类别（如果这个点距离某类别最近，那么就指定它是这个类别)</span></span><br><span class="line">        <span class="keyword">for</span> icluster <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            distances[:,icluster] = <span class="number">1</span> - iou(clusters[icluster], boxes)</span><br><span class="line">        nearest_clusters = np.argmin(distances, axis=<span class="number">1</span>)</span><br><span class="line">	<span class="comment"># 如果聚类簇的中心位置基本不变了，那么迭代终止。</span></span><br><span class="line">        <span class="keyword">if</span> (last_clusters == nearest_clusters).<span class="built_in">all</span>():</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        <span class="comment"># 重新计算每个聚类簇的平均中心位置，并它作为聚类中心点</span></span><br><span class="line">        <span class="keyword">for</span> cluster <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            clusters[cluster] = dist(boxes[nearest_clusters == cluster], axis=<span class="number">0</span>)</span><br><span class="line">        last_clusters = nearest_clusters</span><br><span class="line">    <span class="keyword">return</span> clusters,nearest_clusters,distances</span><br></pre></td></tr></table></figure>

<h3 id="6-2-正负样本分配"><a href="#6-2-正负样本分配" class="headerlink" title="6.2 正负样本分配"></a>6.2 正负样本分配</h3><ul>
<li>如果 Anchor 与 Ground-truth Bounding Boxes 的 IoU &gt; 0.3，标定为正样本;</li>
<li>在第 1 种规则下基本能够产生足够多的样本，但是如果它们的 iou 不大于 0.3，那么只能把 iou 最大的那个 Anchor 标记为正样本，这样便能保证每个 Ground-truth 框都至少匹配一个先验框。</li>
</ul>
<p>按照上述原则，一个 ground-truth 框会同时与多个先验框进行匹配。记得之前有人问过我，为什么不能只用 iou 最大的 anchor 去负责预测该物体？其实我想回答的是，如果按照这种原则去分配正负样本，那么势必会导致正负样本的数量极其不均衡（正样本特别少，负样本特别多），这将使得模型在预测时会出现大量漏检的情况。实际上很多目标检测网络都会避免这种情况，并且尽量保持正负样本的数目相平衡。例如，SSD 网络就使用了 hard negative mining 的方法对负样本进行抽样，抽样时按照置信度误差（预测背景的置信度越小，误差越大）进行降序排列，选取误差较大的 top-k 作为训练的负样本，以保证正负样本的比例接近1:3。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>): <span class="comment"># 针对 3 种网格尺寸</span></span><br><span class="line">    <span class="comment"># 设定变量，用于存储每种网格尺寸下 3 个 anchor 框的中心位置和宽高</span></span><br><span class="line">    anchors_xywh = np.zeros((self.anchor_per_scale, <span class="number">4</span>))</span><br><span class="line">    <span class="comment"># 将这 3 个 anchor 框都偏移至网格中心</span></span><br><span class="line">    anchors_xywh[:, <span class="number">0</span>:<span class="number">2</span>] = np.floor(bbox_xywh_scaled[i, <span class="number">0</span>:<span class="number">2</span>]).astype(np.int32) + <span class="number">0.5</span></span><br><span class="line">    <span class="comment"># 填充这 3 个 anchor 框的宽和高</span></span><br><span class="line">    anchors_xywh[:, <span class="number">2</span>:<span class="number">4</span>] = self.anchors[i]</span><br><span class="line">    <span class="comment"># 计算真实框与 3 个 anchor 框之间的 iou 值</span></span><br><span class="line">    iou_scale = self.bbox_iou(bbox_xywh_scaled[i][np.newaxis, :], anchors_xywh)</span><br><span class="line">    iou.append(iou_scale)</span><br><span class="line">    <span class="comment"># 找出 iou 值大于 0.3 的 anchor 框</span></span><br><span class="line">    iou_mask = iou_scale &gt; <span class="number">0.3</span></span><br><span class="line">    exist_positive = <span class="literal">False</span></span><br><span class="line">    <span class="keyword">if</span> np.<span class="built_in">any</span>(iou_mask): <span class="comment"># 规则 1: 对于那些 iou &gt; 0.3 的 anchor 框，做以下处理</span></span><br><span class="line">    	<span class="comment"># 根据真实框的坐标信息来计算所属网格左上角的位置</span></span><br><span class="line">        xind, yind = np.floor(bbox_xywh_scaled[i, <span class="number">0</span>:<span class="number">2</span>]).astype(np.int32)</span><br><span class="line">        label[i][yind, xind, iou_mask, :] = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 填充真实框的中心位置和宽高</span></span><br><span class="line">        label[i][yind, xind, iou_mask, <span class="number">0</span>:<span class="number">4</span>] = bbox_xywh</span><br><span class="line">        <span class="comment"># 设定置信度为 1.0，表明该网格包含物体</span></span><br><span class="line">        label[i][yind, xind, iou_mask, <span class="number">4</span>:<span class="number">5</span>] = <span class="number">1.0</span></span><br><span class="line">        <span class="comment"># 设置网格内 anchor 框的类别概率，做平滑处理</span></span><br><span class="line">        label[i][yind, xind, iou_mask, <span class="number">5</span>:] = smooth_onehot</span><br><span class="line">        exist_positive = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> exist_positive: <span class="comment"># 规则 2: 所有 iou 都不大于0.3， 那么只能选择 iou 最大的</span></span><br><span class="line">    	best_anchor_ind = np.argmax(np.array(iou).reshape(-<span class="number">1</span>), axis=-<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>按照上面两种规则标记出正样本后，剩下的都是负样本了。这些负样本是不会参与到边界框损失和分类损失的计算中去，而只会参与到置信度损失的计算（因为你需要告诉神经网络什么是负样本）。在这里，你不必纠结 Anchor 是否能够准确地框到物体。你只要关心 Anchor 能不能框到物体，如果框到很多了(比如iou&gt;0.3)，那么它就是个正样本了，否则就不是了。 后面的损失函数会进一步告诉神经网络怎么去做精确的尺寸和位置回归，并给出一个置信度评分。最后，那些评分比较低和重叠度较高的预测框就会被 NMS 算法给过滤掉。</p>
<h2 id="7-损失函数"><a href="#7-损失函数" class="headerlink" title="7. 损失函数"></a>7. 损失函数</h2><p>在 YOLOv3 中，作者将目标检测任务看作目标区域预测和类别预测的回归问题, 因此它的损失函数也有些与众不同。对于损失函数, Redmon J 在论文中并 没有进行详细的讲解。但通过对 darknet 源代码的解读，可以总结得到 YOLOv3 的损失函数如下:</p>
<ul>
<li>置信度损失，判断预测框有无物体；</li>
<li>框回归损失，仅当预测框内包含物体时计算；</li>
<li>分类损失，判断预测框内的物体属于哪个类别</li>
</ul>
<h3 id="7-1-置信度损失"><a href="#7-1-置信度损失" class="headerlink" title="7.1 置信度损失"></a>7.1 置信度损失</h3><p>YOLOv3 直接优化置信度损失是为了让模型去学习分辨图片的背景和前景区域，这类似于在 Faster rcnn 里 RPN 功能。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">iou = bbox_iou(pred_xywh[:, :, :, :, np.newaxis, :], bboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :])</span><br><span class="line"><span class="comment"># 找出与真实框 iou 值最大的预测框</span></span><br><span class="line">max_iou = tf.expand_dims(tf.reduce_max(iou, axis=-<span class="number">1</span>), axis=-<span class="number">1</span>)</span><br><span class="line"><span class="comment"># 如果最大的 iou 小于阈值，那么认为该预测框不包含物体,则为背景框</span></span><br><span class="line">respond_bgd = (<span class="number">1.0</span> - respond_bbox) * tf.cast( max_iou &lt; IOU_LOSS_THRESH, tf.float32 )</span><br><span class="line">conf_focal = tf.<span class="built_in">pow</span>(respond_bbox - pred_conf, <span class="number">2</span>)</span><br><span class="line"><span class="comment"># 计算置信度的损失（我们希望假如该网格中包含物体，那么网络输出的预测框置信度为 1，无物体时则为 0。</span></span><br><span class="line">conf_loss = conf_focal * (</span><br><span class="line">     respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)</span><br><span class="line">            +</span><br><span class="line">     respond_bgd * tf.nn.sigmoid_cross_entropy_with_logits(labels=respond_bbox, logits=conv_raw_conf)</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<p>判定的规则很简单：如果一个预测框与所有真实框的 iou 都小于某个阈值，那么就判定它是背景，否则为前景（包含物体）。</p>
<h3 id="7-2-分类损失"><a href="#7-2-分类损失" class="headerlink" title="7.2 分类损失"></a>7.2 分类损失</h3><p>这里分类损失采用的是二分类的交叉熵，即把所有类别的分类问题归结为是否属于这个类别，这样就把多分类看做是二分类问题。这样做的好处在于排除了类别的互斥性，特别是解决了因多个类别物体的重叠而出现漏检的问题。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508224731.jpg">
</p>


<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">respond_bbox  = label[:, :, :, :, <span class="number">4</span>:<span class="number">5</span>]</span><br><span class="line">prob_loss = respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(labels=label_prob, logits=conv_raw_prob)</span><br></pre></td></tr></table></figure>

<h3 id="7-3-框回归损失"><a href="#7-3-框回归损失" class="headerlink" title="7.3 框回归损失"></a>7.3 框回归损失</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">respond_bbox  = label[:, :, :, :, <span class="number">4</span>:<span class="number">5</span>]  <span class="comment"># 置信度，判断网格内有无物体</span></span><br><span class="line">...</span><br><span class="line">bbox_loss_scale = <span class="number">2.0</span> - <span class="number">1.0</span> * label_xywh[:, :, :, :, <span class="number">2</span>:<span class="number">3</span>] * label_xywh[:, :, :, :, <span class="number">3</span>:<span class="number">4</span>] / (input_size ** <span class="number">2</span>)</span><br><span class="line">giou_loss = respond_bbox * bbox_loss_scale * (<span class="number">1</span> - giou)</span><br></pre></td></tr></table></figure>

<ul>
<li>边界框的尺寸越小，bbox_loss_scale 的值就越大。实际上，我们知道 YOLOv1 里作者在 loss 里对宽高都做了开根号处理，这是为了弱化边界框尺寸对损失值的影响；</li>
<li>respond_bbox 的意思是如果网格单元中包含物体，那么就会计算边界框损失；</li>
<li>两个边界框之间的 GIoU 值越大，giou 的损失值就会越小, 因此网络会朝着预测框与真实框重叠度较高的方向去优化。</li>
</ul>
<p>受 g-darknet 所启示，将原始 iou loss 替换成了 giou loss ，检测精度提高了大约 1 个百分点。 GIoU 的好处在于，改进了预测框与先验框的距离度量方式。</p>
<h4 id="GIoU-的背景介绍"><a href="#GIoU-的背景介绍" class="headerlink" title="GIoU 的背景介绍"></a>GIoU 的背景介绍</h4><p>这篇论文 出自于 CVPR 2019，这篇论文提出了一种优化边界框的新方式 —— GIoU (Generalized IoU，广义 IoU )。边界框一般由左上角和右下角坐标所表示，即 (x1,y1,x2,y2)。那么，你发现这其实也是一个向量。向量的距离一般可以 L1 范数或者 L2 范数来度量。但是在L1及L2范数取到相同的值时，实际上检测效果却是差异巨大的，直接表现就是预测和真实检测框的IoU值变化较大，这说明L1和L2范数不能很好的反映检测效果。</p>
<blockquote>
<p>L1 范数：向量元素的绝对值之和；<br>L2 范数：即欧几里德范数，常用于计算向量的长度；</p>
</blockquote>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508224828.png">
</p>

<p>当 L1 或 L2 范数都相同的时候，发现 IoU 和 GIoU 的值差别都很大，这表明使用 L 范数来度量边界框的距离是不合适的。在这种情况下，学术界普遍使用 IoU 来衡量两个边界框之间的相似性。作者发现使用 IoU 会有两个缺点，导致其不太适合做损失函数:</p>
<ul>
<li>预测框和真实框之间没有重合时，IoU 值为 0， 导致优化损失函数时梯度也为 0，意味着无法优化。例如，场景 A 和场景 B 的 IoU 值都为 0，但是显然场景 B 的预测效果较 A 更佳，因为两个边界框的距离更近( L 范数更小)。</li>
</ul>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508224918.png">
</p>

<blockquote>
<p>尽管场景 A 和场景 B 的 IoU 值都为 0，但是场景 B 的预测效果较 A 更佳，这是因为两个边界框的距离更近。</p>
</blockquote>
<ul>
<li>即使预测框和真实框之间相重合且具有相同的 IoU 值时，检测的效果也具有较大差异，如下图所示。</li>
</ul>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508225002.png">
</p>

<blockquote>
<p>上面三幅图的 IoU = 0.33， 但是 GIoU 值分别是 0.33, 0.24 和 -0.1， 这表明如果两个边界框重叠和对齐得越好，那么得到的 GIoU 值就会越高。</p>
</blockquote>
<h4 id="GIoU-的计算公式"><a href="#GIoU-的计算公式" class="headerlink" title="GIoU 的计算公式"></a>GIoU 的计算公式</h4><p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508225036.png">
</p>

<p>the smallest enclosing convex object C 指的是最小闭合凸面 C，例如在上述场景 A 和 B 中，C 的形状分别为:</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508225127.png">
</p>

<blockquote>
<p>图中绿色包含的区域就是最小闭合凸面 C，the smallest enclosing convex object。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bbox_giou</span>(<span class="params">boxes1, boxes2</span>):</span></span><br><span class="line">	......</span><br><span class="line">    <span class="comment"># 计算两个边界框之间的 iou 值</span></span><br><span class="line">    iou = inter_area / union_area</span><br><span class="line">    <span class="comment"># 计算最小闭合凸面 C 左上角和右下角的坐标</span></span><br><span class="line">    enclose_left_up = tf.minimum(boxes1[..., :<span class="number">2</span>], boxes2[..., :<span class="number">2</span>])</span><br><span class="line">    enclose_right_down = tf.maximum(boxes1[..., <span class="number">2</span>:], boxes2[..., <span class="number">2</span>:])</span><br><span class="line">    enclose = tf.maximum(enclose_right_down - enclose_left_up, <span class="number">0.0</span>)</span><br><span class="line">    <span class="comment"># 计算最小闭合凸面 C 的面积</span></span><br><span class="line">    enclose_area = enclose[..., <span class="number">0</span>] * enclose[..., <span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 根据 GIoU 公式计算 GIoU 值</span></span><br><span class="line">    giou = iou - <span class="number">1.0</span> * (enclose_area - union_area) / enclose_area</span><br><span class="line">    <span class="keyword">return</span> giou</span><br></pre></td></tr></table></figure>

<h2 id="8-模型训练"><a href="#8-模型训练" class="headerlink" title="8. 模型训练"></a>8. 模型训练</h2><h3 id="8-1-权重初始化"><a href="#8-1-权重初始化" class="headerlink" title="8.1 权重初始化"></a>8.1 权重初始化</h3><p>训练神经网络尤其是深度神经网络所面临的一个问题是，梯度消失或梯度爆炸，也就是说 当你训练深度网络时，导数或坡度有时会变得非常大，或非常小甚至以指数方式变小，这个时候我们看到的损失就会变成了 NaN。假设你正在训练下面这样一个极深的神经网络，为了简单起见，这里激活函数 g(z) = z 并且忽略偏置参数。</p>
<p align="center">
    <img width="55%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508225309.png">
</p>

<p>这里我们首先假定 g(z)=z, b[l]=0，所以对目标输出有：</p>
<p align="center">
    <img width="35%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508225352.jpg">
</p>

<p>其实这里直观的理解是：如果权重 W 只比 1 略大一点，或者说只比单位矩阵大一点，深度神经网络的输出将会以爆炸式增长，而如果 W 比 1 略小一点，可能是 0.9, 0.9，每层网络的输出值将会以指数级递减。因此合适的初始化权重值就显得尤为重要! 下面就写个简单的代码给大家演示一下。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x = np.random.randn(<span class="number">2000</span>, <span class="number">800</span>) * <span class="number">0.01</span> <span class="comment"># 制作输入数据</span></span><br><span class="line">stds = [<span class="number">0.1</span>, <span class="number">0.05</span>, <span class="number">0.01</span>, <span class="number">0.005</span>, <span class="number">0.001</span>] <span class="comment"># 尝试使用不同标准差，这样初始权重大小也不一样</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i, std <span class="keyword">in</span> <span class="built_in">enumerate</span>(stds):</span><br><span class="line">    <span class="comment"># 第一层全连接层</span></span><br><span class="line">    dense_1 = tf.keras.layers.Dense(<span class="number">750</span>, kernel_initializer=tf.random_normal_initializer(std), activation=<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line">    output_1 = dense_1(x)</span><br><span class="line">    <span class="comment"># 第二层全连接层</span></span><br><span class="line">    dense_2 = tf.keras.layers.Dense(<span class="number">700</span>, kernel_initializer=tf.random_normal_initializer(std), activation=<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line">    output_2 = dense_2(output_1)</span><br><span class="line">    <span class="comment"># 第三层全连接层</span></span><br><span class="line">    dense_3 = tf.keras.layers.Dense(<span class="number">650</span>, kernel_initializer=tf.random_normal_initializer(std), activation=<span class="string">&#x27;tanh&#x27;</span>)</span><br><span class="line">    output_3 = dense_3(output_2).numpy().flatten()</span><br><span class="line"></span><br><span class="line">    plt.subplot(<span class="number">1</span>, <span class="built_in">len</span>(stds), i+<span class="number">1</span>)</span><br><span class="line">    plt.hist(output_3, bins=<span class="number">60</span>, <span class="built_in">range</span>=[-<span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;std = %.3f&#x27;</span> %std)</span><br><span class="line">    plt.yticks([])</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508225433.png">
</p>

<p>我们可以看到当标准差较大( std = 0.1 和 0.05 )时，几乎所有的输出值集中在 -1 或1 附近，这表明此时的神经网络发生了梯度爆炸；当标准差较小( std = 0.005 和 0.001）时，我们看到输出值迅速向 0 靠拢，这表明此时的神经网络发生了梯度消失。其实笔者也曾在 YOLOv3 网络里做过实验，初始化权重的标准差如果太大或太小，都容易出现 NaN 。</p>
<h3 id="8-2-学习率的设置"><a href="#8-2-学习率的设置" class="headerlink" title="8.2 学习率的设置"></a>8.2 学习率的设置</h3><p>学习率是最影响性能的超参数之一，如果我们只能调整一个超参数，那么最好的选择就是它。 其实在我们的大多数的炼丹过程中，遇到 loss 变成 NaN 的情况大多数是由于学习率选择不当引起的。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508225441.png">
</p>


<p>有句话讲得好啊，步子大了容易扯到蛋。由于神经网络在刚开始训练的时候是非常不稳定的，因此刚开始的学习率应当设置得很低很低，这样可以保证网络能够具有良好的收敛性。但是较低的学习率会使得训练过程变得非常缓慢，因此这里会采用以较低学习率逐渐增大至较高学习率的方式实现网络训练的“热身”阶段，称为 warmup stage。但是如果我们使得网络训练的 loss 最小，那么一直使用较高学习率是不合适的，因为它会使得权重的梯度一直来回震荡，很难使训练的损失值达到全局最低谷。因此最后采用了这篇论文里[8]的 cosine 的衰减方式，这个阶段可以称为 consine decay stage。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> global_steps &lt; warmup_steps:</span><br><span class="line">    lr = global_steps / warmup_steps *cfg.TRAIN.LR_INIT</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    lr = cfg.TRAIN.LR_END + <span class="number">0.5</span> * (cfg.TRAIN.LR_INIT - cfg.TRAIN.LR_END) * (</span><br><span class="line">        (<span class="number">1</span> + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi))</span><br><span class="line">    )</span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="37%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508225436.png">
</p>

<h3 id="8-3-加载预训练模型"><a href="#8-3-加载预训练模型" class="headerlink" title="8.3 加载预训练模型"></a>8.3 加载预训练模型</h3><p>目前针对目标检测的主流做法是基于 Imagenet 数据集预训练的模型来提取特征，然后在 COCO 数据集进行目标检测fine-tunning训练（比如 yolo 算法)，也就是大家常说的迁移学习。其实迁移学习是建立在数据集分布相似的基础上的，像 yymnist 这种与 COCO 数据集分布完全不同的情况，就没有必要加载 COCO 预训练模型的必要了吧。</p>
<p>在 tensorflow-yolov3 版本里，由于 README 里训练的是 VOC 数据集，因此推荐加载预训练模型。由于在 YOLOv3 网络的三个分支里的最后卷积层与训练的类别数目有关，因此除掉这三层的网络权重以外，其余所有的网络权重都加载进来了。</p>
<p>下面是 tensorflow-yolov3 在 PASCAL VOC 2012 上比赛刷的成绩，最后进了榜单的前十名。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/YOLOv3-算法的一点理解-20210508225439.png">
</p>


<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li>[1] Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik. <a href="https://arxiv.org/abs/1311.2524">Rich feature hierarchies for accurate object detection and semantic segmentation</a>, CVPR 2014</li>
<li>[2] Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun. <a href="https://arxiv.org/abs/1506.01497">Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks</a>, CVPR 2016</li>
<li>[3] Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi. <a href="https://arxiv.org/abs/1506.02640">You Only Look Once: Unified, Real-Time Object Detection</a>, CVPR 2016</li>
<li>[4] Joseph Redmon, Ali Farhadi. <a href="https://arxiv.org/abs/1612.08242">YOLO9000: Better, Faster, Stronger</a>, CVPR 2017</li>
<li>[5] Joseph Redmon, Ali Farhadi. <a href="https://pjreddie.com/media/files/papers/YOLOv3.pdf">YOLOv3: An Incremental Improvement</a></li>
<li>[6] Conv2DTranspose 层，<a href="https://keras-cn.readthedocs.io/en/latest/layers/convolutional_layer/">Keras 中文文档</a>.</li>
<li>[7] Rezatofighi, Hamid. <a href="https://arxiv.org/pdf/1902.09630.pdf">Generalized Intersection over Union, A Metric and A Loss for Bounding Box Regression</a>, CVPR 2018</li>
<li>[8] Tong He, Zhi Zhang, Hang Zhang, Zhongyue Zhang, Junyuan Xie, Mu Li. <a href="https://arxiv.org/pdf/1812.01187.pdf">Bag of Tricks for Image Classification with Convolutional Neural Networks</a></li>
</ul>
]]></content>
      <categories>
        <category>目标检测</category>
      </categories>
      <tags>
        <tag>YOLOv3</tag>
      </tags>
  </entry>
  <entry>
    <title>医学图片分割网络 —— Unet</title>
    <url>/2018/11/12/%E5%8C%BB%E5%AD%A6%E5%9B%BE%E7%89%87%E5%88%86%E5%89%B2%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94Unet/</url>
    <content><![CDATA[<p>Unet 是 Kaggle 语义分割挑战赛上的常客。因为它简单，高效，易懂，容易定制，最主要的是它可以从相对较小的数据集中学习。在医学图像处理领域，各路高手更是拿着 Unet 各种魔改。</p>
<p align="center">
    <img width="72%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/医学图片分割网络——Unet-20210508220238.png">
</p>

<span id="more"></span>

<h2 id="1-网络结构"><a href="#1-网络结构" class="headerlink" title="1. 网络结构"></a>1. 网络结构</h2><p>U-Net 与 FCN 非常的相似（比如都没有使用全连接层），U-Net 比 FCN 稍晚提出来，但都发表在 2015 年，和 FCN 相比，U-Net 的第一个特点是完全对称，也就是左边和右边是很类似的。当我第一次看到该网络的拓扑结构时，顿时惊为天人，卧槽，简直是一个大写的 U。</p>
<p>其次，Unet 与 FCN 第二个不同点就是 skip-connections（跳跃连接）的操作不一样：FCN 采用的是 tf.add，而 Unet 则使用的 tf.concat 操作，它们之间的区别在于前者在 pixel-to-pixel 上直接相加，而后者是相叠加而改变了通道数目。Unet 的网络结构主要包括三点：</p>
<ul>
<li>下采样路径, 论文里称为 The contracting path；</li>
<li>Bottleneck 结构；</li>
<li>上采样路径，论文里称为 The expanding path；</li>
</ul>
<h2 id="2-下采样路径"><a href="#2-下采样路径" class="headerlink" title="2. 下采样路径"></a>2. 下采样路径</h2><p>下采样路径一共由4个模块组成，每个模块的结构为：</p>
<ul>
<li>3x3 的卷积操作 + relu 激活函数；</li>
<li>3x3 的卷积操作 + relu 激活函数；</li>
<li>2x2 的 Pooling 操作。</li>
</ul>
<blockquote>
<p>It consists of the repeated application of two 3x3 convolutions (unpadded convolutions), each followed by a rectified linear unit (ReLU) and a 2x2 max pooling operation with stride 2 for downsampling. At each downsampling step we double the number of feature channels.</p>
</blockquote>
<p>但是值得一提的是每次在 Pooling 结构后，feature map 的通道数目就会加倍，最终 feature map 的空间尺寸越来越小，而通道数目越来越多。这样做的目的是为了捕获输入图像的上下文信息，以便能够进行分割。随后，这些粗略的上下文信息随后将通过跳跃连接传输到上采样路径。</p>
<h2 id="3-Bottleneck-结构"><a href="#3-Bottleneck-结构" class="headerlink" title="3. Bottleneck 结构"></a>3. Bottleneck 结构</h2><p>瓶颈结构，顾名思义，就是在下采样和上采样之间的结构。它由两个卷积层组成，并且后面接有 dropout。在代码里是这样实现的：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">conv5 = Conv2D(<span class="number">1024</span>, <span class="number">3</span>, activation = <span class="string">&#x27;relu&#x27;</span>, padding = <span class="string">&#x27;same&#x27;</span>)(pool4)</span><br><span class="line">conv5 = Conv2D(<span class="number">1024</span>, <span class="number">3</span>, activation = <span class="string">&#x27;relu&#x27;</span>, padding = <span class="string">&#x27;same&#x27;</span>)(conv5)</span><br><span class="line">drop5 = Dropout(<span class="number">0.5</span>)(conv5)</span><br></pre></td></tr></table></figure>

<h2 id="4-上采样路径"><a href="#4-上采样路径" class="headerlink" title="4. 上采样路径"></a>4. 上采样路径</h2><p>跟下采样结构一样，上采样结构也是由 4 个模块组成，这样才能对称，每个模块都结构为:</p>
<ul>
<li>上采样层；</li>
<li>3x3 卷积操作 + relu 激活函数；</li>
</ul>
<p>不过这里面多了一些骚操作，在对称的地方与来自下采样路径的跳跃连接进行了 Concate 操作，从而融合网络的浅层特征。</p>
<h2 id="5-个人思考"><a href="#5-个人思考" class="headerlink" title="5. 个人思考"></a>5. 个人思考</h2><p>从 Unet 的主体结构设计来看，其实是借鉴了 Hinton 祖师爷的自编码网络。仔细看 Unet 会发现：它的下采样结构其实是一个编码过程，所谓的编码就是尽可能地压缩图像的空间信息，而保留最本质的特征；上采样结构则是一个解码过程，尽可能地还原到原来的图像。在 FCN 的 skip-connection 提出后，这几乎成了语义分割和目标检测领域的标配，因此 Unet 网络避免不了得用它。所以 Unet 更像是 AutoEncoder 与 FCN 的结合版。</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ul>
<li>[1] Olaf Ronneberger, Philipp Fischer, Thomas Brox. <a href="https://arxiv.org/abs/1505.04597">U-Net: Convolutional Networks for Biomedical Image Segmentation</a>, accepted at MICCAI 2015</li>
</ul>
]]></content>
      <categories>
        <category>图像分割</category>
      </categories>
      <tags>
        <tag>Skip Connection</tag>
        <tag>Unet 网络结构</tag>
      </tags>
  </entry>
  <entry>
    <title>使用 Pytorch 对 mnist 数字进行分类</title>
    <url>/2018/09/09/%E4%BD%BF%E7%94%A8-Pytorch-%E5%AF%B9-mnist-%E6%95%B0%E5%AD%97%E8%BF%9B%E8%A1%8C%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<p>一直以来就非常喜欢 Pytorch，今天就小试牛刀一下，用它实现对 mnist 数字进行分类。</p>
<p align="center">
    <img width="80%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/使用-Pytorch-对-mnist-数字进行分类-20210508214147.jpg">
</p>

<span id="more"></span>

<p>首先可以从<a href="https://github.com/YunYang1994/yymnist/releases/download/v1.0/mnist.zip"><font color=Red>这里</font></a>下载 mnist 数据集并解压，然后代码的开始部分如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, utils</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br><span class="line"></span><br><span class="line"><span class="comment"># Device configuration</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda:0&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>之后，我们会想办法构造一个手写数字数据集:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MnistDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;custom mnist dataset.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, root_dir, transform=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            root_dir (string): Directory with all the images.</span></span><br><span class="line"><span class="string">            transform (callable, optional): Optional transform to be applied</span></span><br><span class="line"><span class="string">                on a sample.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        self.transform = transform</span><br><span class="line">        self.data_list = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">            img_paths = glob.glob(root_dir + <span class="string">&quot;%d/*.jpg&quot;</span> %i)</span><br><span class="line">            <span class="keyword">for</span> img_path <span class="keyword">in</span> img_paths:</span><br><span class="line">                img_label = &#123;<span class="string">&#x27;img_path&#x27;</span>:img_path, <span class="string">&#x27;label&#x27;</span>:i &#125;</span><br><span class="line">                self.data_list.append(img_label)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.data_list)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        <span class="keyword">if</span> torch.is_tensor(idx):</span><br><span class="line">            idx = idx.tolist()</span><br><span class="line">        img_path = self.data_list[idx][<span class="string">&#x27;img_path&#x27;</span>]</span><br><span class="line">        image = transforms.ToTensor()(Image.<span class="built_in">open</span>(img_path).convert(<span class="string">&#x27;RGB&#x27;</span>))</span><br><span class="line">        label = self.data_list[idx][<span class="string">&#x27;label&#x27;</span>]</span><br><span class="line">        <span class="keyword">return</span> image, label</span><br></pre></td></tr></table></figure>

<p>对数据集的装载使用的是 <code>torch.utils.data.DataLoader</code> 类，类中的 <code>dataset</code> 参数用于指定我们载入的数据集名称，<code>batch_size</code> 设置了每个 <code>batch</code> 的样本数量，<code>shuffle=True</code> 会在装载过程将数据的顺序打乱然后打包。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">train_dataset = MnistDataset(<span class="string">&quot;./mnist/train/&quot;</span>)</span><br><span class="line">train_loader = torch.utils.data.DataLoader(dataset=train_dataset,</span><br><span class="line">    						batch_size=<span class="number">32</span>,</span><br><span class="line">    						shuffle=<span class="literal">True</span>,</span><br><span class="line">    						num_workers=<span class="number">4</span>)</span><br></pre></td></tr></table></figure>

<p>在顺利完成数据的加载后，我们就可以搭建一个简单的 CNN 模型，如下所示：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConvNet</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot; Convolutional neural network (two convolutional layers) &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, num_classes</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(ConvNet, self).__init__()</span><br><span class="line">        self.layer1 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">3</span>, <span class="number">16</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">16</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">        self.layer2 = nn.Sequential(</span><br><span class="line">            nn.Conv2d(<span class="number">16</span>, <span class="number">32</span>, kernel_size=<span class="number">5</span>, stride=<span class="number">1</span>, padding=<span class="number">2</span>),</span><br><span class="line">            nn.BatchNorm2d(<span class="number">32</span>),</span><br><span class="line">            nn.ReLU(),</span><br><span class="line">            nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>))</span><br><span class="line">        self.fc = nn.Linear(<span class="number">7</span>*<span class="number">7</span>*<span class="number">32</span>, num_classes)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        out = self.layer1(x)</span><br><span class="line">        out = self.layer2(out)</span><br><span class="line">        out = out.reshape(out.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        out = self.fc(out)</span><br><span class="line">        <span class="keyword">return</span> F.log_softmax(out, dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">model = ConvNet(num_classes=<span class="number">10</span>).to(device)</span><br><span class="line">optimizer = optim.SGD(model.parameters(), lr=<span class="number">0.01</span>)</span><br></pre></td></tr></table></figure>
<p>在编写完搭建卷积神经网络的模型代码后，我们就可以开始对模型进行训练和对参数进行优化了。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Define training loops</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    loss_value = <span class="number">0.</span></span><br><span class="line">    acc_value  = <span class="number">0.</span></span><br><span class="line">    num_batch  = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> tqdm(total=<span class="built_in">len</span>(train_loader),</span><br><span class="line">                desc=<span class="string">&quot;Epoch %2d/20&quot;</span> %(epoch+<span class="number">1</span>)) <span class="keyword">as</span> pbar:</span><br><span class="line">        <span class="keyword">for</span> data, target <span class="keyword">in</span> train_loader:</span><br><span class="line">            data, target = data.to(device), target.to(device)</span><br><span class="line"></span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            output = model(data)</span><br><span class="line">            loss = F.nll_loss(output, target)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            num_batch  += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            loss_value += loss.item()</span><br><span class="line">            <span class="comment"># get the index of the max log-probability</span></span><br><span class="line">            pred = output.<span class="built_in">max</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)[<span class="number">1</span>]</span><br><span class="line">            correct = pred.eq(target.view_as(pred)).<span class="built_in">sum</span>().item()</span><br><span class="line">            acc_value += correct / <span class="built_in">len</span>(target)</span><br><span class="line"></span><br><span class="line">            pbar.set_postfix(&#123;<span class="string">&#x27;loss&#x27;</span> :<span class="string">&#x27;%.4f&#x27;</span> %(loss_value / num_batch),</span><br><span class="line">                              <span class="string">&#x27;acc&#x27;</span>  :<span class="string">&#x27;%.4f&#x27;</span> %(acc_value  / num_batch)&#125;)</span><br><span class="line">            pbar.update(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>

<p>在测试阶段，代码也非常简洁:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Define testing step</span></span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    model(data)</span><br></pre></td></tr></table></figure>

<p>接着我们可以保存模型：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">torch.save(model.state_dict(), <span class="string">&#x27;model.pth&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>然后下次便可以重新加载模型:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = ConvNet(num_classes=<span class="number">10</span>).to(device)</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&quot;model.pth&quot;</span>))</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>mnist 分类</tag>
      </tags>
  </entry>
  <entry>
    <title>FAST 角点检测</title>
    <url>/2018/07/17/FAST-%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B/</url>
    <content><![CDATA[<p>FAST 是一种角点，主要检测局部像素灰度变化明显的地方，以速度快著称。<font color=Red>它的思想是: 如果一个像素与它邻域的像素差别较大(过亮或过暗), 那它更可能是角点。相比于其他角点检测算法，FAST 只需比较像素亮度的大小， 十分快捷。</font>它的检测过程如下:</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/FAST-角点检测-20210508213941.png">
</p>

<span id="more"></span>

<ol>
<li>在图像中选取像素 p，假设它的亮度为 C，并设置一个阈值 T。</li>
<li>以像素 p 为中心, 选取半径为 3 的圆上的<font color=Red> 16 个像素点</font>（如上图所示)。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">circle</span>(<span class="params">row,col</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    对于图片上一像素点位置 (row,col)，获取其邻域圆上 16 个像素点坐标，圆由 16 个像素点组成</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    args:</span></span><br><span class="line"><span class="string">        row：行坐标 注意 row 要大于等于3</span></span><br><span class="line"><span class="string">        col：列坐标 注意 col 要大于等于3       </span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    point1  = (row-<span class="number">3</span>, col)</span><br><span class="line">    point2  = (row-<span class="number">3</span>, col+<span class="number">1</span>)</span><br><span class="line">    point3  = (row-<span class="number">2</span>, col+<span class="number">2</span>)</span><br><span class="line">    point4  = (row-<span class="number">1</span>, col+<span class="number">3</span>)</span><br><span class="line">    point5  = (row, col+<span class="number">3</span>)</span><br><span class="line">    point6  = (row+<span class="number">1</span>, col+<span class="number">3</span>)</span><br><span class="line">    point7  = (row+<span class="number">2</span>, col+<span class="number">2</span>)</span><br><span class="line">    point8  = (row+<span class="number">3</span>, col+<span class="number">1</span>)</span><br><span class="line">    point9  = (row+<span class="number">3</span>, col)</span><br><span class="line">    point10 = (row+<span class="number">3</span>, col-<span class="number">1</span>)</span><br><span class="line">    point11 = (row+<span class="number">2</span>, col-<span class="number">2</span>)</span><br><span class="line">    point12 = (row+<span class="number">1</span>, col-<span class="number">3</span>)</span><br><span class="line">    point13 = (row, col-<span class="number">3</span>)</span><br><span class="line">    point14 = (row-<span class="number">1</span>, col-<span class="number">3</span>)</span><br><span class="line">    point15 = (row-<span class="number">2</span>, col-<span class="number">2</span>)</span><br><span class="line">    point16 = (row-<span class="number">3</span>, col-<span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> [point1, point2,point3,point4,point5,point6,point7,point8,point9,point10,point11,point12, point13,point14,point15,point16]</span><br></pre></td></tr></table></figure>

<ol start="3">
<li><font color=Red>假如这 16 个点中，有连续的 N 个点的亮度大于 C + T 或小于 C − T，那么像素 p 可以被认为是角点。</font></li>
<li>为了排除大量的非角点提出了一种高速测试方法：<font color=Red>直接检测邻域圆上的第  1，5，9，13 个像素的亮度。只有当这四个像素中有三个同时大于 C + T 或小于  C − T 时，当前像素才有可能是一个角点，否则应该直接排除。</font>这样的预测试操作大大加速了角点检测。</li>
</ol>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">is_corner</span>(<span class="params">image,row,col,threshold</span>):</span></span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    检测图像位置(row,col)处像素点是不是角点</span></span><br><span class="line"><span class="string">    如果圆上有12个连续的点满足阈值条件，那么它就是一个角点</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    方法：</span></span><br><span class="line"><span class="string">        如果位置1和9它的像素值比阈值暗或比阈值亮，则检测位置5和位置15</span></span><br><span class="line"><span class="string">        如果这些像素符合标准，请检查像素5和13是否相符</span></span><br><span class="line"><span class="string">        如果满足有3个位置满足阈值条件，则它是一个角点</span></span><br><span class="line"><span class="string">        重复循环函数返回的每个点如果没有满足阈值，则不是一个角落</span></span><br><span class="line"><span class="string">        </span></span><br><span class="line"><span class="string">        注意：这里我们简化了论文章中的角点检测过程，会造成一些误差</span></span><br><span class="line"><span class="string">    </span></span><br><span class="line"><span class="string">    args:</span></span><br><span class="line"><span class="string">        image：输入图片数据,要求为灰度图片</span></span><br><span class="line"><span class="string">        row：行坐标 注意row要大于等于3</span></span><br><span class="line"><span class="string">        col：列坐标 注意col要大于等于3 </span></span><br><span class="line"><span class="string">        threshold：阈值        </span></span><br><span class="line"><span class="string">    return : </span></span><br><span class="line"><span class="string">        返回True或者False</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># 校验</span></span><br><span class="line">    rows,cols = image.shape[:<span class="number">2</span>]</span><br><span class="line">    <span class="keyword">if</span> row &lt; <span class="number">3</span> <span class="keyword">or</span> col &lt; <span class="number">3</span> : <span class="keyword">return</span> <span class="literal">False</span>    </span><br><span class="line">    <span class="keyword">if</span> row &gt;= rows-<span class="number">3</span> <span class="keyword">or</span> col &gt;= cols-<span class="number">3</span>: <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">       </span><br><span class="line">    intensity = <span class="built_in">int</span>(image[row][col])</span><br><span class="line">    ROI = circle(row,col)</span><br><span class="line">    <span class="comment"># 获取位置1,9,5,13的像素值</span></span><br><span class="line">    row1, col1   = ROI[<span class="number">0</span>]</span><br><span class="line">    row9, col9   = ROI[<span class="number">8</span>]</span><br><span class="line">    row5, col5   = ROI[<span class="number">4</span>]</span><br><span class="line">    row13, col13 = ROI[<span class="number">12</span>]</span><br><span class="line">    intensity1  = <span class="built_in">int</span>(image[row1][col1])</span><br><span class="line">    intensity9  = <span class="built_in">int</span>(image[row9][col9])</span><br><span class="line">    intensity5  = <span class="built_in">int</span>(image[row5][col5])</span><br><span class="line">    intensity13 = <span class="built_in">int</span>(image[row13][col13])</span><br><span class="line">    <span class="comment"># 统计上面4个位置中满足  像素值  &gt;  intensity + threshold点的个数</span></span><br><span class="line">    countMore = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 统计上面4个位置中满足 像素值  &lt; intensity - threshold点的个数</span></span><br><span class="line">    countLess = <span class="number">0</span></span><br><span class="line">    <span class="keyword">if</span> intensity1 - intensity &gt; threshold:</span><br><span class="line">        countMore += <span class="number">1</span> </span><br><span class="line">    <span class="keyword">elif</span> intensity1 + threshold &lt; intensity:</span><br><span class="line">        countLess += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> intensity9 - intensity &gt; threshold:</span><br><span class="line">        countMore += <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> intensity9 + threshold &lt; intensity:</span><br><span class="line">        countLess += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> intensity5 - intensity &gt; threshold:</span><br><span class="line">        countMore += <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> intensity5 + threshold &lt; intensity:</span><br><span class="line">        countLess += <span class="number">1</span></span><br><span class="line">    <span class="keyword">if</span> intensity13 - intensity &gt; threshold:</span><br><span class="line">        countMore += <span class="number">1</span></span><br><span class="line">    <span class="keyword">elif</span> intensity13 + threshold &lt; intensity:</span><br><span class="line">        countLess += <span class="number">1</span></span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> countMore &gt;= <span class="number">3</span> <span class="keyword">or</span> countLess&gt;=<span class="number">3</span></span><br></pre></td></tr></table></figure>

<ol start="5">
<li>在第一遍检测后，原始的 FAST 角点经常出现“扎堆”的现象。因此需要使用非极大值抑制，在一定区域内仅保留响应极大值的角点，避免角点集中的问题。</li>
</ol>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/FAST-角点检测-20210508213949.png">
</p>

<blockquote>
<p>第一张图片使用了非最大值抑制，而第二张没有使用。可以明显看到，第二张图的关键点的位置重复比较严重。</p>
</blockquote>
<p>为了方便，我们可以在 OpenCV 里直接创建 FAST 特征点检测器并使用它:</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2 </span><br><span class="line"></span><br><span class="line">img = cv2.imread(<span class="string">&#x27;simple.jpg&#x27;</span>,<span class="number">0</span>)</span><br><span class="line"><span class="comment"># Initiate FAST object with default values</span></span><br><span class="line">fast = cv.FastFeatureDetector_create()</span><br><span class="line"></span><br><span class="line"><span class="comment"># enable nonmaxSuppression</span></span><br><span class="line">fast.setNonmaxSuppression(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># find and draw the keypoints</span></span><br><span class="line">kp = fast.detect(img, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">img = cv.drawKeypoints(img, kp, <span class="literal">None</span>, color=(<span class="number">255</span>,<span class="number">0</span>,<span class="number">0</span>))</span><br></pre></td></tr></table></figure>

<p>参考文献:</p>
<ul>
<li><a href="https://www.cnblogs.com/zyly/p/9542164.html#_label3">[1] 第十四节、FAST角点检测(附源码)</a></li>
<li><a href="https://www.bookstack.cn/read/opencv-doc-zh-4.0/docs-4.0.0-5.6-tutorial_py_fast.md">[2] OpenCV 中文文档 4.0.0 - 角点检测的FAST算法</a></li>
</ul>
]]></content>
      <categories>
        <category>图像处理</category>
      </categories>
      <tags>
        <tag>角点检测</tag>
      </tags>
  </entry>
  <entry>
    <title>Pytorch 的数据集准备</title>
    <url>/2018/06/11/Pytorch-%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E5%87%86%E5%A4%87/</url>
    <content><![CDATA[<p>深度学习的绝大部分工作都是在准备数据集，<strong>Pytorch</strong> 提供了很多工具使数据加载变得更简单。在本节内容中，我们来看看是如何利用 <strong>torch.utils.data.DataLoader</strong> 加载数据集的。</p>
<p>首先需要 import 一些必要的库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> skimage</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, utils</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br></pre></td></tr></table></figure>

<p>然后从<a href="https://download.pytorch.org/tutorial/faces.zip">这里</a>下载一个名为 <strong>faces</strong> 的文件夹，该文件夹里包含了一些 <strong>68 个特征点（part_0 ~ part_67)</strong> 的人脸图片和 <code>face_landmarks.csv</code> </p>
<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Pytorch-的数据集准备-20210508212935.jpg">
</p>

<span id="more"></span>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">landmarks_frame = pd.read_csv(<span class="string">&#x27;faces/face_landmarks.csv&#x27;</span>)</span><br><span class="line">landmarks_frame.head()</span><br></pre></td></tr></table></figure>

<h2 id="1-Dataset-class"><a href="#1-Dataset-class" class="headerlink" title="1. Dataset class"></a>1. Dataset class</h2><p><code>torch.utils.data.Dataset</code> 是一个抽象的类，我们构造的数据集需要继承它得到，并且重载下面 2 个成员函数：</p>
<ul>
<li><code>__len__</code> 函数，通过<code>len(dataset)</code>返回数据集大小；</li>
<li><code>__getitem__</code> 函数，通过索引<code>dataset[i]</code>而得到一个样本。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FaceLandmarksDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Face Landmarks dataset.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, csv_file, root_dir, transform=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            csv_file (string): Path to the csv file with annotations.</span></span><br><span class="line"><span class="string">            root_dir (string): Directory with all the images.</span></span><br><span class="line"><span class="string">            transform (callable, optional): Optional transform to be applied</span></span><br><span class="line"><span class="string">                on a sample.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.landmarks_frame = pd.read_csv(csv_file)</span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.landmarks_frame)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        <span class="keyword">if</span> torch.is_tensor(idx):</span><br><span class="line">            idx = idx.tolist()</span><br><span class="line"></span><br><span class="line">        img_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, <span class="number">0</span>])</span><br><span class="line">        image = skimage.io.imread(img_name)</span><br><span class="line">        </span><br><span class="line">        landmarks = self.landmarks_frame.iloc[idx, <span class="number">1</span>:]</span><br><span class="line">        landmarks = np.array([landmarks])</span><br><span class="line">        landmarks = landmarks.astype(<span class="string">&#x27;float&#x27;</span>).reshape(-<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        sample = &#123;<span class="string">&#x27;image&#x27;</span>: image, <span class="string">&#x27;landmarks&#x27;</span>: landmarks&#125;</span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            sample = self.transform(sample)</span><br><span class="line">        <span class="keyword">return</span> sample</span><br></pre></td></tr></table></figure>

<p>现在我们可以对 <code>FaceLandmarksDataset</code> 类构建一个实例 <code>face_dataset</code>。其中每个样本都是一个字典，分别是 <code>&#39;image&#39;</code> 和 <code>&#39;landmarks&#39;</code> 。我们可以索引第 65 个样本将它们的数组形状打印出来。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">face_dataset = FaceLandmarksDataset(csv_file=<span class="string">&#x27;faces/face_landmarks.csv&#x27;</span>,</span><br><span class="line">                                    root_dir=<span class="string">&#x27;faces/&#x27;</span>)</span><br><span class="line">sample = face_dataset[<span class="number">65</span>]             <span class="comment"># 取第 65 个样本</span></span><br><span class="line"><span class="built_in">print</span>(sample[<span class="string">&#x27;image&#x27;</span>].shape)          <span class="comment"># (160, 160, 3)</span></span><br><span class="line"><span class="built_in">print</span>(sample[<span class="string">&#x27;landmarks&#x27;</span>].shape)      <span class="comment"># (68, 2)</span></span><br></pre></td></tr></table></figure>

<h2 id="2-Transforms"><a href="#2-Transforms" class="headerlink" title="2. Transforms"></a>2. Transforms</h2><p>上述过程完成了对人脸图片和 65 个特征点的读取，接下来需要对它们进行一些预处理操作。本文将介绍 3 种 Transforms 操作：</p>
<ul>
<li>Rescale，对图片进行 <code>resize</code> 操作</li>
<li>RandomCrop，随机地裁剪图片</li>
<li>ToTensor，将 numpy 的 <code>array</code> 类型转变为 torch 的 <code>tensor</code> 类型</li>
</ul>
<h3 id="2-1-Rescale"><a href="#2-1-Rescale" class="headerlink" title="2.1 Rescale"></a>2.1 Rescale</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rescale</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Rescale the image in a sample to a given size.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        output_size (tuple or int): Desired output size. If tuple, output is</span></span><br><span class="line"><span class="string">            matched to output_size. If int, smaller of image edges is matched</span></span><br><span class="line"><span class="string">            to output_size keeping aspect ratio the same.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, output_size</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(output_size, <span class="built_in">tuple</span>)</span><br><span class="line">        self.output_size = output_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, sample</span>):</span></span><br><span class="line">        image, landmarks = sample[<span class="string">&#x27;image&#x27;</span>], sample[<span class="string">&#x27;landmarks&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        h, w = image.shape[:<span class="number">2</span>]</span><br><span class="line">        new_h, new_w = self.output_size</span><br><span class="line"></span><br><span class="line">        img = skimage.transform.resize(image, (new_h, new_w))</span><br><span class="line">        landmarks = landmarks * [new_w / w, new_h / h]</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;image&#x27;</span>: img, <span class="string">&#x27;landmarks&#x27;</span>: landmarks&#125;</span><br></pre></td></tr></table></figure>
<p>然后我们对人脸图片的尺寸 resize 到 (256, 256)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rescale_transform = Rescale((<span class="number">256</span>, <span class="number">256</span>))</span><br><span class="line">rescale_sample = rescale_transform(sample)</span><br><span class="line"><span class="built_in">print</span>(rescale_sample[<span class="string">&#x27;image&#x27;</span>].shape)           <span class="comment"># (256,  256, 3)</span></span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="27%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Pytorch-的数据集准备-20210508212935.jpg">
</p>

<h3 id="2-2-RandomCrop"><a href="#2-2-RandomCrop" class="headerlink" title="2.2 RandomCrop"></a>2.2 RandomCrop</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomCrop</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Crop randomly the image in a sample.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        output_size (tuple): Desired output size is made.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, output_size</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(output_size, <span class="built_in">tuple</span>)</span><br><span class="line">        self.output_size = output_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, sample</span>):</span></span><br><span class="line">        image, landmarks = sample[<span class="string">&#x27;image&#x27;</span>], sample[<span class="string">&#x27;landmarks&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        h, w = image.shape[:<span class="number">2</span>]</span><br><span class="line">        new_h, new_w = self.output_size</span><br><span class="line"></span><br><span class="line">        top = np.random.randint(<span class="number">0</span>, h - new_h)</span><br><span class="line">        left = np.random.randint(<span class="number">0</span>, w - new_w)</span><br><span class="line"></span><br><span class="line">        image = image[top: top + new_h, left: left + new_w]</span><br><span class="line">        landmarks = landmarks - [left, top]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;image&#x27;</span>: image, <span class="string">&#x27;landmarks&#x27;</span>: landmarks&#125;</span><br></pre></td></tr></table></figure>
<p>然后我们对人脸图片进行随机裁剪，裁剪的尺寸大小为 (128, 128)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">crop_transform = RandomCrop((<span class="number">128</span>, <span class="number">128</span>))</span><br><span class="line">crop_sample = crop_transform(sample)</span><br><span class="line"><span class="built_in">print</span>(crop_sample[<span class="string">&#x27;image&#x27;</span>].shape)           <span class="comment"># (128,  128, 3)</span></span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="16%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Pytorch-的数据集准备-20210508212958.jpg">
</p>

<h3 id="2-3-ToTensor"><a href="#2-3-ToTensor" class="headerlink" title="2.3 ToTensor"></a>2.3 ToTensor</h3><p>现在需要使用 <code>torch.from_numpy</code> 函数将数据转化成 <code>tensor</code>，在进行这项操作之前，考虑到 torch 的图片输入顺序为 <code>[C, H, W]</code>，而 numpy 的图片顺序为 <code>[H, W, C]</code>，因此需要通过 transpose 转化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToTensor</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Convert ndarrays in sample to Tensors.&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, sample</span>):</span></span><br><span class="line">        image, landmarks = sample[<span class="string">&#x27;image&#x27;</span>], sample[<span class="string">&#x27;landmarks&#x27;</span>]</span><br><span class="line">        <span class="comment"># swap color axis because</span></span><br><span class="line">        <span class="comment"># numpy image: H x W x C</span></span><br><span class="line">        <span class="comment"># torch image: C X H X W</span></span><br><span class="line">        image = image.transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;image&#x27;</span>: torch.from_numpy(image),</span><br><span class="line">                <span class="string">&#x27;landmarks&#x27;</span>: torch.from_numpy(landmarks)&#125;</span><br></pre></td></tr></table></figure>
<p>现在可以尝试改变图片的通道顺序，并转化成 tensor</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensor_transform = ToTensor()</span><br><span class="line">tensor_sample = tensor_transform(sample)</span><br><span class="line"><span class="built_in">print</span>(tensor_sample[<span class="string">&#x27;image&#x27;</span>].shape)           <span class="comment"># (3,  160, 160)</span></span><br></pre></td></tr></table></figure>

<h2 id="3-Compose-transforms"><a href="#3-Compose-transforms" class="headerlink" title="3. Compose transforms"></a>3. Compose transforms</h2><p>最后我们可以通过 <code>transforms.Compose</code> 函数将这些操作串联起来, 并将它传递 <code>FaceLandmarksDataset</code> 类的 <code>transform</code> 参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">composed_transform = transforms.Compose([Rescale((<span class="number">256</span>, <span class="number">256</span>)),</span><br><span class="line">                               RandomCrop((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">                               ToTensor()])</span><br><span class="line">face_dataset = FaceLandmarksDataset(csv_file=<span class="string">&#x27;faces/face_landmarks.csv&#x27;</span>,</span><br><span class="line">                                    root_dir=<span class="string">&#x27;faces/&#x27;</span>,</span><br><span class="line">                                    transform=composed_transform)</span><br></pre></td></tr></table></figure>

<h2 id="4-Iterating-through-the-dataset"><a href="#4-Iterating-through-the-dataset" class="headerlink" title="4. Iterating through the dataset"></a>4. Iterating through the dataset</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataloader = DataLoader(face_dataset, batch_size=<span class="number">32</span>, </span><br><span class="line">                                         shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span>)</span><br><span class="line"><span class="keyword">for</span> batch_samples <span class="keyword">in</span> dataloader:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=&gt; &quot;</span>, batch_samples[<span class="string">&quot;image&quot;</span>].shape, batch_samples[<span class="string">&#x27;landmarks&#x27;</span>].shape)</span><br></pre></td></tr></table></figure>
<p>打印出来的结果为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">=&gt;  torch.Size([32, 3, 224, 224]) torch.Size([32, 68, 2])</span><br><span class="line">=&gt;  torch.Size([32, 3, 224, 224]) torch.Size([32, 68, 2])</span><br><span class="line">=&gt;  torch.Size([5, 3, 224, 224]) torch.Size([5, 68, 2])</span><br></pre></td></tr></table></figure>

<p>一共有 69 张人脸图片，分成了 3 个 <code>batch</code> （32 + 32 +5）进行吞吐。</p>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
  </entry>
  <entry>
    <title>精确率、召回率和 ROC 曲线</title>
    <url>/2017/03/11/%E7%B2%BE%E7%A1%AE%E7%8E%87%E3%80%81%E5%8F%AC%E5%9B%9E%E7%8E%87%E5%92%8C-ROC-%E6%9B%B2%E7%BA%BF/</url>
    <content><![CDATA[<p>机器学习领域里评估指标这么多，今天就简单回顾下常用的准确率(accuracy)，精确率(precision) 和召回率(recall)等概念吧！哎，有时候时间太久了就会记不太清楚了。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/精确率、召回率和-ROC-曲线-20210508210547.png">
</p>

<span id="more"></span>

<p>首先来看看混淆矩阵：</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/精确率、召回率和-ROC-曲线-20210508210636.jpg">
</p>


<p><font color=blue>精确率(precision)</font>是针对<font color=red>预测结果</font>而言的，它表示的是<font color=red>预测为正的样本中有多少是对的</font>。那么预测为正就有两种可能：一种就是把正类预测为正类(TP)，另一种就是把负类预测为正类(FP)。</p>
<p align="center">
    <img width="18%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/精确率、召回率和-ROC-曲线-20210508210652.jpg">
</p>

<p><font color=blue>召回率(recall)</font>是针对<font color=red>原来样本</font>而言的，它表示的是<font color=red>样本中的正例有多少被预测正确了</font>。那也有两种可能：一种是把原来的正类预测成正类(TP)，另一种就是把原来的正类预测为负类(FN)。</p>
<p align="center">
    <img width="18%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/精确率、召回率和-ROC-曲线-20210508210658.jpg">
</p>


<p>一般来说，精确率和召回率是一对矛盾的度量。精确率高的时候，往往召回率就低；而召回率高的时候，精确率就会下降。当我们不断地调整评判阈值时，就能获得一条 <font color=red><strong>P-R 曲线</strong></font>。</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/精确率、召回率和-ROC-曲线-20210508210718.jpg">
</p>

<p>但是在人脸识别领域里，关注更多的还是 <strong><font color=red>ROC 曲线</font></strong>。例如，某某公司经常说自己的人脸识别算法可以做到在千万分之一误报率下其准确率超过 99%，这说的其实就是 ROC 曲线。要知道这个概念，就必须了解 <font color=blue>TPR（True Positive Rate）</font>和 <font color=blue>FPR（False Positive Rate）</font>的概念。</p>
<p><font color=red>TPR: 原来是对的，预测为对的比例。</font>（当然越大越好，1 为理想状态）</p>
<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/精确率、召回率和-ROC-曲线-20210508210709.jpg">
</p>


<p><font color=red>FPR: 原来是错的，预测为对的比例，误报率。</font>（当然越小越好，0 为理想状态）</p>
<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/精确率、召回率和-ROC-曲线-20210508210713.jpg">
</p>

<p>同样不断地调整评判阈值，就能获得一条 ROC 曲线。其中，ROC曲线下与坐标轴围成的面积称为 <font color=red><strong>AUC</strong></font>（AUC 的值越接近于 1，说明该模型就越好）。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/精确率、召回率和-ROC-曲线-20210508210722.jpg">
</p>

<p>最后，必须要注意的是<font color=blue>准确率(accuracy)</font>和<font color=blue>精确率(precision)</font>是不一样的: </p>
<p align="center">
    <img width="35%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/精确率、召回率和-ROC-曲线-20210508210704.jpg">
</p>


<p>参考文献:</p>
<ul>
<li>[1] 张志华，《机器学习》. 清华大学出版社，2016.</li>
<li>[2] <a href="http://www.bio1000.com/news/201811/203913.html">在人脸识别领域业界通常以误报率漏报率作为衡量算法能力的主要指标.</a></li>
</ul>
]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>精确率、召回率和ROC曲线</tag>
      </tags>
  </entry>
</search>
