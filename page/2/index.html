<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Stay hungry, Stay foolish"><title>四一的随写 | Stay hungry, Stay foolish</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">四一的随写</h1><a id="logo" href="/.">四一的随写</a><p class="description">Stay hungry, Stay foolish</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title"><a href="/2021/08/27/DeepSort-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E7%AE%97%E6%B3%95-SORT-%E7%9A%84%E8%BF%9B%E9%98%B6%E7%89%88/">DeepSort：多目标跟踪算法 Sort 的进化版</a></h1><div class="post-meta">2021-08-27</div><div class="post-content"><p>在<a target="_blank" rel="noopener" href="https://yunyang1994.gitee.io/2021/08/14/%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AASORT%E7%AE%97%E6%B3%95-Simple-Online-and-Realtime-Tracking/">之前的 Sort 算法</a>中讲到：<strong>尽管 Sort 具有速度快和计算量较小的优点，但它在关联匹配时没有用到物体的表观特征，导致物体被遮挡时容易出现 id-switch 的情况。</strong>针对这个算法的痛点，原 author 团队又发明了 Sort 的进化版 —— <a target="_blank" rel="noopener" href="https://arxiv.org/abs/1703.07402">DeepSort: Simple Online and Realtime Tracking with a Deep Associate Metric</a></p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/DeepSort-多目标跟踪算法-SORT-的进阶版-20210827115042.png">
</p></div><p class="readmore"><a href="/2021/08/27/DeepSort-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E7%AE%97%E6%B3%95-SORT-%E7%9A%84%E8%BF%9B%E9%98%B6%E7%89%88/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2021/08/21/%E4%B8%89%E7%BB%B4%E4%BA%BA%E4%BD%93%E6%A8%A1%E5%9E%8B-SMPL-A-Skinned-Multi-Person-Linear-Model/">三维人体动捕模型 SMPL：A Skinned Multi Person Linear Model</a></h1><div class="post-meta">2021-08-21</div><div class="post-content"><p>在<strong>人体动作捕捉</strong>（motion capture）领域，SMPL 算法最为常见，它是由德国马普所提出的一种参数化的三维人体动捕模型，具有通用性、易于渲染和兼容现有商业软件（比如 UE4 和 Unity）的优点。</p>
<p align="center">
    <img width="60%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/三维人体模型-SMPL-A-Skinned-Multi-Person-Linear-Model-20210816165705.png">
</p>

<p>「这是一篇鸽了很久的文章，今天补上。」</p></div><p class="readmore"><a href="/2021/08/21/%E4%B8%89%E7%BB%B4%E4%BA%BA%E4%BD%93%E6%A8%A1%E5%9E%8B-SMPL-A-Skinned-Multi-Person-Linear-Model/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2021/08/14/%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AASORT%E7%AE%97%E6%B3%95-Simple-Online-and-Realtime-Tracking/">多目标追踪 SORT 算法：Simple Online and Realtime Tracking</a></h1><div class="post-meta">2021-08-14</div><div class="post-content"><p>在<strong>多目标跟踪</strong>（multiple object tracking）领域，<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1602.00763">SORT（Simple Online and Realtime Tracking）</a>算是最经典的入门算法了。<a target="_blank" rel="noopener" href="https://github.com/YunYang1994/openwork/tree/master/sort">这份代码</a>对该算法进行了 python 和 C++ 实现，感兴趣的可以点开看看。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/多目标追踪SORT算法-Simple-Online-and-Realtime-Tracking-20210812202019.png">
</p></div><p class="readmore"><a href="/2021/08/14/%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%BF%BD%E8%B8%AASORT%E7%AE%97%E6%B3%95-Simple-Online-and-Realtime-Tracking/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2021/07/18/C++11_%E6%96%B0%E7%89%B9%E6%80%A7%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8/">C++11 新特性解析与应用</a></h1><div class="post-meta">2021-07-18</div><div class="post-content"><p>这是我这阵子学习 C++11 做的一些记录，材料大多来自《深入理解 C++11 新特性解析与应用》这本书。</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/C++11新特性解析与应用-20210720143126.jpg">
</p></div><p class="readmore"><a href="/2021/07/18/C++11_%E6%96%B0%E7%89%B9%E6%80%A7%E8%A7%A3%E6%9E%90%E4%B8%8E%E5%BA%94%E7%94%A8/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2021/07/10/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%AE%97%E6%B3%95-%E6%B0%B8%E8%BF%9C%E6%BB%B4%E7%A5%9E/">卡尔曼滤波算法，永远滴神！</a></h1><div class="post-meta">2021-07-10</div><div class="post-content"><p>鲁道夫 • 卡尔曼在一次访问 NASA 埃姆斯研究中心时，发现他的卡尔曼滤波算法能帮助解决阿波罗计划的轨道预测问题，最终，飞船正确驶向月球，完成了人类历史上的第一次登月。卡尔曼因而一举成名，后来还被美国总统奥巴马授予了国家科学勋章。</p>
<p align="center">
    <img width="45%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/卡尔曼滤波-永远滴神-20210712113922.jpeg">
</p></div><p class="readmore"><a href="/2021/07/10/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2%E7%AE%97%E6%B3%95-%E6%B0%B8%E8%BF%9C%E6%BB%B4%E7%A5%9E/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2021/06/06/%E7%90%86%E8%A7%A3%E8%8B%B1%E4%BC%9F%E8%BE%BE-TensorRT-%E7%9A%84-INT8-%E5%8A%A0%E9%80%9F%E5%8E%9F%E7%90%86/">理解英伟达 TensorRT 的 INT8 加速原理</a></h1><div class="post-meta">2021-06-06</div><div class="post-content"><p>目前的神经网络推理大部分是利用 32bit float 类型的数据进行计算的，bit 位数的多少直接限制了数据类型能够表达的数据范围，比如 float 32 的数据是由 1bit 表示符号，8bit 表示整数部，23 位表示分数部组成。但是这种运算比较耗时和消耗计算资源，因此诞生了 int8 量化算法。</p>
<p align="center">
    <img width="70%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/理解英伟达-TensorRT-的-INT8-加速原理-20210609152045.png">
</p>


<p>int8 量化是将数据保存为 int8 格式，这样一样计算时间和占用内存大大减小。目前量化有两种方式：一种是通过训练量化 finetune 原来的模型，另一种是直接对模型和计算进行量化。后者的代表便是英伟达的方案了，目前 PPT 已经公开，但是代码并没有开源。</p></div><p class="readmore"><a href="/2021/06/06/%E7%90%86%E8%A7%A3%E8%8B%B1%E4%BC%9F%E8%BE%BE-TensorRT-%E7%9A%84-INT8-%E5%8A%A0%E9%80%9F%E5%8E%9F%E7%90%86/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2021/05/23/C++_Primer-%E7%AC%AC5%E7%89%88-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/"> 去年阅读 《C++ Primer 中文版(第5版)》 的印象笔记</a></h1><div class="post-meta">2021-05-23</div><div class="post-content"><p>去年5月份我一个人从上海跳槽来广州，在这半年多的独居生活里我利用零碎的时间读了这本久负盛名 《C++ Primer 中文版(第5版)》。当时每周双休的时候坚持读大概二十页，竟不知不觉也读了一半多。但我觉得还是第六版写得更好，否则我也不会读了七八遍。而这本书还尚未读完，惭愧！</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/C++_Primer-第5版-阅读笔记-20210524180315.jpg">
</p>

<p>今天整理文档的时候发现了这份宝藏笔记，于是乎拿出来晒一晒。</p></div><p class="readmore"><a href="/2021/05/23/C++_Primer-%E7%AC%AC5%E7%89%88-%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2021/04/20/%E4%BF%AE%E6%94%B9-YOLOv5-%E6%BA%90%E7%A0%81%E5%9C%A8-DOTAv1.5-%E9%81%A5%E6%84%9F%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%97%8B%E8%BD%AC%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">修改 YOLOv5 源码在 DOTAv1.5 遥感数据集上进行旋转目标检测</a></h1><div class="post-meta">2021-04-20</div><div class="post-content"><p><a target="_blank" rel="noopener" href="https://github.com/ultralytics/yolov5">YOLOv5</a> 发布已经有一段时间了，但是我一直还没有怎么去用过它。机会终于来了，最近需要做一个「旋转目标检测」的项目。于是我想到用它来进行魔改，使其能输出目标的 <code>rotated bounding boxes</code>。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/修改-YOLOv5-源码在-DOTAv1.5-遥感数据集上进行旋转目标检测-20210509005417.jpg">
</p></div><p class="readmore"><a href="/2021/04/20/%E4%BF%AE%E6%94%B9-YOLOv5-%E6%BA%90%E7%A0%81%E5%9C%A8-DOTAv1.5-%E9%81%A5%E6%84%9F%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%97%8B%E8%BD%AC%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2020/12/19/%E7%94%A8-Python-%E6%89%8B%E6%92%B8%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E5%8D%95%E7%9B%AE-Slam-%E4%BE%8B%E5%AD%90/">随手用 Python 撸一个单目视觉里程计的例子</a></h1><div class="post-meta">2020-12-19</div><div class="post-content"><p>最近因工作需要，开始接触到一些关于 SLAM（Simultaneous Localization and Mapping）的研究。网上关于 slam 的资料有很多，譬如高博的十四讲，github 上的 VINS 等等。但是他们大多是用 C++ 写的，并且环境依赖复杂。今天， 我使用 Python 手撸了一个简单的单目 slam，对 slam 有了一个初步的认识。完整的代码在<a target="_blank" rel="noopener" href="https://github.com/YunYang1994/openwork/tree/master/MonocularSlam">这里</a>。</p>
<p align="center">
<iframe src="//player.bilibili.com/player.html?aid=245798532&bvid=BV1Tv411t7aN&cid=270731969&page=1"  width="400" height="300"  scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
</p></div><p class="readmore"><a href="/2020/12/19/%E7%94%A8-Python-%E6%89%8B%E6%92%B8%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E5%8D%95%E7%9B%AE-Slam-%E4%BE%8B%E5%AD%90/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2020/10/10/2D%E4%BA%BA%E4%BD%93%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E7%9A%84%E6%80%BB%E7%BB%93%E5%92%8C%E6%A2%B3%E7%90%86/">2D人体姿态估计的总结和梳理</a></h1><div class="post-meta">2020-10-10</div><div class="post-content"><p>最近在虎牙直播做了一些关于人体姿态估计的工作，也看了蛮多这方面的文章，于是对这个内容做了一些总结和梳理，希望能抛砖引玉吧。我们不妨先把问题抛出来，人体姿态估计是做什么？从名字的角度来看，可以理解为对“人体”的姿态（关键点，比如头，左手，右脚等）的位置估计。根据 RGB 图片里人体的数量，又可以分为<strong>单人姿态估计</strong>和<strong>多人姿态估计</strong>。</p>
<p align="center">
    <img width="100%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/2D人体姿态估计的总结和梳理-20210509001617.jpg">
</p></div><p class="readmore"><a href="/2020/10/10/2D%E4%BA%BA%E4%BD%93%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E7%9A%84%E6%80%BB%E7%BB%93%E5%92%8C%E6%A2%B3%E7%90%86/">阅读全文</a></p></div><nav class="page-navigator"><a class="extend prev" rel="prev" href="/">上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/3/">下一页</a></nav></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/">图像分割</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/">姿态估计</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/">杂七杂八</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/">目标跟踪</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/">立体视觉</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/anchor-free/" style="font-size: 15px;">anchor free</a> <a href="/tags/DeepSort/" style="font-size: 15px;">DeepSort</a> <a href="/tags/%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">角点检测</a> <a href="/tags/Faster-rcnn/" style="font-size: 15px;">Faster-rcnn</a> <a href="/tags/%E5%A4%9A%E5%8D%A1GPU%E8%AE%AD%E7%BB%83/" style="font-size: 15px;">多卡GPU训练</a> <a href="/tags/%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/" style="font-size: 15px;">移动端部署</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3/" style="font-size: 15px;">人脸矫正</a> <a href="/tags/%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2/" style="font-size: 15px;">仿射变换</a> <a href="/tags/%E7%9B%B8%E6%9C%BA%E4%BD%8D%E5%A7%BF/" style="font-size: 15px;">相机位姿</a> <a href="/tags/%E8%A7%86%E8%A7%89-Slam/" style="font-size: 15px;">视觉 Slam</a> <a href="/tags/mnist-%E5%88%86%E7%B1%BB/" style="font-size: 15px;">mnist 分类</a> <a href="/tags/rotated-object-detection/" style="font-size: 15px;">rotated object detection</a> <a href="/tags/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">全卷积网络</a> <a href="/tags/Skip-Connection/" style="font-size: 15px;">Skip Connection</a> <a href="/tags/Unet-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/" style="font-size: 15px;">Unet 网络结构</a> <a href="/tags/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/" style="font-size: 15px;">三维重建</a> <a href="/tags/%E5%8F%AF%E5%8F%98%E5%BD%A2%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">可变形卷积网络</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">深度估计</a> <a href="/tags/sort/" style="font-size: 15px;">sort</a> <a href="/tags/%E8%A7%86%E5%B7%AE%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">视差估计</a> <a href="/tags/%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D/" style="font-size: 15px;">立体匹配</a> <a href="/tags/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB/" style="font-size: 15px;">汉明距离</a> <a href="/tags/Batch-Normalization/" style="font-size: 15px;">Batch Normalization</a> <a href="/tags/TensorRT-%E9%83%A8%E7%BD%B2/" style="font-size: 15px;">TensorRT 部署</a> <a href="/tags/INT8-%E5%8A%A0%E9%80%9F%E5%8E%9F%E7%90%86/" style="font-size: 15px;">INT8 加速原理</a> <a href="/tags/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/" style="font-size: 15px;">立体视觉</a> <a href="/tags/%E7%9B%B8%E6%9C%BA%E5%8F%82%E6%95%B0/" style="font-size: 15px;">相机参数</a> <a href="/tags/%E7%B2%BE%E7%A1%AE%E7%8E%87%E3%80%81%E5%8F%AC%E5%9B%9E%E7%8E%87%E5%92%8CROC%E6%9B%B2%E7%BA%BF/" style="font-size: 15px;">精确率、召回率和ROC曲线</a> <a href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/" style="font-size: 15px;">梯度下降</a> <a href="/tags/hourglass-%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">hourglass 网络</a> <a href="/tags/C-%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">C++ 编程学习</a> <a href="/tags/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2/" style="font-size: 15px;">卡尔曼滤波</a> <a href="/tags/%E6%9C%AC%E8%B4%A8%E7%9F%A9%E9%98%B5/" style="font-size: 15px;">本质矩阵</a> <a href="/tags/YOLOv3/" style="font-size: 15px;">YOLOv3</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/09/18/%E8%AE%B2%E4%B8%80%E8%AE%B2%E7%9B%AE%E5%89%8D%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8B%E5%9F%BA%E4%BA%8E%E5%8D%95%E7%9B%AE%E7%9A%84%E4%B8%89%E7%BB%B4%E4%BA%BA%E4%BD%93%E9%87%8D%E5%BB%BA%E6%8A%80%E6%9C%AF/">讲一讲目前深度学习下基于单目的三维人体重建技术</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/09/FairMOT-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E9%87%8C%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%86%8D%E8%AF%86%E5%88%AB%E7%9A%84%E5%85%AC%E5%B9%B3%E6%80%A7/">FairMOT：讨论多目标跟踪里检测与再识别的公平性</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/08/%E6%BB%9A%E8%9B%8B%E5%90%A7-Anchor-%E5%90%9B-%E6%97%B7%E8%A7%86%E6%96%B0%E7%A7%91%E6%8A%80-YOLOX/">滚蛋吧，Anchor 君！旷视新科技，YOLOX</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/07/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F-Distilling-the-Knowledge-in-a-Neural-Network/">知识蒸馏：Distilling the Knowledge in a Neural Network</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/05/UnitBox%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84-iou-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-%E6%8A%8A%20box-%E5%BD%93%E4%BD%9C%E4%B8%80%E4%B8%AA%E6%95%B4%E4%BD%93%E5%8E%BB%E9%A2%84%E6%B5%8B/">UnitBox：一种新的 IoU 损失函数，把 box 当作一个整体去预测</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/03/%E8%A7%A3%E5%86%B3%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E4%B8%8D%E5%9D%87%E8%A1%A1%E9%97%AE%E9%A2%98%E2%80%94%E2%80%94Focal-Loss/">老生常谈 Focal Loss —— 解决正负样本不均衡问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/02/FCOS-Fully-Convolutional-One-Stage-Object-Detection/">FCOS：Fully Convolutional One-Stage Object Detection</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/01/CenterNet-Objects-as-Points/">CenterNet 和 CenterTrack：以点代物，同时进行目标检测和跟踪</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/01/CornerNet-Detecting-Objects-as-Paired-Keypoints/">CornerNet：Detecting Objects as Paired Keypoints</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/08/27/DeepSort-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E7%AE%97%E6%B3%95-SORT-%E7%9A%84%E8%BF%9B%E9%98%B6%E7%89%88/">DeepSort：多目标跟踪算法 Sort 的进化版</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://www.zhihu.com/people/yang-xiao-yun-tong-xue" title="我的知乎" target="_blank">我的知乎</a><ul></ul><a href="https://github.com/YunYang1994" title="我的 GitHub" target="_blank">我的 GitHub</a><ul></ul><a href="https://leetcode-cn.com/u/yunyang1994/" title="我的力扣" target="_blank">我的力扣</a><ul></ul><a href="https://blog.devtang.com" title="猿辅导创始人唐巧的博客" target="_blank">猿辅导创始人唐巧的博客</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">四一的随写.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=1.0.0"><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>