<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Stay hungry, Stay foolish"><title>四一的世界 | Stay hungry, Stay foolish</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">四一的世界</h1><a id="logo" href="/.">四一的世界</a><p class="description">Stay hungry, Stay foolish</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title"><a href="/2019/12/27/CameraPose/">什么是相机的位姿 ？</a></h1><div class="post-meta">2019-12-27</div><div class="post-content"><p>在视觉 slam 领域里，相机的位姿是一个特别重要的概念。简单来说，相机的位姿（pose）就是相机的位置和姿态的合称，它描述了世界坐标系与相机坐标系之间的转换关系。</p>
<p align="center">
    <img width="50%" src="https://gitee.com/yunyang1994/BlogSource/raw/master/hexo/source/images/CameraPose/RT.png">
</p></div><p class="readmore"><a href="/2019/12/27/CameraPose/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/12/23/CameraParam/">相机的内参和外参</a></h1><div class="post-meta">2019-12-23</div><div class="post-content"><p>相机的内参和外参是立体视觉的基础，今天做个笔记记录下。</p>
<h2 id="相机模型"><a href="#相机模型" class="headerlink" title="相机模型"></a>相机模型</h2><p>照片的本质是真实的 3D 场景在相机的成像平面上留下的一个投影，最早的相机是在小孔成像的基础上发展起来的，下面这幅图简单地解释了相机的成像过程。</p>
<p align="center">
    <img width="70%" src="https://gitee.com/yunyang1994/BlogSource/raw/master/hexo/source/images/CameraParam/01.png">
</p></div><p class="readmore"><a href="/2019/12/23/CameraParam/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/12/10/Deep3D/">基于卷积神经网络的 2D-to-3D 视频转换</a></h1><div class="post-meta">2019-12-10</div><div class="post-content"><p>目前制作 3D 电影的方法有两种：一种是直接用昂贵的立体相机设备进行拍摄，这种制作成本非常庞大。另一种则是通过图像处理技术将 2D 电影转化成 3D 格式，这种转换处理通常依赖于“深度艺术家”，他们手工地为每一帧创造深度图，然后利用标准的基于深度图像的渲染算法将与原始图像相结合，得到一个立体的图像对，这需要大量的人力成本。现在来说，每年只有 20 左右部新的 3D 电影发行。</p>
<p><img src="https://gitee.com/yunyang1994/BlogSource/raw/master/hexo/source/images/Deep3D/Deep3D_01.png" alt="image"></p></div><p class="readmore"><a href="/2019/12/10/Deep3D/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/11/18/%E5%8F%AF%E5%8F%98%E5%BD%A2%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%96%B0%E8%A7%86%E7%95%8C/">可变形卷积网络：计算机新“视”界</a></h1><div class="post-meta">2019-11-18</div><div class="post-content"><p>2017年，微软亚洲研究院视觉计算组的研究员在 arXiv 上公布了一篇题为 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1703.06211.pdf">“Deformable Convolutional Networks”（可变形卷积网络）</a> 的论文，首次在卷积神经网络（convolutional neutral networks，CNN）中引入了学习空间几何形变的能力，得到可变形卷积网络（deformable convolutional networks），从而更好地解决了具有空间形变的图像识别任务。</p>
<p align="center">
    <img width="55%" src="https://gitee.com/yunyang1994/BlogSource/raw/master/hexo/source/images/可变形卷积网络-计算机新视界/002.png">
</p>

<p>研究员们通过大量的实验结果验证了该方法在复杂的计算机视觉任务（如目标检测和语义分割）上的有效性，首次表明在深度卷积神经网络（deep CNN）中学习空间上密集的几何形变是可行的。</p></div><p class="readmore"><a href="/2019/11/18/%E5%8F%AF%E5%8F%98%E5%BD%A2%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%96%B0%E8%A7%86%E7%95%8C/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/09/27/RPN/">Faster-rcnn 里的区域生成网络（RPN）</a></h1><div class="post-meta">2019-09-27</div><div class="post-content"><p>我觉得 RPN 是目标检测领域里最经典也是最容易入门的网络了。如果你想学好目标检测，那一定不能不知道它！今天讲的 RPN 是来一篇来自 CVPR 2017 的论文 Expecting the Unexpected: Training Detectors for Unusual Pedestrians with Adversarial Imposters， 作者在 Faster-rcnn 的 RPN 基础上进行了改进，用于行人检测。</p>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p align="center">
    <img width="65%" src="https://gitee.com/yunyang1994/BlogSource/raw/master/hexo/source/images/RPN/RPN.png">
</p>


<p>上面是 RPN 的网络结构，它采用了 VGG16 网络进行特征提取。从 VGG16 的整体架构来看，作者为了提高 RPN 在不同分辨率图片下的检测率，分别将 Pool3 层、Pool4 层和 Pool5 层的输出进行卷积和融合得到了一个 45 x 60 x 1280 尺寸的 feature map。最后将这个 feature map 分别输入两个卷积层中得到 softmax 分类层与 bboxes 回归层。</p></div><p class="readmore"><a href="/2019/09/27/RPN/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/07/12/FCN/">全卷积神经网络（FCN)</a></h1><div class="post-meta">2019-07-12</div><div class="post-content"><p>在我还是实习生的时候，我们组的 leader 讲了 FCN 网络。由于当时对图像分割还不是很了解，所以也没太听懂，只记得他当时讲这篇文章拿了 CVPR-2015 的最佳论文奖。现在学习 FCN 就觉得，这应该是图像分割领域里最经典也是最适合入门的网络了吧。</p>
<p align="center">
    <img width="70%" src="https://gitee.com/yunyang1994/BlogSource/raw/master/hexo/source/images/FCN/67369222-33df5d80-f5ab-11e9-95d4-3d7813cfa0a8.png">
</p></div><p class="readmore"><a href="/2019/07/12/FCN/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/07/09/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96%E5%B1%82%EF%BC%88Batch-Normalization/">批量归一化层（Batch Normalization)</a></h1><div class="post-meta">2019-07-09</div><div class="post-content"><p>通常来说，数据标准化预处理对于浅层模型就足够有效了。<font color=red>但随着模型训练的进行，当每层中参数更新时，靠近输出层的输出容易出现剧烈变化。这令我们难以训练出有效的深度模型，而批量归一化（batch normalization）的提出正是为了应对这种挑战。</font></p>
<p align="center">
    <img width="40%" src="https://gitee.com/yunyang1994/BlogSource/raw/master/hexo/source/images/批量归一化层（Batch Normalization)/Internal_Covariate_Shift.jpg"></p>

<h2 id="BN-来源"><a href="#BN-来源" class="headerlink" title="BN 来源"></a>BN 来源</h2><p>在机器学习领域中，满足一个很重要的假设，即独立同分布的假设：就是假设训练数据和测试数据是满足相同分布的，这样通过训练数据获得的模型就能够在测试集获得一个较好的效果。而在实际的神经网络模型训练中，隐层的每一层数据分布老是变来变去的，这就是所谓的 <font color=red><strong>“Internal Covariate Shift”</strong></font>。</p></div><p class="readmore"><a href="/2019/07/09/%E6%89%B9%E9%87%8F%E5%BD%92%E4%B8%80%E5%8C%96%E5%B1%82%EF%BC%88Batch-Normalization/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2019/05/16/Tensorflow-%E6%A8%A1%E5%9E%8B%E8%BD%AC%E5%8C%96-tflite/">TensorFlow 模型转化 tflite</a></h1><div class="post-meta">2019-05-16</div><div class="post-content"><p>自从有了TensorFlow Lite，应用开发者可以在移动设备上很轻松地部署神经网络。</p>
<p align="center">
    <img width="90%" src="https://gitee.com/yunyang1994/BlogSource/raw/master/hexo/source/images/Tensorflow-模型转化-tflite/tflite.jpg">
</p></div><p class="readmore"><a href="/2019/05/16/Tensorflow-%E6%A8%A1%E5%9E%8B%E8%BD%AC%E5%8C%96-tflite/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/12/28/YOLOv3/">YOLOv3 算法的一点理解</a></h1><div class="post-meta">2018-12-28</div><div class="post-content"><p>今天讲一讲 YOLOv3, 目标检测网络的巅峰之作, 疾如风，快如闪电。</p>
<p align="center">
    <img width="40%" src="https://gitee.com/yunyang1994/BlogSource/raw/master/hexo/source/images/YOLOv3/sayit.jpg">
</p></div><p class="readmore"><a href="/2018/12/28/YOLOv3/">阅读全文</a></p></div><div class="post"><h1 class="post-title"><a href="/2018/11/12/Unet/">医学图片分割网络 —— Unet</a></h1><div class="post-meta">2018-11-12</div><div class="post-content"><p>Unet 是 Kaggle 语义分割挑战赛上的常客。因为它简单，高效，易懂，容易定制，最主要的是它可以从相对较小的数据集中学习。在医学图像处理领域，各路高手更是拿着 Unet 各种魔改。</p>
<h2 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h2><p>U-Net 与 FCN 非常的相似（比如都没有使用全连接层），U-Net 比 FCN 稍晚提出来，但都发表在 2015 年，和 FCN 相比，U-Net 的第一个特点是完全对称，也就是左边和右边是很类似的。当我第一次看到该网络的拓扑结构时，顿时惊为天人，卧槽，简直是一个大写的 U。</p>
<p align="center">
    <img width="65%" src="https://gitee.com/yunyang1994/BlogSource/raw/master/hexo/source/images/Unet/Unet.png">
</p></div><p class="readmore"><a href="/2018/11/12/Unet/">阅读全文</a></p></div><nav class="page-navigator"><a class="extend prev" rel="prev" href="/">上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/">下一页</a></nav></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/">图像分割</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/">姿态估计</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/">立体视觉</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2/" style="font-size: 15px;">仿射变换</a> <a href="/tags/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/" style="font-size: 15px;">立体视觉</a> <a href="/tags/%E7%9B%B8%E6%9C%BA%E5%8F%82%E6%95%B0/" style="font-size: 15px;">相机参数</a> <a href="/tags/%E7%9B%B8%E6%9C%BA%E4%BD%8D%E5%A7%BF/" style="font-size: 15px;">相机位姿</a> <a href="/tags/%E8%A7%86%E8%A7%89-Slam/" style="font-size: 15px;">视觉 Slam</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">深度估计</a> <a href="/tags/%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">角点检测</a> <a href="/tags/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">全卷积网络</a> <a href="/tags/Skip-Connection/" style="font-size: 15px;">Skip Connection</a> <a href="/tags/Faster-rcnn/" style="font-size: 15px;">Faster-rcnn</a> <a href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/" style="font-size: 15px;">梯度下降</a> <a href="/tags/%E8%A7%86%E5%B7%AE%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">视差估计</a> <a href="/tags/%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D/" style="font-size: 15px;">立体匹配</a> <a href="/tags/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB/" style="font-size: 15px;">汉明距离</a> <a href="/tags/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/" style="font-size: 15px;">三维重建</a> <a href="/tags/%E5%A4%9A%E5%8D%A1GPU%E8%AE%AD%E7%BB%83/" style="font-size: 15px;">多卡GPU训练</a> <a href="/tags/Unet-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/" style="font-size: 15px;">Unet 网络结构</a> <a href="/tags/%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/" style="font-size: 15px;">移动端部署</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3/" style="font-size: 15px;">人脸矫正</a> <a href="/tags/mnist-%E5%88%86%E7%B1%BB/" style="font-size: 15px;">mnist 分类</a> <a href="/tags/rotated-object-detection/" style="font-size: 15px;">rotated object detection</a> <a href="/tags/%E5%8F%AF%E5%8F%98%E5%BD%A2%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">可变形卷积网络</a> <a href="/tags/Batch-Normalization/" style="font-size: 15px;">Batch Normalization</a> <a href="/tags/%E7%B2%BE%E7%A1%AE%E7%8E%87%E3%80%81%E5%8F%AC%E5%9B%9E%E7%8E%87%E5%92%8CROC%E6%9B%B2%E7%BA%BF/" style="font-size: 15px;">精确率、召回率和ROC曲线</a> <a href="/tags/hourglass-%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">hourglass 网络</a> <a href="/tags/%E6%9C%AC%E8%B4%A8%E7%9F%A9%E9%98%B5/" style="font-size: 15px;">本质矩阵</a> <a href="/tags/YOLOv3/" style="font-size: 15px;">YOLOv3</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/04/20/%E4%BF%AE%E6%94%B9-YOLOv5-%E6%BA%90%E7%A0%81%E5%9C%A8-DOTAv1.5-%E9%81%A5%E6%84%9F%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%97%8B%E8%BD%AC%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">修改 YOLOv5 源码在 DOTAv1.5 遥感数据集上进行旋转目标检测</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/19/%E7%94%A8-Python-%E6%89%8B%E6%92%B8%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E5%8D%95%E7%9B%AE-Slam-%E4%BE%8B%E5%AD%90/">用 Python 手撸一个单目视觉里程计的例子</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/10/2D%E4%BA%BA%E4%BD%93%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E7%9A%84%E8%BF%87%E5%8E%BB%EF%BC%8C%E7%8E%B0%E5%9C%A8%E5%92%8C%E6%9C%AA%E6%9D%A5/">2D人体姿态估计的总结和梳理</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/16/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E4%B9%8B%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3/">人脸识别之人脸矫正</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/TensorFlow-%E7%9A%84%E5%A4%9A%E5%8D%A1-GPU-%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%88%B6/">TensorFlow 的多卡 GPU 训练机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/22/AffineTransformation/">说说图像的仿射变换</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/21/SGD/">能不能用梯度下降法求解平方根 ？</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/20/SGM_02/">手写双目立体匹配 SGM 算法（下)</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/17/SGM_01/">手写双目立体匹配 SGM 算法（上)</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/29/StereoVision/">双目测距和三维重建</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/YunYang1994" title="YunYang1994's GitHub" target="_blank">YunYang1994's GitHub</a><ul></ul><a href="https://blog.devtang.com" title="猿辅导创始人唐巧的博客" target="_blank">猿辅导创始人唐巧的博客</a><ul></ul><a href="http://pengzhihui.xyz" title="稚晖的个人站" target="_blank">稚晖的个人站</a><ul></ul><a href="https://wizyoung.github.io" title="CaptainChen" target="_blank">CaptainChen</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">四一的世界.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=1.0.0"><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>