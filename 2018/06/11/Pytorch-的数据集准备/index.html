<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Stay hungry, Stay foolish"><title>Pytorch 的数据集准备 | 四一的随写</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Pytorch 的数据集准备</h1><a id="logo" href="/.">四一的随写</a><p class="description">Stay hungry, Stay foolish</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Pytorch 的数据集准备</h1><div class="post-meta">2018-06-11<span> | </span><span class="category"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 1.1k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 5</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>深度学习的绝大部分工作都是在准备数据集，<strong>Pytorch</strong> 提供了很多工具使数据加载变得更简单。在本节内容中，我们来看看是如何利用 <strong>torch.utils.data.DataLoader</strong> 加载数据集的。</p>
<p>首先需要 import 一些必要的库：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> skimage</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, utils</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> Dataset, DataLoader</span><br></pre></td></tr></table></figure>

<p>然后从<a target="_blank" rel="noopener" href="https://download.pytorch.org/tutorial/faces.zip">这里</a>下载一个名为 <strong>faces</strong> 的文件夹，该文件夹里包含了一些 <strong>68 个特征点（part_0 ~ part_67)</strong> 的人脸图片和 <code>face_landmarks.csv</code> </p>
<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Pytorch-的数据集准备-20210508212935.jpg">
</p>

<span id="more"></span>

<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">landmarks_frame = pd.read_csv(<span class="string">&#x27;faces/face_landmarks.csv&#x27;</span>)</span><br><span class="line">landmarks_frame.head()</span><br></pre></td></tr></table></figure>

<h2 id="1-Dataset-class"><a href="#1-Dataset-class" class="headerlink" title="1. Dataset class"></a>1. Dataset class</h2><p><code>torch.utils.data.Dataset</code> 是一个抽象的类，我们构造的数据集需要继承它得到，并且重载下面 2 个成员函数：</p>
<ul>
<li><code>__len__</code> 函数，通过<code>len(dataset)</code>返回数据集大小；</li>
<li><code>__getitem__</code> 函数，通过索引<code>dataset[i]</code>而得到一个样本。</li>
</ul>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">FaceLandmarksDataset</span>(<span class="params">Dataset</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Face Landmarks dataset.&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, csv_file, root_dir, transform=<span class="literal">None</span></span>):</span></span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        Args:</span></span><br><span class="line"><span class="string">            csv_file (string): Path to the csv file with annotations.</span></span><br><span class="line"><span class="string">            root_dir (string): Directory with all the images.</span></span><br><span class="line"><span class="string">            transform (callable, optional): Optional transform to be applied</span></span><br><span class="line"><span class="string">                on a sample.</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        self.landmarks_frame = pd.read_csv(csv_file)</span><br><span class="line">        self.root_dir = root_dir</span><br><span class="line">        self.transform = transform</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__len__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">len</span>(self.landmarks_frame)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getitem__</span>(<span class="params">self, idx</span>):</span></span><br><span class="line">        <span class="keyword">if</span> torch.is_tensor(idx):</span><br><span class="line">            idx = idx.tolist()</span><br><span class="line"></span><br><span class="line">        img_name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, <span class="number">0</span>])</span><br><span class="line">        image = skimage.io.imread(img_name)</span><br><span class="line">        </span><br><span class="line">        landmarks = self.landmarks_frame.iloc[idx, <span class="number">1</span>:]</span><br><span class="line">        landmarks = np.array([landmarks])</span><br><span class="line">        landmarks = landmarks.astype(<span class="string">&#x27;float&#x27;</span>).reshape(-<span class="number">1</span>, <span class="number">2</span>)</span><br><span class="line">        </span><br><span class="line">        sample = &#123;<span class="string">&#x27;image&#x27;</span>: image, <span class="string">&#x27;landmarks&#x27;</span>: landmarks&#125;</span><br><span class="line">        <span class="keyword">if</span> self.transform:</span><br><span class="line">            sample = self.transform(sample)</span><br><span class="line">        <span class="keyword">return</span> sample</span><br></pre></td></tr></table></figure>

<p>现在我们可以对 <code>FaceLandmarksDataset</code> 类构建一个实例 <code>face_dataset</code>。其中每个样本都是一个字典，分别是 <code>&#39;image&#39;</code> 和 <code>&#39;landmarks&#39;</code> 。我们可以索引第 65 个样本将它们的数组形状打印出来。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">face_dataset = FaceLandmarksDataset(csv_file=<span class="string">&#x27;faces/face_landmarks.csv&#x27;</span>,</span><br><span class="line">                                    root_dir=<span class="string">&#x27;faces/&#x27;</span>)</span><br><span class="line">sample = face_dataset[<span class="number">65</span>]             <span class="comment"># 取第 65 个样本</span></span><br><span class="line"><span class="built_in">print</span>(sample[<span class="string">&#x27;image&#x27;</span>].shape)          <span class="comment"># (160, 160, 3)</span></span><br><span class="line"><span class="built_in">print</span>(sample[<span class="string">&#x27;landmarks&#x27;</span>].shape)      <span class="comment"># (68, 2)</span></span><br></pre></td></tr></table></figure>

<h2 id="2-Transforms"><a href="#2-Transforms" class="headerlink" title="2. Transforms"></a>2. Transforms</h2><p>上述过程完成了对人脸图片和 65 个特征点的读取，接下来需要对它们进行一些预处理操作。本文将介绍 3 种 Transforms 操作：</p>
<ul>
<li>Rescale，对图片进行 <code>resize</code> 操作</li>
<li>RandomCrop，随机地裁剪图片</li>
<li>ToTensor，将 numpy 的 <code>array</code> 类型转变为 torch 的 <code>tensor</code> 类型</li>
</ul>
<h3 id="2-1-Rescale"><a href="#2-1-Rescale" class="headerlink" title="2.1 Rescale"></a>2.1 Rescale</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Rescale</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Rescale the image in a sample to a given size.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        output_size (tuple or int): Desired output size. If tuple, output is</span></span><br><span class="line"><span class="string">            matched to output_size. If int, smaller of image edges is matched</span></span><br><span class="line"><span class="string">            to output_size keeping aspect ratio the same.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, output_size</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(output_size, <span class="built_in">tuple</span>)</span><br><span class="line">        self.output_size = output_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, sample</span>):</span></span><br><span class="line">        image, landmarks = sample[<span class="string">&#x27;image&#x27;</span>], sample[<span class="string">&#x27;landmarks&#x27;</span>]</span><br><span class="line">        </span><br><span class="line">        h, w = image.shape[:<span class="number">2</span>]</span><br><span class="line">        new_h, new_w = self.output_size</span><br><span class="line"></span><br><span class="line">        img = skimage.transform.resize(image, (new_h, new_w))</span><br><span class="line">        landmarks = landmarks * [new_w / w, new_h / h]</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;image&#x27;</span>: img, <span class="string">&#x27;landmarks&#x27;</span>: landmarks&#125;</span><br></pre></td></tr></table></figure>
<p>然后我们对人脸图片的尺寸 resize 到 (256, 256)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">rescale_transform = Rescale((<span class="number">256</span>, <span class="number">256</span>))</span><br><span class="line">rescale_sample = rescale_transform(sample)</span><br><span class="line"><span class="built_in">print</span>(rescale_sample[<span class="string">&#x27;image&#x27;</span>].shape)           <span class="comment"># (256,  256, 3)</span></span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="27%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Pytorch-的数据集准备-20210508212935.jpg">
</p>

<h3 id="2-2-RandomCrop"><a href="#2-2-RandomCrop" class="headerlink" title="2.2 RandomCrop"></a>2.2 RandomCrop</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">RandomCrop</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Crop randomly the image in a sample.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Args:</span></span><br><span class="line"><span class="string">        output_size (tuple): Desired output size is made.</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self, output_size</span>):</span></span><br><span class="line">        <span class="keyword">assert</span> <span class="built_in">isinstance</span>(output_size, <span class="built_in">tuple</span>)</span><br><span class="line">        self.output_size = output_size</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, sample</span>):</span></span><br><span class="line">        image, landmarks = sample[<span class="string">&#x27;image&#x27;</span>], sample[<span class="string">&#x27;landmarks&#x27;</span>]</span><br><span class="line"></span><br><span class="line">        h, w = image.shape[:<span class="number">2</span>]</span><br><span class="line">        new_h, new_w = self.output_size</span><br><span class="line"></span><br><span class="line">        top = np.random.randint(<span class="number">0</span>, h - new_h)</span><br><span class="line">        left = np.random.randint(<span class="number">0</span>, w - new_w)</span><br><span class="line"></span><br><span class="line">        image = image[top: top + new_h, left: left + new_w]</span><br><span class="line">        landmarks = landmarks - [left, top]</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;image&#x27;</span>: image, <span class="string">&#x27;landmarks&#x27;</span>: landmarks&#125;</span><br></pre></td></tr></table></figure>
<p>然后我们对人脸图片进行随机裁剪，裁剪的尺寸大小为 (128, 128)</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">crop_transform = RandomCrop((<span class="number">128</span>, <span class="number">128</span>))</span><br><span class="line">crop_sample = crop_transform(sample)</span><br><span class="line"><span class="built_in">print</span>(crop_sample[<span class="string">&#x27;image&#x27;</span>].shape)           <span class="comment"># (128,  128, 3)</span></span><br></pre></td></tr></table></figure>

<p align="center">
    <img width="16%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/Pytorch-的数据集准备-20210508212958.jpg">
</p>

<h3 id="2-3-ToTensor"><a href="#2-3-ToTensor" class="headerlink" title="2.3 ToTensor"></a>2.3 ToTensor</h3><p>现在需要使用 <code>torch.from_numpy</code> 函数将数据转化成 <code>tensor</code>，在进行这项操作之前，考虑到 torch 的图片输入顺序为 <code>[C, H, W]</code>，而 numpy 的图片顺序为 <code>[H, W, C]</code>，因此需要通过 transpose 转化。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ToTensor</span>(<span class="params"><span class="built_in">object</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Convert ndarrays in sample to Tensors.&quot;&quot;&quot;</span></span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__call__</span>(<span class="params">self, sample</span>):</span></span><br><span class="line">        image, landmarks = sample[<span class="string">&#x27;image&#x27;</span>], sample[<span class="string">&#x27;landmarks&#x27;</span>]</span><br><span class="line">        <span class="comment"># swap color axis because</span></span><br><span class="line">        <span class="comment"># numpy image: H x W x C</span></span><br><span class="line">        <span class="comment"># torch image: C X H X W</span></span><br><span class="line">        image = image.transpose((<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>))</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&#x27;image&#x27;</span>: torch.from_numpy(image),</span><br><span class="line">                <span class="string">&#x27;landmarks&#x27;</span>: torch.from_numpy(landmarks)&#125;</span><br></pre></td></tr></table></figure>
<p>现在可以尝试改变图片的通道顺序，并转化成 tensor</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">tensor_transform = ToTensor()</span><br><span class="line">tensor_sample = tensor_transform(sample)</span><br><span class="line"><span class="built_in">print</span>(tensor_sample[<span class="string">&#x27;image&#x27;</span>].shape)           <span class="comment"># (3,  160, 160)</span></span><br></pre></td></tr></table></figure>

<h2 id="3-Compose-transforms"><a href="#3-Compose-transforms" class="headerlink" title="3. Compose transforms"></a>3. Compose transforms</h2><p>最后我们可以通过 <code>transforms.Compose</code> 函数将这些操作串联起来, 并将它传递 <code>FaceLandmarksDataset</code> 类的 <code>transform</code> 参数：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">composed_transform = transforms.Compose([Rescale((<span class="number">256</span>, <span class="number">256</span>)),</span><br><span class="line">                               RandomCrop((<span class="number">224</span>, <span class="number">224</span>)),</span><br><span class="line">                               ToTensor()])</span><br><span class="line">face_dataset = FaceLandmarksDataset(csv_file=<span class="string">&#x27;faces/face_landmarks.csv&#x27;</span>,</span><br><span class="line">                                    root_dir=<span class="string">&#x27;faces/&#x27;</span>,</span><br><span class="line">                                    transform=composed_transform)</span><br></pre></td></tr></table></figure>

<h2 id="4-Iterating-through-the-dataset"><a href="#4-Iterating-through-the-dataset" class="headerlink" title="4. Iterating through the dataset"></a>4. Iterating through the dataset</h2><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataloader = DataLoader(face_dataset, batch_size=<span class="number">32</span>, </span><br><span class="line">                                         shuffle=<span class="literal">True</span>, num_workers=<span class="number">4</span>)</span><br><span class="line"><span class="keyword">for</span> batch_samples <span class="keyword">in</span> dataloader:</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=&gt; &quot;</span>, batch_samples[<span class="string">&quot;image&quot;</span>].shape, batch_samples[<span class="string">&#x27;landmarks&#x27;</span>].shape)</span><br></pre></td></tr></table></figure>
<p>打印出来的结果为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">=&gt;  torch.Size([32, 3, 224, 224]) torch.Size([32, 68, 2])</span><br><span class="line">=&gt;  torch.Size([32, 3, 224, 224]) torch.Size([32, 68, 2])</span><br><span class="line">=&gt;  torch.Size([5, 3, 224, 224]) torch.Size([5, 68, 2])</span><br></pre></td></tr></table></figure>

<p>一共有 69 张人脸图片，分成了 3 个 <code>batch</code> （32 + 32 +5）进行吞吐。</p>
</div><script type="text/javascript" src="/js/share.js?v=1.0.0" async></script><a class="article-share-link" data-url="https://yunyang1994.github.io/2018/06/11/Pytorch-%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E5%87%86%E5%A4%87/" data-id="ckw5vsray000g1vra92967tn9" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAPYAAAD2CAAAAADAeSUUAAADJklEQVR42u3aQW7jQAwEwP3/p7PXBIHsbtIJonHpZBiKRjWHtEnOv3/x9fHp+vzN1efv93+/8+r+5Lp6qxdf2NjY2DdhbxbY3Jm/evJuuQUbGxv7VPbVYu09jzeifc6M/fj52NjY2NibJWeAxyUNNjY2NvYswHJAslYbh0mrCxsbG/vd2C0jXyB/rXZTfqmXho2Njf3n2flU9O9//pH5NjY2NvYfZs8OymwiLYm3dsBQK7CxsbEPYucB0L5QPqydDRjyRtVlqYONjY19BHuGSZpBeVsnbzNtGk9fvsHGxsY+jp3/3J819DcFT97YyiMTGxsb+yR2W3gk4HbhTUzOZgHY2NjYZ7M3pPwJs+JkNn6u9wYbGxv7huzZAHUTXe2dOa8YJGBjY2Mfym4jIYmufMteVa5EzTJsbGzsI9htwCRlw744acfG9XZgY2NjvwF7Nrhtoyh/Wn6gJxonYGNjYx/Ebhs37eGY/JmbuMq3BhsbG/tsdv7NrD30E02lVUsLGxsb+yD2rCXUwjZxlT+5LkiwsbGxb87OW//RnpVto7aRtGkqXU62sbGxsW/O3odZEjB5eTDboNWQABsbG/sI9iwwZocy8yHBJhqjLcDGxsY+gt2G02vZ+8OXw43AxsbGPoi9j6u8OGmHx/nn1TwEGxsb+w3Ym9FsEhvJdmwOEg2n3NjY2Ng3Yef/+mc/9GelTjJsmMXYlwoMGxsb+wh2O3Z9LW/2hHxs8CSMsbGxsQ9iv/aoZX4qJh/ubg5iPtk4bGxs7CPYswJj05qfxeGsqXS5fdjY2NjHsdvgyReYNa3asGwPEmFjY2Ofys5rl9nxnd9kP1kXGxsb+zh2PmqdbUpbBeTlSl7wYGNjY5/H/iivWVOpBRSNodmIAhsbG/sgdn7lJUTLbsfMm6irtwAbGxv7Juz21fMWUhJ47eBhtu6w84SNjY19K/YsVFpGW/C0o9y8zYSNjY39zuzHn9u/yrdp/4arAMPGxsY+iJ0HWFLwzMqVdtz75KQSNjY29hHsdny7iZO8id8WJ3mgYmNjY5/EbtsxbZu+HRvvR8uboMXGxsa+Ffs/oL4XcqhYKM0AAAAASUVORK5CYII=">分享</a><div class="tags"></div><div class="post-nav"><a class="pre" href="/2018/07/17/FAST-%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B/">FAST 角点检测</a><a class="next" href="/2017/03/11/%E7%B2%BE%E7%A1%AE%E7%8E%87%E3%80%81%E5%8F%AC%E5%9B%9E%E7%8E%87%E5%92%8C-ROC-%E6%9B%B2%E7%BA%BF/">精确率、召回率和 ROC 曲线</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/">图像分割</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/">姿态估计</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/">杂七杂八</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/">目标跟踪</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/">立体视觉</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/anchor-free/" style="font-size: 15px;">anchor free</a> <a href="/tags/DeepSort/" style="font-size: 15px;">DeepSort</a> <a href="/tags/%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">角点检测</a> <a href="/tags/Faster-rcnn/" style="font-size: 15px;">Faster-rcnn</a> <a href="/tags/%E5%A4%9A%E5%8D%A1GPU%E8%AE%AD%E7%BB%83/" style="font-size: 15px;">多卡GPU训练</a> <a href="/tags/%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/" style="font-size: 15px;">移动端部署</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3/" style="font-size: 15px;">人脸矫正</a> <a href="/tags/%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2/" style="font-size: 15px;">仿射变换</a> <a href="/tags/%E7%9B%B8%E6%9C%BA%E4%BD%8D%E5%A7%BF/" style="font-size: 15px;">相机位姿</a> <a href="/tags/%E8%A7%86%E8%A7%89-Slam/" style="font-size: 15px;">视觉 Slam</a> <a href="/tags/mnist-%E5%88%86%E7%B1%BB/" style="font-size: 15px;">mnist 分类</a> <a href="/tags/rotated-object-detection/" style="font-size: 15px;">rotated object detection</a> <a href="/tags/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">全卷积网络</a> <a href="/tags/Skip-Connection/" style="font-size: 15px;">Skip Connection</a> <a href="/tags/Unet-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/" style="font-size: 15px;">Unet 网络结构</a> <a href="/tags/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/" style="font-size: 15px;">三维重建</a> <a href="/tags/%E5%8F%AF%E5%8F%98%E5%BD%A2%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">可变形卷积网络</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">深度估计</a> <a href="/tags/sort/" style="font-size: 15px;">sort</a> <a href="/tags/%E8%A7%86%E5%B7%AE%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">视差估计</a> <a href="/tags/%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D/" style="font-size: 15px;">立体匹配</a> <a href="/tags/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB/" style="font-size: 15px;">汉明距离</a> <a href="/tags/Batch-Normalization/" style="font-size: 15px;">Batch Normalization</a> <a href="/tags/TensorRT-%E9%83%A8%E7%BD%B2/" style="font-size: 15px;">TensorRT 部署</a> <a href="/tags/INT8-%E5%8A%A0%E9%80%9F%E5%8E%9F%E7%90%86/" style="font-size: 15px;">INT8 加速原理</a> <a href="/tags/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/" style="font-size: 15px;">立体视觉</a> <a href="/tags/%E7%9B%B8%E6%9C%BA%E5%8F%82%E6%95%B0/" style="font-size: 15px;">相机参数</a> <a href="/tags/%E7%B2%BE%E7%A1%AE%E7%8E%87%E3%80%81%E5%8F%AC%E5%9B%9E%E7%8E%87%E5%92%8CROC%E6%9B%B2%E7%BA%BF/" style="font-size: 15px;">精确率、召回率和ROC曲线</a> <a href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/" style="font-size: 15px;">梯度下降</a> <a href="/tags/hourglass-%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">hourglass 网络</a> <a href="/tags/C-%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">C++ 编程学习</a> <a href="/tags/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2/" style="font-size: 15px;">卡尔曼滤波</a> <a href="/tags/%E6%9C%AC%E8%B4%A8%E7%9F%A9%E9%98%B5/" style="font-size: 15px;">本质矩阵</a> <a href="/tags/YOLOv3/" style="font-size: 15px;">YOLOv3</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/09/18/%E8%AE%B2%E4%B8%80%E8%AE%B2%E7%9B%AE%E5%89%8D%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8B%E5%9F%BA%E4%BA%8E%E5%8D%95%E7%9B%AE%E7%9A%84%E4%B8%89%E7%BB%B4%E4%BA%BA%E4%BD%93%E9%87%8D%E5%BB%BA%E6%8A%80%E6%9C%AF/">讲一讲目前深度学习下基于单目的三维人体重建技术</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/09/FairMOT-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E9%87%8C%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%86%8D%E8%AF%86%E5%88%AB%E7%9A%84%E5%85%AC%E5%B9%B3%E6%80%A7/">FairMOT：讨论多目标跟踪里检测与再识别的公平性</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/08/%E6%BB%9A%E8%9B%8B%E5%90%A7-Anchor-%E5%90%9B-%E6%97%B7%E8%A7%86%E6%96%B0%E7%A7%91%E6%8A%80-YOLOX/">滚蛋吧，Anchor 君！旷视新科技，YOLOX</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/07/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F-Distilling-the-Knowledge-in-a-Neural-Network/">知识蒸馏：Distilling the Knowledge in a Neural Network</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/05/UnitBox%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84-iou-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-%E6%8A%8A%20box-%E5%BD%93%E4%BD%9C%E4%B8%80%E4%B8%AA%E6%95%B4%E4%BD%93%E5%8E%BB%E9%A2%84%E6%B5%8B/">UnitBox：一种新的 IoU 损失函数，把 box 当作一个整体去预测</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/03/%E8%A7%A3%E5%86%B3%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E4%B8%8D%E5%9D%87%E8%A1%A1%E9%97%AE%E9%A2%98%E2%80%94%E2%80%94Focal-Loss/">老生常谈 Focal Loss —— 解决正负样本不均衡问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/02/FCOS-Fully-Convolutional-One-Stage-Object-Detection/">FCOS：Fully Convolutional One-Stage Object Detection</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/01/CenterNet-Objects-as-Points/">CenterNet 和 CenterTrack：以点代物，同时进行目标检测和跟踪</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/01/CornerNet-Detecting-Objects-as-Paired-Keypoints/">CornerNet：Detecting Objects as Paired Keypoints</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/08/27/DeepSort-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E7%AE%97%E6%B3%95-SORT-%E7%9A%84%E8%BF%9B%E9%98%B6%E7%89%88/">DeepSort：多目标跟踪算法 Sort 的进化版</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://www.zhihu.com/people/yang-xiao-yun-tong-xue" title="我的知乎" target="_blank">我的知乎</a><ul></ul><a href="https://github.com/YunYang1994" title="我的 GitHub" target="_blank">我的 GitHub</a><ul></ul><a href="https://leetcode-cn.com/u/yunyang1994/" title="我的力扣" target="_blank">我的力扣</a><ul></ul><a href="https://blog.devtang.com" title="猿辅导创始人唐巧的博客" target="_blank">猿辅导创始人唐巧的博客</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">四一的随写.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=1.0.0"><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>