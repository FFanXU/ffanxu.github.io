<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Stay hungry, Stay foolish"><title>双目测距和三维重建 | 四一的随写</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">双目测距和三维重建</h1><a id="logo" href="/.">四一的随写</a><p class="description">Stay hungry, Stay foolish</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">双目测距和三维重建</h1><div class="post-meta">2019-12-29<span> | </span><span class="category"><a href="/categories/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/">立体视觉</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 517</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 2</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>双目相机通过同步采集左右相机的图像，计算图像间视差，来估计每一个像素的深度。一旦我们获取了物体在图像上的每个像素深度，我们便能重构出一些它的三维信息。</p>
<p align="center">
    <img width="50%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/双目测距和三维重建-20210508235103.gif">
</p>

<p>双目相机一般由左眼和右眼两个水平放置的相机组成，其距离称为双目相机的基线(Baseline, 记作 b)，是双目的重要参数。由于左右两个相机之间有一定距离，因此同一个物体在左右图上的横坐标会有一些差异，称为<font color=red><strong>视差(Disparity)</strong></font>。</p>
<span id="more"></span>

<p align="center">
    <img width="30%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/双目测距和三维重建-20210508235112.png">
</p>


<p>根据视差，我们可以估计一个像素离相机的距离。</p>
<p align="center">
    <img width="40%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/双目测距和三维重建-20210508235118.png">
</p>

<p align="center">
    <img width="28%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/双目测距和三维重建-20210508235217.jpg">
</p>

<p>根据相机坐标系点 <code>P</code> 坐标为 <code>(X, Y, Z)</code> 到图像坐标系 <code>(u, v)</code> 之间的投影关系：</p>
<p align="center">
    <img width="20%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/双目测距和三维重建-20210508235222.jpg">
</p>

<p>从而反推得到点 <code>P</code> 的坐标信息</p>
<p align="center">
    <img width="17%" src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/双目测距和三维重建-20210508235226.jpg">
</p>

<p>例如，以下图片为例：</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody><tr>
<td align="center"><img src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/%E5%8F%8C%E7%9B%AE%E6%B5%8B%E8%B7%9D%E5%92%8C%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA-20210508235337.jpg" alt="原图"></td>
<td align="center"><img src="https://cdn.jsdelivr.net/gh/YunYang1994/blogimgs/%E5%8F%8C%E7%9B%AE%E6%B5%8B%E8%B7%9D%E5%92%8C%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA-20210508235341.png" alt="视差图"></td>
</tr>
</tbody></table>
<blockquote>
<p>视差图采用十六位 (uint16) 整数来存取，并将视差值扩大了 256 倍，所以在读取时需要除以256。</p>
</blockquote>
<p>鼠标右键将原图和视差图下载下来，然后安装好第三方库 PyOpenGL==3.1.0 和 <a target="_blank" rel="noopener" href="https://github.com/uoip/pangolin">pangolin</a> 即可执行以下程序便得到了动图的结果。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> pangolin</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> OpenGL.GL <span class="keyword">as</span> gl</span><br><span class="line"></span><br><span class="line">fx = <span class="number">721.5377</span></span><br><span class="line">fy = <span class="number">721.5377</span></span><br><span class="line">cx = <span class="number">607.1928</span></span><br><span class="line">cy = <span class="number">185.2157</span></span><br><span class="line">B  = <span class="number">0.54</span></span><br><span class="line"></span><br><span class="line">img_disp = cv2.imread(<span class="string">&#x27;000004_10_disp.png&#x27;</span>, -<span class="number">1</span>) / <span class="number">256.</span></span><br><span class="line">imgL = cv2.imread(<span class="string">&#x27;000004_10.jpg&#x27;</span>)</span><br><span class="line">imgL = cv2.cvtColor(imgL, cv2.COLOR_BGR2RGB)</span><br><span class="line"></span><br><span class="line">h, w = imgL.shape[:<span class="number">2</span>]</span><br><span class="line">f = <span class="number">0.5</span> * w</span><br><span class="line">points, colors = [], []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> v <span class="keyword">in</span> <span class="built_in">range</span>(h):</span><br><span class="line">    <span class="keyword">for</span> u <span class="keyword">in</span> <span class="built_in">range</span>(w):</span><br><span class="line">        disp = img_disp[v, u]</span><br><span class="line">        <span class="keyword">if</span> disp &gt; <span class="number">0.</span>:</span><br><span class="line">            depth = B * fx / disp</span><br><span class="line">            z_w = depth</span><br><span class="line">            x_w = (u - cx) * z_w / fx</span><br><span class="line">            y_w = (v - cy) * z_w / fy</span><br><span class="line">            points.append([x_w, y_w, z_w])</span><br><span class="line">            colors.append(imgL[v, u])</span><br><span class="line">points = np.array(points)</span><br><span class="line">colors = np.array(colors) / <span class="number">255.</span></span><br><span class="line"></span><br><span class="line">pangolin.CreateWindowAndBind(<span class="string">&#x27;Main&#x27;</span>, <span class="number">640</span>, <span class="number">480</span>)</span><br><span class="line">gl.glEnable(gl.GL_DEPTH_TEST)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Define Projection and initial ModelView matrix</span></span><br><span class="line">scam = pangolin.OpenGlRenderState(</span><br><span class="line">    pangolin.ProjectionMatrix(<span class="number">640</span>, <span class="number">480</span>, <span class="number">2000</span>, <span class="number">2000</span>, <span class="number">320</span>, <span class="number">240</span>, <span class="number">0.1</span>, <span class="number">1000</span>),</span><br><span class="line">    pangolin.ModelViewLookAt(<span class="number">0</span>, <span class="number">0</span>, -<span class="number">20</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, -<span class="number">1</span>, <span class="number">0</span>))</span><br><span class="line">handler = pangolin.Handler3D(scam)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create Interactive View in window</span></span><br><span class="line">dcam = pangolin.CreateDisplay()</span><br><span class="line">dcam.SetBounds(<span class="number">0.0</span>, <span class="number">1.0</span>, <span class="number">0.0</span>, <span class="number">1.0</span>, -<span class="number">640.0</span>/<span class="number">480.0</span>)</span><br><span class="line">dcam.SetHandler(handler)</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="keyword">not</span> pangolin.ShouldQuit():</span><br><span class="line">    gl.glClear(gl.GL_COLOR_BUFFER_BIT | gl.GL_DEPTH_BUFFER_BIT)</span><br><span class="line">    gl.glClearColor(<span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>, <span class="number">1.0</span>)</span><br><span class="line">    dcam.Activate(scam)</span><br><span class="line">    gl.glPointSize(<span class="number">3</span>)</span><br><span class="line">    pangolin.DrawPoints(points, colors)</span><br><span class="line">    pangolin.FinishFrame()</span><br></pre></td></tr></table></figure>

</div><script type="text/javascript" src="/js/share.js?v=1.0.0" async></script><a class="article-share-link" data-url="https://yunyang1994.github.io/2019/12/29/%E5%8F%8C%E7%9B%AE%E6%B5%8B%E8%B7%9D%E5%92%8C%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/" data-id="ckw5vsrbe001m1vraeyuwaotv" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASYAAAEmCAAAAADqr2IGAAAEg0lEQVR42u3a3Y7aQAwG0H3/l6ZSr1qp0M/2ZBVnT65QgJA5QRr/fX3Fx+v38e7M64/j3bvvrvPut95dPz+f3NvhAxMmTJgw3ZLp9fHIbzQHze/hM9/n88kjT9aOCRMmTJiewZRcLll2vpjPC6s+sCseGyZMmDBh+mlMSXqZLKAXInxnGowJEyZMmDBVy769NPVUMNF7SJgwYcKE6UlM+eWqm32eQidXSJqskzDiQC0cEyZMmDDdjKnXAnzG6wvnmzBhwoQJ0w2YXq2jmsomt5Wnpr2xntF6MWHChAnTWqY8Bb2ihdkr9Z46X25zYsKECROmhUzJR88mljnZpDRcLRA3/0eYMGHChOn2TNWBm+qZXlLaW2QvGioEJZgwYcKEaTlTdXynR9NLm5OQovd4kkQdEyZMmDBtZzo1wdIrpFaT3nwZeUjRDBEwYcKECdMqpt7WXk1ik4Cj2gTtPapekRoTJkyYMG1kSjb4PPnsNUHzgKOH1VsFJkyYMGF6BlOPrNo4nBSU8wCiWkRu/l0wYcKECdMSpitQqoFFXoGel2ubd4UJEyZMmNYyTVLZJAXNP3P1+WrwcSzjx4QJEyZMt2HqEeRb+OfkM09N5wFBHhxgwoQJE6btTFc0F3OOXkjRa3YeqBBgwoQJE6a1TPmt52FEdanV4u98GChptX4l2T8mTJgwYbox06TRmJdKJ2M61Sv3Pt9MjDFhwoQJ0+2ZyltgcZQnv8V8WGfe7ByN7GDChAkTplVM1WJrdQGfb6i3pGoqWw0jov8UJkyYMGFayFR93Ws6fk9h95JxIkyYMGHCtJapl1Lm2/OkwTkp/uYNzs+BDiZMmDBh2s5U3VDz7+YLy38r+cUr1oIJEyZMmJ7BNBnxzGl6Jdf5+bw5igkTJkyYnsE0Ieg1O/PdNi+/VpPeJBT46x4wYcKECdNypuQSPYhksGY+HjR5YFEgggkTJkyY1jJVUfKtetKYrBZ8ey3VZp0AEyZMmDAtZKoO0+TJ6mTZZ0u9eer+n1o4JkyYMGFayFQdspnEHflGfvZ8/pn/FIUxYcKECdNaprzoWd1QqxxJe/Xs+TwMwoQJEyZMu5iqt5WXUHuI1SGeaurbZMWECRMmTGuZeq2+SViQvM6T2PnrwicxYcKECdODmD5faDIZlIcd1Vbo2TQ4CggwYcKECdNCplMDLnkYkReX8wCi1+YszBZhwoQJE6YlTHm3s9wXLbZIe+FCHspU14UJEyZMmJ7HdF0BtzqmMx/0mTzIf6wFEyZMmDCtZZp/odqA7C2gN7IzKRlHyTAmTJgwYbo909ltNR+RyUuxvW/Nk2FMmDBhwvQMpvlwTO86eXNxEhAko0Xl3i8mTJgwYVrIVC2tViEmLdL5CM6poAQTJkyYMG1nSpLYvLWZQE+KvNXEu/qACzERJkyYMGF6HFM+lNMLFKoPLB/u6SXPmDBhwoTp5zDlm2gvTc1ver7s8rcwYcKECdNypskWm6edvbGYU4M7vZViwoQJE6btTNXBnbzUWy3dVr/VOz9/FxMmTJgwLWH6BbxU2VKzhct/AAAAAElFTkSuQmCC">分享</a><div class="tags"><a href="/tags/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/"><i class="fa fa-tag"></i>三维重建</a></div><div class="post-nav"><a class="pre" href="/2020/01/17/%E6%89%8B%E5%86%99%E5%8F%8C%E7%9B%AE%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D-SGM-%E7%AE%97%E6%B3%95-%E4%B8%8A/">手写双目立体匹配 SGM 算法（上)</a><a class="next" href="/2019/12/27/%E4%BB%80%E4%B9%88%E6%98%AF%E7%9B%B8%E6%9C%BA%E7%9A%84%E4%BD%8D%E5%A7%BF/">什么是相机的位姿 ？</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/">图像分割</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/">姿态估计</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/">杂七杂八</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA/">目标跟踪</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/">立体视觉</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/anchor-free/" style="font-size: 15px;">anchor free</a> <a href="/tags/DeepSort/" style="font-size: 15px;">DeepSort</a> <a href="/tags/%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">角点检测</a> <a href="/tags/Faster-rcnn/" style="font-size: 15px;">Faster-rcnn</a> <a href="/tags/%E5%A4%9A%E5%8D%A1GPU%E8%AE%AD%E7%BB%83/" style="font-size: 15px;">多卡GPU训练</a> <a href="/tags/%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/" style="font-size: 15px;">移动端部署</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3/" style="font-size: 15px;">人脸矫正</a> <a href="/tags/%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2/" style="font-size: 15px;">仿射变换</a> <a href="/tags/%E7%9B%B8%E6%9C%BA%E4%BD%8D%E5%A7%BF/" style="font-size: 15px;">相机位姿</a> <a href="/tags/%E8%A7%86%E8%A7%89-Slam/" style="font-size: 15px;">视觉 Slam</a> <a href="/tags/mnist-%E5%88%86%E7%B1%BB/" style="font-size: 15px;">mnist 分类</a> <a href="/tags/rotated-object-detection/" style="font-size: 15px;">rotated object detection</a> <a href="/tags/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">全卷积网络</a> <a href="/tags/Skip-Connection/" style="font-size: 15px;">Skip Connection</a> <a href="/tags/Unet-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/" style="font-size: 15px;">Unet 网络结构</a> <a href="/tags/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/" style="font-size: 15px;">三维重建</a> <a href="/tags/%E5%8F%AF%E5%8F%98%E5%BD%A2%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">可变形卷积网络</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">深度估计</a> <a href="/tags/sort/" style="font-size: 15px;">sort</a> <a href="/tags/%E8%A7%86%E5%B7%AE%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">视差估计</a> <a href="/tags/%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D/" style="font-size: 15px;">立体匹配</a> <a href="/tags/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB/" style="font-size: 15px;">汉明距离</a> <a href="/tags/Batch-Normalization/" style="font-size: 15px;">Batch Normalization</a> <a href="/tags/TensorRT-%E9%83%A8%E7%BD%B2/" style="font-size: 15px;">TensorRT 部署</a> <a href="/tags/INT8-%E5%8A%A0%E9%80%9F%E5%8E%9F%E7%90%86/" style="font-size: 15px;">INT8 加速原理</a> <a href="/tags/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/" style="font-size: 15px;">立体视觉</a> <a href="/tags/%E7%9B%B8%E6%9C%BA%E5%8F%82%E6%95%B0/" style="font-size: 15px;">相机参数</a> <a href="/tags/%E7%B2%BE%E7%A1%AE%E7%8E%87%E3%80%81%E5%8F%AC%E5%9B%9E%E7%8E%87%E5%92%8CROC%E6%9B%B2%E7%BA%BF/" style="font-size: 15px;">精确率、召回率和ROC曲线</a> <a href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/" style="font-size: 15px;">梯度下降</a> <a href="/tags/hourglass-%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">hourglass 网络</a> <a href="/tags/C-%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">C++ 编程学习</a> <a href="/tags/%E5%8D%A1%E5%B0%94%E6%9B%BC%E6%BB%A4%E6%B3%A2/" style="font-size: 15px;">卡尔曼滤波</a> <a href="/tags/%E6%9C%AC%E8%B4%A8%E7%9F%A9%E9%98%B5/" style="font-size: 15px;">本质矩阵</a> <a href="/tags/YOLOv3/" style="font-size: 15px;">YOLOv3</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/09/18/%E8%AE%B2%E4%B8%80%E8%AE%B2%E7%9B%AE%E5%89%8D%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E4%B8%8B%E5%9F%BA%E4%BA%8E%E5%8D%95%E7%9B%AE%E7%9A%84%E4%B8%89%E7%BB%B4%E4%BA%BA%E4%BD%93%E9%87%8D%E5%BB%BA%E6%8A%80%E6%9C%AF/">讲一讲目前深度学习下基于单目的三维人体重建技术</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/09/FairMOT-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E9%87%8C%E6%A3%80%E6%B5%8B%E4%B8%8E%E5%86%8D%E8%AF%86%E5%88%AB%E7%9A%84%E5%85%AC%E5%B9%B3%E6%80%A7/">FairMOT：讨论多目标跟踪里检测与再识别的公平性</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/08/%E6%BB%9A%E8%9B%8B%E5%90%A7-Anchor-%E5%90%9B-%E6%97%B7%E8%A7%86%E6%96%B0%E7%A7%91%E6%8A%80-YOLOX/">滚蛋吧，Anchor 君！旷视新科技，YOLOX</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/07/%E7%9F%A5%E8%AF%86%E8%92%B8%E9%A6%8F-Distilling-the-Knowledge-in-a-Neural-Network/">知识蒸馏：Distilling the Knowledge in a Neural Network</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/05/UnitBox%E4%B8%80%E7%A7%8D%E6%96%B0%E7%9A%84-iou-%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-%E6%8A%8A%20box-%E5%BD%93%E4%BD%9C%E4%B8%80%E4%B8%AA%E6%95%B4%E4%BD%93%E5%8E%BB%E9%A2%84%E6%B5%8B/">UnitBox：一种新的 IoU 损失函数，把 box 当作一个整体去预测</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/03/%E8%A7%A3%E5%86%B3%E6%AD%A3%E8%B4%9F%E6%A0%B7%E6%9C%AC%E4%B8%8D%E5%9D%87%E8%A1%A1%E9%97%AE%E9%A2%98%E2%80%94%E2%80%94Focal-Loss/">老生常谈 Focal Loss —— 解决正负样本不均衡问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/02/FCOS-Fully-Convolutional-One-Stage-Object-Detection/">FCOS：Fully Convolutional One-Stage Object Detection</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/01/CenterNet-Objects-as-Points/">CenterNet 和 CenterTrack：以点代物，同时进行目标检测和跟踪</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/09/01/CornerNet-Detecting-Objects-as-Paired-Keypoints/">CornerNet：Detecting Objects as Paired Keypoints</a></li><li class="post-list-item"><a class="post-list-link" href="/2021/08/27/DeepSort-%E5%A4%9A%E7%9B%AE%E6%A0%87%E8%B7%9F%E8%B8%AA%E7%AE%97%E6%B3%95-SORT-%E7%9A%84%E8%BF%9B%E9%98%B6%E7%89%88/">DeepSort：多目标跟踪算法 Sort 的进化版</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://www.zhihu.com/people/yang-xiao-yun-tong-xue" title="我的知乎" target="_blank">我的知乎</a><ul></ul><a href="https://github.com/YunYang1994" title="我的 GitHub" target="_blank">我的 GitHub</a><ul></ul><a href="https://leetcode-cn.com/u/yunyang1994/" title="我的力扣" target="_blank">我的力扣</a><ul></ul><a href="https://blog.devtang.com" title="猿辅导创始人唐巧的博客" target="_blank">猿辅导创始人唐巧的博客</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">四一的随写.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=1.0.0"><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>