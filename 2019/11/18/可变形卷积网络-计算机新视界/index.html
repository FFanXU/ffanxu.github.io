<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description" content="Stay hungry, Stay foolish"><title>可变形卷积网络：计算机新“视”界 | 四一的世界</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">可变形卷积网络：计算机新“视”界</h1><a id="logo" href="/.">四一的世界</a><p class="description">Stay hungry, Stay foolish</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">可变形卷积网络：计算机新“视”界</h1><div class="post-meta">2019-11-18<span> | </span><span class="category"><a href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span><script src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span><span class="post-time"><span class="post-meta-item-text"> | </span><span class="post-meta-item-icon"><i class="fa fa-keyboard-o"></i><span class="post-count"> 2.1k</span><span class="post-meta-item-text"> 字</span></span></span><span class="post-time"> | <span class="post-meta-item-icon"><i class="fa fa-clock-o"></i><span class="post-count"> 7</span><span class="post-meta-item-text"> 分钟</span></span></span></div><div class="post-content"><p>2017年，微软亚洲研究院视觉计算组的研究员在 arXiv 上公布了一篇题为 <a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1703.06211.pdf">“Deformable Convolutional Networks”（可变形卷积网络）</a> 的论文，首次在卷积神经网络（convolutional neutral networks，CNN）中引入了学习空间几何形变的能力，得到可变形卷积网络（deformable convolutional networks），从而更好地解决了具有空间形变的图像识别任务。</p>
<p align="center">
    <img width="55%" src="https://gitee.com/yunyang1994/BlogSource/raw/master/hexo/source/images/可变形卷积网络-计算机新视界/002.png">
</p>

<p>研究员们通过大量的实验结果验证了该方法在复杂的计算机视觉任务（如目标检测和语义分割）上的有效性，首次表明在深度卷积神经网络（deep CNN）中学习空间上密集的几何形变是可行的。</p>
<span id="more"></span>

<h2 id="卷积神经网络的成功和局限"><a href="#卷积神经网络的成功和局限" class="headerlink" title="卷积神经网络的成功和局限"></a>卷积神经网络的成功和局限</h2><p>由于同样的物体在图像中可能呈现出不同的大小、姿态、视角变化甚至非刚体形变，因此如何适应这些复杂的几何形变是物体识别的主要难点，同时也是计算机视觉领域多年来关注的核心问题。很多传统经典方法，如尺度不变的特征变换（scale invariant feature transform, or SIFT）和可变形部件模型（deformable part models）等，都旨在解决这一问题。然而，由于人工设计特征的局限性，传统视觉方法在物体识别问题上多年来并未取得突破性的进展。</p>
<p>由于强大的建模能力和自动的端到端的学习方式，深度卷积神经网络可以从大量数据中学习到有效特征，避免了传统方法人工设计特征的弊端。然而，现有的网络模型对于物体几何形变的适应能力几乎完全来自于数据本身所具有的多样性，其模型内部并不具有适应几何形变的机制。究其根本，是因为卷积操作本身具有固定的几何结构，而由其层叠搭建而成的卷积网络的几何结构也是固定的，所以不具有对于几何形变建模的能力。</p>
<p>举个例子，想要识别出同一图像中不同大小的物体（比如远近不同的两个人），理想的结果是，在对应于每个物体的位置网络需要具有相应大小的感受野（receptive field）。直观的说，为了识别更大的物体网络需要看到更大的图像区域。然而，在现有的卷积网络架构中，图像中任何位置的感受野大小都是相同的，其取决于事先设定的网络参数（卷积核的大小、步长和网络深度等），无法根据图像内容自适应调整，从而限制了识别精度。</p>
<h2 id="消除网络难以适应几何变形的“罪魁祸首”"><a href="#消除网络难以适应几何变形的“罪魁祸首”" class="headerlink" title="消除网络难以适应几何变形的“罪魁祸首”"></a>消除网络难以适应几何变形的“罪魁祸首”</h2><p>追根溯源，上述局限来自于卷积网络的基本构成单元，即卷积操作。该操作在输入图像的每个位置时会进行基于规则格点位置的采样，然后对于采样到的图像值做卷积并作为该位置的输出。通过端到端的梯度反向传播学习，系统将会得到一个用矩阵表示的卷积核的权重。这就是自卷积网络诞生之初，已使用二十多年的基本单元结构。</p>
<p>微软亚洲研究院的研究员们发现，标准卷积中的规则格点采样是导致网络难以适应几何形变的“罪魁祸首”。为了削弱这个限制，研究员们对卷积核中每个采样点的位置都增加了一个偏移的变量。通过这些变量，卷积核就可以在当前位置附近随意的采样，而不再局限于之前的规则格点。这样扩展后的卷积操作被称为可变形卷积（deformable convolution）。标准卷积和可变形卷积在图1中有简要的展示。</p>
<p align="center">
    <img width="70%" src="https://gitee.com/yunyang1994/BlogSource/raw/master/hexo/source/images/可变形卷积网络-计算机新视界/001.jpg">
</p>

<blockquote>
<p>图1：展示了卷积核大小为 3x3 的正常卷积和可变形卷积的采样方式，(a) 所示的正常卷积规律的采样 9 个点（绿点），(b)(c)(d) 为可变形卷积，在正常的采样坐标上加上一个位移量（蓝色箭头），其中(c)(d) 作为 (b) 的特殊情况，展示了可变形卷积可以作为尺度变换，比例变换和旋转变换的特殊情况</p>
</blockquote>
<p>事实上，可变形卷积单元中增加的偏移量是网络结构的一部分，通过另外一个平行的标准卷积单元计算得到，进而也可以通过梯度反向传播进行端到端的学习。加上该偏移量的学习之后，可变形卷积核的大小和位置可以根据当前需要识别的图像内容进行动态调整，其直观效果就是不同位置的卷积核采样点位置会根据图像内容发生自适应的变化，从而适应不同物体的形状、大小等几何形变，如图2、图3中所展示。</p>
<p align="center">
    <img width="70%" src="https://gitee.com/yunyang1994/BlogSource/raw/master/hexo/source/images/可变形卷积网络-计算机新视界/003.png">
</p>

<blockquote>
<p>图2：两层3*3的标准卷积和可变形卷积的区别。(a) 标准卷积中固定的感受野和卷积核采样点。(b) 可变性卷积中自适应的感受野和卷积核采样点。</p>
</blockquote>
<p align="center">
    <img width="100%" src="https://gitee.com/yunyang1994/BlogSource/raw/master/hexo/source/images/可变形卷积网络-计算机新视界/004.jpg">
</p>

<blockquote>
<p>图 3：更多可变形卷积的示例。每个图像三元组显示了三层 3x3 可变形卷积核的采样点位置（共 729 个点），对应于三个不同的图像区域（从左至右，背景，小物体，大物体）。</p>
</blockquote>
<h2 id="可变形卷积神经网络：简明深刻的网络结构革新"><a href="#可变形卷积神经网络：简明深刻的网络结构革新" class="headerlink" title="可变形卷积神经网络：简明深刻的网络结构革新"></a>可变形卷积神经网络：简明深刻的网络结构革新</h2><p>可变形卷积单元具有诸多良好的性质。它不需要任何额外的监督信号，可以直接通过目标任务学习得到。它可以方便地取代任何已有视觉识别任务的卷积神经网络中的若干个标准卷积单元，并通过标准的反向传播进行端到端的训练。由此得到的网络则称为“可变形卷积网络”。</p>
<p>可变形卷积网络是对于传统卷积网络简明而又意义深远的结构革新，具有重要的学术和实践意义。它适用于所有待识别目标具有一定几何形变的任务（几乎所有重要的视觉识别任务都有此特点，人脸、行人、车辆、文字、动物等），可以直接由已有网络结构扩充而来，无需重新预训练。它仅增加了很少的模型复杂度和计算量，且显著提高了识别精度。例如，在用于自动驾驶的图像语义分割数据集（CityScapes）上，可变形卷积神经网络将准确率由70%提高到了75%。</p>
<p>此外，通过增加偏移量来学习几何形变的思想还可方便地扩展到其它计算单元中去。例如，目前业界最好的物体检测方法都使用了基于规则块采样的兴趣区域（region of interests, ROI）池化（pooling）。在该操作中，对于每个采样的规则块增加类似的偏移量，从而得到可变形兴趣区域池化 (deformable ROI pooling）。由此所获得的新的物体检测方法也取得了显著的性能提升。</p>
<h2 id="卷积网络的新思路"><a href="#卷积网络的新思路" class="headerlink" title="卷积网络的新思路"></a>卷积网络的新思路</h2><p>近年来，与神经网络结构相关的研究工作层出不穷，大多是对于各种基本网络单元连接关系的研究。不同于大部分已有的工作，可变形卷积网络首次表明了可以在卷积网络中显式地学习几何形变。它修改了已使用二十余年的基本卷积单元结构，在重要的物体检测和语义分割等计算机视觉任务上获得了重大的性能提升。</p>
<p>可以想象，在不远的未来，在更多的计算机视觉识别任务中（如文字检测、视频物体检测跟踪等）都将看到它的成功应用。</p>
</div><script type="text/javascript" src="/js/share.js?v=1.0.0" async></script><a class="article-share-link" data-url="https://yunyang1994.github.io/2019/11/18/%E5%8F%AF%E5%8F%98%E5%BD%A2%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C-%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%96%B0%E8%A7%86%E7%95%8C/" data-id="ckofioh6p001fn3rahb094etm" data-qrcode="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAT4AAAE+CAAAAAAxUyPsAAAFRUlEQVR42u3aQW7bQBAEQP//0w6QUwKbVPfM0gii0ikQZHG3GEDNnv34iF+fv19f/33/+T9fX9+///zVq11DsperVR174cOHDx8+fPHSr7adECTLnX1+djMSgXyd+PDhw4cP34YvDyvJl+aL3rPmt3PzbZfv48OHDx8+fI/xPRdfkhgx+552Vfjw4cOHD9+/xpc8rs+Y9uX7qRuADx8+fPjwPc3XjqXzgjsv1vMRe3sj99c6MOvAhw8fPnz41gfU/td//9D5Pnz48OHD92Z8n4tXcsnkJ38TUNqBffuZFwL48OHDhw/fROBAvd5W9u1tyG9VfntmNceLWQc+fPjw4cMXr7P9OZ8t+mzsaAf5szo+qunx4cOHDx++gK+92KYUaINCHpLyCLUft0dlAT58+PDhw3fLdzY0zL4njxFnj7XNRg6Xsw58+PDhw4cvzQNRHZ8v4lTFMCvf22+exS98+PDhw4ev5ds3/bMH+7Zqz8fwbYjJX99cCx8+fPjw4Sv59g/27Q9/Hg7a25DfyLYKidaDDx8+fPjwBevJH/5P9ROb0JAfRGshhuU+Pnz48OHDN5oLt8Pj2cj8xYB5kblmt3A2CL8sC/Dhw4cPH77gWrMBc0szG6u3Nf0sfLT1AT58+PDhw7fha3+295X32SJgdq28yo8GBvjw4cOHD1/JtwkrCWiygQMBIj48lwegdkSBDx8+fPjw3fPNaNoAkW8p2d4mgmxu8zfXwocPHz58+Eq+fX2Q1N+b6mEfbmbvz6ISPnz48OHDd2rCm9fxs+Nls9BzajyQD+bx4cOHDx++DV87us4L/XxBp8r6zefbgf1ff4sPHz58+PCN+OrDWCO4Ntbkw4D29rfXfVEc4MOHDx8+fDFfHkfacXj+lL2p1DelfM5UFwf48OHDhw/fiG8TaGYHzlrWJLhsSoc6weHDhw8fPnyjbbeF+ywEnIoXSfm+v2507gAfPnz48OG72O+mNE9KgfavZqmgLfc3Zf2xmQM+fPjw4Xt7vn0geKLcbwNHC7c61oYPHz58+PCVfG1QmEWQ/Ma0B9pmA4AWIjqghg8fPnz48I348uDSUiblexuM8lvShqrkYBw+fPjw4cPX8p0t6zfbaK/Y1hBtrR+tFh8+fPjw4Sv5TtXxba2w+bZTiG2FUfwfxIcPHz58+C521A6DN+Pw2eN9G0Ta9+vhd5vg8OHDhw8fvsVj8yx8JOht0MkhNkfchu0LPnz48OHDdzvn3RTo+1q8jVCzQ2yzUPVij/jw4cOHD1/JN9vSrNBvlziDSD6/D1ur/xH48OHDh++N+fabbxfdfrI9drYZt9dRDB8+fPjw4Vvw5aP0fMN5aMg3cGoQnrNGjQs+fPjw4cNXriEv65OH7c2RtRlc8v35StpRAT58+PDhw5fwtcfONg/5Ld8+WMwiV1Fn4MOHDx8+fIsmPIkseWm+mdsnj/ftI30eyGbHBfDhw4cPH76Erz2elRztuv/5bxc9Kw5mK68DEz58+PDhwzfi2x8US37s22CUAO0H3rOr79oFfPjw4cOHr/uxf6JcaCv7/Wghjy+XK8eHDx8+fPhKvg1Bu418KfnfPlEQnIpZ+PDhw4cP32aMvXn/vobYBIjZStpK4gUoPnz48OHDN+Jrw8p9kd1uI9/ebNAele9lMsGHDx8+fPh+hu8+arQLPRWG2uNxn4vXKrjgw4cPHz58o0Bwdkqw2cDZmqMdGODDhw8fPnwzvryszxHzyntf2bexaQZ9WRngw4cPHz58Md/sgFpUZB8aACQxohhsB3/VFhD48OHDhw9fwPcLZs95kCuAI6QAAAAASUVORK5CYII=">分享</a><div class="tags"><a href="/tags/%E5%8F%AF%E5%8F%98%E5%BD%A2%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/"><i class="fa fa-tag"></i>可变形卷积网络</a></div><div class="post-nav"><a class="pre" href="/2019/12/10/Deep3D/">基于卷积神经网络的 2D-to-3D 视频转换</a><a class="next" href="/2019/09/27/RPN/">Faster-rcnn 里的区域生成网络（RPN）</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/">图像分割</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/">图像处理</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1/">姿态估计</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">目标检测</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/">立体视觉</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/%E4%BB%BF%E5%B0%84%E5%8F%98%E6%8D%A2/" style="font-size: 15px;">仿射变换</a> <a href="/tags/%E7%AB%8B%E4%BD%93%E8%A7%86%E8%A7%89/" style="font-size: 15px;">立体视觉</a> <a href="/tags/%E7%9B%B8%E6%9C%BA%E5%8F%82%E6%95%B0/" style="font-size: 15px;">相机参数</a> <a href="/tags/%E7%9B%B8%E6%9C%BA%E4%BD%8D%E5%A7%BF/" style="font-size: 15px;">相机位姿</a> <a href="/tags/%E8%A7%86%E8%A7%89-Slam/" style="font-size: 15px;">视觉 Slam</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">深度估计</a> <a href="/tags/%E8%A7%92%E7%82%B9%E6%A3%80%E6%B5%8B/" style="font-size: 15px;">角点检测</a> <a href="/tags/%E5%85%A8%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">全卷积网络</a> <a href="/tags/Skip-Connection/" style="font-size: 15px;">Skip Connection</a> <a href="/tags/Faster-rcnn/" style="font-size: 15px;">Faster-rcnn</a> <a href="/tags/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/" style="font-size: 15px;">梯度下降</a> <a href="/tags/%E8%A7%86%E5%B7%AE%E4%BC%B0%E8%AE%A1/" style="font-size: 15px;">视差估计</a> <a href="/tags/%E7%AB%8B%E4%BD%93%E5%8C%B9%E9%85%8D/" style="font-size: 15px;">立体匹配</a> <a href="/tags/%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB/" style="font-size: 15px;">汉明距离</a> <a href="/tags/%E4%B8%89%E7%BB%B4%E9%87%8D%E5%BB%BA/" style="font-size: 15px;">三维重建</a> <a href="/tags/%E5%A4%9A%E5%8D%A1GPU%E8%AE%AD%E7%BB%83/" style="font-size: 15px;">多卡GPU训练</a> <a href="/tags/Unet-%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/" style="font-size: 15px;">Unet 网络结构</a> <a href="/tags/%E7%A7%BB%E5%8A%A8%E7%AB%AF%E9%83%A8%E7%BD%B2/" style="font-size: 15px;">移动端部署</a> <a href="/tags/%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3/" style="font-size: 15px;">人脸矫正</a> <a href="/tags/mnist-%E5%88%86%E7%B1%BB/" style="font-size: 15px;">mnist 分类</a> <a href="/tags/rotated-object-detection/" style="font-size: 15px;">rotated object detection</a> <a href="/tags/%E5%8F%AF%E5%8F%98%E5%BD%A2%E5%8D%B7%E7%A7%AF%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">可变形卷积网络</a> <a href="/tags/Batch-Normalization/" style="font-size: 15px;">Batch Normalization</a> <a href="/tags/%E7%B2%BE%E7%A1%AE%E7%8E%87%E3%80%81%E5%8F%AC%E5%9B%9E%E7%8E%87%E5%92%8CROC%E6%9B%B2%E7%BA%BF/" style="font-size: 15px;">精确率、召回率和ROC曲线</a> <a href="/tags/hourglass-%E7%BD%91%E7%BB%9C/" style="font-size: 15px;">hourglass 网络</a> <a href="/tags/%E6%9C%AC%E8%B4%A8%E7%9F%A9%E9%98%B5/" style="font-size: 15px;">本质矩阵</a> <a href="/tags/YOLOv3/" style="font-size: 15px;">YOLOv3</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2021/04/20/%E4%BF%AE%E6%94%B9-YOLOv5-%E6%BA%90%E7%A0%81%E5%9C%A8-DOTAv1.5-%E9%81%A5%E6%84%9F%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%8A%E8%BF%9B%E8%A1%8C%E6%97%8B%E8%BD%AC%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B/">修改 YOLOv5 源码在 DOTAv1.5 遥感数据集上进行旋转目标检测</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/12/19/%E7%94%A8-Python-%E6%89%8B%E6%92%B8%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E5%8D%95%E7%9B%AE-Slam-%E4%BE%8B%E5%AD%90/">用 Python 手撸一个单目视觉里程计的例子</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/10/10/2D%E4%BA%BA%E4%BD%93%E5%A7%BF%E6%80%81%E4%BC%B0%E8%AE%A1%E7%9A%84%E8%BF%87%E5%8E%BB%EF%BC%8C%E7%8E%B0%E5%9C%A8%E5%92%8C%E6%9C%AA%E6%9D%A5/">2D人体姿态估计的总结和梳理</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/16/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E4%B9%8B%E4%BA%BA%E8%84%B8%E7%9F%AB%E6%AD%A3/">人脸识别之人脸矫正</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/02/07/TensorFlow-%E7%9A%84%E5%A4%9A%E5%8D%A1-GPU-%E8%AE%AD%E7%BB%83%E6%9C%BA%E5%88%B6/">TensorFlow 的多卡 GPU 训练机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/22/AffineTransformation/">说说图像的仿射变换</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/21/SGD/">能不能用梯度下降法求解平方根 ？</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/20/SGM_02/">手写双目立体匹配 SGM 算法（下)</a></li><li class="post-list-item"><a class="post-list-link" href="/2020/01/17/SGM_01/">手写双目立体匹配 SGM 算法（上)</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/12/29/StereoVision/">双目测距和三维重建</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://github.com/YunYang1994" title="YunYang1994's GitHub" target="_blank">YunYang1994's GitHub</a><ul></ul><a href="https://blog.devtang.com" title="猿辅导创始人唐巧的博客" target="_blank">猿辅导创始人唐巧的博客</a><ul></ul><a href="http://pengzhihui.xyz" title="稚晖的个人站" target="_blank">稚晖的个人站</a><ul></ul><a href="https://wizyoung.github.io" title="CaptainChen" target="_blank">CaptainChen</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2021 <a href="/." rel="nofollow">四一的世界.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=1.0.0"><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>